2025-11-02 03:30:12,909: Using device: cuda:0
2025-11-02 03:30:14,696: Using torch.compile
2025-11-02 03:30:15,882: Initialized RNN decoding model
2025-11-02 03:30:15,883: OptimizedModule(
  (_orig_mod): GRUDecoder(
    (day_layer_activation): Softsign()
    (day_weights): ParameterList(
        (0): Parameter containing: [torch.float32 of size 512x512]
        (1): Parameter containing: [torch.float32 of size 512x512]
        (2): Parameter containing: [torch.float32 of size 512x512]
        (3): Parameter containing: [torch.float32 of size 512x512]
        (4): Parameter containing: [torch.float32 of size 512x512]
        (5): Parameter containing: [torch.float32 of size 512x512]
        (6): Parameter containing: [torch.float32 of size 512x512]
        (7): Parameter containing: [torch.float32 of size 512x512]
        (8): Parameter containing: [torch.float32 of size 512x512]
        (9): Parameter containing: [torch.float32 of size 512x512]
        (10): Parameter containing: [torch.float32 of size 512x512]
        (11): Parameter containing: [torch.float32 of size 512x512]
        (12): Parameter containing: [torch.float32 of size 512x512]
        (13): Parameter containing: [torch.float32 of size 512x512]
        (14): Parameter containing: [torch.float32 of size 512x512]
        (15): Parameter containing: [torch.float32 of size 512x512]
        (16): Parameter containing: [torch.float32 of size 512x512]
        (17): Parameter containing: [torch.float32 of size 512x512]
        (18): Parameter containing: [torch.float32 of size 512x512]
        (19): Parameter containing: [torch.float32 of size 512x512]
        (20): Parameter containing: [torch.float32 of size 512x512]
        (21): Parameter containing: [torch.float32 of size 512x512]
        (22): Parameter containing: [torch.float32 of size 512x512]
        (23): Parameter containing: [torch.float32 of size 512x512]
        (24): Parameter containing: [torch.float32 of size 512x512]
        (25): Parameter containing: [torch.float32 of size 512x512]
        (26): Parameter containing: [torch.float32 of size 512x512]
        (27): Parameter containing: [torch.float32 of size 512x512]
        (28): Parameter containing: [torch.float32 of size 512x512]
        (29): Parameter containing: [torch.float32 of size 512x512]
        (30): Parameter containing: [torch.float32 of size 512x512]
        (31): Parameter containing: [torch.float32 of size 512x512]
        (32): Parameter containing: [torch.float32 of size 512x512]
        (33): Parameter containing: [torch.float32 of size 512x512]
        (34): Parameter containing: [torch.float32 of size 512x512]
        (35): Parameter containing: [torch.float32 of size 512x512]
        (36): Parameter containing: [torch.float32 of size 512x512]
        (37): Parameter containing: [torch.float32 of size 512x512]
        (38): Parameter containing: [torch.float32 of size 512x512]
        (39): Parameter containing: [torch.float32 of size 512x512]
        (40): Parameter containing: [torch.float32 of size 512x512]
        (41): Parameter containing: [torch.float32 of size 512x512]
        (42): Parameter containing: [torch.float32 of size 512x512]
        (43): Parameter containing: [torch.float32 of size 512x512]
        (44): Parameter containing: [torch.float32 of size 512x512]
    )
    (day_biases): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x512]
        (1): Parameter containing: [torch.float32 of size 1x512]
        (2): Parameter containing: [torch.float32 of size 1x512]
        (3): Parameter containing: [torch.float32 of size 1x512]
        (4): Parameter containing: [torch.float32 of size 1x512]
        (5): Parameter containing: [torch.float32 of size 1x512]
        (6): Parameter containing: [torch.float32 of size 1x512]
        (7): Parameter containing: [torch.float32 of size 1x512]
        (8): Parameter containing: [torch.float32 of size 1x512]
        (9): Parameter containing: [torch.float32 of size 1x512]
        (10): Parameter containing: [torch.float32 of size 1x512]
        (11): Parameter containing: [torch.float32 of size 1x512]
        (12): Parameter containing: [torch.float32 of size 1x512]
        (13): Parameter containing: [torch.float32 of size 1x512]
        (14): Parameter containing: [torch.float32 of size 1x512]
        (15): Parameter containing: [torch.float32 of size 1x512]
        (16): Parameter containing: [torch.float32 of size 1x512]
        (17): Parameter containing: [torch.float32 of size 1x512]
        (18): Parameter containing: [torch.float32 of size 1x512]
        (19): Parameter containing: [torch.float32 of size 1x512]
        (20): Parameter containing: [torch.float32 of size 1x512]
        (21): Parameter containing: [torch.float32 of size 1x512]
        (22): Parameter containing: [torch.float32 of size 1x512]
        (23): Parameter containing: [torch.float32 of size 1x512]
        (24): Parameter containing: [torch.float32 of size 1x512]
        (25): Parameter containing: [torch.float32 of size 1x512]
        (26): Parameter containing: [torch.float32 of size 1x512]
        (27): Parameter containing: [torch.float32 of size 1x512]
        (28): Parameter containing: [torch.float32 of size 1x512]
        (29): Parameter containing: [torch.float32 of size 1x512]
        (30): Parameter containing: [torch.float32 of size 1x512]
        (31): Parameter containing: [torch.float32 of size 1x512]
        (32): Parameter containing: [torch.float32 of size 1x512]
        (33): Parameter containing: [torch.float32 of size 1x512]
        (34): Parameter containing: [torch.float32 of size 1x512]
        (35): Parameter containing: [torch.float32 of size 1x512]
        (36): Parameter containing: [torch.float32 of size 1x512]
        (37): Parameter containing: [torch.float32 of size 1x512]
        (38): Parameter containing: [torch.float32 of size 1x512]
        (39): Parameter containing: [torch.float32 of size 1x512]
        (40): Parameter containing: [torch.float32 of size 1x512]
        (41): Parameter containing: [torch.float32 of size 1x512]
        (42): Parameter containing: [torch.float32 of size 1x512]
        (43): Parameter containing: [torch.float32 of size 1x512]
        (44): Parameter containing: [torch.float32 of size 1x512]
    )
    (day_layer_dropout): Dropout(p=0.2, inplace=False)
    (gru): GRU(10240, 768, num_layers=5, batch_first=True, dropout=0.3)
    (out): Linear(in_features=768, out_features=41, bias=True)
  )
)
2025-11-02 03:30:15,885: Model has 51,393,065 parameters
2025-11-02 03:30:15,885: Model has 11,819,520 day-specific parameters | 23.00% of total parameters
2025-11-02 03:30:37,786: Successfully initialized datasets
2025-11-02 03:30:46,273: Train batch 0: loss: 750.89 grad norm: 357.22 time: 6.114
2025-11-02 03:30:46,274: Running test after training batch: 0
2025-11-02 03:31:28,162: Val batch 0: PER (avg): 1.2817 CTC Loss (avg): 708.2872 time: 41.887
2025-11-02 03:31:28,163: t15.2023.08.13 val PER: 1.1975
2025-11-02 03:31:28,163: t15.2023.08.18 val PER: 1.2682
2025-11-02 03:31:28,164: t15.2023.08.20 val PER: 1.1819
2025-11-02 03:31:28,164: t15.2023.08.25 val PER: 1.2861
2025-11-02 03:31:28,164: t15.2023.08.27 val PER: 1.1158
2025-11-02 03:31:28,165: t15.2023.09.01 val PER: 1.2394
2025-11-02 03:31:28,165: t15.2023.09.03 val PER: 1.1318
2025-11-02 03:31:28,166: t15.2023.09.24 val PER: 1.4090
2025-11-02 03:31:28,166: t15.2023.09.29 val PER: 1.3746
2025-11-02 03:31:28,184: t15.2023.10.01 val PER: 1.1301
2025-11-02 03:31:28,185: t15.2023.10.06 val PER: 1.3348
2025-11-02 03:31:28,185: t15.2023.10.08 val PER: 1.0650
2025-11-02 03:31:28,185: t15.2023.10.13 val PER: 1.3126
2025-11-02 03:31:28,186: t15.2023.10.15 val PER: 1.3415
2025-11-02 03:31:28,186: t15.2023.10.20 val PER: 1.3322
2025-11-02 03:31:28,187: t15.2023.10.22 val PER: 1.2483
2025-11-02 03:31:28,187: t15.2023.11.03 val PER: 1.3833
2025-11-02 03:31:28,187: t15.2023.11.04 val PER: 1.6451
2025-11-02 03:31:28,188: t15.2023.11.17 val PER: 1.7278
2025-11-02 03:31:28,188: t15.2023.11.19 val PER: 1.4431
2025-11-02 03:31:28,189: t15.2023.11.26 val PER: 1.3406
2025-11-02 03:31:28,189: t15.2023.12.03 val PER: 1.2342
2025-11-02 03:31:28,189: t15.2023.12.08 val PER: 1.3276
2025-11-02 03:31:28,190: t15.2023.12.10 val PER: 1.4389
2025-11-02 03:31:28,190: t15.2023.12.17 val PER: 1.1019
2025-11-02 03:31:28,191: t15.2023.12.29 val PER: 1.2176
2025-11-02 03:31:28,191: t15.2024.02.25 val PER: 1.2570
2025-11-02 03:31:28,191: t15.2024.03.08 val PER: 1.1152
2025-11-02 03:31:28,192: t15.2024.03.15 val PER: 1.1513
2025-11-02 03:31:28,192: t15.2024.03.17 val PER: 1.2371
2025-11-02 03:31:28,192: t15.2024.05.10 val PER: 1.3001
2025-11-02 03:31:28,192: t15.2024.06.14 val PER: 1.4401
2025-11-02 03:31:28,193: t15.2024.07.19 val PER: 1.0066
2025-11-02 03:31:28,193: t15.2024.07.21 val PER: 1.4490
2025-11-02 03:31:28,193: t15.2024.07.28 val PER: 1.4324
2025-11-02 03:31:28,194: t15.2025.01.10 val PER: 1.0152
2025-11-02 03:31:28,194: t15.2025.01.12 val PER: 1.5135
2025-11-02 03:31:28,194: t15.2025.03.14 val PER: 1.0311
2025-11-02 03:31:28,194: t15.2025.03.16 val PER: 1.5445
2025-11-02 03:31:28,195: t15.2025.03.30 val PER: 1.2333
2025-11-02 03:31:28,196: t15.2025.04.13 val PER: 1.3695
2025-11-02 03:31:28,196: New best test PER inf --> 1.2817
2025-11-02 03:31:28,196: Checkpointing model
2025-11-02 03:31:29,795: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:32:03,489: Train batch 200: loss: 619.54 grad norm: 402.53 time: 0.076
2025-11-02 03:32:27,903: Train batch 400: loss: 540.28 grad norm: 583.58 time: 0.061
2025-11-02 03:32:51,638: Train batch 600: loss: 375.96 grad norm: 711.10 time: 0.082
2025-11-02 03:33:14,697: Train batch 800: loss: 130.71 grad norm: 514.43 time: 0.081
2025-11-02 03:33:38,474: Train batch 1000: loss: 99.40 grad norm: 55.28 time: 0.116
2025-11-02 03:33:38,475: Running test after training batch: 1000
2025-11-02 03:33:50,304: Val batch 1000: PER (avg): 0.9996 CTC Loss (avg): 101.1241 time: 11.829
2025-11-02 03:33:50,305: t15.2023.08.13 val PER: 1.0000
2025-11-02 03:33:50,306: t15.2023.08.18 val PER: 0.9992
2025-11-02 03:33:50,306: t15.2023.08.20 val PER: 0.9992
2025-11-02 03:33:50,307: t15.2023.08.25 val PER: 1.0000
2025-11-02 03:33:50,307: t15.2023.08.27 val PER: 1.0000
2025-11-02 03:33:50,307: t15.2023.09.01 val PER: 0.9984
2025-11-02 03:33:50,307: t15.2023.09.03 val PER: 1.0000
2025-11-02 03:33:50,308: t15.2023.09.24 val PER: 1.0000
2025-11-02 03:33:50,308: t15.2023.09.29 val PER: 1.0000
2025-11-02 03:33:50,308: t15.2023.10.01 val PER: 1.0000
2025-11-02 03:33:50,309: t15.2023.10.06 val PER: 0.9978
2025-11-02 03:33:50,309: t15.2023.10.08 val PER: 1.0000
2025-11-02 03:33:50,309: t15.2023.10.13 val PER: 1.0000
2025-11-02 03:33:50,309: t15.2023.10.15 val PER: 0.9993
2025-11-02 03:33:50,310: t15.2023.10.20 val PER: 1.0000
2025-11-02 03:33:50,310: t15.2023.10.22 val PER: 0.9989
2025-11-02 03:33:50,311: t15.2023.11.03 val PER: 0.9980
2025-11-02 03:33:50,311: t15.2023.11.04 val PER: 1.0000
2025-11-02 03:33:50,311: t15.2023.11.17 val PER: 1.0000
2025-11-02 03:33:50,311: t15.2023.11.19 val PER: 1.0000
2025-11-02 03:33:50,312: t15.2023.11.26 val PER: 1.0000
2025-11-02 03:33:50,312: t15.2023.12.03 val PER: 0.9989
2025-11-02 03:33:50,312: t15.2023.12.08 val PER: 0.9993
2025-11-02 03:33:50,313: t15.2023.12.10 val PER: 0.9987
2025-11-02 03:33:50,313: t15.2023.12.17 val PER: 1.0000
2025-11-02 03:33:50,313: t15.2023.12.29 val PER: 1.0000
2025-11-02 03:33:50,313: t15.2024.02.25 val PER: 1.0000
2025-11-02 03:33:50,314: t15.2024.03.08 val PER: 1.0000
2025-11-02 03:33:50,314: t15.2024.03.15 val PER: 1.0000
2025-11-02 03:33:50,314: t15.2024.03.17 val PER: 1.0000
2025-11-02 03:33:50,315: t15.2024.05.10 val PER: 1.0000
2025-11-02 03:33:50,315: t15.2024.06.14 val PER: 1.0000
2025-11-02 03:33:50,316: t15.2024.07.19 val PER: 1.0000
2025-11-02 03:33:50,316: t15.2024.07.21 val PER: 1.0000
2025-11-02 03:33:50,316: t15.2024.07.28 val PER: 1.0000
2025-11-02 03:33:50,316: t15.2025.01.10 val PER: 1.0000
2025-11-02 03:33:50,317: t15.2025.01.12 val PER: 0.9992
2025-11-02 03:33:50,317: t15.2025.03.14 val PER: 1.0000
2025-11-02 03:33:50,317: t15.2025.03.16 val PER: 1.0000
2025-11-02 03:33:50,318: t15.2025.03.30 val PER: 0.9989
2025-11-02 03:33:50,318: t15.2025.04.13 val PER: 1.0000
2025-11-02 03:33:50,318: New best test PER 1.2817 --> 0.9996
2025-11-02 03:33:50,318: Checkpointing model
2025-11-02 03:33:51,954: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:34:15,489: Train batch 1200: loss: 95.84 grad norm: 26.53 time: 0.091
2025-11-02 03:34:39,881: Train batch 1400: loss: 74.65 grad norm: 14.19 time: 0.054
2025-11-02 03:35:04,180: Train batch 1600: loss: 85.91 grad norm: 32.04 time: 0.122
2025-11-02 03:35:28,886: Train batch 1800: loss: 100.91 grad norm: 28.30 time: 0.091
2025-11-02 03:35:53,040: Train batch 2000: loss: 99.69 grad norm: 21.23 time: 0.072
2025-11-02 03:35:53,041: Running test after training batch: 2000
2025-11-02 03:36:05,113: Val batch 2000: PER (avg): 1.0000 CTC Loss (avg): 92.7119 time: 12.072
2025-11-02 03:36:05,114: t15.2023.08.13 val PER: 1.0000
2025-11-02 03:36:05,115: t15.2023.08.18 val PER: 1.0000
2025-11-02 03:36:05,115: t15.2023.08.20 val PER: 1.0000
2025-11-02 03:36:05,115: t15.2023.08.25 val PER: 1.0000
2025-11-02 03:36:05,116: t15.2023.08.27 val PER: 1.0000
2025-11-02 03:36:05,116: t15.2023.09.01 val PER: 1.0000
2025-11-02 03:36:05,117: t15.2023.09.03 val PER: 1.0000
2025-11-02 03:36:05,117: t15.2023.09.24 val PER: 1.0000
2025-11-02 03:36:05,117: t15.2023.09.29 val PER: 1.0000
2025-11-02 03:36:05,118: t15.2023.10.01 val PER: 1.0000
2025-11-02 03:36:05,118: t15.2023.10.06 val PER: 1.0000
2025-11-02 03:36:05,119: t15.2023.10.08 val PER: 1.0000
2025-11-02 03:36:05,119: t15.2023.10.13 val PER: 1.0000
2025-11-02 03:36:05,119: t15.2023.10.15 val PER: 1.0000
2025-11-02 03:36:05,120: t15.2023.10.20 val PER: 1.0000
2025-11-02 03:36:05,120: t15.2023.10.22 val PER: 1.0000
2025-11-02 03:36:05,120: t15.2023.11.03 val PER: 1.0000
2025-11-02 03:36:05,121: t15.2023.11.04 val PER: 1.0000
2025-11-02 03:36:05,121: t15.2023.11.17 val PER: 1.0000
2025-11-02 03:36:05,121: t15.2023.11.19 val PER: 1.0000
2025-11-02 03:36:05,122: t15.2023.11.26 val PER: 1.0000
2025-11-02 03:36:05,122: t15.2023.12.03 val PER: 1.0000
2025-11-02 03:36:05,122: t15.2023.12.08 val PER: 1.0000
2025-11-02 03:36:05,123: t15.2023.12.10 val PER: 1.0000
2025-11-02 03:36:05,123: t15.2023.12.17 val PER: 1.0000
2025-11-02 03:36:05,123: t15.2023.12.29 val PER: 1.0000
2025-11-02 03:36:05,124: t15.2024.02.25 val PER: 1.0000
2025-11-02 03:36:05,124: t15.2024.03.08 val PER: 1.0000
2025-11-02 03:36:05,124: t15.2024.03.15 val PER: 1.0000
2025-11-02 03:36:05,125: t15.2024.03.17 val PER: 1.0000
2025-11-02 03:36:05,125: t15.2024.05.10 val PER: 1.0000
2025-11-02 03:36:05,126: t15.2024.06.14 val PER: 1.0000
2025-11-02 03:36:05,126: t15.2024.07.19 val PER: 1.0000
2025-11-02 03:36:05,126: t15.2024.07.21 val PER: 1.0000
2025-11-02 03:36:05,127: t15.2024.07.28 val PER: 1.0000
2025-11-02 03:36:05,127: t15.2025.01.10 val PER: 1.0000
2025-11-02 03:36:05,127: t15.2025.01.12 val PER: 1.0000
2025-11-02 03:36:05,128: t15.2025.03.14 val PER: 1.0000
2025-11-02 03:36:05,128: t15.2025.03.16 val PER: 1.0000
2025-11-02 03:36:05,128: t15.2025.03.30 val PER: 1.0000
2025-11-02 03:36:05,129: t15.2025.04.13 val PER: 1.0000
2025-11-02 03:36:28,984: Train batch 2200: loss: 79.31 grad norm: 36.43 time: 0.062
2025-11-02 03:36:52,690: Train batch 2400: loss: 88.55 grad norm: 31.15 time: 0.108
2025-11-02 03:37:17,065: Train batch 2600: loss: 87.32 grad norm: 38.19 time: 0.083
2025-11-02 03:37:40,957: Train batch 2800: loss: 75.62 grad norm: 21.27 time: 0.063
2025-11-02 03:38:05,533: Train batch 3000: loss: 92.54 grad norm: 35.13 time: 0.069
2025-11-02 03:38:05,534: Running test after training batch: 3000
2025-11-02 03:38:18,113: Val batch 3000: PER (avg): 0.9998 CTC Loss (avg): 84.3747 time: 12.578
2025-11-02 03:38:18,114: t15.2023.08.13 val PER: 1.0000
2025-11-02 03:38:18,114: t15.2023.08.18 val PER: 0.9992
2025-11-02 03:38:18,115: t15.2023.08.20 val PER: 0.9992
2025-11-02 03:38:18,116: t15.2023.08.25 val PER: 1.0000
2025-11-02 03:38:18,116: t15.2023.08.27 val PER: 1.0000
2025-11-02 03:38:18,117: t15.2023.09.01 val PER: 0.9984
2025-11-02 03:38:18,118: t15.2023.09.03 val PER: 1.0000
2025-11-02 03:38:18,118: t15.2023.09.24 val PER: 1.0000
2025-11-02 03:38:18,118: t15.2023.09.29 val PER: 0.9987
2025-11-02 03:38:18,119: t15.2023.10.01 val PER: 1.0000
2025-11-02 03:38:18,119: t15.2023.10.06 val PER: 1.0000
2025-11-02 03:38:18,120: t15.2023.10.08 val PER: 1.0000
2025-11-02 03:38:18,120: t15.2023.10.13 val PER: 0.9992
2025-11-02 03:38:18,121: t15.2023.10.15 val PER: 0.9993
2025-11-02 03:38:18,121: t15.2023.10.20 val PER: 1.0000
2025-11-02 03:38:18,121: t15.2023.10.22 val PER: 1.0000
2025-11-02 03:38:18,122: t15.2023.11.03 val PER: 1.0000
2025-11-02 03:38:18,122: t15.2023.11.04 val PER: 1.0000
2025-11-02 03:38:18,122: t15.2023.11.17 val PER: 1.0000
2025-11-02 03:38:18,122: t15.2023.11.19 val PER: 1.0000
2025-11-02 03:38:18,123: t15.2023.11.26 val PER: 1.0000
2025-11-02 03:38:18,123: t15.2023.12.03 val PER: 1.0000
2025-11-02 03:38:18,123: t15.2023.12.08 val PER: 0.9993
2025-11-02 03:38:18,123: t15.2023.12.10 val PER: 1.0000
2025-11-02 03:38:18,124: t15.2023.12.17 val PER: 1.0000
2025-11-02 03:38:18,124: t15.2023.12.29 val PER: 1.0000
2025-11-02 03:38:18,124: t15.2024.02.25 val PER: 1.0000
2025-11-02 03:38:18,124: t15.2024.03.08 val PER: 1.0000
2025-11-02 03:38:18,125: t15.2024.03.15 val PER: 1.0000
2025-11-02 03:38:18,125: t15.2024.03.17 val PER: 1.0000
2025-11-02 03:38:18,126: t15.2024.05.10 val PER: 1.0000
2025-11-02 03:38:18,126: t15.2024.06.14 val PER: 1.0000
2025-11-02 03:38:18,126: t15.2024.07.19 val PER: 1.0000
2025-11-02 03:38:18,127: t15.2024.07.21 val PER: 1.0000
2025-11-02 03:38:18,127: t15.2024.07.28 val PER: 1.0000
2025-11-02 03:38:18,127: t15.2025.01.10 val PER: 1.0000
2025-11-02 03:38:18,128: t15.2025.01.12 val PER: 1.0000
2025-11-02 03:38:18,128: t15.2025.03.14 val PER: 1.0000
2025-11-02 03:38:18,128: t15.2025.03.16 val PER: 1.0000
2025-11-02 03:38:18,128: t15.2025.03.30 val PER: 1.0000
2025-11-02 03:38:18,129: t15.2025.04.13 val PER: 1.0000
2025-11-02 03:38:42,662: Train batch 3200: loss: 80.68 grad norm: 47.43 time: 0.076
2025-11-02 03:39:06,691: Train batch 3400: loss: 78.95 grad norm: 29.07 time: 0.086
2025-11-02 03:39:30,811: Train batch 3600: loss: 76.24 grad norm: 41.04 time: 0.109
2025-11-02 03:39:55,487: Train batch 3800: loss: 86.71 grad norm: 39.19 time: 0.057
2025-11-02 03:40:19,083: Train batch 4000: loss: 54.33 grad norm: 27.70 time: 0.055
2025-11-02 03:40:19,084: Running test after training batch: 4000
2025-11-02 03:40:31,810: Val batch 4000: PER (avg): 0.9705 CTC Loss (avg): 74.5634 time: 12.725
2025-11-02 03:40:31,811: t15.2023.08.13 val PER: 0.9626
2025-11-02 03:40:31,811: t15.2023.08.18 val PER: 0.9413
2025-11-02 03:40:31,811: t15.2023.08.20 val PER: 0.9547
2025-11-02 03:40:31,812: t15.2023.08.25 val PER: 0.9307
2025-11-02 03:40:31,812: t15.2023.08.27 val PER: 1.0000
2025-11-02 03:40:31,812: t15.2023.09.01 val PER: 0.9554
2025-11-02 03:40:31,813: t15.2023.09.03 val PER: 0.9917
2025-11-02 03:40:31,813: t15.2023.09.24 val PER: 0.9806
2025-11-02 03:40:31,813: t15.2023.09.29 val PER: 0.9285
2025-11-02 03:40:31,814: t15.2023.10.01 val PER: 0.9551
2025-11-02 03:40:31,814: t15.2023.10.06 val PER: 0.9419
2025-11-02 03:40:31,814: t15.2023.10.08 val PER: 0.9729
2025-11-02 03:40:31,814: t15.2023.10.13 val PER: 0.9224
2025-11-02 03:40:31,815: t15.2023.10.15 val PER: 0.9479
2025-11-02 03:40:31,815: t15.2023.10.20 val PER: 0.9329
2025-11-02 03:40:31,816: t15.2023.10.22 val PER: 0.9855
2025-11-02 03:40:31,816: t15.2023.11.03 val PER: 0.9763
2025-11-02 03:40:31,816: t15.2023.11.04 val PER: 0.9966
2025-11-02 03:40:31,816: t15.2023.11.17 val PER: 0.9953
2025-11-02 03:40:31,817: t15.2023.11.19 val PER: 0.9940
2025-11-02 03:40:31,817: t15.2023.11.26 val PER: 0.9681
2025-11-02 03:40:31,817: t15.2023.12.03 val PER: 0.9811
2025-11-02 03:40:31,818: t15.2023.12.08 val PER: 0.9594
2025-11-02 03:40:31,818: t15.2023.12.10 val PER: 0.9606
2025-11-02 03:40:31,818: t15.2023.12.17 val PER: 0.9948
2025-11-02 03:40:31,818: t15.2023.12.29 val PER: 0.9979
2025-11-02 03:40:31,819: t15.2024.02.25 val PER: 0.9663
2025-11-02 03:40:31,819: t15.2024.03.08 val PER: 0.9957
2025-11-02 03:40:31,819: t15.2024.03.15 val PER: 0.9850
2025-11-02 03:40:31,820: t15.2024.03.17 val PER: 0.9812
2025-11-02 03:40:31,820: t15.2024.05.10 val PER: 0.9837
2025-11-02 03:40:31,821: t15.2024.06.14 val PER: 0.9811
2025-11-02 03:40:31,821: t15.2024.07.19 val PER: 0.9954
2025-11-02 03:40:31,821: t15.2024.07.21 val PER: 0.9841
2025-11-02 03:40:31,821: t15.2024.07.28 val PER: 0.9625
2025-11-02 03:40:31,822: t15.2025.01.10 val PER: 0.9986
2025-11-02 03:40:31,822: t15.2025.01.12 val PER: 0.9769
2025-11-02 03:40:31,822: t15.2025.03.14 val PER: 1.0000
2025-11-02 03:40:31,823: t15.2025.03.16 val PER: 0.9673
2025-11-02 03:40:31,823: t15.2025.03.30 val PER: 0.9943
2025-11-02 03:40:31,823: t15.2025.04.13 val PER: 0.9715
2025-11-02 03:40:31,823: New best test PER 0.9996 --> 0.9705
2025-11-02 03:40:31,824: Checkpointing model
2025-11-02 03:40:33,769: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:40:58,153: Train batch 4200: loss: 68.30 grad norm: 44.59 time: 0.095
2025-11-02 03:41:22,253: Train batch 4400: loss: 62.27 grad norm: 28.19 time: 0.098
2025-11-02 03:41:46,724: Train batch 4600: loss: 76.92 grad norm: 50.61 time: 0.078
2025-11-02 03:42:11,625: Train batch 4800: loss: 56.87 grad norm: 33.13 time: 0.075
2025-11-02 03:42:37,093: Train batch 5000: loss: 70.53 grad norm: 37.86 time: 0.084
2025-11-02 03:42:37,094: Running test after training batch: 5000
2025-11-02 03:42:51,720: Val batch 5000: PER (avg): 0.6329 CTC Loss (avg): 64.5629 time: 14.625
2025-11-02 03:42:51,720: t15.2023.08.13 val PER: 0.5780
2025-11-02 03:42:51,721: t15.2023.08.18 val PER: 0.5767
2025-11-02 03:42:51,721: t15.2023.08.20 val PER: 0.5790
2025-11-02 03:42:51,722: t15.2023.08.25 val PER: 0.5889
2025-11-02 03:42:51,722: t15.2023.08.27 val PER: 0.6527
2025-11-02 03:42:51,723: t15.2023.09.01 val PER: 0.5560
2025-11-02 03:42:51,723: t15.2023.09.03 val PER: 0.6176
2025-11-02 03:42:51,723: t15.2023.09.24 val PER: 0.5934
2025-11-02 03:42:51,724: t15.2023.09.29 val PER: 0.5929
2025-11-02 03:42:51,724: t15.2023.10.01 val PER: 0.6328
2025-11-02 03:42:51,724: t15.2023.10.06 val PER: 0.5910
2025-11-02 03:42:51,725: t15.2023.10.08 val PER: 0.6509
2025-11-02 03:42:51,725: t15.2023.10.13 val PER: 0.6633
2025-11-02 03:42:51,726: t15.2023.10.15 val PER: 0.6249
2025-11-02 03:42:51,726: t15.2023.10.20 val PER: 0.5940
2025-11-02 03:42:51,726: t15.2023.10.22 val PER: 0.5768
2025-11-02 03:42:51,727: t15.2023.11.03 val PER: 0.6282
2025-11-02 03:42:51,727: t15.2023.11.04 val PER: 0.4846
2025-11-02 03:42:51,727: t15.2023.11.17 val PER: 0.5241
2025-11-02 03:42:51,728: t15.2023.11.19 val PER: 0.5210
2025-11-02 03:42:51,728: t15.2023.11.26 val PER: 0.6609
2025-11-02 03:42:51,728: t15.2023.12.03 val PER: 0.6303
2025-11-02 03:42:51,729: t15.2023.12.08 val PER: 0.6312
2025-11-02 03:42:51,729: t15.2023.12.10 val PER: 0.6281
2025-11-02 03:42:51,729: t15.2023.12.17 val PER: 0.6954
2025-11-02 03:42:51,729: t15.2023.12.29 val PER: 0.6644
2025-11-02 03:42:51,730: t15.2024.02.25 val PER: 0.6025
2025-11-02 03:42:51,784: t15.2024.03.08 val PER: 0.6700
2025-11-02 03:42:51,784: t15.2024.03.15 val PER: 0.6717
2025-11-02 03:42:51,785: t15.2024.03.17 val PER: 0.6346
2025-11-02 03:42:51,785: t15.2024.05.10 val PER: 0.6256
2025-11-02 03:42:51,785: t15.2024.06.14 val PER: 0.6467
2025-11-02 03:42:51,786: t15.2024.07.19 val PER: 0.7093
2025-11-02 03:42:51,786: t15.2024.07.21 val PER: 0.6103
2025-11-02 03:42:51,786: t15.2024.07.28 val PER: 0.6331
2025-11-02 03:42:51,787: t15.2025.01.10 val PER: 0.7796
2025-11-02 03:42:51,787: t15.2025.01.12 val PER: 0.6474
2025-11-02 03:42:51,787: t15.2025.03.14 val PER: 0.7870
2025-11-02 03:42:51,788: t15.2025.03.16 val PER: 0.6662
2025-11-02 03:42:51,788: t15.2025.03.30 val PER: 0.7299
2025-11-02 03:42:51,788: t15.2025.04.13 val PER: 0.6534
2025-11-02 03:42:51,789: New best test PER 0.9705 --> 0.6329
2025-11-02 03:42:51,789: Checkpointing model
2025-11-02 03:42:53,927: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:43:19,745: Train batch 5200: loss: 62.42 grad norm: 46.02 time: 0.080
2025-11-02 03:43:45,591: Train batch 5400: loss: 58.73 grad norm: 36.47 time: 0.079
2025-11-02 03:44:11,703: Train batch 5600: loss: 65.76 grad norm: 48.86 time: 0.082
2025-11-02 03:44:37,347: Train batch 5800: loss: 69.02 grad norm: 58.16 time: 0.077
2025-11-02 03:45:02,071: Train batch 6000: loss: 53.61 grad norm: 34.18 time: 0.079
2025-11-02 03:45:02,072: Running test after training batch: 6000
2025-11-02 03:45:15,515: Val batch 6000: PER (avg): 0.5782 CTC Loss (avg): 60.1368 time: 13.443
2025-11-02 03:45:15,516: t15.2023.08.13 val PER: 0.5239
2025-11-02 03:45:15,517: t15.2023.08.18 val PER: 0.5331
2025-11-02 03:45:15,517: t15.2023.08.20 val PER: 0.5322
2025-11-02 03:45:15,518: t15.2023.08.25 val PER: 0.5226
2025-11-02 03:45:15,518: t15.2023.08.27 val PER: 0.5981
2025-11-02 03:45:15,519: t15.2023.09.01 val PER: 0.5024
2025-11-02 03:45:15,519: t15.2023.09.03 val PER: 0.5677
2025-11-02 03:45:15,520: t15.2023.09.24 val PER: 0.5498
2025-11-02 03:45:15,520: t15.2023.09.29 val PER: 0.5501
2025-11-02 03:45:15,521: t15.2023.10.01 val PER: 0.5766
2025-11-02 03:45:15,521: t15.2023.10.06 val PER: 0.5414
2025-11-02 03:45:15,521: t15.2023.10.08 val PER: 0.6062
2025-11-02 03:45:15,522: t15.2023.10.13 val PER: 0.6261
2025-11-02 03:45:15,522: t15.2023.10.15 val PER: 0.5676
2025-11-02 03:45:15,522: t15.2023.10.20 val PER: 0.5470
2025-11-02 03:45:15,523: t15.2023.10.22 val PER: 0.5212
2025-11-02 03:45:15,523: t15.2023.11.03 val PER: 0.5604
2025-11-02 03:45:15,523: t15.2023.11.04 val PER: 0.3823
2025-11-02 03:45:15,524: t15.2023.11.17 val PER: 0.4635
2025-11-02 03:45:15,524: t15.2023.11.19 val PER: 0.4770
2025-11-02 03:45:15,524: t15.2023.11.26 val PER: 0.6080
2025-11-02 03:45:15,525: t15.2023.12.03 val PER: 0.5851
2025-11-02 03:45:15,525: t15.2023.12.08 val PER: 0.5639
2025-11-02 03:45:15,525: t15.2023.12.10 val PER: 0.5769
2025-11-02 03:45:15,526: t15.2023.12.17 val PER: 0.6133
2025-11-02 03:45:15,526: t15.2023.12.29 val PER: 0.5903
2025-11-02 03:45:15,526: t15.2024.02.25 val PER: 0.5478
2025-11-02 03:45:15,527: t15.2024.03.08 val PER: 0.6302
2025-11-02 03:45:15,527: t15.2024.03.15 val PER: 0.6054
2025-11-02 03:45:15,527: t15.2024.03.17 val PER: 0.5795
2025-11-02 03:45:15,528: t15.2024.05.10 val PER: 0.5795
2025-11-02 03:45:15,528: t15.2024.06.14 val PER: 0.5899
2025-11-02 03:45:15,528: t15.2024.07.19 val PER: 0.6552
2025-11-02 03:45:15,529: t15.2024.07.21 val PER: 0.5655
2025-11-02 03:45:15,529: t15.2024.07.28 val PER: 0.5801
2025-11-02 03:45:15,529: t15.2025.01.10 val PER: 0.7218
2025-11-02 03:45:15,530: t15.2025.01.12 val PER: 0.5851
2025-11-02 03:45:15,531: t15.2025.03.14 val PER: 0.7278
2025-11-02 03:45:15,531: t15.2025.03.16 val PER: 0.6113
2025-11-02 03:45:15,531: t15.2025.03.30 val PER: 0.6851
2025-11-02 03:45:15,532: t15.2025.04.13 val PER: 0.6020
2025-11-02 03:45:15,532: New best test PER 0.6329 --> 0.5782
2025-11-02 03:45:15,532: Checkpointing model
2025-11-02 03:45:17,530: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:45:43,344: Train batch 6200: loss: 47.09 grad norm: 37.03 time: 0.067
2025-11-02 03:46:09,014: Train batch 6400: loss: 51.21 grad norm: 43.22 time: 0.078
2025-11-02 03:46:34,195: Train batch 6600: loss: 58.95 grad norm: 45.30 time: 0.068
2025-11-02 03:46:59,138: Train batch 6800: loss: 45.93 grad norm: 49.60 time: 0.087
2025-11-02 03:47:23,959: Train batch 7000: loss: 58.44 grad norm: 42.63 time: 0.065
2025-11-02 03:47:23,959: Running test after training batch: 7000
2025-11-02 03:47:37,735: Val batch 7000: PER (avg): 0.5485 CTC Loss (avg): 57.1635 time: 13.775
2025-11-02 03:47:37,736: t15.2023.08.13 val PER: 0.5042
2025-11-02 03:47:37,736: t15.2023.08.18 val PER: 0.5021
2025-11-02 03:47:37,737: t15.2023.08.20 val PER: 0.4996
2025-11-02 03:47:37,737: t15.2023.08.25 val PER: 0.4940
2025-11-02 03:47:37,784: t15.2023.08.27 val PER: 0.5804
2025-11-02 03:47:37,784: t15.2023.09.01 val PER: 0.4708
2025-11-02 03:47:37,785: t15.2023.09.03 val PER: 0.5475
2025-11-02 03:47:37,785: t15.2023.09.24 val PER: 0.5146
2025-11-02 03:47:37,786: t15.2023.09.29 val PER: 0.5150
2025-11-02 03:47:37,786: t15.2023.10.01 val PER: 0.5535
2025-11-02 03:47:37,787: t15.2023.10.06 val PER: 0.5167
2025-11-02 03:47:37,787: t15.2023.10.08 val PER: 0.5765
2025-11-02 03:47:37,788: t15.2023.10.13 val PER: 0.6036
2025-11-02 03:47:37,788: t15.2023.10.15 val PER: 0.5392
2025-11-02 03:47:37,788: t15.2023.10.20 val PER: 0.5168
2025-11-02 03:47:37,789: t15.2023.10.22 val PER: 0.4800
2025-11-02 03:47:37,789: t15.2023.11.03 val PER: 0.5305
2025-11-02 03:47:37,789: t15.2023.11.04 val PER: 0.3413
2025-11-02 03:47:37,789: t15.2023.11.17 val PER: 0.4106
2025-11-02 03:47:37,790: t15.2023.11.19 val PER: 0.4431
2025-11-02 03:47:37,790: t15.2023.11.26 val PER: 0.5841
2025-11-02 03:47:37,791: t15.2023.12.03 val PER: 0.5368
2025-11-02 03:47:37,791: t15.2023.12.08 val PER: 0.5393
2025-11-02 03:47:37,791: t15.2023.12.10 val PER: 0.5388
2025-11-02 03:47:37,791: t15.2023.12.17 val PER: 0.5613
2025-11-02 03:47:37,792: t15.2023.12.29 val PER: 0.5518
2025-11-02 03:47:37,792: t15.2024.02.25 val PER: 0.5056
2025-11-02 03:47:37,792: t15.2024.03.08 val PER: 0.6017
2025-11-02 03:47:37,792: t15.2024.03.15 val PER: 0.5791
2025-11-02 03:47:37,792: t15.2024.03.17 val PER: 0.5502
2025-11-02 03:47:37,793: t15.2024.05.10 val PER: 0.5483
2025-11-02 03:47:37,793: t15.2024.06.14 val PER: 0.5584
2025-11-02 03:47:37,793: t15.2024.07.19 val PER: 0.6355
2025-11-02 03:47:37,793: t15.2024.07.21 val PER: 0.5352
2025-11-02 03:47:37,794: t15.2024.07.28 val PER: 0.5500
2025-11-02 03:47:37,794: t15.2025.01.10 val PER: 0.7121
2025-11-02 03:47:37,794: t15.2025.01.12 val PER: 0.5604
2025-11-02 03:47:37,794: t15.2025.03.14 val PER: 0.6923
2025-11-02 03:47:37,794: t15.2025.03.16 val PER: 0.5864
2025-11-02 03:47:37,795: t15.2025.03.30 val PER: 0.6678
2025-11-02 03:47:37,795: t15.2025.04.13 val PER: 0.5792
2025-11-02 03:47:37,796: New best test PER 0.5782 --> 0.5485
2025-11-02 03:47:37,796: Checkpointing model
2025-11-02 03:47:39,620: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:48:04,644: Train batch 7200: loss: 56.40 grad norm: 34.80 time: 0.091
2025-11-02 03:48:29,368: Train batch 7400: loss: 48.38 grad norm: 36.61 time: 0.098
2025-11-02 03:48:53,763: Train batch 7600: loss: 48.33 grad norm: 38.27 time: 0.097
2025-11-02 03:49:18,690: Train batch 7800: loss: 46.03 grad norm: 37.30 time: 0.071
2025-11-02 03:49:42,775: Train batch 8000: loss: 43.01 grad norm: 60.06 time: 0.079
2025-11-02 03:49:42,776: Running test after training batch: 8000
2025-11-02 03:49:56,618: Val batch 8000: PER (avg): 0.5265 CTC Loss (avg): 54.7627 time: 13.841
2025-11-02 03:49:56,619: t15.2023.08.13 val PER: 0.4865
2025-11-02 03:49:56,619: t15.2023.08.18 val PER: 0.4795
2025-11-02 03:49:56,620: t15.2023.08.20 val PER: 0.4829
2025-11-02 03:49:56,620: t15.2023.08.25 val PER: 0.4714
2025-11-02 03:49:56,621: t15.2023.08.27 val PER: 0.5450
2025-11-02 03:49:56,621: t15.2023.09.01 val PER: 0.4481
2025-11-02 03:49:56,622: t15.2023.09.03 val PER: 0.5249
2025-11-02 03:49:56,622: t15.2023.09.24 val PER: 0.5012
2025-11-02 03:49:56,622: t15.2023.09.29 val PER: 0.5022
2025-11-02 03:49:56,623: t15.2023.10.01 val PER: 0.5416
2025-11-02 03:49:56,623: t15.2023.10.06 val PER: 0.4779
2025-11-02 03:49:56,623: t15.2023.10.08 val PER: 0.5548
2025-11-02 03:49:56,624: t15.2023.10.13 val PER: 0.5865
2025-11-02 03:49:56,624: t15.2023.10.15 val PER: 0.5122
2025-11-02 03:49:56,624: t15.2023.10.20 val PER: 0.5067
2025-11-02 03:49:56,625: t15.2023.10.22 val PER: 0.4621
2025-11-02 03:49:56,625: t15.2023.11.03 val PER: 0.5061
2025-11-02 03:49:56,626: t15.2023.11.04 val PER: 0.3276
2025-11-02 03:49:56,626: t15.2023.11.17 val PER: 0.3966
2025-11-02 03:49:56,627: t15.2023.11.19 val PER: 0.4112
2025-11-02 03:49:56,627: t15.2023.11.26 val PER: 0.5601
2025-11-02 03:49:56,627: t15.2023.12.03 val PER: 0.5137
2025-11-02 03:49:56,628: t15.2023.12.08 val PER: 0.5186
2025-11-02 03:49:56,628: t15.2023.12.10 val PER: 0.5007
2025-11-02 03:49:56,628: t15.2023.12.17 val PER: 0.5405
2025-11-02 03:49:56,629: t15.2023.12.29 val PER: 0.5319
2025-11-02 03:49:56,629: t15.2024.02.25 val PER: 0.4789
2025-11-02 03:49:56,630: t15.2024.03.08 val PER: 0.5818
2025-11-02 03:49:56,631: t15.2024.03.15 val PER: 0.5472
2025-11-02 03:49:56,631: t15.2024.03.17 val PER: 0.5286
2025-11-02 03:49:56,631: t15.2024.05.10 val PER: 0.5111
2025-11-02 03:49:56,632: t15.2024.06.14 val PER: 0.5394
2025-11-02 03:49:56,632: t15.2024.07.19 val PER: 0.6177
2025-11-02 03:49:56,632: t15.2024.07.21 val PER: 0.5083
2025-11-02 03:49:56,633: t15.2024.07.28 val PER: 0.5294
2025-11-02 03:49:56,633: t15.2025.01.10 val PER: 0.6777
2025-11-02 03:49:56,633: t15.2025.01.12 val PER: 0.5296
2025-11-02 03:49:56,634: t15.2025.03.14 val PER: 0.6775
2025-11-02 03:49:56,634: t15.2025.03.16 val PER: 0.5812
2025-11-02 03:49:56,634: t15.2025.03.30 val PER: 0.6552
2025-11-02 03:49:56,635: t15.2025.04.13 val PER: 0.5563
2025-11-02 03:49:56,635: New best test PER 0.5485 --> 0.5265
2025-11-02 03:49:56,636: Checkpointing model
2025-11-02 03:49:58,419: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:50:23,027: Train batch 8200: loss: 54.47 grad norm: 42.76 time: 0.064
2025-11-02 03:50:47,425: Train batch 8400: loss: 53.15 grad norm: 41.27 time: 0.066
2025-11-02 03:51:11,955: Train batch 8600: loss: 51.05 grad norm: 65.09 time: 0.070
2025-11-02 03:51:36,241: Train batch 8800: loss: 67.45 grad norm: 78.10 time: 0.106
2025-11-02 03:51:59,713: Train batch 9000: loss: 49.63 grad norm: 32.33 time: 0.095
2025-11-02 03:51:59,714: Running test after training batch: 9000
2025-11-02 03:52:12,313: Val batch 9000: PER (avg): 0.5104 CTC Loss (avg): 52.8655 time: 12.599
2025-11-02 03:52:12,314: t15.2023.08.13 val PER: 0.4802
2025-11-02 03:52:12,314: t15.2023.08.18 val PER: 0.4619
2025-11-02 03:52:12,315: t15.2023.08.20 val PER: 0.4631
2025-11-02 03:52:12,315: t15.2023.08.25 val PER: 0.4593
2025-11-02 03:52:12,316: t15.2023.08.27 val PER: 0.5257
2025-11-02 03:52:12,316: t15.2023.09.01 val PER: 0.4310
2025-11-02 03:52:12,317: t15.2023.09.03 val PER: 0.5107
2025-11-02 03:52:12,317: t15.2023.09.24 val PER: 0.4769
2025-11-02 03:52:12,317: t15.2023.09.29 val PER: 0.4805
2025-11-02 03:52:12,318: t15.2023.10.01 val PER: 0.5284
2025-11-02 03:52:12,318: t15.2023.10.06 val PER: 0.4586
2025-11-02 03:52:12,319: t15.2023.10.08 val PER: 0.5413
2025-11-02 03:52:12,319: t15.2023.10.13 val PER: 0.5795
2025-11-02 03:52:12,320: t15.2023.10.15 val PER: 0.4944
2025-11-02 03:52:12,320: t15.2023.10.20 val PER: 0.5101
2025-11-02 03:52:12,321: t15.2023.10.22 val PER: 0.4521
2025-11-02 03:52:12,321: t15.2023.11.03 val PER: 0.4898
2025-11-02 03:52:12,322: t15.2023.11.04 val PER: 0.3106
2025-11-02 03:52:12,322: t15.2023.11.17 val PER: 0.3810
2025-11-02 03:52:12,323: t15.2023.11.19 val PER: 0.3752
2025-11-02 03:52:12,323: t15.2023.11.26 val PER: 0.5580
2025-11-02 03:52:12,323: t15.2023.12.03 val PER: 0.5032
2025-11-02 03:52:12,324: t15.2023.12.08 val PER: 0.5080
2025-11-02 03:52:12,324: t15.2023.12.10 val PER: 0.4862
2025-11-02 03:52:12,324: t15.2023.12.17 val PER: 0.5135
2025-11-02 03:52:12,324: t15.2023.12.29 val PER: 0.5182
2025-11-02 03:52:12,325: t15.2024.02.25 val PER: 0.4579
2025-11-02 03:52:12,325: t15.2024.03.08 val PER: 0.5718
2025-11-02 03:52:12,326: t15.2024.03.15 val PER: 0.5241
2025-11-02 03:52:12,326: t15.2024.03.17 val PER: 0.5056
2025-11-02 03:52:12,326: t15.2024.05.10 val PER: 0.5082
2025-11-02 03:52:12,327: t15.2024.06.14 val PER: 0.5110
2025-11-02 03:52:12,327: t15.2024.07.19 val PER: 0.5985
2025-11-02 03:52:12,327: t15.2024.07.21 val PER: 0.4841
2025-11-02 03:52:12,327: t15.2024.07.28 val PER: 0.5066
2025-11-02 03:52:12,328: t15.2025.01.10 val PER: 0.6639
2025-11-02 03:52:12,328: t15.2025.01.12 val PER: 0.5204
2025-11-02 03:52:12,328: t15.2025.03.14 val PER: 0.6598
2025-11-02 03:52:12,329: t15.2025.03.16 val PER: 0.5497
2025-11-02 03:52:12,329: t15.2025.03.30 val PER: 0.6483
2025-11-02 03:52:12,329: t15.2025.04.13 val PER: 0.5578
2025-11-02 03:52:12,329: New best test PER 0.5265 --> 0.5104
2025-11-02 03:52:12,330: Checkpointing model
2025-11-02 03:52:14,147: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:52:38,658: Train batch 9200: loss: 53.28 grad norm: 45.26 time: 0.082
2025-11-02 03:53:03,377: Train batch 9400: loss: 47.43 grad norm: 55.76 time: 0.100
2025-11-02 03:53:27,778: Train batch 9600: loss: 49.98 grad norm: 37.40 time: 0.065
2025-11-02 03:53:52,037: Train batch 9800: loss: 55.92 grad norm: 64.23 time: 0.089
2025-11-02 03:54:16,787: Train batch 10000: loss: 50.38 grad norm: 48.50 time: 0.067
2025-11-02 03:54:16,788: Running test after training batch: 10000
2025-11-02 03:54:29,714: Val batch 10000: PER (avg): 0.4972 CTC Loss (avg): 51.0393 time: 12.926
2025-11-02 03:54:29,715: t15.2023.08.13 val PER: 0.4636
2025-11-02 03:54:29,716: t15.2023.08.18 val PER: 0.4493
2025-11-02 03:54:29,716: t15.2023.08.20 val PER: 0.4480
2025-11-02 03:54:29,717: t15.2023.08.25 val PER: 0.4367
2025-11-02 03:54:29,718: t15.2023.08.27 val PER: 0.5032
2025-11-02 03:54:29,718: t15.2023.09.01 val PER: 0.4261
2025-11-02 03:54:29,719: t15.2023.09.03 val PER: 0.4952
2025-11-02 03:54:29,719: t15.2023.09.24 val PER: 0.4551
2025-11-02 03:54:29,719: t15.2023.09.29 val PER: 0.4684
2025-11-02 03:54:29,720: t15.2023.10.01 val PER: 0.5053
2025-11-02 03:54:29,720: t15.2023.10.06 val PER: 0.4360
2025-11-02 03:54:29,721: t15.2023.10.08 val PER: 0.5332
2025-11-02 03:54:29,721: t15.2023.10.13 val PER: 0.5593
2025-11-02 03:54:29,722: t15.2023.10.15 val PER: 0.4852
2025-11-02 03:54:29,722: t15.2023.10.20 val PER: 0.4899
2025-11-02 03:54:29,722: t15.2023.10.22 val PER: 0.4421
2025-11-02 03:54:29,723: t15.2023.11.03 val PER: 0.4817
2025-11-02 03:54:29,723: t15.2023.11.04 val PER: 0.3038
2025-11-02 03:54:29,723: t15.2023.11.17 val PER: 0.3624
2025-11-02 03:54:29,724: t15.2023.11.19 val PER: 0.3653
2025-11-02 03:54:29,724: t15.2023.11.26 val PER: 0.5435
2025-11-02 03:54:29,724: t15.2023.12.03 val PER: 0.4937
2025-11-02 03:54:29,725: t15.2023.12.08 val PER: 0.4953
2025-11-02 03:54:29,725: t15.2023.12.10 val PER: 0.4678
2025-11-02 03:54:29,725: t15.2023.12.17 val PER: 0.5021
2025-11-02 03:54:29,726: t15.2023.12.29 val PER: 0.4949
2025-11-02 03:54:29,726: t15.2024.02.25 val PER: 0.4508
2025-11-02 03:54:29,726: t15.2024.03.08 val PER: 0.5605
2025-11-02 03:54:29,727: t15.2024.03.15 val PER: 0.5197
2025-11-02 03:54:29,727: t15.2024.03.17 val PER: 0.4972
2025-11-02 03:54:29,727: t15.2024.05.10 val PER: 0.4963
2025-11-02 03:54:29,728: t15.2024.06.14 val PER: 0.4984
2025-11-02 03:54:29,728: t15.2024.07.19 val PER: 0.5933
2025-11-02 03:54:29,728: t15.2024.07.21 val PER: 0.4779
2025-11-02 03:54:29,729: t15.2024.07.28 val PER: 0.4963
2025-11-02 03:54:29,729: t15.2025.01.10 val PER: 0.6474
2025-11-02 03:54:29,729: t15.2025.01.12 val PER: 0.5042
2025-11-02 03:54:29,729: t15.2025.03.14 val PER: 0.6494
2025-11-02 03:54:29,730: t15.2025.03.16 val PER: 0.5497
2025-11-02 03:54:29,730: t15.2025.03.30 val PER: 0.6253
2025-11-02 03:54:29,731: t15.2025.04.13 val PER: 0.5307
2025-11-02 03:54:29,731: New best test PER 0.5104 --> 0.4972
2025-11-02 03:54:29,731: Checkpointing model
2025-11-02 03:54:31,593: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:54:56,539: Train batch 10200: loss: 44.98 grad norm: 47.17 time: 0.083
2025-11-02 03:55:20,579: Train batch 10400: loss: 43.95 grad norm: 56.27 time: 0.098
2025-11-02 03:55:45,249: Train batch 10600: loss: 45.03 grad norm: 36.60 time: 0.111
2025-11-02 03:56:10,204: Train batch 10800: loss: 47.88 grad norm: 41.60 time: 0.061
2025-11-02 03:56:34,739: Train batch 11000: loss: 60.67 grad norm: 55.93 time: 0.118
2025-11-02 03:56:34,740: Running test after training batch: 11000
2025-11-02 03:56:47,814: Val batch 11000: PER (avg): 0.4791 CTC Loss (avg): 49.3171 time: 13.074
2025-11-02 03:56:47,815: t15.2023.08.13 val PER: 0.4459
2025-11-02 03:56:47,816: t15.2023.08.18 val PER: 0.4359
2025-11-02 03:56:47,816: t15.2023.08.20 val PER: 0.4289
2025-11-02 03:56:47,817: t15.2023.08.25 val PER: 0.4217
2025-11-02 03:56:47,817: t15.2023.08.27 val PER: 0.4871
2025-11-02 03:56:47,817: t15.2023.09.01 val PER: 0.3969
2025-11-02 03:56:47,818: t15.2023.09.03 val PER: 0.4715
2025-11-02 03:56:47,818: t15.2023.09.24 val PER: 0.4333
2025-11-02 03:56:47,819: t15.2023.09.29 val PER: 0.4416
2025-11-02 03:56:47,819: t15.2023.10.01 val PER: 0.4914
2025-11-02 03:56:47,819: t15.2023.10.06 val PER: 0.4177
2025-11-02 03:56:47,820: t15.2023.10.08 val PER: 0.5237
2025-11-02 03:56:47,820: t15.2023.10.13 val PER: 0.5493
2025-11-02 03:56:47,821: t15.2023.10.15 val PER: 0.4608
2025-11-02 03:56:47,821: t15.2023.10.20 val PER: 0.4530
2025-11-02 03:56:47,821: t15.2023.10.22 val PER: 0.4198
2025-11-02 03:56:47,822: t15.2023.11.03 val PER: 0.4634
2025-11-02 03:56:47,822: t15.2023.11.04 val PER: 0.2867
2025-11-02 03:56:47,822: t15.2023.11.17 val PER: 0.3437
2025-11-02 03:56:47,823: t15.2023.11.19 val PER: 0.3473
2025-11-02 03:56:47,823: t15.2023.11.26 val PER: 0.5283
2025-11-02 03:56:47,823: t15.2023.12.03 val PER: 0.4811
2025-11-02 03:56:47,824: t15.2023.12.08 val PER: 0.4774
2025-11-02 03:56:47,824: t15.2023.12.10 val PER: 0.4520
2025-11-02 03:56:47,824: t15.2023.12.17 val PER: 0.4740
2025-11-02 03:56:47,825: t15.2023.12.29 val PER: 0.4832
2025-11-02 03:56:47,825: t15.2024.02.25 val PER: 0.4199
2025-11-02 03:56:47,826: t15.2024.03.08 val PER: 0.5462
2025-11-02 03:56:47,826: t15.2024.03.15 val PER: 0.5041
2025-11-02 03:56:47,826: t15.2024.03.17 val PER: 0.4874
2025-11-02 03:56:47,827: t15.2024.05.10 val PER: 0.4710
2025-11-02 03:56:47,827: t15.2024.06.14 val PER: 0.4905
2025-11-02 03:56:47,827: t15.2024.07.19 val PER: 0.5755
2025-11-02 03:56:47,827: t15.2024.07.21 val PER: 0.4655
2025-11-02 03:56:47,828: t15.2024.07.28 val PER: 0.4691
2025-11-02 03:56:47,828: t15.2025.01.10 val PER: 0.6226
2025-11-02 03:56:47,828: t15.2025.01.12 val PER: 0.4996
2025-11-02 03:56:47,829: t15.2025.03.14 val PER: 0.6139
2025-11-02 03:56:47,829: t15.2025.03.16 val PER: 0.5196
2025-11-02 03:56:47,829: t15.2025.03.30 val PER: 0.6138
2025-11-02 03:56:47,830: t15.2025.04.13 val PER: 0.5250
2025-11-02 03:56:47,830: New best test PER 0.4972 --> 0.4791
2025-11-02 03:56:47,831: Checkpointing model
2025-11-02 03:56:49,581: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:57:14,834: Train batch 11200: loss: 48.76 grad norm: 50.21 time: 0.097
2025-11-02 03:57:39,179: Train batch 11400: loss: 41.57 grad norm: 39.49 time: 0.052
2025-11-02 03:58:03,494: Train batch 11600: loss: 38.20 grad norm: 31.30 time: 0.083
2025-11-02 03:58:27,845: Train batch 11800: loss: 48.46 grad norm: 63.95 time: 0.082
2025-11-02 03:58:52,384: Train batch 12000: loss: 31.75 grad norm: 32.64 time: 0.062
2025-11-02 03:58:52,386: Running test after training batch: 12000
2025-11-02 03:59:05,216: Val batch 12000: PER (avg): 0.4641 CTC Loss (avg): 47.7140 time: 12.830
2025-11-02 03:59:05,217: t15.2023.08.13 val PER: 0.4283
2025-11-02 03:59:05,217: t15.2023.08.18 val PER: 0.4258
2025-11-02 03:59:05,218: t15.2023.08.20 val PER: 0.4186
2025-11-02 03:59:05,218: t15.2023.08.25 val PER: 0.3946
2025-11-02 03:59:05,218: t15.2023.08.27 val PER: 0.4711
2025-11-02 03:59:05,219: t15.2023.09.01 val PER: 0.3791
2025-11-02 03:59:05,219: t15.2023.09.03 val PER: 0.4537
2025-11-02 03:59:05,220: t15.2023.09.24 val PER: 0.4114
2025-11-02 03:59:05,220: t15.2023.09.29 val PER: 0.4167
2025-11-02 03:59:05,221: t15.2023.10.01 val PER: 0.4769
2025-11-02 03:59:05,221: t15.2023.10.06 val PER: 0.4015
2025-11-02 03:59:05,221: t15.2023.10.08 val PER: 0.5061
2025-11-02 03:59:05,222: t15.2023.10.13 val PER: 0.5400
2025-11-02 03:59:05,222: t15.2023.10.15 val PER: 0.4403
2025-11-02 03:59:05,222: t15.2023.10.20 val PER: 0.4396
2025-11-02 03:59:05,223: t15.2023.10.22 val PER: 0.4143
2025-11-02 03:59:05,223: t15.2023.11.03 val PER: 0.4498
2025-11-02 03:59:05,223: t15.2023.11.04 val PER: 0.2730
2025-11-02 03:59:05,224: t15.2023.11.17 val PER: 0.3204
2025-11-02 03:59:05,224: t15.2023.11.19 val PER: 0.3453
2025-11-02 03:59:05,224: t15.2023.11.26 val PER: 0.5174
2025-11-02 03:59:05,224: t15.2023.12.03 val PER: 0.4590
2025-11-02 03:59:05,225: t15.2023.12.08 val PER: 0.4621
2025-11-02 03:59:05,225: t15.2023.12.10 val PER: 0.4402
2025-11-02 03:59:05,226: t15.2023.12.17 val PER: 0.4563
2025-11-02 03:59:05,226: t15.2023.12.29 val PER: 0.4674
2025-11-02 03:59:05,227: t15.2024.02.25 val PER: 0.4059
2025-11-02 03:59:05,227: t15.2024.03.08 val PER: 0.5306
2025-11-02 03:59:05,227: t15.2024.03.15 val PER: 0.4928
2025-11-02 03:59:05,227: t15.2024.03.17 val PER: 0.4728
2025-11-02 03:59:05,228: t15.2024.05.10 val PER: 0.4636
2025-11-02 03:59:05,228: t15.2024.06.14 val PER: 0.4779
2025-11-02 03:59:05,228: t15.2024.07.19 val PER: 0.5597
2025-11-02 03:59:05,229: t15.2024.07.21 val PER: 0.4469
2025-11-02 03:59:05,229: t15.2024.07.28 val PER: 0.4529
2025-11-02 03:59:05,229: t15.2025.01.10 val PER: 0.6116
2025-11-02 03:59:05,229: t15.2025.01.12 val PER: 0.4827
2025-11-02 03:59:05,230: t15.2025.03.14 val PER: 0.6095
2025-11-02 03:59:05,230: t15.2025.03.16 val PER: 0.5105
2025-11-02 03:59:05,230: t15.2025.03.30 val PER: 0.5989
2025-11-02 03:59:05,231: t15.2025.04.13 val PER: 0.5093
2025-11-02 03:59:05,231: New best test PER 0.4791 --> 0.4641
2025-11-02 03:59:05,231: Checkpointing model
2025-11-02 03:59:06,842: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 03:59:31,025: Train batch 12200: loss: 45.01 grad norm: 37.07 time: 0.089
2025-11-02 03:59:55,014: Train batch 12400: loss: 38.65 grad norm: 48.19 time: 0.064
2025-11-02 04:00:19,923: Train batch 12600: loss: 36.63 grad norm: 35.70 time: 0.052
2025-11-02 04:00:43,802: Train batch 12800: loss: 46.81 grad norm: 48.62 time: 0.086
2025-11-02 04:01:08,112: Train batch 13000: loss: 47.99 grad norm: 48.95 time: 0.075
2025-11-02 04:01:08,113: Running test after training batch: 13000
2025-11-02 04:01:20,791: Val batch 13000: PER (avg): 0.4493 CTC Loss (avg): 46.1262 time: 12.678
2025-11-02 04:01:20,792: t15.2023.08.13 val PER: 0.4127
2025-11-02 04:01:20,793: t15.2023.08.18 val PER: 0.4107
2025-11-02 04:01:20,793: t15.2023.08.20 val PER: 0.4003
2025-11-02 04:01:20,794: t15.2023.08.25 val PER: 0.3825
2025-11-02 04:01:20,794: t15.2023.08.27 val PER: 0.4711
2025-11-02 04:01:20,794: t15.2023.09.01 val PER: 0.3604
2025-11-02 04:01:20,795: t15.2023.09.03 val PER: 0.4513
2025-11-02 04:01:20,795: t15.2023.09.24 val PER: 0.3920
2025-11-02 04:01:20,796: t15.2023.09.29 val PER: 0.4059
2025-11-02 04:01:20,796: t15.2023.10.01 val PER: 0.4650
2025-11-02 04:01:20,796: t15.2023.10.06 val PER: 0.3875
2025-11-02 04:01:20,797: t15.2023.10.08 val PER: 0.4939
2025-11-02 04:01:20,797: t15.2023.10.13 val PER: 0.5237
2025-11-02 04:01:20,797: t15.2023.10.15 val PER: 0.4232
2025-11-02 04:01:20,798: t15.2023.10.20 val PER: 0.4262
2025-11-02 04:01:20,798: t15.2023.10.22 val PER: 0.3998
2025-11-02 04:01:20,798: t15.2023.11.03 val PER: 0.4389
2025-11-02 04:01:20,799: t15.2023.11.04 val PER: 0.2662
2025-11-02 04:01:20,799: t15.2023.11.17 val PER: 0.3079
2025-11-02 04:01:20,799: t15.2023.11.19 val PER: 0.3054
2025-11-02 04:01:20,803: t15.2023.11.26 val PER: 0.5080
2025-11-02 04:01:20,804: t15.2023.12.03 val PER: 0.4370
2025-11-02 04:01:20,804: t15.2023.12.08 val PER: 0.4447
2025-11-02 04:01:20,804: t15.2023.12.10 val PER: 0.4166
2025-11-02 04:01:20,805: t15.2023.12.17 val PER: 0.4397
2025-11-02 04:01:20,805: t15.2023.12.29 val PER: 0.4544
2025-11-02 04:01:20,805: t15.2024.02.25 val PER: 0.3975
2025-11-02 04:01:20,806: t15.2024.03.08 val PER: 0.5192
2025-11-02 04:01:20,806: t15.2024.03.15 val PER: 0.4841
2025-11-02 04:01:20,806: t15.2024.03.17 val PER: 0.4547
2025-11-02 04:01:20,807: t15.2024.05.10 val PER: 0.4487
2025-11-02 04:01:20,807: t15.2024.06.14 val PER: 0.4590
2025-11-02 04:01:20,807: t15.2024.07.19 val PER: 0.5491
2025-11-02 04:01:20,807: t15.2024.07.21 val PER: 0.4234
2025-11-02 04:01:20,808: t15.2024.07.28 val PER: 0.4368
2025-11-02 04:01:20,808: t15.2025.01.10 val PER: 0.5950
2025-11-02 04:01:20,808: t15.2025.01.12 val PER: 0.4650
2025-11-02 04:01:20,808: t15.2025.03.14 val PER: 0.5902
2025-11-02 04:01:20,809: t15.2025.03.16 val PER: 0.4895
2025-11-02 04:01:20,809: t15.2025.03.30 val PER: 0.5874
2025-11-02 04:01:20,809: t15.2025.04.13 val PER: 0.5021
2025-11-02 04:01:20,810: New best test PER 0.4641 --> 0.4493
2025-11-02 04:01:20,810: Checkpointing model
2025-11-02 04:01:22,366: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:01:46,658: Train batch 13200: loss: 43.42 grad norm: 43.49 time: 0.068
2025-11-02 04:02:10,525: Train batch 13400: loss: 38.10 grad norm: 35.68 time: 0.075
2025-11-02 04:02:34,858: Train batch 13600: loss: 49.02 grad norm: 56.78 time: 0.072
2025-11-02 04:02:58,775: Train batch 13800: loss: 42.89 grad norm: 42.46 time: 0.081
2025-11-02 04:03:22,381: Train batch 14000: loss: 35.33 grad norm: 41.70 time: 0.069
2025-11-02 04:03:22,382: Running test after training batch: 14000
2025-11-02 04:03:34,697: Val batch 14000: PER (avg): 0.4355 CTC Loss (avg): 44.7269 time: 12.314
2025-11-02 04:03:34,698: t15.2023.08.13 val PER: 0.3929
2025-11-02 04:03:34,698: t15.2023.08.18 val PER: 0.3906
2025-11-02 04:03:34,699: t15.2023.08.20 val PER: 0.3916
2025-11-02 04:03:34,699: t15.2023.08.25 val PER: 0.3630
2025-11-02 04:03:34,699: t15.2023.08.27 val PER: 0.4566
2025-11-02 04:03:34,704: t15.2023.09.01 val PER: 0.3571
2025-11-02 04:03:34,704: t15.2023.09.03 val PER: 0.4299
2025-11-02 04:03:34,705: t15.2023.09.24 val PER: 0.3786
2025-11-02 04:03:34,705: t15.2023.09.29 val PER: 0.4020
2025-11-02 04:03:34,706: t15.2023.10.01 val PER: 0.4610
2025-11-02 04:03:34,706: t15.2023.10.06 val PER: 0.3789
2025-11-02 04:03:34,706: t15.2023.10.08 val PER: 0.4831
2025-11-02 04:03:34,706: t15.2023.10.13 val PER: 0.5097
2025-11-02 04:03:34,707: t15.2023.10.15 val PER: 0.4113
2025-11-02 04:03:34,707: t15.2023.10.20 val PER: 0.4195
2025-11-02 04:03:34,707: t15.2023.10.22 val PER: 0.3686
2025-11-02 04:03:34,708: t15.2023.11.03 val PER: 0.4199
2025-11-02 04:03:34,708: t15.2023.11.04 val PER: 0.2457
2025-11-02 04:03:34,708: t15.2023.11.17 val PER: 0.3079
2025-11-02 04:03:34,709: t15.2023.11.19 val PER: 0.3014
2025-11-02 04:03:34,709: t15.2023.11.26 val PER: 0.4942
2025-11-02 04:03:34,709: t15.2023.12.03 val PER: 0.4265
2025-11-02 04:03:34,709: t15.2023.12.08 val PER: 0.4248
2025-11-02 04:03:34,710: t15.2023.12.10 val PER: 0.4074
2025-11-02 04:03:34,710: t15.2023.12.17 val PER: 0.4272
2025-11-02 04:03:34,711: t15.2023.12.29 val PER: 0.4482
2025-11-02 04:03:34,711: t15.2024.02.25 val PER: 0.3876
2025-11-02 04:03:34,711: t15.2024.03.08 val PER: 0.4964
2025-11-02 04:03:34,711: t15.2024.03.15 val PER: 0.4659
2025-11-02 04:03:34,712: t15.2024.03.17 val PER: 0.4484
2025-11-02 04:03:34,712: t15.2024.05.10 val PER: 0.4279
2025-11-02 04:03:34,712: t15.2024.06.14 val PER: 0.4401
2025-11-02 04:03:34,712: t15.2024.07.19 val PER: 0.5254
2025-11-02 04:03:34,713: t15.2024.07.21 val PER: 0.4152
2025-11-02 04:03:34,713: t15.2024.07.28 val PER: 0.4294
2025-11-02 04:03:34,713: t15.2025.01.10 val PER: 0.5744
2025-11-02 04:03:34,713: t15.2025.01.12 val PER: 0.4480
2025-11-02 04:03:34,714: t15.2025.03.14 val PER: 0.5784
2025-11-02 04:03:34,714: t15.2025.03.16 val PER: 0.4620
2025-11-02 04:03:34,714: t15.2025.03.30 val PER: 0.5609
2025-11-02 04:03:34,714: t15.2025.04.13 val PER: 0.4879
2025-11-02 04:03:34,715: New best test PER 0.4493 --> 0.4355
2025-11-02 04:03:34,715: Checkpointing model
2025-11-02 04:03:36,406: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:04:01,054: Train batch 14200: loss: 38.58 grad norm: 73.66 time: 0.063
2025-11-02 04:04:24,885: Train batch 14400: loss: 32.12 grad norm: 35.84 time: 0.089
2025-11-02 04:04:49,099: Train batch 14600: loss: 44.21 grad norm: 47.77 time: 0.097
2025-11-02 04:05:12,610: Train batch 14800: loss: 41.11 grad norm: 40.00 time: 0.061
2025-11-02 04:05:36,505: Train batch 15000: loss: 45.67 grad norm: 45.24 time: 0.081
2025-11-02 04:05:36,507: Running test after training batch: 15000
2025-11-02 04:05:49,014: Val batch 15000: PER (avg): 0.4221 CTC Loss (avg): 43.2646 time: 12.485
2025-11-02 04:05:49,015: t15.2023.08.13 val PER: 0.3815
2025-11-02 04:05:49,016: t15.2023.08.18 val PER: 0.3797
2025-11-02 04:05:49,016: t15.2023.08.20 val PER: 0.3662
2025-11-02 04:05:49,016: t15.2023.08.25 val PER: 0.3464
2025-11-02 04:05:49,017: t15.2023.08.27 val PER: 0.4453
2025-11-02 04:05:49,017: t15.2023.09.01 val PER: 0.3401
2025-11-02 04:05:49,018: t15.2023.09.03 val PER: 0.4216
2025-11-02 04:05:49,018: t15.2023.09.24 val PER: 0.3689
2025-11-02 04:05:49,018: t15.2023.09.29 val PER: 0.3906
2025-11-02 04:05:49,019: t15.2023.10.01 val PER: 0.4458
2025-11-02 04:05:49,019: t15.2023.10.06 val PER: 0.3692
2025-11-02 04:05:49,019: t15.2023.10.08 val PER: 0.4817
2025-11-02 04:05:49,020: t15.2023.10.13 val PER: 0.4888
2025-11-02 04:05:49,020: t15.2023.10.15 val PER: 0.3975
2025-11-02 04:05:49,021: t15.2023.10.20 val PER: 0.4027
2025-11-02 04:05:49,021: t15.2023.10.22 val PER: 0.3630
2025-11-02 04:05:49,021: t15.2023.11.03 val PER: 0.4138
2025-11-02 04:05:49,021: t15.2023.11.04 val PER: 0.2423
2025-11-02 04:05:49,022: t15.2023.11.17 val PER: 0.2924
2025-11-02 04:05:49,022: t15.2023.11.19 val PER: 0.2854
2025-11-02 04:05:49,022: t15.2023.11.26 val PER: 0.4804
2025-11-02 04:05:49,023: t15.2023.12.03 val PER: 0.4065
2025-11-02 04:05:49,023: t15.2023.12.08 val PER: 0.4174
2025-11-02 04:05:49,024: t15.2023.12.10 val PER: 0.3890
2025-11-02 04:05:49,024: t15.2023.12.17 val PER: 0.4200
2025-11-02 04:05:49,024: t15.2023.12.29 val PER: 0.4345
2025-11-02 04:05:49,024: t15.2024.02.25 val PER: 0.3764
2025-11-02 04:05:49,025: t15.2024.03.08 val PER: 0.4780
2025-11-02 04:05:49,025: t15.2024.03.15 val PER: 0.4578
2025-11-02 04:05:49,025: t15.2024.03.17 val PER: 0.4365
2025-11-02 04:05:49,026: t15.2024.05.10 val PER: 0.4205
2025-11-02 04:05:49,026: t15.2024.06.14 val PER: 0.4180
2025-11-02 04:05:49,026: t15.2024.07.19 val PER: 0.5056
2025-11-02 04:05:49,027: t15.2024.07.21 val PER: 0.3938
2025-11-02 04:05:49,027: t15.2024.07.28 val PER: 0.4110
2025-11-02 04:05:49,027: t15.2025.01.10 val PER: 0.5675
2025-11-02 04:05:49,027: t15.2025.01.12 val PER: 0.4296
2025-11-02 04:05:49,028: t15.2025.03.14 val PER: 0.5754
2025-11-02 04:05:49,028: t15.2025.03.16 val PER: 0.4529
2025-11-02 04:05:49,028: t15.2025.03.30 val PER: 0.5437
2025-11-02 04:05:49,028: t15.2025.04.13 val PER: 0.4736
2025-11-02 04:05:49,029: New best test PER 0.4355 --> 0.4221
2025-11-02 04:05:49,029: Checkpointing model
2025-11-02 04:05:50,839: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:06:15,263: Train batch 15200: loss: 43.75 grad norm: 93.00 time: 0.106
2025-11-02 04:06:39,348: Train batch 15400: loss: 40.77 grad norm: 41.32 time: 0.088
2025-11-02 04:07:03,266: Train batch 15600: loss: 37.19 grad norm: 41.55 time: 0.079
2025-11-02 04:07:27,112: Train batch 15800: loss: 33.44 grad norm: 35.23 time: 0.077
2025-11-02 04:07:52,195: Train batch 16000: loss: 38.60 grad norm: 39.88 time: 0.086
2025-11-02 04:07:52,196: Running test after training batch: 16000
2025-11-02 04:08:04,726: Val batch 16000: PER (avg): 0.4075 CTC Loss (avg): 42.0595 time: 12.529
2025-11-02 04:08:04,728: t15.2023.08.13 val PER: 0.3794
2025-11-02 04:08:04,728: t15.2023.08.18 val PER: 0.3588
2025-11-02 04:08:04,729: t15.2023.08.20 val PER: 0.3535
2025-11-02 04:08:04,729: t15.2023.08.25 val PER: 0.3313
2025-11-02 04:08:04,729: t15.2023.08.27 val PER: 0.4389
2025-11-02 04:08:04,730: t15.2023.09.01 val PER: 0.3239
2025-11-02 04:08:04,730: t15.2023.09.03 val PER: 0.4062
2025-11-02 04:08:04,731: t15.2023.09.24 val PER: 0.3434
2025-11-02 04:08:04,731: t15.2023.09.29 val PER: 0.3689
2025-11-02 04:08:04,731: t15.2023.10.01 val PER: 0.4373
2025-11-02 04:08:04,731: t15.2023.10.06 val PER: 0.3584
2025-11-02 04:08:04,732: t15.2023.10.08 val PER: 0.4668
2025-11-02 04:08:04,732: t15.2023.10.13 val PER: 0.4701
2025-11-02 04:08:04,732: t15.2023.10.15 val PER: 0.3909
2025-11-02 04:08:04,732: t15.2023.10.20 val PER: 0.3758
2025-11-02 04:08:04,733: t15.2023.10.22 val PER: 0.3497
2025-11-02 04:08:04,733: t15.2023.11.03 val PER: 0.3969
2025-11-02 04:08:04,733: t15.2023.11.04 val PER: 0.2218
2025-11-02 04:08:04,734: t15.2023.11.17 val PER: 0.2675
2025-11-02 04:08:04,734: t15.2023.11.19 val PER: 0.2695
2025-11-02 04:08:04,734: t15.2023.11.26 val PER: 0.4616
2025-11-02 04:08:04,735: t15.2023.12.03 val PER: 0.3908
2025-11-02 04:08:04,735: t15.2023.12.08 val PER: 0.4048
2025-11-02 04:08:04,735: t15.2023.12.10 val PER: 0.3653
2025-11-02 04:08:04,736: t15.2023.12.17 val PER: 0.4033
2025-11-02 04:08:04,736: t15.2023.12.29 val PER: 0.4214
2025-11-02 04:08:04,736: t15.2024.02.25 val PER: 0.3624
2025-11-02 04:08:04,736: t15.2024.03.08 val PER: 0.4609
2025-11-02 04:08:04,737: t15.2024.03.15 val PER: 0.4434
2025-11-02 04:08:04,737: t15.2024.03.17 val PER: 0.4212
2025-11-02 04:08:04,737: t15.2024.05.10 val PER: 0.4131
2025-11-02 04:08:04,738: t15.2024.06.14 val PER: 0.3991
2025-11-02 04:08:04,738: t15.2024.07.19 val PER: 0.4924
2025-11-02 04:08:04,738: t15.2024.07.21 val PER: 0.3814
2025-11-02 04:08:04,738: t15.2024.07.28 val PER: 0.3971
2025-11-02 04:08:04,739: t15.2025.01.10 val PER: 0.5455
2025-11-02 04:08:04,739: t15.2025.01.12 val PER: 0.4226
2025-11-02 04:08:04,739: t15.2025.03.14 val PER: 0.5636
2025-11-02 04:08:04,740: t15.2025.03.16 val PER: 0.4450
2025-11-02 04:08:04,740: t15.2025.03.30 val PER: 0.5310
2025-11-02 04:08:04,740: t15.2025.04.13 val PER: 0.4579
2025-11-02 04:08:04,741: New best test PER 0.4221 --> 0.4075
2025-11-02 04:08:04,741: Checkpointing model
2025-11-02 04:08:06,695: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:08:31,262: Train batch 16200: loss: 34.40 grad norm: 37.73 time: 0.095
2025-11-02 04:08:55,335: Train batch 16400: loss: 37.09 grad norm: 45.11 time: 0.069
2025-11-02 04:09:19,949: Train batch 16600: loss: 36.98 grad norm: 39.86 time: 0.085
2025-11-02 04:09:44,449: Train batch 16800: loss: 43.78 grad norm: 72.36 time: 0.091
2025-11-02 04:10:09,118: Train batch 17000: loss: 39.52 grad norm: 43.06 time: 0.088
2025-11-02 04:10:09,120: Running test after training batch: 17000
2025-11-02 04:10:21,417: Val batch 17000: PER (avg): 0.3962 CTC Loss (avg): 40.7570 time: 12.297
2025-11-02 04:10:21,419: t15.2023.08.13 val PER: 0.3680
2025-11-02 04:10:21,419: t15.2023.08.18 val PER: 0.3470
2025-11-02 04:10:21,420: t15.2023.08.20 val PER: 0.3431
2025-11-02 04:10:21,420: t15.2023.08.25 val PER: 0.3193
2025-11-02 04:10:21,421: t15.2023.08.27 val PER: 0.4260
2025-11-02 04:10:21,421: t15.2023.09.01 val PER: 0.3117
2025-11-02 04:10:21,422: t15.2023.09.03 val PER: 0.3884
2025-11-02 04:10:21,422: t15.2023.09.24 val PER: 0.3386
2025-11-02 04:10:21,422: t15.2023.09.29 val PER: 0.3650
2025-11-02 04:10:21,423: t15.2023.10.01 val PER: 0.4240
2025-11-02 04:10:21,423: t15.2023.10.06 val PER: 0.3445
2025-11-02 04:10:21,423: t15.2023.10.08 val PER: 0.4628
2025-11-02 04:10:21,424: t15.2023.10.13 val PER: 0.4577
2025-11-02 04:10:21,424: t15.2023.10.15 val PER: 0.3784
2025-11-02 04:10:21,425: t15.2023.10.20 val PER: 0.3691
2025-11-02 04:10:21,425: t15.2023.10.22 val PER: 0.3408
2025-11-02 04:10:21,426: t15.2023.11.03 val PER: 0.3833
2025-11-02 04:10:21,426: t15.2023.11.04 val PER: 0.1980
2025-11-02 04:10:21,426: t15.2023.11.17 val PER: 0.2706
2025-11-02 04:10:21,427: t15.2023.11.19 val PER: 0.2435
2025-11-02 04:10:21,427: t15.2023.11.26 val PER: 0.4493
2025-11-02 04:10:21,428: t15.2023.12.03 val PER: 0.3845
2025-11-02 04:10:21,428: t15.2023.12.08 val PER: 0.3915
2025-11-02 04:10:21,428: t15.2023.12.10 val PER: 0.3443
2025-11-02 04:10:21,429: t15.2023.12.17 val PER: 0.3898
2025-11-02 04:10:21,429: t15.2023.12.29 val PER: 0.4029
2025-11-02 04:10:21,430: t15.2024.02.25 val PER: 0.3427
2025-11-02 04:10:21,430: t15.2024.03.08 val PER: 0.4538
2025-11-02 04:10:21,431: t15.2024.03.15 val PER: 0.4359
2025-11-02 04:10:21,431: t15.2024.03.17 val PER: 0.4163
2025-11-02 04:10:21,431: t15.2024.05.10 val PER: 0.3848
2025-11-02 04:10:21,432: t15.2024.06.14 val PER: 0.3880
2025-11-02 04:10:21,432: t15.2024.07.19 val PER: 0.4852
2025-11-02 04:10:21,432: t15.2024.07.21 val PER: 0.3662
2025-11-02 04:10:21,433: t15.2024.07.28 val PER: 0.3809
2025-11-02 04:10:21,433: t15.2025.01.10 val PER: 0.5427
2025-11-02 04:10:21,433: t15.2025.01.12 val PER: 0.4203
2025-11-02 04:10:21,434: t15.2025.03.14 val PER: 0.5577
2025-11-02 04:10:21,434: t15.2025.03.16 val PER: 0.4346
2025-11-02 04:10:21,434: t15.2025.03.30 val PER: 0.5172
2025-11-02 04:10:21,435: t15.2025.04.13 val PER: 0.4479
2025-11-02 04:10:21,435: New best test PER 0.4075 --> 0.3962
2025-11-02 04:10:21,436: Checkpointing model
2025-11-02 04:10:23,420: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:10:47,831: Train batch 17200: loss: 36.82 grad norm: 58.09 time: 0.071
2025-11-02 04:11:11,940: Train batch 17400: loss: 47.51 grad norm: 66.89 time: 0.091
2025-11-02 04:11:36,061: Train batch 17600: loss: 31.48 grad norm: 39.91 time: 0.082
2025-11-02 04:12:00,190: Train batch 17800: loss: 36.92 grad norm: 37.94 time: 0.125
2025-11-02 04:12:24,991: Train batch 18000: loss: 35.18 grad norm: 39.80 time: 0.069
2025-11-02 04:12:24,992: Running test after training batch: 18000
2025-11-02 04:12:37,490: Val batch 18000: PER (avg): 0.3849 CTC Loss (avg): 39.6893 time: 12.498
2025-11-02 04:12:37,491: t15.2023.08.13 val PER: 0.3617
2025-11-02 04:12:37,491: t15.2023.08.18 val PER: 0.3412
2025-11-02 04:12:37,492: t15.2023.08.20 val PER: 0.3312
2025-11-02 04:12:37,492: t15.2023.08.25 val PER: 0.3102
2025-11-02 04:12:37,493: t15.2023.08.27 val PER: 0.4212
2025-11-02 04:12:37,493: t15.2023.09.01 val PER: 0.2938
2025-11-02 04:12:37,493: t15.2023.09.03 val PER: 0.3765
2025-11-02 04:12:37,494: t15.2023.09.24 val PER: 0.3204
2025-11-02 04:12:37,494: t15.2023.09.29 val PER: 0.3529
2025-11-02 04:12:37,495: t15.2023.10.01 val PER: 0.4069
2025-11-02 04:12:37,495: t15.2023.10.06 val PER: 0.3326
2025-11-02 04:12:37,495: t15.2023.10.08 val PER: 0.4479
2025-11-02 04:12:37,496: t15.2023.10.13 val PER: 0.4445
2025-11-02 04:12:37,496: t15.2023.10.15 val PER: 0.3672
2025-11-02 04:12:37,496: t15.2023.10.20 val PER: 0.3725
2025-11-02 04:12:37,497: t15.2023.10.22 val PER: 0.3296
2025-11-02 04:12:37,497: t15.2023.11.03 val PER: 0.3752
2025-11-02 04:12:37,497: t15.2023.11.04 val PER: 0.2014
2025-11-02 04:12:37,498: t15.2023.11.17 val PER: 0.2613
2025-11-02 04:12:37,498: t15.2023.11.19 val PER: 0.2395
2025-11-02 04:12:37,498: t15.2023.11.26 val PER: 0.4348
2025-11-02 04:12:37,499: t15.2023.12.03 val PER: 0.3761
2025-11-02 04:12:37,503: t15.2023.12.08 val PER: 0.3881
2025-11-02 04:12:37,503: t15.2023.12.10 val PER: 0.3443
2025-11-02 04:12:37,504: t15.2023.12.17 val PER: 0.3753
2025-11-02 04:12:37,504: t15.2023.12.29 val PER: 0.3933
2025-11-02 04:12:37,504: t15.2024.02.25 val PER: 0.3343
2025-11-02 04:12:37,505: t15.2024.03.08 val PER: 0.4523
2025-11-02 04:12:37,505: t15.2024.03.15 val PER: 0.4290
2025-11-02 04:12:37,505: t15.2024.03.17 val PER: 0.3989
2025-11-02 04:12:37,506: t15.2024.05.10 val PER: 0.3774
2025-11-02 04:12:37,506: t15.2024.06.14 val PER: 0.3754
2025-11-02 04:12:37,506: t15.2024.07.19 val PER: 0.4733
2025-11-02 04:12:37,507: t15.2024.07.21 val PER: 0.3531
2025-11-02 04:12:37,507: t15.2024.07.28 val PER: 0.3735
2025-11-02 04:12:37,507: t15.2025.01.10 val PER: 0.5358
2025-11-02 04:12:37,507: t15.2025.01.12 val PER: 0.4103
2025-11-02 04:12:37,508: t15.2025.03.14 val PER: 0.5385
2025-11-02 04:12:37,508: t15.2025.03.16 val PER: 0.4084
2025-11-02 04:12:37,508: t15.2025.03.30 val PER: 0.4805
2025-11-02 04:12:37,509: t15.2025.04.13 val PER: 0.4379
2025-11-02 04:12:37,509: New best test PER 0.3962 --> 0.3849
2025-11-02 04:12:37,510: Checkpointing model
2025-11-02 04:12:39,328: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:13:04,637: Train batch 18200: loss: 35.67 grad norm: 43.63 time: 0.108
2025-11-02 04:13:29,466: Train batch 18400: loss: 31.32 grad norm: 40.23 time: 0.123
2025-11-02 04:13:53,287: Train batch 18600: loss: 27.68 grad norm: 39.05 time: 0.101
2025-11-02 04:14:17,878: Train batch 18800: loss: 36.02 grad norm: 51.23 time: 0.090
2025-11-02 04:14:43,050: Train batch 19000: loss: 35.77 grad norm: 60.44 time: 0.090
2025-11-02 04:14:43,051: Running test after training batch: 19000
2025-11-02 04:14:56,919: Val batch 19000: PER (avg): 0.3749 CTC Loss (avg): 38.6180 time: 13.868
2025-11-02 04:14:56,920: t15.2023.08.13 val PER: 0.3555
2025-11-02 04:14:56,921: t15.2023.08.18 val PER: 0.3277
2025-11-02 04:14:56,921: t15.2023.08.20 val PER: 0.3209
2025-11-02 04:14:56,921: t15.2023.08.25 val PER: 0.3027
2025-11-02 04:14:56,922: t15.2023.08.27 val PER: 0.4084
2025-11-02 04:14:56,922: t15.2023.09.01 val PER: 0.2865
2025-11-02 04:14:56,923: t15.2023.09.03 val PER: 0.3694
2025-11-02 04:14:56,923: t15.2023.09.24 val PER: 0.3131
2025-11-02 04:14:56,923: t15.2023.09.29 val PER: 0.3414
2025-11-02 04:14:56,924: t15.2023.10.01 val PER: 0.4062
2025-11-02 04:14:56,924: t15.2023.10.06 val PER: 0.3122
2025-11-02 04:14:56,924: t15.2023.10.08 val PER: 0.4438
2025-11-02 04:14:56,925: t15.2023.10.13 val PER: 0.4422
2025-11-02 04:14:56,925: t15.2023.10.15 val PER: 0.3586
2025-11-02 04:14:56,925: t15.2023.10.20 val PER: 0.3658
2025-11-02 04:14:56,926: t15.2023.10.22 val PER: 0.3218
2025-11-02 04:14:56,926: t15.2023.11.03 val PER: 0.3718
2025-11-02 04:14:56,926: t15.2023.11.04 val PER: 0.1775
2025-11-02 04:14:56,927: t15.2023.11.17 val PER: 0.2426
2025-11-02 04:14:56,927: t15.2023.11.19 val PER: 0.2176
2025-11-02 04:14:56,927: t15.2023.11.26 val PER: 0.4181
2025-11-02 04:14:56,927: t15.2023.12.03 val PER: 0.3676
2025-11-02 04:14:56,928: t15.2023.12.08 val PER: 0.3788
2025-11-02 04:14:56,928: t15.2023.12.10 val PER: 0.3285
2025-11-02 04:14:56,928: t15.2023.12.17 val PER: 0.3773
2025-11-02 04:14:56,929: t15.2023.12.29 val PER: 0.3789
2025-11-02 04:14:56,929: t15.2024.02.25 val PER: 0.3090
2025-11-02 04:14:56,930: t15.2024.03.08 val PER: 0.4310
2025-11-02 04:14:56,930: t15.2024.03.15 val PER: 0.4165
2025-11-02 04:14:56,930: t15.2024.03.17 val PER: 0.3975
2025-11-02 04:14:56,931: t15.2024.05.10 val PER: 0.3670
2025-11-02 04:14:56,931: t15.2024.06.14 val PER: 0.3565
2025-11-02 04:14:56,931: t15.2024.07.19 val PER: 0.4621
2025-11-02 04:14:56,932: t15.2024.07.21 val PER: 0.3372
2025-11-02 04:14:56,932: t15.2024.07.28 val PER: 0.3640
2025-11-02 04:14:56,932: t15.2025.01.10 val PER: 0.5110
2025-11-02 04:14:56,932: t15.2025.01.12 val PER: 0.4026
2025-11-02 04:14:56,933: t15.2025.03.14 val PER: 0.5325
2025-11-02 04:14:56,933: t15.2025.03.16 val PER: 0.4058
2025-11-02 04:14:56,933: t15.2025.03.30 val PER: 0.4747
2025-11-02 04:14:56,933: t15.2025.04.13 val PER: 0.4322
2025-11-02 04:14:56,934: New best test PER 0.3849 --> 0.3749
2025-11-02 04:14:56,934: Checkpointing model
2025-11-02 04:14:58,861: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:15:23,591: Train batch 19200: loss: 19.71 grad norm: 30.70 time: 0.066
2025-11-02 04:15:47,698: Train batch 19400: loss: 26.36 grad norm: 30.21 time: 0.061
2025-11-02 04:16:12,338: Train batch 19600: loss: 42.76 grad norm: 55.33 time: 0.073
2025-11-02 04:16:37,199: Train batch 19800: loss: 40.91 grad norm: 47.27 time: 0.101
2025-11-02 04:17:02,353: Train batch 20000: loss: 39.15 grad norm: 39.79 time: 0.103
2025-11-02 04:17:02,355: Running test after training batch: 20000
2025-11-02 04:17:15,815: Val batch 20000: PER (avg): 0.3656 CTC Loss (avg): 37.6921 time: 13.459
2025-11-02 04:17:15,816: t15.2023.08.13 val PER: 0.3472
2025-11-02 04:17:15,816: t15.2023.08.18 val PER: 0.3185
2025-11-02 04:17:15,816: t15.2023.08.20 val PER: 0.3106
2025-11-02 04:17:15,817: t15.2023.08.25 val PER: 0.2907
2025-11-02 04:17:15,817: t15.2023.08.27 val PER: 0.4003
2025-11-02 04:17:15,817: t15.2023.09.01 val PER: 0.2817
2025-11-02 04:17:15,818: t15.2023.09.03 val PER: 0.3563
2025-11-02 04:17:15,818: t15.2023.09.24 val PER: 0.2985
2025-11-02 04:17:15,818: t15.2023.09.29 val PER: 0.3350
2025-11-02 04:17:15,819: t15.2023.10.01 val PER: 0.3904
2025-11-02 04:17:15,819: t15.2023.10.06 val PER: 0.3132
2025-11-02 04:17:15,820: t15.2023.10.08 val PER: 0.4371
2025-11-02 04:17:15,820: t15.2023.10.13 val PER: 0.4352
2025-11-02 04:17:15,820: t15.2023.10.15 val PER: 0.3514
2025-11-02 04:17:15,820: t15.2023.10.20 val PER: 0.3356
2025-11-02 04:17:15,821: t15.2023.10.22 val PER: 0.3107
2025-11-02 04:17:15,821: t15.2023.11.03 val PER: 0.3569
2025-11-02 04:17:15,821: t15.2023.11.04 val PER: 0.1638
2025-11-02 04:17:15,822: t15.2023.11.17 val PER: 0.2317
2025-11-02 04:17:15,822: t15.2023.11.19 val PER: 0.2196
2025-11-02 04:17:15,822: t15.2023.11.26 val PER: 0.4043
2025-11-02 04:17:15,822: t15.2023.12.03 val PER: 0.3561
2025-11-02 04:17:15,823: t15.2023.12.08 val PER: 0.3695
2025-11-02 04:17:15,823: t15.2023.12.10 val PER: 0.3206
2025-11-02 04:17:15,823: t15.2023.12.17 val PER: 0.3607
2025-11-02 04:17:15,824: t15.2023.12.29 val PER: 0.3706
2025-11-02 04:17:15,824: t15.2024.02.25 val PER: 0.2992
2025-11-02 04:17:15,824: t15.2024.03.08 val PER: 0.4225
2025-11-02 04:17:15,825: t15.2024.03.15 val PER: 0.4065
2025-11-02 04:17:15,825: t15.2024.03.17 val PER: 0.3919
2025-11-02 04:17:15,825: t15.2024.05.10 val PER: 0.3655
2025-11-02 04:17:15,825: t15.2024.06.14 val PER: 0.3549
2025-11-02 04:17:15,826: t15.2024.07.19 val PER: 0.4522
2025-11-02 04:17:15,826: t15.2024.07.21 val PER: 0.3310
2025-11-02 04:17:15,826: t15.2024.07.28 val PER: 0.3559
2025-11-02 04:17:15,826: t15.2025.01.10 val PER: 0.5028
2025-11-02 04:17:15,827: t15.2025.01.12 val PER: 0.3934
2025-11-02 04:17:15,827: t15.2025.03.14 val PER: 0.5237
2025-11-02 04:17:15,827: t15.2025.03.16 val PER: 0.4045
2025-11-02 04:17:15,827: t15.2025.03.30 val PER: 0.4586
2025-11-02 04:17:15,828: t15.2025.04.13 val PER: 0.4180
2025-11-02 04:17:15,828: New best test PER 0.3749 --> 0.3656
2025-11-02 04:17:15,828: Checkpointing model
2025-11-02 04:17:17,848: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:17:42,957: Train batch 20200: loss: 23.69 grad norm: 35.75 time: 0.071
2025-11-02 04:18:07,452: Train batch 20400: loss: 37.33 grad norm: 46.80 time: 0.102
2025-11-02 04:18:32,486: Train batch 20600: loss: 35.05 grad norm: 41.87 time: 0.093
2025-11-02 04:18:57,443: Train batch 20800: loss: 39.82 grad norm: 55.32 time: 0.124
2025-11-02 04:19:21,852: Train batch 21000: loss: 28.66 grad norm: 33.77 time: 0.082
2025-11-02 04:19:21,853: Running test after training batch: 21000
2025-11-02 04:19:35,337: Val batch 21000: PER (avg): 0.3573 CTC Loss (avg): 36.7539 time: 13.483
2025-11-02 04:19:35,337: t15.2023.08.13 val PER: 0.3420
2025-11-02 04:19:35,338: t15.2023.08.18 val PER: 0.3051
2025-11-02 04:19:35,338: t15.2023.08.20 val PER: 0.3018
2025-11-02 04:19:35,384: t15.2023.08.25 val PER: 0.2907
2025-11-02 04:19:35,384: t15.2023.08.27 val PER: 0.3923
2025-11-02 04:19:35,385: t15.2023.09.01 val PER: 0.2679
2025-11-02 04:19:35,385: t15.2023.09.03 val PER: 0.3480
2025-11-02 04:19:35,386: t15.2023.09.24 val PER: 0.2985
2025-11-02 04:19:35,386: t15.2023.09.29 val PER: 0.3210
2025-11-02 04:19:35,386: t15.2023.10.01 val PER: 0.3851
2025-11-02 04:19:35,387: t15.2023.10.06 val PER: 0.3025
2025-11-02 04:19:35,387: t15.2023.10.08 val PER: 0.4222
2025-11-02 04:19:35,387: t15.2023.10.13 val PER: 0.4228
2025-11-02 04:19:35,388: t15.2023.10.15 val PER: 0.3454
2025-11-02 04:19:35,388: t15.2023.10.20 val PER: 0.3255
2025-11-02 04:19:35,389: t15.2023.10.22 val PER: 0.3096
2025-11-02 04:19:35,389: t15.2023.11.03 val PER: 0.3494
2025-11-02 04:19:35,390: t15.2023.11.04 val PER: 0.1604
2025-11-02 04:19:35,390: t15.2023.11.17 val PER: 0.2240
2025-11-02 04:19:35,391: t15.2023.11.19 val PER: 0.2136
2025-11-02 04:19:35,391: t15.2023.11.26 val PER: 0.4014
2025-11-02 04:19:35,391: t15.2023.12.03 val PER: 0.3540
2025-11-02 04:19:35,392: t15.2023.12.08 val PER: 0.3635
2025-11-02 04:19:35,392: t15.2023.12.10 val PER: 0.3180
2025-11-02 04:19:35,393: t15.2023.12.17 val PER: 0.3649
2025-11-02 04:19:35,393: t15.2023.12.29 val PER: 0.3631
2025-11-02 04:19:35,393: t15.2024.02.25 val PER: 0.2935
2025-11-02 04:19:35,394: t15.2024.03.08 val PER: 0.4097
2025-11-02 04:19:35,394: t15.2024.03.15 val PER: 0.3971
2025-11-02 04:19:35,395: t15.2024.03.17 val PER: 0.3759
2025-11-02 04:19:35,395: t15.2024.05.10 val PER: 0.3715
2025-11-02 04:19:35,395: t15.2024.06.14 val PER: 0.3502
2025-11-02 04:19:35,396: t15.2024.07.19 val PER: 0.4430
2025-11-02 04:19:35,396: t15.2024.07.21 val PER: 0.3145
2025-11-02 04:19:35,396: t15.2024.07.28 val PER: 0.3404
2025-11-02 04:19:35,397: t15.2025.01.10 val PER: 0.4959
2025-11-02 04:19:35,397: t15.2025.01.12 val PER: 0.3734
2025-11-02 04:19:35,397: t15.2025.03.14 val PER: 0.5207
2025-11-02 04:19:35,397: t15.2025.03.16 val PER: 0.3940
2025-11-02 04:19:35,398: t15.2025.03.30 val PER: 0.4483
2025-11-02 04:19:35,398: t15.2025.04.13 val PER: 0.4165
2025-11-02 04:19:35,399: New best test PER 0.3656 --> 0.3573
2025-11-02 04:19:35,399: Checkpointing model
2025-11-02 04:19:37,338: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:20:03,064: Train batch 21200: loss: 31.43 grad norm: 42.62 time: 0.058
2025-11-02 04:20:28,557: Train batch 21400: loss: 36.31 grad norm: 47.22 time: 0.105
2025-11-02 04:20:53,014: Train batch 21600: loss: 37.99 grad norm: 55.44 time: 0.099
2025-11-02 04:21:17,513: Train batch 21800: loss: 32.39 grad norm: 37.55 time: 0.074
2025-11-02 04:21:41,621: Train batch 22000: loss: 37.85 grad norm: 46.67 time: 0.079
2025-11-02 04:21:41,622: Running test after training batch: 22000
2025-11-02 04:21:54,411: Val batch 22000: PER (avg): 0.3484 CTC Loss (avg): 35.8646 time: 12.789
2025-11-02 04:21:54,412: t15.2023.08.13 val PER: 0.3316
2025-11-02 04:21:54,412: t15.2023.08.18 val PER: 0.2967
2025-11-02 04:21:54,413: t15.2023.08.20 val PER: 0.2971
2025-11-02 04:21:54,413: t15.2023.08.25 val PER: 0.2711
2025-11-02 04:21:54,414: t15.2023.08.27 val PER: 0.3891
2025-11-02 04:21:54,414: t15.2023.09.01 val PER: 0.2597
2025-11-02 04:21:54,415: t15.2023.09.03 val PER: 0.3349
2025-11-02 04:21:54,415: t15.2023.09.24 val PER: 0.2937
2025-11-02 04:21:54,415: t15.2023.09.29 val PER: 0.3127
2025-11-02 04:21:54,416: t15.2023.10.01 val PER: 0.3752
2025-11-02 04:21:54,416: t15.2023.10.06 val PER: 0.2853
2025-11-02 04:21:54,416: t15.2023.10.08 val PER: 0.4208
2025-11-02 04:21:54,417: t15.2023.10.13 val PER: 0.4112
2025-11-02 04:21:54,417: t15.2023.10.15 val PER: 0.3355
2025-11-02 04:21:54,417: t15.2023.10.20 val PER: 0.3054
2025-11-02 04:21:54,418: t15.2023.10.22 val PER: 0.2996
2025-11-02 04:21:54,418: t15.2023.11.03 val PER: 0.3467
2025-11-02 04:21:54,418: t15.2023.11.04 val PER: 0.1468
2025-11-02 04:21:54,419: t15.2023.11.17 val PER: 0.2193
2025-11-02 04:21:54,419: t15.2023.11.19 val PER: 0.1976
2025-11-02 04:21:54,420: t15.2023.11.26 val PER: 0.3891
2025-11-02 04:21:54,420: t15.2023.12.03 val PER: 0.3351
2025-11-02 04:21:54,420: t15.2023.12.08 val PER: 0.3529
2025-11-02 04:21:54,421: t15.2023.12.10 val PER: 0.3075
2025-11-02 04:21:54,421: t15.2023.12.17 val PER: 0.3482
2025-11-02 04:21:54,421: t15.2023.12.29 val PER: 0.3528
2025-11-02 04:21:54,422: t15.2024.02.25 val PER: 0.2809
2025-11-02 04:21:54,422: t15.2024.03.08 val PER: 0.4196
2025-11-02 04:21:54,422: t15.2024.03.15 val PER: 0.3852
2025-11-02 04:21:54,422: t15.2024.03.17 val PER: 0.3675
2025-11-02 04:21:54,423: t15.2024.05.10 val PER: 0.3655
2025-11-02 04:21:54,423: t15.2024.06.14 val PER: 0.3360
2025-11-02 04:21:54,424: t15.2024.07.19 val PER: 0.4364
2025-11-02 04:21:54,424: t15.2024.07.21 val PER: 0.3062
2025-11-02 04:21:54,425: t15.2024.07.28 val PER: 0.3419
2025-11-02 04:21:54,425: t15.2025.01.10 val PER: 0.4890
2025-11-02 04:21:54,425: t15.2025.01.12 val PER: 0.3672
2025-11-02 04:21:54,426: t15.2025.03.14 val PER: 0.5044
2025-11-02 04:21:54,426: t15.2025.03.16 val PER: 0.3874
2025-11-02 04:21:54,426: t15.2025.03.30 val PER: 0.4460
2025-11-02 04:21:54,427: t15.2025.04.13 val PER: 0.4066
2025-11-02 04:21:54,427: New best test PER 0.3573 --> 0.3484
2025-11-02 04:21:54,427: Checkpointing model
2025-11-02 04:21:56,217: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:22:21,087: Train batch 22200: loss: 33.64 grad norm: 46.13 time: 0.085
2025-11-02 04:22:45,284: Train batch 22400: loss: 35.73 grad norm: 49.40 time: 0.071
2025-11-02 04:23:09,957: Train batch 22600: loss: 30.57 grad norm: 38.80 time: 0.074
2025-11-02 04:23:34,383: Train batch 22800: loss: 28.35 grad norm: 37.19 time: 0.071
2025-11-02 04:23:58,791: Train batch 23000: loss: 29.30 grad norm: 46.67 time: 0.099
2025-11-02 04:23:58,793: Running test after training batch: 23000
2025-11-02 04:24:12,318: Val batch 23000: PER (avg): 0.3424 CTC Loss (avg): 35.1130 time: 13.525
2025-11-02 04:24:12,319: t15.2023.08.13 val PER: 0.3222
2025-11-02 04:24:12,319: t15.2023.08.18 val PER: 0.2917
2025-11-02 04:24:12,320: t15.2023.08.20 val PER: 0.2883
2025-11-02 04:24:12,320: t15.2023.08.25 val PER: 0.2651
2025-11-02 04:24:12,321: t15.2023.08.27 val PER: 0.3826
2025-11-02 04:24:12,321: t15.2023.09.01 val PER: 0.2524
2025-11-02 04:24:12,321: t15.2023.09.03 val PER: 0.3361
2025-11-02 04:24:12,322: t15.2023.09.24 val PER: 0.2852
2025-11-02 04:24:12,322: t15.2023.09.29 val PER: 0.3025
2025-11-02 04:24:12,323: t15.2023.10.01 val PER: 0.3686
2025-11-02 04:24:12,323: t15.2023.10.06 val PER: 0.2756
2025-11-02 04:24:12,323: t15.2023.10.08 val PER: 0.4127
2025-11-02 04:24:12,324: t15.2023.10.13 val PER: 0.4057
2025-11-02 04:24:12,324: t15.2023.10.15 val PER: 0.3296
2025-11-02 04:24:12,325: t15.2023.10.20 val PER: 0.3054
2025-11-02 04:24:12,325: t15.2023.10.22 val PER: 0.2962
2025-11-02 04:24:12,325: t15.2023.11.03 val PER: 0.3365
2025-11-02 04:24:12,326: t15.2023.11.04 val PER: 0.1331
2025-11-02 04:24:12,326: t15.2023.11.17 val PER: 0.2193
2025-11-02 04:24:12,326: t15.2023.11.19 val PER: 0.1936
2025-11-02 04:24:12,326: t15.2023.11.26 val PER: 0.3899
2025-11-02 04:24:12,327: t15.2023.12.03 val PER: 0.3372
2025-11-02 04:24:12,327: t15.2023.12.08 val PER: 0.3422
2025-11-02 04:24:12,327: t15.2023.12.10 val PER: 0.2983
2025-11-02 04:24:12,328: t15.2023.12.17 val PER: 0.3420
2025-11-02 04:24:12,328: t15.2023.12.29 val PER: 0.3445
2025-11-02 04:24:12,328: t15.2024.02.25 val PER: 0.2767
2025-11-02 04:24:12,329: t15.2024.03.08 val PER: 0.4026
2025-11-02 04:24:12,329: t15.2024.03.15 val PER: 0.3859
2025-11-02 04:24:12,330: t15.2024.03.17 val PER: 0.3556
2025-11-02 04:24:12,330: t15.2024.05.10 val PER: 0.3611
2025-11-02 04:24:12,330: t15.2024.06.14 val PER: 0.3344
2025-11-02 04:24:12,331: t15.2024.07.19 val PER: 0.4331
2025-11-02 04:24:12,331: t15.2024.07.21 val PER: 0.3055
2025-11-02 04:24:12,331: t15.2024.07.28 val PER: 0.3375
2025-11-02 04:24:12,331: t15.2025.01.10 val PER: 0.4862
2025-11-02 04:24:12,332: t15.2025.01.12 val PER: 0.3587
2025-11-02 04:24:12,332: t15.2025.03.14 val PER: 0.4926
2025-11-02 04:24:12,332: t15.2025.03.16 val PER: 0.3783
2025-11-02 04:24:12,332: t15.2025.03.30 val PER: 0.4391
2025-11-02 04:24:12,333: t15.2025.04.13 val PER: 0.4123
2025-11-02 04:24:12,333: New best test PER 0.3484 --> 0.3424
2025-11-02 04:24:12,333: Checkpointing model
2025-11-02 04:24:14,378: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:24:39,388: Train batch 23200: loss: 26.97 grad norm: 35.37 time: 0.052
2025-11-02 04:25:04,609: Train batch 23400: loss: 37.20 grad norm: 46.69 time: 0.092
2025-11-02 04:25:29,045: Train batch 23600: loss: 27.27 grad norm: 54.36 time: 0.076
2025-11-02 04:25:54,133: Train batch 23800: loss: 37.70 grad norm: 52.68 time: 0.124
2025-11-02 04:26:18,074: Train batch 24000: loss: 28.49 grad norm: 42.03 time: 0.077
2025-11-02 04:26:18,075: Running test after training batch: 24000
2025-11-02 04:26:31,318: Val batch 24000: PER (avg): 0.3346 CTC Loss (avg): 34.3588 time: 13.242
2025-11-02 04:26:31,319: t15.2023.08.13 val PER: 0.3139
2025-11-02 04:26:31,320: t15.2023.08.18 val PER: 0.2816
2025-11-02 04:26:31,320: t15.2023.08.20 val PER: 0.2836
2025-11-02 04:26:31,320: t15.2023.08.25 val PER: 0.2575
2025-11-02 04:26:31,321: t15.2023.08.27 val PER: 0.3714
2025-11-02 04:26:31,321: t15.2023.09.01 val PER: 0.2403
2025-11-02 04:26:31,322: t15.2023.09.03 val PER: 0.3314
2025-11-02 04:26:31,322: t15.2023.09.24 val PER: 0.2876
2025-11-02 04:26:31,322: t15.2023.09.29 val PER: 0.3006
2025-11-02 04:26:31,323: t15.2023.10.01 val PER: 0.3560
2025-11-02 04:26:31,323: t15.2023.10.06 val PER: 0.2637
2025-11-02 04:26:31,323: t15.2023.10.08 val PER: 0.4087
2025-11-02 04:26:31,324: t15.2023.10.13 val PER: 0.3972
2025-11-02 04:26:31,324: t15.2023.10.15 val PER: 0.3158
2025-11-02 04:26:31,325: t15.2023.10.20 val PER: 0.3054
2025-11-02 04:26:31,325: t15.2023.10.22 val PER: 0.2906
2025-11-02 04:26:31,325: t15.2023.11.03 val PER: 0.3338
2025-11-02 04:26:31,326: t15.2023.11.04 val PER: 0.1297
2025-11-02 04:26:31,326: t15.2023.11.17 val PER: 0.2053
2025-11-02 04:26:31,326: t15.2023.11.19 val PER: 0.1836
2025-11-02 04:26:31,327: t15.2023.11.26 val PER: 0.3746
2025-11-02 04:26:31,327: t15.2023.12.03 val PER: 0.3235
2025-11-02 04:26:31,327: t15.2023.12.08 val PER: 0.3395
2025-11-02 04:26:31,327: t15.2023.12.10 val PER: 0.2891
2025-11-02 04:26:31,328: t15.2023.12.17 val PER: 0.3378
2025-11-02 04:26:31,328: t15.2023.12.29 val PER: 0.3370
2025-11-02 04:26:31,328: t15.2024.02.25 val PER: 0.2739
2025-11-02 04:26:31,329: t15.2024.03.08 val PER: 0.4026
2025-11-02 04:26:31,329: t15.2024.03.15 val PER: 0.3765
2025-11-02 04:26:31,330: t15.2024.03.17 val PER: 0.3480
2025-11-02 04:26:31,330: t15.2024.05.10 val PER: 0.3522
2025-11-02 04:26:31,330: t15.2024.06.14 val PER: 0.3249
2025-11-02 04:26:31,331: t15.2024.07.19 val PER: 0.4179
2025-11-02 04:26:31,331: t15.2024.07.21 val PER: 0.2959
2025-11-02 04:26:31,331: t15.2024.07.28 val PER: 0.3250
2025-11-02 04:26:31,331: t15.2025.01.10 val PER: 0.4876
2025-11-02 04:26:31,332: t15.2025.01.12 val PER: 0.3541
2025-11-02 04:26:31,332: t15.2025.03.14 val PER: 0.4911
2025-11-02 04:26:31,332: t15.2025.03.16 val PER: 0.3822
2025-11-02 04:26:31,332: t15.2025.03.30 val PER: 0.4287
2025-11-02 04:26:31,333: t15.2025.04.13 val PER: 0.3980
2025-11-02 04:26:31,333: New best test PER 0.3424 --> 0.3346
2025-11-02 04:26:31,333: Checkpointing model
2025-11-02 04:26:33,249: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:26:57,640: Train batch 24200: loss: 30.67 grad norm: 48.63 time: 0.074
2025-11-02 04:27:22,395: Train batch 24400: loss: 28.68 grad norm: 39.39 time: 0.079
2025-11-02 04:27:46,659: Train batch 24600: loss: 33.94 grad norm: 57.22 time: 0.112
2025-11-02 04:28:11,124: Train batch 24800: loss: 25.02 grad norm: 39.74 time: 0.068
2025-11-02 04:28:35,844: Train batch 25000: loss: 27.01 grad norm: 40.03 time: 0.065
2025-11-02 04:28:35,845: Running test after training batch: 25000
2025-11-02 04:28:48,922: Val batch 25000: PER (avg): 0.3281 CTC Loss (avg): 33.6516 time: 13.077
2025-11-02 04:28:48,923: t15.2023.08.13 val PER: 0.3087
2025-11-02 04:28:48,923: t15.2023.08.18 val PER: 0.2741
2025-11-02 04:28:48,924: t15.2023.08.20 val PER: 0.2780
2025-11-02 04:28:48,924: t15.2023.08.25 val PER: 0.2545
2025-11-02 04:28:48,925: t15.2023.08.27 val PER: 0.3585
2025-11-02 04:28:48,925: t15.2023.09.01 val PER: 0.2370
2025-11-02 04:28:48,925: t15.2023.09.03 val PER: 0.3230
2025-11-02 04:28:48,925: t15.2023.09.24 val PER: 0.2767
2025-11-02 04:28:48,926: t15.2023.09.29 val PER: 0.2846
2025-11-02 04:28:48,926: t15.2023.10.01 val PER: 0.3514
2025-11-02 04:28:48,926: t15.2023.10.06 val PER: 0.2659
2025-11-02 04:28:48,926: t15.2023.10.08 val PER: 0.3924
2025-11-02 04:28:48,927: t15.2023.10.13 val PER: 0.3902
2025-11-02 04:28:48,927: t15.2023.10.15 val PER: 0.3105
2025-11-02 04:28:48,927: t15.2023.10.20 val PER: 0.3020
2025-11-02 04:28:48,927: t15.2023.10.22 val PER: 0.2851
2025-11-02 04:28:48,928: t15.2023.11.03 val PER: 0.3318
2025-11-02 04:28:48,928: t15.2023.11.04 val PER: 0.1399
2025-11-02 04:28:48,928: t15.2023.11.17 val PER: 0.2006
2025-11-02 04:28:48,928: t15.2023.11.19 val PER: 0.1717
2025-11-02 04:28:48,929: t15.2023.11.26 val PER: 0.3601
2025-11-02 04:28:48,929: t15.2023.12.03 val PER: 0.3183
2025-11-02 04:28:48,929: t15.2023.12.08 val PER: 0.3249
2025-11-02 04:28:48,930: t15.2023.12.10 val PER: 0.2773
2025-11-02 04:28:48,930: t15.2023.12.17 val PER: 0.3326
2025-11-02 04:28:48,930: t15.2023.12.29 val PER: 0.3315
2025-11-02 04:28:48,930: t15.2024.02.25 val PER: 0.2669
2025-11-02 04:28:48,930: t15.2024.03.08 val PER: 0.3969
2025-11-02 04:28:48,931: t15.2024.03.15 val PER: 0.3715
2025-11-02 04:28:48,931: t15.2024.03.17 val PER: 0.3466
2025-11-02 04:28:48,931: t15.2024.05.10 val PER: 0.3373
2025-11-02 04:28:48,931: t15.2024.06.14 val PER: 0.3233
2025-11-02 04:28:48,932: t15.2024.07.19 val PER: 0.4153
2025-11-02 04:28:48,932: t15.2024.07.21 val PER: 0.2869
2025-11-02 04:28:48,932: t15.2024.07.28 val PER: 0.3213
2025-11-02 04:28:48,932: t15.2025.01.10 val PER: 0.4876
2025-11-02 04:28:48,933: t15.2025.01.12 val PER: 0.3503
2025-11-02 04:28:48,933: t15.2025.03.14 val PER: 0.4911
2025-11-02 04:28:48,933: t15.2025.03.16 val PER: 0.3599
2025-11-02 04:28:48,933: t15.2025.03.30 val PER: 0.4310
2025-11-02 04:28:48,934: t15.2025.04.13 val PER: 0.3937
2025-11-02 04:28:48,934: New best test PER 0.3346 --> 0.3281
2025-11-02 04:28:48,934: Checkpointing model
2025-11-02 04:28:50,710: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:29:15,683: Train batch 25200: loss: 29.57 grad norm: 47.38 time: 0.066
2025-11-02 04:29:40,117: Train batch 25400: loss: 29.47 grad norm: 43.64 time: 0.110
2025-11-02 04:30:04,940: Train batch 25600: loss: 32.01 grad norm: 47.78 time: 0.068
2025-11-02 04:30:29,323: Train batch 25800: loss: 25.54 grad norm: 42.16 time: 0.080
2025-11-02 04:30:53,951: Train batch 26000: loss: 26.05 grad norm: 49.04 time: 0.059
2025-11-02 04:30:53,952: Running test after training batch: 26000
2025-11-02 04:31:07,349: Val batch 26000: PER (avg): 0.3219 CTC Loss (avg): 33.0410 time: 13.397
2025-11-02 04:31:07,350: t15.2023.08.13 val PER: 0.3046
2025-11-02 04:31:07,350: t15.2023.08.18 val PER: 0.2674
2025-11-02 04:31:07,351: t15.2023.08.20 val PER: 0.2693
2025-11-02 04:31:07,351: t15.2023.08.25 val PER: 0.2455
2025-11-02 04:31:07,351: t15.2023.08.27 val PER: 0.3537
2025-11-02 04:31:07,352: t15.2023.09.01 val PER: 0.2289
2025-11-02 04:31:07,352: t15.2023.09.03 val PER: 0.3159
2025-11-02 04:31:07,352: t15.2023.09.24 val PER: 0.2706
2025-11-02 04:31:07,352: t15.2023.09.29 val PER: 0.2782
2025-11-02 04:31:07,353: t15.2023.10.01 val PER: 0.3375
2025-11-02 04:31:07,384: t15.2023.10.06 val PER: 0.2476
2025-11-02 04:31:07,384: t15.2023.10.08 val PER: 0.4046
2025-11-02 04:31:07,385: t15.2023.10.13 val PER: 0.3840
2025-11-02 04:31:07,385: t15.2023.10.15 val PER: 0.3118
2025-11-02 04:31:07,385: t15.2023.10.20 val PER: 0.2953
2025-11-02 04:31:07,386: t15.2023.10.22 val PER: 0.2784
2025-11-02 04:31:07,386: t15.2023.11.03 val PER: 0.3236
2025-11-02 04:31:07,386: t15.2023.11.04 val PER: 0.1229
2025-11-02 04:31:07,386: t15.2023.11.17 val PER: 0.1882
2025-11-02 04:31:07,387: t15.2023.11.19 val PER: 0.1776
2025-11-02 04:31:07,387: t15.2023.11.26 val PER: 0.3507
2025-11-02 04:31:07,387: t15.2023.12.03 val PER: 0.3088
2025-11-02 04:31:07,387: t15.2023.12.08 val PER: 0.3182
2025-11-02 04:31:07,388: t15.2023.12.10 val PER: 0.2720
2025-11-02 04:31:07,388: t15.2023.12.17 val PER: 0.3191
2025-11-02 04:31:07,388: t15.2023.12.29 val PER: 0.3301
2025-11-02 04:31:07,389: t15.2024.02.25 val PER: 0.2612
2025-11-02 04:31:07,389: t15.2024.03.08 val PER: 0.3826
2025-11-02 04:31:07,389: t15.2024.03.15 val PER: 0.3709
2025-11-02 04:31:07,390: t15.2024.03.17 val PER: 0.3382
2025-11-02 04:31:07,390: t15.2024.05.10 val PER: 0.3373
2025-11-02 04:31:07,390: t15.2024.06.14 val PER: 0.3139
2025-11-02 04:31:07,391: t15.2024.07.19 val PER: 0.4094
2025-11-02 04:31:07,391: t15.2024.07.21 val PER: 0.2793
2025-11-02 04:31:07,391: t15.2024.07.28 val PER: 0.3169
2025-11-02 04:31:07,391: t15.2025.01.10 val PER: 0.4807
2025-11-02 04:31:07,392: t15.2025.01.12 val PER: 0.3441
2025-11-02 04:31:07,392: t15.2025.03.14 val PER: 0.4852
2025-11-02 04:31:07,392: t15.2025.03.16 val PER: 0.3652
2025-11-02 04:31:07,392: t15.2025.03.30 val PER: 0.4253
2025-11-02 04:31:07,393: t15.2025.04.13 val PER: 0.3923
2025-11-02 04:31:07,393: New best test PER 0.3281 --> 0.3219
2025-11-02 04:31:07,393: Checkpointing model
2025-11-02 04:31:09,050: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:31:34,050: Train batch 26200: loss: 28.46 grad norm: 46.75 time: 0.085
2025-11-02 04:31:58,088: Train batch 26400: loss: 22.72 grad norm: 34.11 time: 0.096
2025-11-02 04:32:22,019: Train batch 26600: loss: 35.81 grad norm: 55.73 time: 0.082
2025-11-02 04:32:46,317: Train batch 26800: loss: 30.71 grad norm: 50.55 time: 0.080
2025-11-02 04:33:10,042: Train batch 27000: loss: 31.10 grad norm: 54.47 time: 0.066
2025-11-02 04:33:10,043: Running test after training batch: 27000
2025-11-02 04:33:22,718: Val batch 27000: PER (avg): 0.3166 CTC Loss (avg): 32.4323 time: 12.674
2025-11-02 04:33:22,718: t15.2023.08.13 val PER: 0.2994
2025-11-02 04:33:22,719: t15.2023.08.18 val PER: 0.2624
2025-11-02 04:33:22,720: t15.2023.08.20 val PER: 0.2573
2025-11-02 04:33:22,720: t15.2023.08.25 val PER: 0.2410
2025-11-02 04:33:22,721: t15.2023.08.27 val PER: 0.3424
2025-11-02 04:33:22,721: t15.2023.09.01 val PER: 0.2216
2025-11-02 04:33:22,721: t15.2023.09.03 val PER: 0.3135
2025-11-02 04:33:22,722: t15.2023.09.24 val PER: 0.2621
2025-11-02 04:33:22,722: t15.2023.09.29 val PER: 0.2750
2025-11-02 04:33:22,722: t15.2023.10.01 val PER: 0.3342
2025-11-02 04:33:22,723: t15.2023.10.06 val PER: 0.2433
2025-11-02 04:33:22,723: t15.2023.10.08 val PER: 0.4005
2025-11-02 04:33:22,723: t15.2023.10.13 val PER: 0.3894
2025-11-02 04:33:22,724: t15.2023.10.15 val PER: 0.2914
2025-11-02 04:33:22,724: t15.2023.10.20 val PER: 0.2987
2025-11-02 04:33:22,725: t15.2023.10.22 val PER: 0.2684
2025-11-02 04:33:22,725: t15.2023.11.03 val PER: 0.3209
2025-11-02 04:33:22,725: t15.2023.11.04 val PER: 0.1195
2025-11-02 04:33:22,726: t15.2023.11.17 val PER: 0.1928
2025-11-02 04:33:22,726: t15.2023.11.19 val PER: 0.1717
2025-11-02 04:33:22,726: t15.2023.11.26 val PER: 0.3457
2025-11-02 04:33:22,726: t15.2023.12.03 val PER: 0.3025
2025-11-02 04:33:22,727: t15.2023.12.08 val PER: 0.3216
2025-11-02 04:33:22,727: t15.2023.12.10 val PER: 0.2641
2025-11-02 04:33:22,727: t15.2023.12.17 val PER: 0.3212
2025-11-02 04:33:22,728: t15.2023.12.29 val PER: 0.3260
2025-11-02 04:33:22,728: t15.2024.02.25 val PER: 0.2556
2025-11-02 04:33:22,728: t15.2024.03.08 val PER: 0.3826
2025-11-02 04:33:22,728: t15.2024.03.15 val PER: 0.3684
2025-11-02 04:33:22,729: t15.2024.03.17 val PER: 0.3278
2025-11-02 04:33:22,729: t15.2024.05.10 val PER: 0.3269
2025-11-02 04:33:22,730: t15.2024.06.14 val PER: 0.3123
2025-11-02 04:33:22,730: t15.2024.07.19 val PER: 0.4061
2025-11-02 04:33:22,730: t15.2024.07.21 val PER: 0.2731
2025-11-02 04:33:22,731: t15.2024.07.28 val PER: 0.3059
2025-11-02 04:33:22,731: t15.2025.01.10 val PER: 0.4725
2025-11-02 04:33:22,731: t15.2025.01.12 val PER: 0.3356
2025-11-02 04:33:22,731: t15.2025.03.14 val PER: 0.4763
2025-11-02 04:33:22,732: t15.2025.03.16 val PER: 0.3560
2025-11-02 04:33:22,732: t15.2025.03.30 val PER: 0.4253
2025-11-02 04:33:22,732: t15.2025.04.13 val PER: 0.3880
2025-11-02 04:33:22,732: New best test PER 0.3219 --> 0.3166
2025-11-02 04:33:22,733: Checkpointing model
2025-11-02 04:33:24,297: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:33:49,328: Train batch 27200: loss: 28.89 grad norm: 53.79 time: 0.081
2025-11-02 04:34:13,362: Train batch 27400: loss: 32.58 grad norm: 45.66 time: 0.094
2025-11-02 04:34:37,384: Train batch 27600: loss: 28.33 grad norm: 42.69 time: 0.089
2025-11-02 04:35:01,454: Train batch 27800: loss: 29.13 grad norm: 41.11 time: 0.124
2025-11-02 04:35:25,472: Train batch 28000: loss: 26.45 grad norm: 41.54 time: 0.087
2025-11-02 04:35:25,473: Running test after training batch: 28000
2025-11-02 04:35:38,917: Val batch 28000: PER (avg): 0.3119 CTC Loss (avg): 31.8609 time: 13.444
2025-11-02 04:35:38,918: t15.2023.08.13 val PER: 0.2952
2025-11-02 04:35:38,919: t15.2023.08.18 val PER: 0.2632
2025-11-02 04:35:38,919: t15.2023.08.20 val PER: 0.2486
2025-11-02 04:35:38,920: t15.2023.08.25 val PER: 0.2380
2025-11-02 04:35:38,920: t15.2023.08.27 val PER: 0.3360
2025-11-02 04:35:38,921: t15.2023.09.01 val PER: 0.2183
2025-11-02 04:35:38,921: t15.2023.09.03 val PER: 0.3017
2025-11-02 04:35:38,922: t15.2023.09.24 val PER: 0.2633
2025-11-02 04:35:38,922: t15.2023.09.29 val PER: 0.2693
2025-11-02 04:35:38,922: t15.2023.10.01 val PER: 0.3269
2025-11-02 04:35:38,923: t15.2023.10.06 val PER: 0.2465
2025-11-02 04:35:38,923: t15.2023.10.08 val PER: 0.3897
2025-11-02 04:35:38,923: t15.2023.10.13 val PER: 0.3794
2025-11-02 04:35:38,924: t15.2023.10.15 val PER: 0.2854
2025-11-02 04:35:38,924: t15.2023.10.20 val PER: 0.2819
2025-11-02 04:35:38,925: t15.2023.10.22 val PER: 0.2762
2025-11-02 04:35:38,925: t15.2023.11.03 val PER: 0.3148
2025-11-02 04:35:38,926: t15.2023.11.04 val PER: 0.1126
2025-11-02 04:35:38,926: t15.2023.11.17 val PER: 0.1820
2025-11-02 04:35:38,927: t15.2023.11.19 val PER: 0.1617
2025-11-02 04:35:38,927: t15.2023.11.26 val PER: 0.3428
2025-11-02 04:35:38,927: t15.2023.12.03 val PER: 0.2952
2025-11-02 04:35:38,928: t15.2023.12.08 val PER: 0.3156
2025-11-02 04:35:38,928: t15.2023.12.10 val PER: 0.2589
2025-11-02 04:35:38,928: t15.2023.12.17 val PER: 0.3160
2025-11-02 04:35:38,929: t15.2023.12.29 val PER: 0.3233
2025-11-02 04:35:38,929: t15.2024.02.25 val PER: 0.2472
2025-11-02 04:35:38,929: t15.2024.03.08 val PER: 0.3770
2025-11-02 04:35:38,930: t15.2024.03.15 val PER: 0.3684
2025-11-02 04:35:38,930: t15.2024.03.17 val PER: 0.3229
2025-11-02 04:35:38,931: t15.2024.05.10 val PER: 0.3239
2025-11-02 04:35:38,931: t15.2024.06.14 val PER: 0.3139
2025-11-02 04:35:38,931: t15.2024.07.19 val PER: 0.4047
2025-11-02 04:35:38,932: t15.2024.07.21 val PER: 0.2621
2025-11-02 04:35:38,932: t15.2024.07.28 val PER: 0.3022
2025-11-02 04:35:38,932: t15.2025.01.10 val PER: 0.4656
2025-11-02 04:35:38,933: t15.2025.01.12 val PER: 0.3256
2025-11-02 04:35:38,933: t15.2025.03.14 val PER: 0.4808
2025-11-02 04:35:38,933: t15.2025.03.16 val PER: 0.3469
2025-11-02 04:35:38,934: t15.2025.03.30 val PER: 0.4299
2025-11-02 04:35:38,934: t15.2025.04.13 val PER: 0.3852
2025-11-02 04:35:38,934: New best test PER 0.3166 --> 0.3119
2025-11-02 04:35:38,935: Checkpointing model
2025-11-02 04:35:40,938: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:36:05,661: Train batch 28200: loss: 30.26 grad norm: 53.29 time: 0.075
2025-11-02 04:36:29,929: Train batch 28400: loss: 30.45 grad norm: 53.15 time: 0.087
2025-11-02 04:36:53,521: Train batch 28600: loss: 32.22 grad norm: 53.11 time: 0.078
2025-11-02 04:37:18,058: Train batch 28800: loss: 29.68 grad norm: 40.09 time: 0.094
2025-11-02 04:37:41,618: Train batch 29000: loss: 25.60 grad norm: 44.79 time: 0.097
2025-11-02 04:37:41,619: Running test after training batch: 29000
2025-11-02 04:37:54,131: Val batch 29000: PER (avg): 0.3067 CTC Loss (avg): 31.3276 time: 12.512
2025-11-02 04:37:54,132: t15.2023.08.13 val PER: 0.2859
2025-11-02 04:37:54,133: t15.2023.08.18 val PER: 0.2548
2025-11-02 04:37:54,133: t15.2023.08.20 val PER: 0.2502
2025-11-02 04:37:54,133: t15.2023.08.25 val PER: 0.2304
2025-11-02 04:37:54,134: t15.2023.08.27 val PER: 0.3328
2025-11-02 04:37:54,134: t15.2023.09.01 val PER: 0.2094
2025-11-02 04:37:54,135: t15.2023.09.03 val PER: 0.3040
2025-11-02 04:37:54,135: t15.2023.09.24 val PER: 0.2561
2025-11-02 04:37:54,136: t15.2023.09.29 val PER: 0.2680
2025-11-02 04:37:54,136: t15.2023.10.01 val PER: 0.3230
2025-11-02 04:37:54,136: t15.2023.10.06 val PER: 0.2347
2025-11-02 04:37:54,137: t15.2023.10.08 val PER: 0.3843
2025-11-02 04:37:54,137: t15.2023.10.13 val PER: 0.3708
2025-11-02 04:37:54,137: t15.2023.10.15 val PER: 0.2696
2025-11-02 04:37:54,137: t15.2023.10.20 val PER: 0.2919
2025-11-02 04:37:54,138: t15.2023.10.22 val PER: 0.2695
2025-11-02 04:37:54,138: t15.2023.11.03 val PER: 0.3060
2025-11-02 04:37:54,138: t15.2023.11.04 val PER: 0.1058
2025-11-02 04:37:54,139: t15.2023.11.17 val PER: 0.1742
2025-11-02 04:37:54,139: t15.2023.11.19 val PER: 0.1597
2025-11-02 04:37:54,139: t15.2023.11.26 val PER: 0.3319
2025-11-02 04:37:54,140: t15.2023.12.03 val PER: 0.2899
2025-11-02 04:37:54,140: t15.2023.12.08 val PER: 0.3036
2025-11-02 04:37:54,140: t15.2023.12.10 val PER: 0.2444
2025-11-02 04:37:54,141: t15.2023.12.17 val PER: 0.3191
2025-11-02 04:37:54,141: t15.2023.12.29 val PER: 0.3150
2025-11-02 04:37:54,141: t15.2024.02.25 val PER: 0.2472
2025-11-02 04:37:54,141: t15.2024.03.08 val PER: 0.3627
2025-11-02 04:37:54,142: t15.2024.03.15 val PER: 0.3640
2025-11-02 04:37:54,142: t15.2024.03.17 val PER: 0.3208
2025-11-02 04:37:54,142: t15.2024.05.10 val PER: 0.3314
2025-11-02 04:37:54,143: t15.2024.06.14 val PER: 0.3170
2025-11-02 04:37:54,143: t15.2024.07.19 val PER: 0.3982
2025-11-02 04:37:54,183: t15.2024.07.21 val PER: 0.2586
2025-11-02 04:37:54,184: t15.2024.07.28 val PER: 0.3000
2025-11-02 04:37:54,185: t15.2025.01.10 val PER: 0.4628
2025-11-02 04:37:54,185: t15.2025.01.12 val PER: 0.3264
2025-11-02 04:37:54,186: t15.2025.03.14 val PER: 0.4793
2025-11-02 04:37:54,186: t15.2025.03.16 val PER: 0.3521
2025-11-02 04:37:54,186: t15.2025.03.30 val PER: 0.4253
2025-11-02 04:37:54,187: t15.2025.04.13 val PER: 0.3766
2025-11-02 04:37:54,187: New best test PER 0.3119 --> 0.3067
2025-11-02 04:37:54,188: Checkpointing model
2025-11-02 04:37:55,952: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:38:21,141: Train batch 29200: loss: 25.50 grad norm: 42.25 time: 0.091
2025-11-02 04:38:45,204: Train batch 29400: loss: 25.31 grad norm: 49.00 time: 0.083
2025-11-02 04:39:09,116: Train batch 29600: loss: 23.88 grad norm: 39.56 time: 0.110
2025-11-02 04:39:33,672: Train batch 29800: loss: 25.09 grad norm: 41.24 time: 0.088
2025-11-02 04:39:57,874: Train batch 30000: loss: 33.52 grad norm: 81.22 time: 0.091
2025-11-02 04:39:57,875: Running test after training batch: 30000
2025-11-02 04:40:10,120: Val batch 30000: PER (avg): 0.2997 CTC Loss (avg): 30.8160 time: 12.244
2025-11-02 04:40:10,120: t15.2023.08.13 val PER: 0.2755
2025-11-02 04:40:10,121: t15.2023.08.18 val PER: 0.2439
2025-11-02 04:40:10,121: t15.2023.08.20 val PER: 0.2478
2025-11-02 04:40:10,121: t15.2023.08.25 val PER: 0.2349
2025-11-02 04:40:10,122: t15.2023.08.27 val PER: 0.3199
2025-11-02 04:40:10,122: t15.2023.09.01 val PER: 0.2045
2025-11-02 04:40:10,122: t15.2023.09.03 val PER: 0.2862
2025-11-02 04:40:10,123: t15.2023.09.24 val PER: 0.2476
2025-11-02 04:40:10,123: t15.2023.09.29 val PER: 0.2629
2025-11-02 04:40:10,123: t15.2023.10.01 val PER: 0.3203
2025-11-02 04:40:10,124: t15.2023.10.06 val PER: 0.2239
2025-11-02 04:40:10,124: t15.2023.10.08 val PER: 0.3735
2025-11-02 04:40:10,124: t15.2023.10.13 val PER: 0.3701
2025-11-02 04:40:10,125: t15.2023.10.15 val PER: 0.2703
2025-11-02 04:40:10,125: t15.2023.10.20 val PER: 0.2785
2025-11-02 04:40:10,125: t15.2023.10.22 val PER: 0.2561
2025-11-02 04:40:10,126: t15.2023.11.03 val PER: 0.3100
2025-11-02 04:40:10,126: t15.2023.11.04 val PER: 0.1058
2025-11-02 04:40:10,126: t15.2023.11.17 val PER: 0.1680
2025-11-02 04:40:10,126: t15.2023.11.19 val PER: 0.1617
2025-11-02 04:40:10,127: t15.2023.11.26 val PER: 0.3304
2025-11-02 04:40:10,127: t15.2023.12.03 val PER: 0.2889
2025-11-02 04:40:10,127: t15.2023.12.08 val PER: 0.2983
2025-11-02 04:40:10,127: t15.2023.12.10 val PER: 0.2431
2025-11-02 04:40:10,128: t15.2023.12.17 val PER: 0.3035
2025-11-02 04:40:10,128: t15.2023.12.29 val PER: 0.3040
2025-11-02 04:40:10,128: t15.2024.02.25 val PER: 0.2402
2025-11-02 04:40:10,128: t15.2024.03.08 val PER: 0.3656
2025-11-02 04:40:10,129: t15.2024.03.15 val PER: 0.3571
2025-11-02 04:40:10,129: t15.2024.03.17 val PER: 0.3103
2025-11-02 04:40:10,129: t15.2024.05.10 val PER: 0.3210
2025-11-02 04:40:10,130: t15.2024.06.14 val PER: 0.2950
2025-11-02 04:40:10,130: t15.2024.07.19 val PER: 0.3883
2025-11-02 04:40:10,130: t15.2024.07.21 val PER: 0.2490
2025-11-02 04:40:10,131: t15.2024.07.28 val PER: 0.2919
2025-11-02 04:40:10,131: t15.2025.01.10 val PER: 0.4559
2025-11-02 04:40:10,131: t15.2025.01.12 val PER: 0.3149
2025-11-02 04:40:10,131: t15.2025.03.14 val PER: 0.4675
2025-11-02 04:40:10,132: t15.2025.03.16 val PER: 0.3364
2025-11-02 04:40:10,132: t15.2025.03.30 val PER: 0.4184
2025-11-02 04:40:10,132: t15.2025.04.13 val PER: 0.3680
2025-11-02 04:40:10,132: New best test PER 0.3067 --> 0.2997
2025-11-02 04:40:10,133: Checkpointing model
2025-11-02 04:40:11,923: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:40:37,170: Train batch 30200: loss: 32.13 grad norm: 67.44 time: 0.071
2025-11-02 04:41:01,551: Train batch 30400: loss: 23.79 grad norm: 48.49 time: 0.079
2025-11-02 04:41:25,564: Train batch 30600: loss: 24.48 grad norm: 38.71 time: 0.076
2025-11-02 04:41:48,927: Train batch 30800: loss: 31.57 grad norm: 50.07 time: 0.079
2025-11-02 04:42:12,887: Train batch 31000: loss: 36.64 grad norm: 170.09 time: 0.092
2025-11-02 04:42:12,888: Running test after training batch: 31000
2025-11-02 04:42:24,611: Val batch 31000: PER (avg): 0.2957 CTC Loss (avg): 30.3614 time: 11.722
2025-11-02 04:42:24,612: t15.2023.08.13 val PER: 0.2744
2025-11-02 04:42:24,612: t15.2023.08.18 val PER: 0.2431
2025-11-02 04:42:24,613: t15.2023.08.20 val PER: 0.2438
2025-11-02 04:42:24,613: t15.2023.08.25 val PER: 0.2214
2025-11-02 04:42:24,613: t15.2023.08.27 val PER: 0.3199
2025-11-02 04:42:24,614: t15.2023.09.01 val PER: 0.2029
2025-11-02 04:42:24,614: t15.2023.09.03 val PER: 0.2791
2025-11-02 04:42:24,614: t15.2023.09.24 val PER: 0.2451
2025-11-02 04:42:24,615: t15.2023.09.29 val PER: 0.2527
2025-11-02 04:42:24,615: t15.2023.10.01 val PER: 0.3203
2025-11-02 04:42:24,616: t15.2023.10.06 val PER: 0.2131
2025-11-02 04:42:24,616: t15.2023.10.08 val PER: 0.3721
2025-11-02 04:42:24,616: t15.2023.10.13 val PER: 0.3646
2025-11-02 04:42:24,616: t15.2023.10.15 val PER: 0.2670
2025-11-02 04:42:24,617: t15.2023.10.20 val PER: 0.2752
2025-11-02 04:42:24,617: t15.2023.10.22 val PER: 0.2539
2025-11-02 04:42:24,617: t15.2023.11.03 val PER: 0.3033
2025-11-02 04:42:24,618: t15.2023.11.04 val PER: 0.1024
2025-11-02 04:42:24,618: t15.2023.11.17 val PER: 0.1711
2025-11-02 04:42:24,618: t15.2023.11.19 val PER: 0.1577
2025-11-02 04:42:24,618: t15.2023.11.26 val PER: 0.3290
2025-11-02 04:42:24,619: t15.2023.12.03 val PER: 0.2815
2025-11-02 04:42:24,619: t15.2023.12.08 val PER: 0.3003
2025-11-02 04:42:24,619: t15.2023.12.10 val PER: 0.2378
2025-11-02 04:42:24,620: t15.2023.12.17 val PER: 0.3087
2025-11-02 04:42:24,620: t15.2023.12.29 val PER: 0.2999
2025-11-02 04:42:24,620: t15.2024.02.25 val PER: 0.2317
2025-11-02 04:42:24,621: t15.2024.03.08 val PER: 0.3556
2025-11-02 04:42:24,621: t15.2024.03.15 val PER: 0.3477
2025-11-02 04:42:24,621: t15.2024.03.17 val PER: 0.3089
2025-11-02 04:42:24,622: t15.2024.05.10 val PER: 0.3105
2025-11-02 04:42:24,622: t15.2024.06.14 val PER: 0.2918
2025-11-02 04:42:24,622: t15.2024.07.19 val PER: 0.3883
2025-11-02 04:42:24,622: t15.2024.07.21 val PER: 0.2434
2025-11-02 04:42:24,623: t15.2024.07.28 val PER: 0.2875
2025-11-02 04:42:24,623: t15.2025.01.10 val PER: 0.4449
2025-11-02 04:42:24,623: t15.2025.01.12 val PER: 0.3133
2025-11-02 04:42:24,624: t15.2025.03.14 val PER: 0.4615
2025-11-02 04:42:24,624: t15.2025.03.16 val PER: 0.3194
2025-11-02 04:42:24,624: t15.2025.03.30 val PER: 0.4241
2025-11-02 04:42:24,624: t15.2025.04.13 val PER: 0.3638
2025-11-02 04:42:24,625: New best test PER 0.2997 --> 0.2957
2025-11-02 04:42:24,625: Checkpointing model
2025-11-02 04:42:26,437: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:42:51,220: Train batch 31200: loss: 29.78 grad norm: 46.76 time: 0.062
2025-11-02 04:43:15,594: Train batch 31400: loss: 23.21 grad norm: 39.90 time: 0.063
2025-11-02 04:43:39,906: Train batch 31600: loss: 17.94 grad norm: 37.94 time: 0.082
2025-11-02 04:44:04,063: Train batch 31800: loss: 24.75 grad norm: 38.78 time: 0.061
2025-11-02 04:44:27,804: Train batch 32000: loss: 15.14 grad norm: 36.06 time: 0.105
2025-11-02 04:44:27,805: Running test after training batch: 32000
2025-11-02 04:44:39,811: Val batch 32000: PER (avg): 0.2918 CTC Loss (avg): 29.8418 time: 12.005
2025-11-02 04:44:39,826: t15.2023.08.13 val PER: 0.2692
2025-11-02 04:44:39,829: t15.2023.08.18 val PER: 0.2389
2025-11-02 04:44:39,829: t15.2023.08.20 val PER: 0.2319
2025-11-02 04:44:39,830: t15.2023.08.25 val PER: 0.2274
2025-11-02 04:44:39,830: t15.2023.08.27 val PER: 0.3151
2025-11-02 04:44:39,831: t15.2023.09.01 val PER: 0.1989
2025-11-02 04:44:39,831: t15.2023.09.03 val PER: 0.2874
2025-11-02 04:44:39,831: t15.2023.09.24 val PER: 0.2379
2025-11-02 04:44:39,832: t15.2023.09.29 val PER: 0.2514
2025-11-02 04:44:39,832: t15.2023.10.01 val PER: 0.3184
2025-11-02 04:44:39,832: t15.2023.10.06 val PER: 0.2207
2025-11-02 04:44:39,833: t15.2023.10.08 val PER: 0.3559
2025-11-02 04:44:39,833: t15.2023.10.13 val PER: 0.3576
2025-11-02 04:44:39,833: t15.2023.10.15 val PER: 0.2624
2025-11-02 04:44:39,833: t15.2023.10.20 val PER: 0.2785
2025-11-02 04:44:39,834: t15.2023.10.22 val PER: 0.2439
2025-11-02 04:44:39,834: t15.2023.11.03 val PER: 0.3012
2025-11-02 04:44:39,834: t15.2023.11.04 val PER: 0.0922
2025-11-02 04:44:39,835: t15.2023.11.17 val PER: 0.1664
2025-11-02 04:44:39,835: t15.2023.11.19 val PER: 0.1457
2025-11-02 04:44:39,836: t15.2023.11.26 val PER: 0.3246
2025-11-02 04:44:39,836: t15.2023.12.03 val PER: 0.2763
2025-11-02 04:44:39,836: t15.2023.12.08 val PER: 0.3009
2025-11-02 04:44:39,836: t15.2023.12.10 val PER: 0.2352
2025-11-02 04:44:39,837: t15.2023.12.17 val PER: 0.3025
2025-11-02 04:44:39,837: t15.2023.12.29 val PER: 0.2965
2025-11-02 04:44:39,837: t15.2024.02.25 val PER: 0.2317
2025-11-02 04:44:39,837: t15.2024.03.08 val PER: 0.3485
2025-11-02 04:44:39,838: t15.2024.03.15 val PER: 0.3465
2025-11-02 04:44:39,838: t15.2024.03.17 val PER: 0.3040
2025-11-02 04:44:39,838: t15.2024.05.10 val PER: 0.3120
2025-11-02 04:44:39,839: t15.2024.06.14 val PER: 0.2950
2025-11-02 04:44:39,839: t15.2024.07.19 val PER: 0.3830
2025-11-02 04:44:39,839: t15.2024.07.21 val PER: 0.2379
2025-11-02 04:44:39,839: t15.2024.07.28 val PER: 0.2809
2025-11-02 04:44:39,840: t15.2025.01.10 val PER: 0.4408
2025-11-02 04:44:39,841: t15.2025.01.12 val PER: 0.2995
2025-11-02 04:44:39,841: t15.2025.03.14 val PER: 0.4586
2025-11-02 04:44:39,841: t15.2025.03.16 val PER: 0.3298
2025-11-02 04:44:39,841: t15.2025.03.30 val PER: 0.4172
2025-11-02 04:44:39,842: t15.2025.04.13 val PER: 0.3595
2025-11-02 04:44:39,842: New best test PER 0.2957 --> 0.2918
2025-11-02 04:44:39,842: Checkpointing model
2025-11-02 04:44:41,360: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:45:05,569: Train batch 32200: loss: 19.47 grad norm: 34.93 time: 0.080
2025-11-02 04:45:29,267: Train batch 32400: loss: 17.23 grad norm: 33.36 time: 0.076
2025-11-02 04:45:53,451: Train batch 32600: loss: 22.16 grad norm: 46.63 time: 0.090
2025-11-02 04:46:17,342: Train batch 32800: loss: 26.71 grad norm: 44.96 time: 0.075
2025-11-02 04:46:41,703: Train batch 33000: loss: 26.28 grad norm: 54.01 time: 0.089
2025-11-02 04:46:41,704: Running test after training batch: 33000
2025-11-02 04:46:53,609: Val batch 33000: PER (avg): 0.2865 CTC Loss (avg): 29.4740 time: 11.905
2025-11-02 04:46:53,610: t15.2023.08.13 val PER: 0.2620
2025-11-02 04:46:53,611: t15.2023.08.18 val PER: 0.2313
2025-11-02 04:46:53,611: t15.2023.08.20 val PER: 0.2295
2025-11-02 04:46:53,612: t15.2023.08.25 val PER: 0.2259
2025-11-02 04:46:53,612: t15.2023.08.27 val PER: 0.3151
2025-11-02 04:46:53,612: t15.2023.09.01 val PER: 0.1997
2025-11-02 04:46:53,613: t15.2023.09.03 val PER: 0.2791
2025-11-02 04:46:53,613: t15.2023.09.24 val PER: 0.2330
2025-11-02 04:46:53,613: t15.2023.09.29 val PER: 0.2451
2025-11-02 04:46:53,614: t15.2023.10.01 val PER: 0.3038
2025-11-02 04:46:53,614: t15.2023.10.06 val PER: 0.2142
2025-11-02 04:46:53,614: t15.2023.10.08 val PER: 0.3532
2025-11-02 04:46:53,615: t15.2023.10.13 val PER: 0.3499
2025-11-02 04:46:53,615: t15.2023.10.15 val PER: 0.2624
2025-11-02 04:46:53,616: t15.2023.10.20 val PER: 0.2752
2025-11-02 04:46:53,616: t15.2023.10.22 val PER: 0.2361
2025-11-02 04:46:53,616: t15.2023.11.03 val PER: 0.2938
2025-11-02 04:46:53,617: t15.2023.11.04 val PER: 0.0887
2025-11-02 04:46:53,617: t15.2023.11.17 val PER: 0.1633
2025-11-02 04:46:53,617: t15.2023.11.19 val PER: 0.1437
2025-11-02 04:46:53,618: t15.2023.11.26 val PER: 0.3188
2025-11-02 04:46:53,618: t15.2023.12.03 val PER: 0.2763
2025-11-02 04:46:53,618: t15.2023.12.08 val PER: 0.2856
2025-11-02 04:46:53,618: t15.2023.12.10 val PER: 0.2326
2025-11-02 04:46:53,619: t15.2023.12.17 val PER: 0.3056
2025-11-02 04:46:53,619: t15.2023.12.29 val PER: 0.2924
2025-11-02 04:46:53,619: t15.2024.02.25 val PER: 0.2233
2025-11-02 04:46:53,620: t15.2024.03.08 val PER: 0.3357
2025-11-02 04:46:53,620: t15.2024.03.15 val PER: 0.3490
2025-11-02 04:46:53,621: t15.2024.03.17 val PER: 0.2999
2025-11-02 04:46:53,621: t15.2024.05.10 val PER: 0.2957
2025-11-02 04:46:53,621: t15.2024.06.14 val PER: 0.2934
2025-11-02 04:46:53,622: t15.2024.07.19 val PER: 0.3751
2025-11-02 04:46:53,622: t15.2024.07.21 val PER: 0.2269
2025-11-02 04:46:53,622: t15.2024.07.28 val PER: 0.2765
2025-11-02 04:46:53,623: t15.2025.01.10 val PER: 0.4394
2025-11-02 04:46:53,623: t15.2025.01.12 val PER: 0.3002
2025-11-02 04:46:53,623: t15.2025.03.14 val PER: 0.4586
2025-11-02 04:46:53,624: t15.2025.03.16 val PER: 0.3246
2025-11-02 04:46:53,624: t15.2025.03.30 val PER: 0.4011
2025-11-02 04:46:53,624: t15.2025.04.13 val PER: 0.3609
2025-11-02 04:46:53,624: New best test PER 0.2918 --> 0.2865
2025-11-02 04:46:53,625: Checkpointing model
2025-11-02 04:46:55,451: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:47:20,066: Train batch 33200: loss: 21.05 grad norm: 39.19 time: 0.099
2025-11-02 04:47:44,501: Train batch 33400: loss: 19.28 grad norm: 42.77 time: 0.076
2025-11-02 04:48:08,724: Train batch 33600: loss: 24.78 grad norm: 49.63 time: 0.092
2025-11-02 04:48:32,866: Train batch 33800: loss: 34.81 grad norm: 84.95 time: 0.085
2025-11-02 04:48:57,280: Train batch 34000: loss: 21.74 grad norm: 38.76 time: 0.061
2025-11-02 04:48:57,281: Running test after training batch: 34000
2025-11-02 04:49:09,717: Val batch 34000: PER (avg): 0.2830 CTC Loss (avg): 29.0182 time: 12.435
2025-11-02 04:49:09,718: t15.2023.08.13 val PER: 0.2578
2025-11-02 04:49:09,718: t15.2023.08.18 val PER: 0.2213
2025-11-02 04:49:09,719: t15.2023.08.20 val PER: 0.2248
2025-11-02 04:49:09,719: t15.2023.08.25 val PER: 0.2154
2025-11-02 04:49:09,720: t15.2023.08.27 val PER: 0.3135
2025-11-02 04:49:09,721: t15.2023.09.01 val PER: 0.1916
2025-11-02 04:49:09,721: t15.2023.09.03 val PER: 0.2755
2025-11-02 04:49:09,721: t15.2023.09.24 val PER: 0.2306
2025-11-02 04:49:09,722: t15.2023.09.29 val PER: 0.2387
2025-11-02 04:49:09,722: t15.2023.10.01 val PER: 0.2979
2025-11-02 04:49:09,722: t15.2023.10.06 val PER: 0.2131
2025-11-02 04:49:09,723: t15.2023.10.08 val PER: 0.3559
2025-11-02 04:49:09,723: t15.2023.10.13 val PER: 0.3437
2025-11-02 04:49:09,723: t15.2023.10.15 val PER: 0.2617
2025-11-02 04:49:09,724: t15.2023.10.20 val PER: 0.2651
2025-11-02 04:49:09,724: t15.2023.10.22 val PER: 0.2394
2025-11-02 04:49:09,724: t15.2023.11.03 val PER: 0.2924
2025-11-02 04:49:09,724: t15.2023.11.04 val PER: 0.0956
2025-11-02 04:49:09,725: t15.2023.11.17 val PER: 0.1617
2025-11-02 04:49:09,725: t15.2023.11.19 val PER: 0.1457
2025-11-02 04:49:09,726: t15.2023.11.26 val PER: 0.3174
2025-11-02 04:49:09,726: t15.2023.12.03 val PER: 0.2679
2025-11-02 04:49:09,726: t15.2023.12.08 val PER: 0.2770
2025-11-02 04:49:09,727: t15.2023.12.10 val PER: 0.2286
2025-11-02 04:49:09,727: t15.2023.12.17 val PER: 0.3025
2025-11-02 04:49:09,727: t15.2023.12.29 val PER: 0.2924
2025-11-02 04:49:09,728: t15.2024.02.25 val PER: 0.2205
2025-11-02 04:49:09,728: t15.2024.03.08 val PER: 0.3243
2025-11-02 04:49:09,728: t15.2024.03.15 val PER: 0.3471
2025-11-02 04:49:09,728: t15.2024.03.17 val PER: 0.2922
2025-11-02 04:49:09,729: t15.2024.05.10 val PER: 0.2987
2025-11-02 04:49:09,729: t15.2024.06.14 val PER: 0.2886
2025-11-02 04:49:09,729: t15.2024.07.19 val PER: 0.3724
2025-11-02 04:49:09,730: t15.2024.07.21 val PER: 0.2255
2025-11-02 04:49:09,730: t15.2024.07.28 val PER: 0.2757
2025-11-02 04:49:09,730: t15.2025.01.10 val PER: 0.4380
2025-11-02 04:49:09,731: t15.2025.01.12 val PER: 0.2941
2025-11-02 04:49:09,731: t15.2025.03.14 val PER: 0.4512
2025-11-02 04:49:09,731: t15.2025.03.16 val PER: 0.3181
2025-11-02 04:49:09,732: t15.2025.03.30 val PER: 0.4149
2025-11-02 04:49:09,732: t15.2025.04.13 val PER: 0.3509
2025-11-02 04:49:09,732: New best test PER 0.2865 --> 0.2830
2025-11-02 04:49:09,732: Checkpointing model
2025-11-02 04:49:11,568: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:49:36,811: Train batch 34200: loss: 21.98 grad norm: 42.48 time: 0.074
2025-11-02 04:50:02,349: Train batch 34400: loss: 26.42 grad norm: 45.86 time: 0.067
2025-11-02 04:50:27,000: Train batch 34600: loss: 17.21 grad norm: 36.08 time: 0.073
2025-11-02 04:50:52,458: Train batch 34800: loss: 29.06 grad norm: 65.77 time: 0.073
2025-11-02 04:51:17,615: Train batch 35000: loss: 27.01 grad norm: 51.24 time: 0.113
2025-11-02 04:51:17,617: Running test after training batch: 35000
2025-11-02 04:51:31,129: Val batch 35000: PER (avg): 0.2794 CTC Loss (avg): 28.7459 time: 13.512
2025-11-02 04:51:31,131: t15.2023.08.13 val PER: 0.2568
2025-11-02 04:51:31,131: t15.2023.08.18 val PER: 0.2196
2025-11-02 04:51:31,131: t15.2023.08.20 val PER: 0.2216
2025-11-02 04:51:31,132: t15.2023.08.25 val PER: 0.2093
2025-11-02 04:51:31,132: t15.2023.08.27 val PER: 0.3167
2025-11-02 04:51:31,132: t15.2023.09.01 val PER: 0.1851
2025-11-02 04:51:31,133: t15.2023.09.03 val PER: 0.2803
2025-11-02 04:51:31,133: t15.2023.09.24 val PER: 0.2221
2025-11-02 04:51:31,184: t15.2023.09.29 val PER: 0.2374
2025-11-02 04:51:31,184: t15.2023.10.01 val PER: 0.3005
2025-11-02 04:51:31,185: t15.2023.10.06 val PER: 0.2078
2025-11-02 04:51:31,185: t15.2023.10.08 val PER: 0.3437
2025-11-02 04:51:31,186: t15.2023.10.13 val PER: 0.3406
2025-11-02 04:51:31,186: t15.2023.10.15 val PER: 0.2577
2025-11-02 04:51:31,187: t15.2023.10.20 val PER: 0.2550
2025-11-02 04:51:31,187: t15.2023.10.22 val PER: 0.2372
2025-11-02 04:51:31,187: t15.2023.11.03 val PER: 0.2870
2025-11-02 04:51:31,188: t15.2023.11.04 val PER: 0.0922
2025-11-02 04:51:31,188: t15.2023.11.17 val PER: 0.1571
2025-11-02 04:51:31,189: t15.2023.11.19 val PER: 0.1377
2025-11-02 04:51:31,189: t15.2023.11.26 val PER: 0.3101
2025-11-02 04:51:31,189: t15.2023.12.03 val PER: 0.2605
2025-11-02 04:51:31,190: t15.2023.12.08 val PER: 0.2756
2025-11-02 04:51:31,190: t15.2023.12.10 val PER: 0.2260
2025-11-02 04:51:31,191: t15.2023.12.17 val PER: 0.2963
2025-11-02 04:51:31,191: t15.2023.12.29 val PER: 0.2869
2025-11-02 04:51:31,191: t15.2024.02.25 val PER: 0.2177
2025-11-02 04:51:31,192: t15.2024.03.08 val PER: 0.3314
2025-11-02 04:51:31,192: t15.2024.03.15 val PER: 0.3427
2025-11-02 04:51:31,192: t15.2024.03.17 val PER: 0.2873
2025-11-02 04:51:31,193: t15.2024.05.10 val PER: 0.2912
2025-11-02 04:51:31,193: t15.2024.06.14 val PER: 0.2950
2025-11-02 04:51:31,193: t15.2024.07.19 val PER: 0.3691
2025-11-02 04:51:31,194: t15.2024.07.21 val PER: 0.2228
2025-11-02 04:51:31,194: t15.2024.07.28 val PER: 0.2721
2025-11-02 04:51:31,195: t15.2025.01.10 val PER: 0.4325
2025-11-02 04:51:31,195: t15.2025.01.12 val PER: 0.2918
2025-11-02 04:51:31,196: t15.2025.03.14 val PER: 0.4364
2025-11-02 04:51:31,196: t15.2025.03.16 val PER: 0.3102
2025-11-02 04:51:31,197: t15.2025.03.30 val PER: 0.4034
2025-11-02 04:51:31,197: t15.2025.04.13 val PER: 0.3638
2025-11-02 04:51:31,197: New best test PER 0.2830 --> 0.2794
2025-11-02 04:51:31,198: Checkpointing model
2025-11-02 04:51:33,126: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:51:57,735: Train batch 35200: loss: 19.99 grad norm: 43.34 time: 0.073
2025-11-02 04:52:22,528: Train batch 35400: loss: 19.33 grad norm: 37.45 time: 0.093
2025-11-02 04:52:47,273: Train batch 35600: loss: 22.05 grad norm: 46.70 time: 0.087
2025-11-02 04:53:12,048: Train batch 35800: loss: 26.95 grad norm: 48.81 time: 0.131
2025-11-02 04:53:36,964: Train batch 36000: loss: 23.71 grad norm: 46.05 time: 0.069
2025-11-02 04:53:36,965: Running test after training batch: 36000
2025-11-02 04:53:50,803: Val batch 36000: PER (avg): 0.2761 CTC Loss (avg): 28.3411 time: 13.837
2025-11-02 04:53:50,804: t15.2023.08.13 val PER: 0.2495
2025-11-02 04:53:50,804: t15.2023.08.18 val PER: 0.2112
2025-11-02 04:53:50,805: t15.2023.08.20 val PER: 0.2121
2025-11-02 04:53:50,805: t15.2023.08.25 val PER: 0.2078
2025-11-02 04:53:50,806: t15.2023.08.27 val PER: 0.3087
2025-11-02 04:53:50,806: t15.2023.09.01 val PER: 0.1859
2025-11-02 04:53:50,807: t15.2023.09.03 val PER: 0.2755
2025-11-02 04:53:50,807: t15.2023.09.24 val PER: 0.2209
2025-11-02 04:53:50,807: t15.2023.09.29 val PER: 0.2342
2025-11-02 04:53:50,807: t15.2023.10.01 val PER: 0.2926
2025-11-02 04:53:50,808: t15.2023.10.06 val PER: 0.2056
2025-11-02 04:53:50,808: t15.2023.10.08 val PER: 0.3424
2025-11-02 04:53:50,809: t15.2023.10.13 val PER: 0.3297
2025-11-02 04:53:50,809: t15.2023.10.15 val PER: 0.2538
2025-11-02 04:53:50,809: t15.2023.10.20 val PER: 0.2584
2025-11-02 04:53:50,810: t15.2023.10.22 val PER: 0.2261
2025-11-02 04:53:50,811: t15.2023.11.03 val PER: 0.2843
2025-11-02 04:53:50,811: t15.2023.11.04 val PER: 0.0887
2025-11-02 04:53:50,811: t15.2023.11.17 val PER: 0.1509
2025-11-02 04:53:50,811: t15.2023.11.19 val PER: 0.1397
2025-11-02 04:53:50,812: t15.2023.11.26 val PER: 0.3087
2025-11-02 04:53:50,812: t15.2023.12.03 val PER: 0.2605
2025-11-02 04:53:50,813: t15.2023.12.08 val PER: 0.2730
2025-11-02 04:53:50,813: t15.2023.12.10 val PER: 0.2300
2025-11-02 04:53:50,813: t15.2023.12.17 val PER: 0.2994
2025-11-02 04:53:50,813: t15.2023.12.29 val PER: 0.2807
2025-11-02 04:53:50,814: t15.2024.02.25 val PER: 0.2177
2025-11-02 04:53:50,814: t15.2024.03.08 val PER: 0.3329
2025-11-02 04:53:50,814: t15.2024.03.15 val PER: 0.3390
2025-11-02 04:53:50,815: t15.2024.03.17 val PER: 0.2838
2025-11-02 04:53:50,815: t15.2024.05.10 val PER: 0.2883
2025-11-02 04:53:50,816: t15.2024.06.14 val PER: 0.2792
2025-11-02 04:53:50,816: t15.2024.07.19 val PER: 0.3691
2025-11-02 04:53:50,816: t15.2024.07.21 val PER: 0.2179
2025-11-02 04:53:50,817: t15.2024.07.28 val PER: 0.2699
2025-11-02 04:53:50,817: t15.2025.01.10 val PER: 0.4366
2025-11-02 04:53:50,817: t15.2025.01.12 val PER: 0.2925
2025-11-02 04:53:50,817: t15.2025.03.14 val PER: 0.4423
2025-11-02 04:53:50,818: t15.2025.03.16 val PER: 0.3141
2025-11-02 04:53:50,818: t15.2025.03.30 val PER: 0.3989
2025-11-02 04:53:50,818: t15.2025.04.13 val PER: 0.3552
2025-11-02 04:53:50,818: New best test PER 0.2794 --> 0.2761
2025-11-02 04:53:50,819: Checkpointing model
2025-11-02 04:53:52,869: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:54:17,612: Train batch 36200: loss: 19.88 grad norm: 42.80 time: 0.098
2025-11-02 04:54:43,017: Train batch 36400: loss: 28.73 grad norm: 55.52 time: 0.114
2025-11-02 04:55:07,632: Train batch 36600: loss: 17.53 grad norm: 41.60 time: 0.068
2025-11-02 04:55:32,605: Train batch 36800: loss: 22.54 grad norm: 52.84 time: 0.067
2025-11-02 04:55:57,425: Train batch 37000: loss: 24.00 grad norm: 52.60 time: 0.079
2025-11-02 04:55:57,426: Running test after training batch: 37000
2025-11-02 04:56:10,818: Val batch 37000: PER (avg): 0.2723 CTC Loss (avg): 27.9886 time: 13.391
2025-11-02 04:56:10,818: t15.2023.08.13 val PER: 0.2443
2025-11-02 04:56:10,819: t15.2023.08.18 val PER: 0.2121
2025-11-02 04:56:10,819: t15.2023.08.20 val PER: 0.2153
2025-11-02 04:56:10,820: t15.2023.08.25 val PER: 0.2033
2025-11-02 04:56:10,820: t15.2023.08.27 val PER: 0.3183
2025-11-02 04:56:10,821: t15.2023.09.01 val PER: 0.1851
2025-11-02 04:56:10,821: t15.2023.09.03 val PER: 0.2767
2025-11-02 04:56:10,821: t15.2023.09.24 val PER: 0.2221
2025-11-02 04:56:10,822: t15.2023.09.29 val PER: 0.2278
2025-11-02 04:56:10,822: t15.2023.10.01 val PER: 0.2847
2025-11-02 04:56:10,822: t15.2023.10.06 val PER: 0.2024
2025-11-02 04:56:10,823: t15.2023.10.08 val PER: 0.3383
2025-11-02 04:56:10,823: t15.2023.10.13 val PER: 0.3297
2025-11-02 04:56:10,823: t15.2023.10.15 val PER: 0.2518
2025-11-02 04:56:10,824: t15.2023.10.20 val PER: 0.2383
2025-11-02 04:56:10,824: t15.2023.10.22 val PER: 0.2171
2025-11-02 04:56:10,824: t15.2023.11.03 val PER: 0.2795
2025-11-02 04:56:10,825: t15.2023.11.04 val PER: 0.0785
2025-11-02 04:56:10,825: t15.2023.11.17 val PER: 0.1462
2025-11-02 04:56:10,826: t15.2023.11.19 val PER: 0.1337
2025-11-02 04:56:10,826: t15.2023.11.26 val PER: 0.3094
2025-11-02 04:56:10,826: t15.2023.12.03 val PER: 0.2479
2025-11-02 04:56:10,827: t15.2023.12.08 val PER: 0.2670
2025-11-02 04:56:10,827: t15.2023.12.10 val PER: 0.2326
2025-11-02 04:56:10,827: t15.2023.12.17 val PER: 0.2931
2025-11-02 04:56:10,828: t15.2023.12.29 val PER: 0.2821
2025-11-02 04:56:10,828: t15.2024.02.25 val PER: 0.2149
2025-11-02 04:56:10,828: t15.2024.03.08 val PER: 0.3257
2025-11-02 04:56:10,829: t15.2024.03.15 val PER: 0.3383
2025-11-02 04:56:10,829: t15.2024.03.17 val PER: 0.2803
2025-11-02 04:56:10,829: t15.2024.05.10 val PER: 0.2853
2025-11-02 04:56:10,830: t15.2024.06.14 val PER: 0.2792
2025-11-02 04:56:10,830: t15.2024.07.19 val PER: 0.3619
2025-11-02 04:56:10,831: t15.2024.07.21 val PER: 0.2069
2025-11-02 04:56:10,831: t15.2024.07.28 val PER: 0.2676
2025-11-02 04:56:10,831: t15.2025.01.10 val PER: 0.4187
2025-11-02 04:56:10,832: t15.2025.01.12 val PER: 0.2910
2025-11-02 04:56:10,832: t15.2025.03.14 val PER: 0.4260
2025-11-02 04:56:10,832: t15.2025.03.16 val PER: 0.3154
2025-11-02 04:56:10,833: t15.2025.03.30 val PER: 0.3977
2025-11-02 04:56:10,833: t15.2025.04.13 val PER: 0.3466
2025-11-02 04:56:10,833: New best test PER 0.2761 --> 0.2723
2025-11-02 04:56:10,833: Checkpointing model
2025-11-02 04:56:12,669: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:56:38,093: Train batch 37200: loss: 21.65 grad norm: 46.36 time: 0.100
2025-11-02 04:57:02,967: Train batch 37400: loss: 24.39 grad norm: 53.37 time: 0.091
2025-11-02 04:57:27,730: Train batch 37600: loss: 28.64 grad norm: 52.67 time: 0.095
2025-11-02 04:57:52,800: Train batch 37800: loss: 22.01 grad norm: 44.11 time: 0.085
2025-11-02 04:58:18,156: Train batch 38000: loss: 22.33 grad norm: 46.72 time: 0.083
2025-11-02 04:58:18,157: Running test after training batch: 38000
2025-11-02 04:58:32,718: Val batch 38000: PER (avg): 0.2705 CTC Loss (avg): 27.6383 time: 14.561
2025-11-02 04:58:32,719: t15.2023.08.13 val PER: 0.2484
2025-11-02 04:58:32,720: t15.2023.08.18 val PER: 0.2121
2025-11-02 04:58:32,721: t15.2023.08.20 val PER: 0.2145
2025-11-02 04:58:32,721: t15.2023.08.25 val PER: 0.2018
2025-11-02 04:58:32,722: t15.2023.08.27 val PER: 0.3103
2025-11-02 04:58:32,722: t15.2023.09.01 val PER: 0.1818
2025-11-02 04:58:32,722: t15.2023.09.03 val PER: 0.2672
2025-11-02 04:58:32,723: t15.2023.09.24 val PER: 0.2257
2025-11-02 04:58:32,723: t15.2023.09.29 val PER: 0.2310
2025-11-02 04:58:32,724: t15.2023.10.01 val PER: 0.2801
2025-11-02 04:58:32,724: t15.2023.10.06 val PER: 0.2034
2025-11-02 04:58:32,724: t15.2023.10.08 val PER: 0.3329
2025-11-02 04:58:32,725: t15.2023.10.13 val PER: 0.3274
2025-11-02 04:58:32,725: t15.2023.10.15 val PER: 0.2446
2025-11-02 04:58:32,726: t15.2023.10.20 val PER: 0.2483
2025-11-02 04:58:32,726: t15.2023.10.22 val PER: 0.2249
2025-11-02 04:58:32,726: t15.2023.11.03 val PER: 0.2734
2025-11-02 04:58:32,727: t15.2023.11.04 val PER: 0.0887
2025-11-02 04:58:32,727: t15.2023.11.17 val PER: 0.1446
2025-11-02 04:58:32,727: t15.2023.11.19 val PER: 0.1277
2025-11-02 04:58:32,728: t15.2023.11.26 val PER: 0.2993
2025-11-02 04:58:32,728: t15.2023.12.03 val PER: 0.2500
2025-11-02 04:58:32,728: t15.2023.12.08 val PER: 0.2636
2025-11-02 04:58:32,729: t15.2023.12.10 val PER: 0.2234
2025-11-02 04:58:32,729: t15.2023.12.17 val PER: 0.2931
2025-11-02 04:58:32,729: t15.2023.12.29 val PER: 0.2759
2025-11-02 04:58:32,730: t15.2024.02.25 val PER: 0.2149
2025-11-02 04:58:32,730: t15.2024.03.08 val PER: 0.3229
2025-11-02 04:58:32,731: t15.2024.03.15 val PER: 0.3327
2025-11-02 04:58:32,731: t15.2024.03.17 val PER: 0.2762
2025-11-02 04:58:32,731: t15.2024.05.10 val PER: 0.2793
2025-11-02 04:58:32,731: t15.2024.06.14 val PER: 0.2760
2025-11-02 04:58:32,732: t15.2024.07.19 val PER: 0.3645
2025-11-02 04:58:32,732: t15.2024.07.21 val PER: 0.2076
2025-11-02 04:58:32,732: t15.2024.07.28 val PER: 0.2618
2025-11-02 04:58:32,733: t15.2025.01.10 val PER: 0.4284
2025-11-02 04:58:32,733: t15.2025.01.12 val PER: 0.2902
2025-11-02 04:58:32,733: t15.2025.03.14 val PER: 0.4364
2025-11-02 04:58:32,734: t15.2025.03.16 val PER: 0.3181
2025-11-02 04:58:32,734: t15.2025.03.30 val PER: 0.3977
2025-11-02 04:58:32,734: t15.2025.04.13 val PER: 0.3452
2025-11-02 04:58:32,735: New best test PER 0.2723 --> 0.2705
2025-11-02 04:58:32,736: Checkpointing model
2025-11-02 04:58:34,626: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 04:58:59,817: Train batch 38200: loss: 24.74 grad norm: 42.98 time: 0.077
2025-11-02 04:59:24,303: Train batch 38400: loss: 13.94 grad norm: 34.93 time: 0.078
2025-11-02 04:59:48,410: Train batch 38600: loss: 20.77 grad norm: 44.71 time: 0.072
2025-11-02 05:00:12,872: Train batch 38800: loss: 20.62 grad norm: 47.79 time: 0.084
2025-11-02 05:00:38,384: Train batch 39000: loss: 17.64 grad norm: 41.31 time: 0.099
2025-11-02 05:00:38,386: Running test after training batch: 39000
2025-11-02 05:00:50,708: Val batch 39000: PER (avg): 0.2665 CTC Loss (avg): 27.3904 time: 12.321
2025-11-02 05:00:50,708: t15.2023.08.13 val PER: 0.2453
2025-11-02 05:00:50,709: t15.2023.08.18 val PER: 0.2062
2025-11-02 05:00:50,709: t15.2023.08.20 val PER: 0.2073
2025-11-02 05:00:50,710: t15.2023.08.25 val PER: 0.2003
2025-11-02 05:00:50,710: t15.2023.08.27 val PER: 0.3006
2025-11-02 05:00:50,711: t15.2023.09.01 val PER: 0.1745
2025-11-02 05:00:50,711: t15.2023.09.03 val PER: 0.2720
2025-11-02 05:00:50,711: t15.2023.09.24 val PER: 0.2136
2025-11-02 05:00:50,712: t15.2023.09.29 val PER: 0.2246
2025-11-02 05:00:50,712: t15.2023.10.01 val PER: 0.2814
2025-11-02 05:00:50,712: t15.2023.10.06 val PER: 0.1981
2025-11-02 05:00:50,712: t15.2023.10.08 val PER: 0.3356
2025-11-02 05:00:50,713: t15.2023.10.13 val PER: 0.3266
2025-11-02 05:00:50,713: t15.2023.10.15 val PER: 0.2439
2025-11-02 05:00:50,713: t15.2023.10.20 val PER: 0.2349
2025-11-02 05:00:50,714: t15.2023.10.22 val PER: 0.2205
2025-11-02 05:00:50,714: t15.2023.11.03 val PER: 0.2734
2025-11-02 05:00:50,714: t15.2023.11.04 val PER: 0.0853
2025-11-02 05:00:50,714: t15.2023.11.17 val PER: 0.1353
2025-11-02 05:00:50,715: t15.2023.11.19 val PER: 0.1238
2025-11-02 05:00:50,716: t15.2023.11.26 val PER: 0.3000
2025-11-02 05:00:50,716: t15.2023.12.03 val PER: 0.2395
2025-11-02 05:00:50,716: t15.2023.12.08 val PER: 0.2597
2025-11-02 05:00:50,716: t15.2023.12.10 val PER: 0.2155
2025-11-02 05:00:50,717: t15.2023.12.17 val PER: 0.2869
2025-11-02 05:00:50,717: t15.2023.12.29 val PER: 0.2725
2025-11-02 05:00:50,717: t15.2024.02.25 val PER: 0.2121
2025-11-02 05:00:50,717: t15.2024.03.08 val PER: 0.3186
2025-11-02 05:00:50,718: t15.2024.03.15 val PER: 0.3340
2025-11-02 05:00:50,718: t15.2024.03.17 val PER: 0.2699
2025-11-02 05:00:50,718: t15.2024.05.10 val PER: 0.2779
2025-11-02 05:00:50,718: t15.2024.06.14 val PER: 0.2729
2025-11-02 05:00:50,719: t15.2024.07.19 val PER: 0.3527
2025-11-02 05:00:50,719: t15.2024.07.21 val PER: 0.2041
2025-11-02 05:00:50,719: t15.2024.07.28 val PER: 0.2706
2025-11-02 05:00:50,720: t15.2025.01.10 val PER: 0.4146
2025-11-02 05:00:50,720: t15.2025.01.12 val PER: 0.2841
2025-11-02 05:00:50,720: t15.2025.03.14 val PER: 0.4290
2025-11-02 05:00:50,721: t15.2025.03.16 val PER: 0.3141
2025-11-02 05:00:50,721: t15.2025.03.30 val PER: 0.3862
2025-11-02 05:00:50,721: t15.2025.04.13 val PER: 0.3481
2025-11-02 05:00:50,721: New best test PER 0.2705 --> 0.2665
2025-11-02 05:00:50,722: Checkpointing model
2025-11-02 05:00:52,630: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:01:16,677: Train batch 39200: loss: 26.94 grad norm: 63.43 time: 0.072
2025-11-02 05:01:40,817: Train batch 39400: loss: 14.92 grad norm: 35.47 time: 0.071
2025-11-02 05:02:04,974: Train batch 39600: loss: 24.47 grad norm: 43.61 time: 0.118
2025-11-02 05:02:29,055: Train batch 39800: loss: 22.03 grad norm: 49.51 time: 0.082
2025-11-02 05:02:53,982: Train batch 40000: loss: 25.24 grad norm: 58.72 time: 0.084
2025-11-02 05:02:53,983: Running test after training batch: 40000
2025-11-02 05:03:06,912: Val batch 40000: PER (avg): 0.2631 CTC Loss (avg): 27.1008 time: 12.929
2025-11-02 05:03:06,913: t15.2023.08.13 val PER: 0.2360
2025-11-02 05:03:06,913: t15.2023.08.18 val PER: 0.2045
2025-11-02 05:03:06,914: t15.2023.08.20 val PER: 0.2041
2025-11-02 05:03:06,914: t15.2023.08.25 val PER: 0.1822
2025-11-02 05:03:06,914: t15.2023.08.27 val PER: 0.3023
2025-11-02 05:03:06,915: t15.2023.09.01 val PER: 0.1729
2025-11-02 05:03:06,915: t15.2023.09.03 val PER: 0.2637
2025-11-02 05:03:06,916: t15.2023.09.24 val PER: 0.2087
2025-11-02 05:03:06,916: t15.2023.09.29 val PER: 0.2176
2025-11-02 05:03:06,916: t15.2023.10.01 val PER: 0.2774
2025-11-02 05:03:06,917: t15.2023.10.06 val PER: 0.1927
2025-11-02 05:03:06,917: t15.2023.10.08 val PER: 0.3261
2025-11-02 05:03:06,917: t15.2023.10.13 val PER: 0.3251
2025-11-02 05:03:06,918: t15.2023.10.15 val PER: 0.2393
2025-11-02 05:03:06,918: t15.2023.10.20 val PER: 0.2315
2025-11-02 05:03:06,918: t15.2023.10.22 val PER: 0.2149
2025-11-02 05:03:06,919: t15.2023.11.03 val PER: 0.2748
2025-11-02 05:03:06,919: t15.2023.11.04 val PER: 0.0785
2025-11-02 05:03:06,919: t15.2023.11.17 val PER: 0.1384
2025-11-02 05:03:06,919: t15.2023.11.19 val PER: 0.1257
2025-11-02 05:03:06,920: t15.2023.11.26 val PER: 0.2957
2025-11-02 05:03:06,920: t15.2023.12.03 val PER: 0.2353
2025-11-02 05:03:06,921: t15.2023.12.08 val PER: 0.2577
2025-11-02 05:03:06,921: t15.2023.12.10 val PER: 0.2181
2025-11-02 05:03:06,921: t15.2023.12.17 val PER: 0.2869
2025-11-02 05:03:06,922: t15.2023.12.29 val PER: 0.2677
2025-11-02 05:03:06,922: t15.2024.02.25 val PER: 0.2037
2025-11-02 05:03:06,922: t15.2024.03.08 val PER: 0.3144
2025-11-02 05:03:06,923: t15.2024.03.15 val PER: 0.3333
2025-11-02 05:03:06,923: t15.2024.03.17 val PER: 0.2727
2025-11-02 05:03:06,923: t15.2024.05.10 val PER: 0.2704
2025-11-02 05:03:06,923: t15.2024.06.14 val PER: 0.2650
2025-11-02 05:03:06,924: t15.2024.07.19 val PER: 0.3507
2025-11-02 05:03:06,924: t15.2024.07.21 val PER: 0.2007
2025-11-02 05:03:06,924: t15.2024.07.28 val PER: 0.2625
2025-11-02 05:03:06,924: t15.2025.01.10 val PER: 0.4215
2025-11-02 05:03:06,925: t15.2025.01.12 val PER: 0.2825
2025-11-02 05:03:06,925: t15.2025.03.14 val PER: 0.4290
2025-11-02 05:03:06,926: t15.2025.03.16 val PER: 0.2997
2025-11-02 05:03:06,926: t15.2025.03.30 val PER: 0.3839
2025-11-02 05:03:06,926: t15.2025.04.13 val PER: 0.3495
2025-11-02 05:03:06,927: New best test PER 0.2665 --> 0.2631
2025-11-02 05:03:06,927: Checkpointing model
2025-11-02 05:03:09,036: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:03:34,214: Train batch 40200: loss: 17.24 grad norm: 55.40 time: 0.073
2025-11-02 05:03:58,777: Train batch 40400: loss: 19.41 grad norm: 41.71 time: 0.085
2025-11-02 05:04:22,903: Train batch 40600: loss: 14.69 grad norm: 34.26 time: 0.079
2025-11-02 05:04:47,358: Train batch 40800: loss: 25.42 grad norm: 50.43 time: 0.072
2025-11-02 05:05:12,056: Train batch 41000: loss: 29.34 grad norm: 58.18 time: 0.105
2025-11-02 05:05:12,057: Running test after training batch: 41000
2025-11-02 05:05:24,212: Val batch 41000: PER (avg): 0.2604 CTC Loss (avg): 26.8476 time: 12.154
2025-11-02 05:05:24,213: t15.2023.08.13 val PER: 0.2256
2025-11-02 05:05:24,213: t15.2023.08.18 val PER: 0.2087
2025-11-02 05:05:24,214: t15.2023.08.20 val PER: 0.2010
2025-11-02 05:05:24,214: t15.2023.08.25 val PER: 0.1852
2025-11-02 05:05:24,215: t15.2023.08.27 val PER: 0.2958
2025-11-02 05:05:24,215: t15.2023.09.01 val PER: 0.1729
2025-11-02 05:05:24,216: t15.2023.09.03 val PER: 0.2660
2025-11-02 05:05:24,216: t15.2023.09.24 val PER: 0.2087
2025-11-02 05:05:24,216: t15.2023.09.29 val PER: 0.2240
2025-11-02 05:05:24,217: t15.2023.10.01 val PER: 0.2728
2025-11-02 05:05:24,217: t15.2023.10.06 val PER: 0.1905
2025-11-02 05:05:24,217: t15.2023.10.08 val PER: 0.3234
2025-11-02 05:05:24,217: t15.2023.10.13 val PER: 0.3165
2025-11-02 05:05:24,218: t15.2023.10.15 val PER: 0.2340
2025-11-02 05:05:24,218: t15.2023.10.20 val PER: 0.2315
2025-11-02 05:05:24,219: t15.2023.10.22 val PER: 0.2094
2025-11-02 05:05:24,219: t15.2023.11.03 val PER: 0.2653
2025-11-02 05:05:24,219: t15.2023.11.04 val PER: 0.0751
2025-11-02 05:05:24,220: t15.2023.11.17 val PER: 0.1400
2025-11-02 05:05:24,220: t15.2023.11.19 val PER: 0.1297
2025-11-02 05:05:24,221: t15.2023.11.26 val PER: 0.2913
2025-11-02 05:05:24,221: t15.2023.12.03 val PER: 0.2342
2025-11-02 05:05:24,221: t15.2023.12.08 val PER: 0.2477
2025-11-02 05:05:24,222: t15.2023.12.10 val PER: 0.2129
2025-11-02 05:05:24,222: t15.2023.12.17 val PER: 0.2807
2025-11-02 05:05:24,222: t15.2023.12.29 val PER: 0.2649
2025-11-02 05:05:24,223: t15.2024.02.25 val PER: 0.2051
2025-11-02 05:05:24,223: t15.2024.03.08 val PER: 0.3215
2025-11-02 05:05:24,223: t15.2024.03.15 val PER: 0.3208
2025-11-02 05:05:24,223: t15.2024.03.17 val PER: 0.2762
2025-11-02 05:05:24,224: t15.2024.05.10 val PER: 0.2779
2025-11-02 05:05:24,224: t15.2024.06.14 val PER: 0.2666
2025-11-02 05:05:24,224: t15.2024.07.19 val PER: 0.3481
2025-11-02 05:05:24,225: t15.2024.07.21 val PER: 0.1952
2025-11-02 05:05:24,225: t15.2024.07.28 val PER: 0.2566
2025-11-02 05:05:24,230: t15.2025.01.10 val PER: 0.4132
2025-11-02 05:05:24,231: t15.2025.01.12 val PER: 0.2794
2025-11-02 05:05:24,231: t15.2025.03.14 val PER: 0.4246
2025-11-02 05:05:24,231: t15.2025.03.16 val PER: 0.3037
2025-11-02 05:05:24,232: t15.2025.03.30 val PER: 0.3874
2025-11-02 05:05:24,232: t15.2025.04.13 val PER: 0.3466
2025-11-02 05:05:24,232: New best test PER 0.2631 --> 0.2604
2025-11-02 05:05:24,232: Checkpointing model
2025-11-02 05:05:25,983: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:05:50,945: Train batch 41200: loss: 18.26 grad norm: 44.86 time: 0.067
2025-11-02 05:06:15,541: Train batch 41400: loss: 18.33 grad norm: 39.19 time: 0.057
2025-11-02 05:06:40,091: Train batch 41600: loss: 17.01 grad norm: 42.04 time: 0.076
2025-11-02 05:07:04,980: Train batch 41800: loss: 15.38 grad norm: 40.94 time: 0.094
2025-11-02 05:07:29,415: Train batch 42000: loss: 18.08 grad norm: 47.75 time: 0.109
2025-11-02 05:07:29,417: Running test after training batch: 42000
2025-11-02 05:07:41,922: Val batch 42000: PER (avg): 0.2585 CTC Loss (avg): 26.6034 time: 12.505
2025-11-02 05:07:41,922: t15.2023.08.13 val PER: 0.2277
2025-11-02 05:07:41,923: t15.2023.08.18 val PER: 0.1995
2025-11-02 05:07:41,923: t15.2023.08.20 val PER: 0.2010
2025-11-02 05:07:41,923: t15.2023.08.25 val PER: 0.1852
2025-11-02 05:07:41,924: t15.2023.08.27 val PER: 0.2910
2025-11-02 05:07:41,924: t15.2023.09.01 val PER: 0.1656
2025-11-02 05:07:41,925: t15.2023.09.03 val PER: 0.2660
2025-11-02 05:07:41,925: t15.2023.09.24 val PER: 0.2112
2025-11-02 05:07:41,925: t15.2023.09.29 val PER: 0.2170
2025-11-02 05:07:41,926: t15.2023.10.01 val PER: 0.2662
2025-11-02 05:07:41,926: t15.2023.10.06 val PER: 0.1938
2025-11-02 05:07:41,926: t15.2023.10.08 val PER: 0.3139
2025-11-02 05:07:41,927: t15.2023.10.13 val PER: 0.3165
2025-11-02 05:07:41,927: t15.2023.10.15 val PER: 0.2347
2025-11-02 05:07:41,927: t15.2023.10.20 val PER: 0.2315
2025-11-02 05:07:41,928: t15.2023.10.22 val PER: 0.2071
2025-11-02 05:07:41,928: t15.2023.11.03 val PER: 0.2687
2025-11-02 05:07:41,928: t15.2023.11.04 val PER: 0.0785
2025-11-02 05:07:41,929: t15.2023.11.17 val PER: 0.1322
2025-11-02 05:07:41,929: t15.2023.11.19 val PER: 0.1257
2025-11-02 05:07:41,929: t15.2023.11.26 val PER: 0.2942
2025-11-02 05:07:41,930: t15.2023.12.03 val PER: 0.2321
2025-11-02 05:07:41,930: t15.2023.12.08 val PER: 0.2510
2025-11-02 05:07:41,930: t15.2023.12.10 val PER: 0.2076
2025-11-02 05:07:41,931: t15.2023.12.17 val PER: 0.2817
2025-11-02 05:07:41,931: t15.2023.12.29 val PER: 0.2594
2025-11-02 05:07:41,931: t15.2024.02.25 val PER: 0.2065
2025-11-02 05:07:41,932: t15.2024.03.08 val PER: 0.3158
2025-11-02 05:07:41,932: t15.2024.03.15 val PER: 0.3252
2025-11-02 05:07:41,932: t15.2024.03.17 val PER: 0.2608
2025-11-02 05:07:41,933: t15.2024.05.10 val PER: 0.2585
2025-11-02 05:07:41,933: t15.2024.06.14 val PER: 0.2666
2025-11-02 05:07:41,933: t15.2024.07.19 val PER: 0.3474
2025-11-02 05:07:41,933: t15.2024.07.21 val PER: 0.2000
2025-11-02 05:07:41,934: t15.2024.07.28 val PER: 0.2581
2025-11-02 05:07:41,934: t15.2025.01.10 val PER: 0.4105
2025-11-02 05:07:41,934: t15.2025.01.12 val PER: 0.2794
2025-11-02 05:07:41,935: t15.2025.03.14 val PER: 0.4290
2025-11-02 05:07:41,935: t15.2025.03.16 val PER: 0.3089
2025-11-02 05:07:41,936: t15.2025.03.30 val PER: 0.3770
2025-11-02 05:07:41,936: t15.2025.04.13 val PER: 0.3452
2025-11-02 05:07:41,936: New best test PER 0.2604 --> 0.2585
2025-11-02 05:07:41,936: Checkpointing model
2025-11-02 05:07:43,649: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:08:08,839: Train batch 42200: loss: 18.64 grad norm: 45.97 time: 0.079
2025-11-02 05:08:33,771: Train batch 42400: loss: 21.89 grad norm: 47.95 time: 0.098
2025-11-02 05:08:58,288: Train batch 42600: loss: 15.83 grad norm: 38.52 time: 0.074
2025-11-02 05:09:22,928: Train batch 42800: loss: 17.59 grad norm: 43.50 time: 0.080
2025-11-02 05:09:47,238: Train batch 43000: loss: 15.63 grad norm: 67.52 time: 0.084
2025-11-02 05:09:47,239: Running test after training batch: 43000
2025-11-02 05:09:59,700: Val batch 43000: PER (avg): 0.2561 CTC Loss (avg): 26.3592 time: 12.460
2025-11-02 05:09:59,705: t15.2023.08.13 val PER: 0.2235
2025-11-02 05:09:59,706: t15.2023.08.18 val PER: 0.2054
2025-11-02 05:09:59,706: t15.2023.08.20 val PER: 0.1930
2025-11-02 05:09:59,707: t15.2023.08.25 val PER: 0.1837
2025-11-02 05:09:59,707: t15.2023.08.27 val PER: 0.2910
2025-11-02 05:09:59,707: t15.2023.09.01 val PER: 0.1575
2025-11-02 05:09:59,708: t15.2023.09.03 val PER: 0.2613
2025-11-02 05:09:59,708: t15.2023.09.24 val PER: 0.1978
2025-11-02 05:09:59,708: t15.2023.09.29 val PER: 0.2183
2025-11-02 05:09:59,709: t15.2023.10.01 val PER: 0.2609
2025-11-02 05:09:59,709: t15.2023.10.06 val PER: 0.1927
2025-11-02 05:09:59,709: t15.2023.10.08 val PER: 0.3248
2025-11-02 05:09:59,710: t15.2023.10.13 val PER: 0.3142
2025-11-02 05:09:59,711: t15.2023.10.15 val PER: 0.2340
2025-11-02 05:09:59,711: t15.2023.10.20 val PER: 0.2215
2025-11-02 05:09:59,711: t15.2023.10.22 val PER: 0.2004
2025-11-02 05:09:59,712: t15.2023.11.03 val PER: 0.2673
2025-11-02 05:09:59,712: t15.2023.11.04 val PER: 0.0683
2025-11-02 05:09:59,712: t15.2023.11.17 val PER: 0.1322
2025-11-02 05:09:59,713: t15.2023.11.19 val PER: 0.1257
2025-11-02 05:09:59,713: t15.2023.11.26 val PER: 0.2906
2025-11-02 05:09:59,713: t15.2023.12.03 val PER: 0.2279
2025-11-02 05:09:59,714: t15.2023.12.08 val PER: 0.2463
2025-11-02 05:09:59,714: t15.2023.12.10 val PER: 0.2076
2025-11-02 05:09:59,714: t15.2023.12.17 val PER: 0.2817
2025-11-02 05:09:59,715: t15.2023.12.29 val PER: 0.2574
2025-11-02 05:09:59,715: t15.2024.02.25 val PER: 0.2022
2025-11-02 05:09:59,716: t15.2024.03.08 val PER: 0.3286
2025-11-02 05:09:59,716: t15.2024.03.15 val PER: 0.3215
2025-11-02 05:09:59,716: t15.2024.03.17 val PER: 0.2615
2025-11-02 05:09:59,716: t15.2024.05.10 val PER: 0.2615
2025-11-02 05:09:59,717: t15.2024.06.14 val PER: 0.2603
2025-11-02 05:09:59,717: t15.2024.07.19 val PER: 0.3454
2025-11-02 05:09:59,717: t15.2024.07.21 val PER: 0.1979
2025-11-02 05:09:59,718: t15.2024.07.28 val PER: 0.2507
2025-11-02 05:09:59,718: t15.2025.01.10 val PER: 0.4132
2025-11-02 05:09:59,718: t15.2025.01.12 val PER: 0.2733
2025-11-02 05:09:59,718: t15.2025.03.14 val PER: 0.4320
2025-11-02 05:09:59,719: t15.2025.03.16 val PER: 0.3050
2025-11-02 05:09:59,719: t15.2025.03.30 val PER: 0.3770
2025-11-02 05:09:59,719: t15.2025.04.13 val PER: 0.3352
2025-11-02 05:09:59,719: New best test PER 0.2585 --> 0.2561
2025-11-02 05:09:59,720: Checkpointing model
2025-11-02 05:10:01,450: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:10:26,409: Train batch 43200: loss: 15.20 grad norm: 42.00 time: 0.072
2025-11-02 05:10:50,798: Train batch 43400: loss: 27.05 grad norm: 55.92 time: 0.077
2025-11-02 05:11:15,906: Train batch 43600: loss: 14.61 grad norm: 47.66 time: 0.063
2025-11-02 05:11:40,337: Train batch 43800: loss: 17.18 grad norm: 43.02 time: 0.097
2025-11-02 05:12:05,424: Train batch 44000: loss: 14.14 grad norm: 38.53 time: 0.067
2025-11-02 05:12:05,426: Running test after training batch: 44000
2025-11-02 05:12:20,021: Val batch 44000: PER (avg): 0.2536 CTC Loss (avg): 26.0870 time: 14.595
2025-11-02 05:12:20,022: t15.2023.08.13 val PER: 0.2225
2025-11-02 05:12:20,022: t15.2023.08.18 val PER: 0.2028
2025-11-02 05:12:20,023: t15.2023.08.20 val PER: 0.1970
2025-11-02 05:12:20,023: t15.2023.08.25 val PER: 0.1777
2025-11-02 05:12:20,023: t15.2023.08.27 val PER: 0.2846
2025-11-02 05:12:20,024: t15.2023.09.01 val PER: 0.1615
2025-11-02 05:12:20,024: t15.2023.09.03 val PER: 0.2625
2025-11-02 05:12:20,024: t15.2023.09.24 val PER: 0.2051
2025-11-02 05:12:20,025: t15.2023.09.29 val PER: 0.2151
2025-11-02 05:12:20,025: t15.2023.10.01 val PER: 0.2583
2025-11-02 05:12:20,026: t15.2023.10.06 val PER: 0.1916
2025-11-02 05:12:20,026: t15.2023.10.08 val PER: 0.3153
2025-11-02 05:12:20,026: t15.2023.10.13 val PER: 0.3126
2025-11-02 05:12:20,027: t15.2023.10.15 val PER: 0.2268
2025-11-02 05:12:20,027: t15.2023.10.20 val PER: 0.2349
2025-11-02 05:12:20,027: t15.2023.10.22 val PER: 0.2016
2025-11-02 05:12:20,028: t15.2023.11.03 val PER: 0.2619
2025-11-02 05:12:20,028: t15.2023.11.04 val PER: 0.0614
2025-11-02 05:12:20,028: t15.2023.11.17 val PER: 0.1291
2025-11-02 05:12:20,028: t15.2023.11.19 val PER: 0.1198
2025-11-02 05:12:20,029: t15.2023.11.26 val PER: 0.2891
2025-11-02 05:12:20,029: t15.2023.12.03 val PER: 0.2290
2025-11-02 05:12:20,029: t15.2023.12.08 val PER: 0.2503
2025-11-02 05:12:20,030: t15.2023.12.10 val PER: 0.2037
2025-11-02 05:12:20,030: t15.2023.12.17 val PER: 0.2744
2025-11-02 05:12:20,031: t15.2023.12.29 val PER: 0.2533
2025-11-02 05:12:20,031: t15.2024.02.25 val PER: 0.2022
2025-11-02 05:12:20,031: t15.2024.03.08 val PER: 0.3186
2025-11-02 05:12:20,031: t15.2024.03.15 val PER: 0.3171
2025-11-02 05:12:20,032: t15.2024.03.17 val PER: 0.2622
2025-11-02 05:12:20,032: t15.2024.05.10 val PER: 0.2526
2025-11-02 05:12:20,032: t15.2024.06.14 val PER: 0.2697
2025-11-02 05:12:20,033: t15.2024.07.19 val PER: 0.3401
2025-11-02 05:12:20,033: t15.2024.07.21 val PER: 0.1938
2025-11-02 05:12:20,033: t15.2024.07.28 val PER: 0.2522
2025-11-02 05:12:20,033: t15.2025.01.10 val PER: 0.4063
2025-11-02 05:12:20,034: t15.2025.01.12 val PER: 0.2748
2025-11-02 05:12:20,034: t15.2025.03.14 val PER: 0.4231
2025-11-02 05:12:20,034: t15.2025.03.16 val PER: 0.2932
2025-11-02 05:12:20,034: t15.2025.03.30 val PER: 0.3621
2025-11-02 05:12:20,035: t15.2025.04.13 val PER: 0.3338
2025-11-02 05:12:20,035: New best test PER 0.2561 --> 0.2536
2025-11-02 05:12:20,036: Checkpointing model
2025-11-02 05:12:22,047: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:12:47,180: Train batch 44200: loss: 12.90 grad norm: 34.15 time: 0.064
2025-11-02 05:13:12,083: Train batch 44400: loss: 19.28 grad norm: 48.07 time: 0.092
2025-11-02 05:13:36,750: Train batch 44600: loss: 21.38 grad norm: 56.86 time: 0.072
2025-11-02 05:14:01,413: Train batch 44800: loss: 19.62 grad norm: 46.80 time: 0.068
2025-11-02 05:14:26,531: Train batch 45000: loss: 7.27 grad norm: 27.82 time: 0.068
2025-11-02 05:14:26,532: Running test after training batch: 45000
2025-11-02 05:14:41,823: Val batch 45000: PER (avg): 0.2520 CTC Loss (avg): 25.8157 time: 15.291
2025-11-02 05:14:41,824: t15.2023.08.13 val PER: 0.2183
2025-11-02 05:14:41,824: t15.2023.08.18 val PER: 0.2020
2025-11-02 05:14:41,825: t15.2023.08.20 val PER: 0.2025
2025-11-02 05:14:41,825: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:14:41,826: t15.2023.08.27 val PER: 0.2765
2025-11-02 05:14:41,826: t15.2023.09.01 val PER: 0.1558
2025-11-02 05:14:41,826: t15.2023.09.03 val PER: 0.2542
2025-11-02 05:14:41,827: t15.2023.09.24 val PER: 0.2063
2025-11-02 05:14:41,827: t15.2023.09.29 val PER: 0.2093
2025-11-02 05:14:41,827: t15.2023.10.01 val PER: 0.2563
2025-11-02 05:14:41,827: t15.2023.10.06 val PER: 0.1959
2025-11-02 05:14:41,828: t15.2023.10.08 val PER: 0.3099
2025-11-02 05:14:41,828: t15.2023.10.13 val PER: 0.3111
2025-11-02 05:14:41,828: t15.2023.10.15 val PER: 0.2248
2025-11-02 05:14:41,829: t15.2023.10.20 val PER: 0.2282
2025-11-02 05:14:41,829: t15.2023.10.22 val PER: 0.2016
2025-11-02 05:14:41,829: t15.2023.11.03 val PER: 0.2619
2025-11-02 05:14:41,829: t15.2023.11.04 val PER: 0.0751
2025-11-02 05:14:41,830: t15.2023.11.17 val PER: 0.1291
2025-11-02 05:14:41,831: t15.2023.11.19 val PER: 0.1158
2025-11-02 05:14:41,831: t15.2023.11.26 val PER: 0.2862
2025-11-02 05:14:41,831: t15.2023.12.03 val PER: 0.2258
2025-11-02 05:14:41,831: t15.2023.12.08 val PER: 0.2430
2025-11-02 05:14:41,832: t15.2023.12.10 val PER: 0.2024
2025-11-02 05:14:41,832: t15.2023.12.17 val PER: 0.2713
2025-11-02 05:14:41,832: t15.2023.12.29 val PER: 0.2491
2025-11-02 05:14:41,833: t15.2024.02.25 val PER: 0.2022
2025-11-02 05:14:41,833: t15.2024.03.08 val PER: 0.3172
2025-11-02 05:14:41,833: t15.2024.03.15 val PER: 0.3152
2025-11-02 05:14:41,834: t15.2024.03.17 val PER: 0.2587
2025-11-02 05:14:41,883: t15.2024.05.10 val PER: 0.2585
2025-11-02 05:14:41,884: t15.2024.06.14 val PER: 0.2587
2025-11-02 05:14:41,884: t15.2024.07.19 val PER: 0.3395
2025-11-02 05:14:41,885: t15.2024.07.21 val PER: 0.1924
2025-11-02 05:14:41,885: t15.2024.07.28 val PER: 0.2493
2025-11-02 05:14:41,886: t15.2025.01.10 val PER: 0.4146
2025-11-02 05:14:41,886: t15.2025.01.12 val PER: 0.2702
2025-11-02 05:14:41,886: t15.2025.03.14 val PER: 0.4290
2025-11-02 05:14:41,887: t15.2025.03.16 val PER: 0.3010
2025-11-02 05:14:41,887: t15.2025.03.30 val PER: 0.3736
2025-11-02 05:14:41,887: t15.2025.04.13 val PER: 0.3310
2025-11-02 05:14:41,887: New best test PER 0.2536 --> 0.2520
2025-11-02 05:14:41,888: Checkpointing model
2025-11-02 05:14:43,918: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:15:09,273: Train batch 45200: loss: 27.82 grad norm: 67.31 time: 0.070
2025-11-02 05:15:34,321: Train batch 45400: loss: 16.47 grad norm: 46.78 time: 0.080
2025-11-02 05:15:59,556: Train batch 45600: loss: 16.90 grad norm: 44.74 time: 0.082
2025-11-02 05:16:23,953: Train batch 45800: loss: 22.07 grad norm: 52.34 time: 0.061
2025-11-02 05:16:49,384: Train batch 46000: loss: 17.76 grad norm: 43.57 time: 0.079
2025-11-02 05:16:49,385: Running test after training batch: 46000
2025-11-02 05:17:04,422: Val batch 46000: PER (avg): 0.2501 CTC Loss (avg): 25.7090 time: 15.037
2025-11-02 05:17:04,423: t15.2023.08.13 val PER: 0.2193
2025-11-02 05:17:04,423: t15.2023.08.18 val PER: 0.2003
2025-11-02 05:17:04,424: t15.2023.08.20 val PER: 0.1922
2025-11-02 05:17:04,424: t15.2023.08.25 val PER: 0.1822
2025-11-02 05:17:04,425: t15.2023.08.27 val PER: 0.2781
2025-11-02 05:17:04,425: t15.2023.09.01 val PER: 0.1518
2025-11-02 05:17:04,426: t15.2023.09.03 val PER: 0.2458
2025-11-02 05:17:04,426: t15.2023.09.24 val PER: 0.2027
2025-11-02 05:17:04,426: t15.2023.09.29 val PER: 0.2138
2025-11-02 05:17:04,427: t15.2023.10.01 val PER: 0.2563
2025-11-02 05:17:04,427: t15.2023.10.06 val PER: 0.1916
2025-11-02 05:17:04,427: t15.2023.10.08 val PER: 0.3058
2025-11-02 05:17:04,427: t15.2023.10.13 val PER: 0.3049
2025-11-02 05:17:04,428: t15.2023.10.15 val PER: 0.2248
2025-11-02 05:17:04,428: t15.2023.10.20 val PER: 0.2148
2025-11-02 05:17:04,428: t15.2023.10.22 val PER: 0.1982
2025-11-02 05:17:04,429: t15.2023.11.03 val PER: 0.2585
2025-11-02 05:17:04,429: t15.2023.11.04 val PER: 0.0614
2025-11-02 05:17:04,429: t15.2023.11.17 val PER: 0.1260
2025-11-02 05:17:04,429: t15.2023.11.19 val PER: 0.1238
2025-11-02 05:17:04,430: t15.2023.11.26 val PER: 0.2783
2025-11-02 05:17:04,430: t15.2023.12.03 val PER: 0.2227
2025-11-02 05:17:04,431: t15.2023.12.08 val PER: 0.2437
2025-11-02 05:17:04,431: t15.2023.12.10 val PER: 0.2024
2025-11-02 05:17:04,431: t15.2023.12.17 val PER: 0.2734
2025-11-02 05:17:04,431: t15.2023.12.29 val PER: 0.2471
2025-11-02 05:17:04,432: t15.2024.02.25 val PER: 0.1966
2025-11-02 05:17:04,432: t15.2024.03.08 val PER: 0.3186
2025-11-02 05:17:04,432: t15.2024.03.15 val PER: 0.3215
2025-11-02 05:17:04,433: t15.2024.03.17 val PER: 0.2566
2025-11-02 05:17:04,433: t15.2024.05.10 val PER: 0.2526
2025-11-02 05:17:04,433: t15.2024.06.14 val PER: 0.2571
2025-11-02 05:17:04,434: t15.2024.07.19 val PER: 0.3362
2025-11-02 05:17:04,434: t15.2024.07.21 val PER: 0.1917
2025-11-02 05:17:04,434: t15.2024.07.28 val PER: 0.2419
2025-11-02 05:17:04,434: t15.2025.01.10 val PER: 0.4050
2025-11-02 05:17:04,435: t15.2025.01.12 val PER: 0.2687
2025-11-02 05:17:04,435: t15.2025.03.14 val PER: 0.4216
2025-11-02 05:17:04,436: t15.2025.03.16 val PER: 0.3010
2025-11-02 05:17:04,436: t15.2025.03.30 val PER: 0.3770
2025-11-02 05:17:04,436: t15.2025.04.13 val PER: 0.3438
2025-11-02 05:17:04,436: New best test PER 0.2520 --> 0.2501
2025-11-02 05:17:04,437: Checkpointing model
2025-11-02 05:17:06,428: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:17:31,685: Train batch 46200: loss: 24.71 grad norm: 62.81 time: 0.109
2025-11-02 05:17:57,109: Train batch 46400: loss: 14.41 grad norm: 43.13 time: 0.113
2025-11-02 05:18:21,963: Train batch 46600: loss: 22.83 grad norm: 54.06 time: 0.083
2025-11-02 05:18:46,461: Train batch 46800: loss: 17.20 grad norm: 54.36 time: 0.084
2025-11-02 05:19:11,072: Train batch 47000: loss: 16.54 grad norm: 47.74 time: 0.069
2025-11-02 05:19:11,073: Running test after training batch: 47000
2025-11-02 05:19:26,220: Val batch 47000: PER (avg): 0.2485 CTC Loss (avg): 25.5400 time: 15.147
2025-11-02 05:19:26,221: t15.2023.08.13 val PER: 0.2193
2025-11-02 05:19:26,222: t15.2023.08.18 val PER: 0.1987
2025-11-02 05:19:26,222: t15.2023.08.20 val PER: 0.2002
2025-11-02 05:19:26,222: t15.2023.08.25 val PER: 0.1717
2025-11-02 05:19:26,223: t15.2023.08.27 val PER: 0.2749
2025-11-02 05:19:26,223: t15.2023.09.01 val PER: 0.1477
2025-11-02 05:19:26,223: t15.2023.09.03 val PER: 0.2530
2025-11-02 05:19:26,224: t15.2023.09.24 val PER: 0.2051
2025-11-02 05:19:26,224: t15.2023.09.29 val PER: 0.2023
2025-11-02 05:19:26,224: t15.2023.10.01 val PER: 0.2563
2025-11-02 05:19:26,225: t15.2023.10.06 val PER: 0.1905
2025-11-02 05:19:26,225: t15.2023.10.08 val PER: 0.3018
2025-11-02 05:19:26,226: t15.2023.10.13 val PER: 0.3041
2025-11-02 05:19:26,226: t15.2023.10.15 val PER: 0.2202
2025-11-02 05:19:26,226: t15.2023.10.20 val PER: 0.2282
2025-11-02 05:19:26,227: t15.2023.10.22 val PER: 0.2027
2025-11-02 05:19:26,227: t15.2023.11.03 val PER: 0.2639
2025-11-02 05:19:26,227: t15.2023.11.04 val PER: 0.0717
2025-11-02 05:19:26,228: t15.2023.11.17 val PER: 0.1213
2025-11-02 05:19:26,228: t15.2023.11.19 val PER: 0.1138
2025-11-02 05:19:26,228: t15.2023.11.26 val PER: 0.2826
2025-11-02 05:19:26,229: t15.2023.12.03 val PER: 0.2227
2025-11-02 05:19:26,229: t15.2023.12.08 val PER: 0.2377
2025-11-02 05:19:26,229: t15.2023.12.10 val PER: 0.2089
2025-11-02 05:19:26,229: t15.2023.12.17 val PER: 0.2620
2025-11-02 05:19:26,230: t15.2023.12.29 val PER: 0.2416
2025-11-02 05:19:26,231: t15.2024.02.25 val PER: 0.1980
2025-11-02 05:19:26,231: t15.2024.03.08 val PER: 0.3144
2025-11-02 05:19:26,231: t15.2024.03.15 val PER: 0.3133
2025-11-02 05:19:26,232: t15.2024.03.17 val PER: 0.2531
2025-11-02 05:19:26,232: t15.2024.05.10 val PER: 0.2481
2025-11-02 05:19:26,232: t15.2024.06.14 val PER: 0.2539
2025-11-02 05:19:26,233: t15.2024.07.19 val PER: 0.3342
2025-11-02 05:19:26,233: t15.2024.07.21 val PER: 0.1931
2025-11-02 05:19:26,234: t15.2024.07.28 val PER: 0.2419
2025-11-02 05:19:26,234: t15.2025.01.10 val PER: 0.4008
2025-11-02 05:19:26,234: t15.2025.01.12 val PER: 0.2679
2025-11-02 05:19:26,235: t15.2025.03.14 val PER: 0.4275
2025-11-02 05:19:26,235: t15.2025.03.16 val PER: 0.3024
2025-11-02 05:19:26,236: t15.2025.03.30 val PER: 0.3736
2025-11-02 05:19:26,236: t15.2025.04.13 val PER: 0.3324
2025-11-02 05:19:26,236: New best test PER 0.2501 --> 0.2485
2025-11-02 05:19:26,237: Checkpointing model
2025-11-02 05:19:28,211: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:19:53,359: Train batch 47200: loss: 15.16 grad norm: 39.86 time: 0.083
2025-11-02 05:20:17,477: Train batch 47400: loss: 19.23 grad norm: 50.84 time: 0.085
2025-11-02 05:20:42,414: Train batch 47600: loss: 19.93 grad norm: 48.64 time: 0.092
2025-11-02 05:21:07,946: Train batch 47800: loss: 16.19 grad norm: 40.09 time: 0.073
2025-11-02 05:21:32,102: Train batch 48000: loss: 18.27 grad norm: 55.17 time: 0.098
2025-11-02 05:21:32,104: Running test after training batch: 48000
2025-11-02 05:21:47,225: Val batch 48000: PER (avg): 0.2471 CTC Loss (avg): 25.3657 time: 15.121
2025-11-02 05:21:47,226: t15.2023.08.13 val PER: 0.2183
2025-11-02 05:21:47,227: t15.2023.08.18 val PER: 0.1978
2025-11-02 05:21:47,227: t15.2023.08.20 val PER: 0.2010
2025-11-02 05:21:47,228: t15.2023.08.25 val PER: 0.1822
2025-11-02 05:21:47,228: t15.2023.08.27 val PER: 0.2749
2025-11-02 05:21:47,228: t15.2023.09.01 val PER: 0.1502
2025-11-02 05:21:47,229: t15.2023.09.03 val PER: 0.2447
2025-11-02 05:21:47,229: t15.2023.09.24 val PER: 0.2002
2025-11-02 05:21:47,229: t15.2023.09.29 val PER: 0.2061
2025-11-02 05:21:47,230: t15.2023.10.01 val PER: 0.2510
2025-11-02 05:21:47,230: t15.2023.10.06 val PER: 0.1851
2025-11-02 05:21:47,231: t15.2023.10.08 val PER: 0.3085
2025-11-02 05:21:47,231: t15.2023.10.13 val PER: 0.3072
2025-11-02 05:21:47,232: t15.2023.10.15 val PER: 0.2215
2025-11-02 05:21:47,232: t15.2023.10.20 val PER: 0.2181
2025-11-02 05:21:47,232: t15.2023.10.22 val PER: 0.1971
2025-11-02 05:21:47,232: t15.2023.11.03 val PER: 0.2619
2025-11-02 05:21:47,233: t15.2023.11.04 val PER: 0.0683
2025-11-02 05:21:47,233: t15.2023.11.17 val PER: 0.1260
2025-11-02 05:21:47,233: t15.2023.11.19 val PER: 0.1138
2025-11-02 05:21:47,234: t15.2023.11.26 val PER: 0.2783
2025-11-02 05:21:47,234: t15.2023.12.03 val PER: 0.2216
2025-11-02 05:21:47,234: t15.2023.12.08 val PER: 0.2383
2025-11-02 05:21:47,235: t15.2023.12.10 val PER: 0.2024
2025-11-02 05:21:47,235: t15.2023.12.17 val PER: 0.2599
2025-11-02 05:21:47,236: t15.2023.12.29 val PER: 0.2471
2025-11-02 05:21:47,236: t15.2024.02.25 val PER: 0.1966
2025-11-02 05:21:47,237: t15.2024.03.08 val PER: 0.3186
2025-11-02 05:21:47,237: t15.2024.03.15 val PER: 0.3146
2025-11-02 05:21:47,237: t15.2024.03.17 val PER: 0.2490
2025-11-02 05:21:47,283: t15.2024.05.10 val PER: 0.2422
2025-11-02 05:21:47,284: t15.2024.06.14 val PER: 0.2508
2025-11-02 05:21:47,284: t15.2024.07.19 val PER: 0.3322
2025-11-02 05:21:47,285: t15.2024.07.21 val PER: 0.1903
2025-11-02 05:21:47,285: t15.2024.07.28 val PER: 0.2419
2025-11-02 05:21:47,285: t15.2025.01.10 val PER: 0.4036
2025-11-02 05:21:47,286: t15.2025.01.12 val PER: 0.2602
2025-11-02 05:21:47,286: t15.2025.03.14 val PER: 0.4216
2025-11-02 05:21:47,286: t15.2025.03.16 val PER: 0.3024
2025-11-02 05:21:47,287: t15.2025.03.30 val PER: 0.3575
2025-11-02 05:21:47,287: t15.2025.04.13 val PER: 0.3281
2025-11-02 05:21:47,287: New best test PER 0.2485 --> 0.2471
2025-11-02 05:21:47,287: Checkpointing model
2025-11-02 05:21:49,299: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:22:14,775: Train batch 48200: loss: 17.19 grad norm: 44.32 time: 0.101
2025-11-02 05:22:39,192: Train batch 48400: loss: 19.44 grad norm: 47.70 time: 0.087
2025-11-02 05:23:04,159: Train batch 48600: loss: 18.25 grad norm: 47.71 time: 0.088
2025-11-02 05:23:28,414: Train batch 48800: loss: 15.45 grad norm: 48.89 time: 0.086
2025-11-02 05:23:54,002: Train batch 49000: loss: 19.44 grad norm: 51.21 time: 0.083
2025-11-02 05:23:54,005: Running test after training batch: 49000
2025-11-02 05:24:09,525: Val batch 49000: PER (avg): 0.2450 CTC Loss (avg): 25.2455 time: 15.519
2025-11-02 05:24:09,526: t15.2023.08.13 val PER: 0.2089
2025-11-02 05:24:09,527: t15.2023.08.18 val PER: 0.1970
2025-11-02 05:24:09,527: t15.2023.08.20 val PER: 0.1954
2025-11-02 05:24:09,528: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:24:09,528: t15.2023.08.27 val PER: 0.2733
2025-11-02 05:24:09,528: t15.2023.09.01 val PER: 0.1453
2025-11-02 05:24:09,529: t15.2023.09.03 val PER: 0.2518
2025-11-02 05:24:09,529: t15.2023.09.24 val PER: 0.2027
2025-11-02 05:24:09,529: t15.2023.09.29 val PER: 0.2093
2025-11-02 05:24:09,530: t15.2023.10.01 val PER: 0.2497
2025-11-02 05:24:09,530: t15.2023.10.06 val PER: 0.1830
2025-11-02 05:24:09,531: t15.2023.10.08 val PER: 0.3058
2025-11-02 05:24:09,531: t15.2023.10.13 val PER: 0.3057
2025-11-02 05:24:09,531: t15.2023.10.15 val PER: 0.2162
2025-11-02 05:24:09,532: t15.2023.10.20 val PER: 0.2215
2025-11-02 05:24:09,532: t15.2023.10.22 val PER: 0.2004
2025-11-02 05:24:09,532: t15.2023.11.03 val PER: 0.2592
2025-11-02 05:24:09,532: t15.2023.11.04 val PER: 0.0580
2025-11-02 05:24:09,533: t15.2023.11.17 val PER: 0.1182
2025-11-02 05:24:09,533: t15.2023.11.19 val PER: 0.1158
2025-11-02 05:24:09,533: t15.2023.11.26 val PER: 0.2761
2025-11-02 05:24:09,534: t15.2023.12.03 val PER: 0.2143
2025-11-02 05:24:09,534: t15.2023.12.08 val PER: 0.2390
2025-11-02 05:24:09,534: t15.2023.12.10 val PER: 0.1997
2025-11-02 05:24:09,535: t15.2023.12.17 val PER: 0.2640
2025-11-02 05:24:09,535: t15.2023.12.29 val PER: 0.2450
2025-11-02 05:24:09,536: t15.2024.02.25 val PER: 0.1882
2025-11-02 05:24:09,536: t15.2024.03.08 val PER: 0.3144
2025-11-02 05:24:09,537: t15.2024.03.15 val PER: 0.3083
2025-11-02 05:24:09,537: t15.2024.03.17 val PER: 0.2524
2025-11-02 05:24:09,537: t15.2024.05.10 val PER: 0.2452
2025-11-02 05:24:09,538: t15.2024.06.14 val PER: 0.2492
2025-11-02 05:24:09,538: t15.2024.07.19 val PER: 0.3336
2025-11-02 05:24:09,538: t15.2024.07.21 val PER: 0.1793
2025-11-02 05:24:09,539: t15.2024.07.28 val PER: 0.2412
2025-11-02 05:24:09,539: t15.2025.01.10 val PER: 0.3939
2025-11-02 05:24:09,539: t15.2025.01.12 val PER: 0.2617
2025-11-02 05:24:09,540: t15.2025.03.14 val PER: 0.4216
2025-11-02 05:24:09,540: t15.2025.03.16 val PER: 0.2984
2025-11-02 05:24:09,541: t15.2025.03.30 val PER: 0.3644
2025-11-02 05:24:09,541: t15.2025.04.13 val PER: 0.3210
2025-11-02 05:24:09,541: New best test PER 0.2471 --> 0.2450
2025-11-02 05:24:09,541: Checkpointing model
2025-11-02 05:24:11,731: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:24:37,197: Train batch 49200: loss: 20.08 grad norm: 51.57 time: 0.106
2025-11-02 05:25:02,155: Train batch 49400: loss: 15.98 grad norm: 42.34 time: 0.068
2025-11-02 05:25:27,523: Train batch 49600: loss: 17.90 grad norm: 57.83 time: 0.125
2025-11-02 05:25:52,828: Train batch 49800: loss: 23.82 grad norm: 60.95 time: 0.091
2025-11-02 05:26:17,536: Train batch 50000: loss: 18.74 grad norm: 90.39 time: 0.099
2025-11-02 05:26:17,538: Running test after training batch: 50000
2025-11-02 05:26:32,717: Val batch 50000: PER (avg): 0.2439 CTC Loss (avg): 25.0514 time: 15.179
2025-11-02 05:26:32,718: t15.2023.08.13 val PER: 0.2110
2025-11-02 05:26:32,718: t15.2023.08.18 val PER: 0.1970
2025-11-02 05:26:32,718: t15.2023.08.20 val PER: 0.1954
2025-11-02 05:26:32,719: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:26:32,719: t15.2023.08.27 val PER: 0.2749
2025-11-02 05:26:32,719: t15.2023.09.01 val PER: 0.1494
2025-11-02 05:26:32,720: t15.2023.09.03 val PER: 0.2458
2025-11-02 05:26:32,720: t15.2023.09.24 val PER: 0.2027
2025-11-02 05:26:32,721: t15.2023.09.29 val PER: 0.2049
2025-11-02 05:26:32,721: t15.2023.10.01 val PER: 0.2523
2025-11-02 05:26:32,722: t15.2023.10.06 val PER: 0.1819
2025-11-02 05:26:32,722: t15.2023.10.08 val PER: 0.3045
2025-11-02 05:26:32,722: t15.2023.10.13 val PER: 0.3010
2025-11-02 05:26:32,722: t15.2023.10.15 val PER: 0.2136
2025-11-02 05:26:32,723: t15.2023.10.20 val PER: 0.2081
2025-11-02 05:26:32,723: t15.2023.10.22 val PER: 0.1882
2025-11-02 05:26:32,723: t15.2023.11.03 val PER: 0.2537
2025-11-02 05:26:32,724: t15.2023.11.04 val PER: 0.0614
2025-11-02 05:26:32,724: t15.2023.11.17 val PER: 0.1182
2025-11-02 05:26:32,724: t15.2023.11.19 val PER: 0.1198
2025-11-02 05:26:32,724: t15.2023.11.26 val PER: 0.2732
2025-11-02 05:26:32,725: t15.2023.12.03 val PER: 0.2153
2025-11-02 05:26:32,725: t15.2023.12.08 val PER: 0.2344
2025-11-02 05:26:32,726: t15.2023.12.10 val PER: 0.1971
2025-11-02 05:26:32,726: t15.2023.12.17 val PER: 0.2651
2025-11-02 05:26:32,727: t15.2023.12.29 val PER: 0.2375
2025-11-02 05:26:32,727: t15.2024.02.25 val PER: 0.1910
2025-11-02 05:26:32,727: t15.2024.03.08 val PER: 0.3186
2025-11-02 05:26:32,727: t15.2024.03.15 val PER: 0.3083
2025-11-02 05:26:32,728: t15.2024.03.17 val PER: 0.2483
2025-11-02 05:26:32,728: t15.2024.05.10 val PER: 0.2452
2025-11-02 05:26:32,728: t15.2024.06.14 val PER: 0.2492
2025-11-02 05:26:32,729: t15.2024.07.19 val PER: 0.3276
2025-11-02 05:26:32,729: t15.2024.07.21 val PER: 0.1828
2025-11-02 05:26:32,729: t15.2024.07.28 val PER: 0.2324
2025-11-02 05:26:32,729: t15.2025.01.10 val PER: 0.4008
2025-11-02 05:26:32,730: t15.2025.01.12 val PER: 0.2664
2025-11-02 05:26:32,730: t15.2025.03.14 val PER: 0.4231
2025-11-02 05:26:32,731: t15.2025.03.16 val PER: 0.3010
2025-11-02 05:26:32,731: t15.2025.03.30 val PER: 0.3713
2025-11-02 05:26:32,731: t15.2025.04.13 val PER: 0.3281
2025-11-02 05:26:32,732: New best test PER 0.2450 --> 0.2439
2025-11-02 05:26:32,732: Checkpointing model
2025-11-02 05:26:34,816: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:26:59,562: Train batch 50200: loss: 15.74 grad norm: 42.53 time: 0.072
2025-11-02 05:27:24,137: Train batch 50400: loss: 16.83 grad norm: 49.24 time: 0.072
2025-11-02 05:27:48,188: Train batch 50600: loss: 16.96 grad norm: 41.10 time: 0.109
2025-11-02 05:28:12,506: Train batch 50800: loss: 18.82 grad norm: 48.07 time: 0.096
2025-11-02 05:28:36,598: Train batch 51000: loss: 12.95 grad norm: 41.46 time: 0.065
2025-11-02 05:28:36,599: Running test after training batch: 51000
2025-11-02 05:28:51,023: Val batch 51000: PER (avg): 0.2420 CTC Loss (avg): 24.8716 time: 14.424
2025-11-02 05:28:51,024: t15.2023.08.13 val PER: 0.2100
2025-11-02 05:28:51,024: t15.2023.08.18 val PER: 0.1936
2025-11-02 05:28:51,025: t15.2023.08.20 val PER: 0.1970
2025-11-02 05:28:51,025: t15.2023.08.25 val PER: 0.1717
2025-11-02 05:28:51,025: t15.2023.08.27 val PER: 0.2669
2025-11-02 05:28:51,026: t15.2023.09.01 val PER: 0.1445
2025-11-02 05:28:51,026: t15.2023.09.03 val PER: 0.2482
2025-11-02 05:28:51,027: t15.2023.09.24 val PER: 0.1954
2025-11-02 05:28:51,027: t15.2023.09.29 val PER: 0.2023
2025-11-02 05:28:51,027: t15.2023.10.01 val PER: 0.2483
2025-11-02 05:28:51,028: t15.2023.10.06 val PER: 0.1798
2025-11-02 05:28:51,028: t15.2023.10.08 val PER: 0.3004
2025-11-02 05:28:51,028: t15.2023.10.13 val PER: 0.2971
2025-11-02 05:28:51,028: t15.2023.10.15 val PER: 0.2129
2025-11-02 05:28:51,029: t15.2023.10.20 val PER: 0.2081
2025-11-02 05:28:51,029: t15.2023.10.22 val PER: 0.1915
2025-11-02 05:28:51,029: t15.2023.11.03 val PER: 0.2585
2025-11-02 05:28:51,030: t15.2023.11.04 val PER: 0.0683
2025-11-02 05:28:51,030: t15.2023.11.17 val PER: 0.1151
2025-11-02 05:28:51,030: t15.2023.11.19 val PER: 0.1118
2025-11-02 05:28:51,031: t15.2023.11.26 val PER: 0.2688
2025-11-02 05:28:51,031: t15.2023.12.03 val PER: 0.2143
2025-11-02 05:28:51,032: t15.2023.12.08 val PER: 0.2350
2025-11-02 05:28:51,032: t15.2023.12.10 val PER: 0.2011
2025-11-02 05:28:51,032: t15.2023.12.17 val PER: 0.2599
2025-11-02 05:28:51,033: t15.2023.12.29 val PER: 0.2347
2025-11-02 05:28:51,033: t15.2024.02.25 val PER: 0.1854
2025-11-02 05:28:51,033: t15.2024.03.08 val PER: 0.3115
2025-11-02 05:28:51,033: t15.2024.03.15 val PER: 0.2996
2025-11-02 05:28:51,034: t15.2024.03.17 val PER: 0.2434
2025-11-02 05:28:51,034: t15.2024.05.10 val PER: 0.2377
2025-11-02 05:28:51,034: t15.2024.06.14 val PER: 0.2539
2025-11-02 05:28:51,084: t15.2024.07.19 val PER: 0.3322
2025-11-02 05:28:51,084: t15.2024.07.21 val PER: 0.1848
2025-11-02 05:28:51,084: t15.2024.07.28 val PER: 0.2331
2025-11-02 05:28:51,085: t15.2025.01.10 val PER: 0.3967
2025-11-02 05:28:51,085: t15.2025.01.12 val PER: 0.2602
2025-11-02 05:28:51,086: t15.2025.03.14 val PER: 0.4142
2025-11-02 05:28:51,086: t15.2025.03.16 val PER: 0.2997
2025-11-02 05:28:51,087: t15.2025.03.30 val PER: 0.3678
2025-11-02 05:28:51,087: t15.2025.04.13 val PER: 0.3381
2025-11-02 05:28:51,087: New best test PER 0.2439 --> 0.2420
2025-11-02 05:28:51,087: Checkpointing model
2025-11-02 05:28:53,181: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:29:18,321: Train batch 51200: loss: 16.10 grad norm: 50.36 time: 0.087
2025-11-02 05:29:43,276: Train batch 51400: loss: 9.91 grad norm: 33.44 time: 0.065
2025-11-02 05:30:07,790: Train batch 51600: loss: 13.44 grad norm: 38.22 time: 0.076
2025-11-02 05:30:32,944: Train batch 51800: loss: 17.58 grad norm: 46.20 time: 0.073
2025-11-02 05:30:57,334: Train batch 52000: loss: 13.89 grad norm: 35.78 time: 0.067
2025-11-02 05:30:57,335: Running test after training batch: 52000
2025-11-02 05:31:12,220: Val batch 52000: PER (avg): 0.2406 CTC Loss (avg): 24.7216 time: 14.885
2025-11-02 05:31:12,221: t15.2023.08.13 val PER: 0.2110
2025-11-02 05:31:12,222: t15.2023.08.18 val PER: 0.1936
2025-11-02 05:31:12,222: t15.2023.08.20 val PER: 0.1922
2025-11-02 05:31:12,222: t15.2023.08.25 val PER: 0.1747
2025-11-02 05:31:12,223: t15.2023.08.27 val PER: 0.2637
2025-11-02 05:31:12,223: t15.2023.09.01 val PER: 0.1420
2025-11-02 05:31:12,224: t15.2023.09.03 val PER: 0.2435
2025-11-02 05:31:12,224: t15.2023.09.24 val PER: 0.2002
2025-11-02 05:31:12,225: t15.2023.09.29 val PER: 0.2049
2025-11-02 05:31:12,225: t15.2023.10.01 val PER: 0.2470
2025-11-02 05:31:12,225: t15.2023.10.06 val PER: 0.1841
2025-11-02 05:31:12,226: t15.2023.10.08 val PER: 0.2923
2025-11-02 05:31:12,226: t15.2023.10.13 val PER: 0.3026
2025-11-02 05:31:12,227: t15.2023.10.15 val PER: 0.2142
2025-11-02 05:31:12,227: t15.2023.10.20 val PER: 0.2114
2025-11-02 05:31:12,227: t15.2023.10.22 val PER: 0.1927
2025-11-02 05:31:12,228: t15.2023.11.03 val PER: 0.2517
2025-11-02 05:31:12,228: t15.2023.11.04 val PER: 0.0648
2025-11-02 05:31:12,228: t15.2023.11.17 val PER: 0.1073
2025-11-02 05:31:12,229: t15.2023.11.19 val PER: 0.1078
2025-11-02 05:31:12,229: t15.2023.11.26 val PER: 0.2703
2025-11-02 05:31:12,229: t15.2023.12.03 val PER: 0.2059
2025-11-02 05:31:12,230: t15.2023.12.08 val PER: 0.2357
2025-11-02 05:31:12,230: t15.2023.12.10 val PER: 0.1945
2025-11-02 05:31:12,230: t15.2023.12.17 val PER: 0.2599
2025-11-02 05:31:12,231: t15.2023.12.29 val PER: 0.2388
2025-11-02 05:31:12,231: t15.2024.02.25 val PER: 0.1952
2025-11-02 05:31:12,232: t15.2024.03.08 val PER: 0.3158
2025-11-02 05:31:12,232: t15.2024.03.15 val PER: 0.3014
2025-11-02 05:31:12,232: t15.2024.03.17 val PER: 0.2420
2025-11-02 05:31:12,238: t15.2024.05.10 val PER: 0.2318
2025-11-02 05:31:12,239: t15.2024.06.14 val PER: 0.2555
2025-11-02 05:31:12,239: t15.2024.07.19 val PER: 0.3283
2025-11-02 05:31:12,240: t15.2024.07.21 val PER: 0.1793
2025-11-02 05:31:12,240: t15.2024.07.28 val PER: 0.2243
2025-11-02 05:31:12,241: t15.2025.01.10 val PER: 0.3843
2025-11-02 05:31:12,241: t15.2025.01.12 val PER: 0.2556
2025-11-02 05:31:12,242: t15.2025.03.14 val PER: 0.4186
2025-11-02 05:31:12,242: t15.2025.03.16 val PER: 0.3010
2025-11-02 05:31:12,242: t15.2025.03.30 val PER: 0.3621
2025-11-02 05:31:12,243: t15.2025.04.13 val PER: 0.3310
2025-11-02 05:31:12,243: New best test PER 0.2420 --> 0.2406
2025-11-02 05:31:12,243: Checkpointing model
2025-11-02 05:31:14,479: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:31:39,213: Train batch 52200: loss: 19.66 grad norm: 56.09 time: 0.100
2025-11-02 05:32:03,710: Train batch 52400: loss: 15.42 grad norm: 45.57 time: 0.104
2025-11-02 05:32:28,306: Train batch 52600: loss: 17.00 grad norm: 57.91 time: 0.102
2025-11-02 05:32:52,350: Train batch 52800: loss: 19.01 grad norm: 54.00 time: 0.068
2025-11-02 05:33:16,600: Train batch 53000: loss: 22.17 grad norm: 56.36 time: 0.105
2025-11-02 05:33:16,605: Running test after training batch: 53000
2025-11-02 05:33:31,619: Val batch 53000: PER (avg): 0.2384 CTC Loss (avg): 24.6307 time: 15.013
2025-11-02 05:33:31,620: t15.2023.08.13 val PER: 0.2017
2025-11-02 05:33:31,620: t15.2023.08.18 val PER: 0.1903
2025-11-02 05:33:31,621: t15.2023.08.20 val PER: 0.1898
2025-11-02 05:33:31,621: t15.2023.08.25 val PER: 0.1762
2025-11-02 05:33:31,622: t15.2023.08.27 val PER: 0.2605
2025-11-02 05:33:31,622: t15.2023.09.01 val PER: 0.1380
2025-11-02 05:33:31,623: t15.2023.09.03 val PER: 0.2411
2025-11-02 05:33:31,623: t15.2023.09.24 val PER: 0.1954
2025-11-02 05:33:31,623: t15.2023.09.29 val PER: 0.2010
2025-11-02 05:33:31,623: t15.2023.10.01 val PER: 0.2457
2025-11-02 05:33:31,624: t15.2023.10.06 val PER: 0.1798
2025-11-02 05:33:31,624: t15.2023.10.08 val PER: 0.2991
2025-11-02 05:33:31,624: t15.2023.10.13 val PER: 0.2964
2025-11-02 05:33:31,625: t15.2023.10.15 val PER: 0.2156
2025-11-02 05:33:31,625: t15.2023.10.20 val PER: 0.2047
2025-11-02 05:33:31,625: t15.2023.10.22 val PER: 0.1960
2025-11-02 05:33:31,626: t15.2023.11.03 val PER: 0.2531
2025-11-02 05:33:31,626: t15.2023.11.04 val PER: 0.0648
2025-11-02 05:33:31,627: t15.2023.11.17 val PER: 0.1104
2025-11-02 05:33:31,627: t15.2023.11.19 val PER: 0.1078
2025-11-02 05:33:31,627: t15.2023.11.26 val PER: 0.2667
2025-11-02 05:33:31,628: t15.2023.12.03 val PER: 0.2101
2025-11-02 05:33:31,628: t15.2023.12.08 val PER: 0.2324
2025-11-02 05:33:31,628: t15.2023.12.10 val PER: 0.1853
2025-11-02 05:33:31,628: t15.2023.12.17 val PER: 0.2630
2025-11-02 05:33:31,629: t15.2023.12.29 val PER: 0.2340
2025-11-02 05:33:31,629: t15.2024.02.25 val PER: 0.1910
2025-11-02 05:33:31,630: t15.2024.03.08 val PER: 0.3101
2025-11-02 05:33:31,630: t15.2024.03.15 val PER: 0.2983
2025-11-02 05:33:31,631: t15.2024.03.17 val PER: 0.2406
2025-11-02 05:33:31,631: t15.2024.05.10 val PER: 0.2318
2025-11-02 05:33:31,632: t15.2024.06.14 val PER: 0.2492
2025-11-02 05:33:31,684: t15.2024.07.19 val PER: 0.3263
2025-11-02 05:33:31,684: t15.2024.07.21 val PER: 0.1738
2025-11-02 05:33:31,684: t15.2024.07.28 val PER: 0.2272
2025-11-02 05:33:31,685: t15.2025.01.10 val PER: 0.3912
2025-11-02 05:33:31,685: t15.2025.01.12 val PER: 0.2525
2025-11-02 05:33:31,685: t15.2025.03.14 val PER: 0.4112
2025-11-02 05:33:31,686: t15.2025.03.16 val PER: 0.2945
2025-11-02 05:33:31,687: t15.2025.03.30 val PER: 0.3621
2025-11-02 05:33:31,687: t15.2025.04.13 val PER: 0.3252
2025-11-02 05:33:31,687: New best test PER 0.2406 --> 0.2384
2025-11-02 05:33:31,688: Checkpointing model
2025-11-02 05:33:33,942: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:33:59,056: Train batch 53200: loss: 16.56 grad norm: 47.54 time: 0.075
2025-11-02 05:34:23,955: Train batch 53400: loss: 15.63 grad norm: 43.18 time: 0.087
2025-11-02 05:34:49,123: Train batch 53600: loss: 15.73 grad norm: 51.83 time: 0.077
2025-11-02 05:35:13,031: Train batch 53800: loss: 14.11 grad norm: 50.54 time: 0.075
2025-11-02 05:35:37,327: Train batch 54000: loss: 20.62 grad norm: 60.15 time: 0.064
2025-11-02 05:35:37,328: Running test after training batch: 54000
2025-11-02 05:35:52,023: Val batch 54000: PER (avg): 0.2365 CTC Loss (avg): 24.5193 time: 14.695
2025-11-02 05:35:52,024: t15.2023.08.13 val PER: 0.2089
2025-11-02 05:35:52,025: t15.2023.08.18 val PER: 0.1869
2025-11-02 05:35:52,025: t15.2023.08.20 val PER: 0.1922
2025-11-02 05:35:52,025: t15.2023.08.25 val PER: 0.1762
2025-11-02 05:35:52,026: t15.2023.08.27 val PER: 0.2669
2025-11-02 05:35:52,026: t15.2023.09.01 val PER: 0.1339
2025-11-02 05:35:52,026: t15.2023.09.03 val PER: 0.2268
2025-11-02 05:35:52,027: t15.2023.09.24 val PER: 0.1881
2025-11-02 05:35:52,027: t15.2023.09.29 val PER: 0.1991
2025-11-02 05:35:52,028: t15.2023.10.01 val PER: 0.2470
2025-11-02 05:35:52,028: t15.2023.10.06 val PER: 0.1722
2025-11-02 05:35:52,028: t15.2023.10.08 val PER: 0.2977
2025-11-02 05:35:52,029: t15.2023.10.13 val PER: 0.2933
2025-11-02 05:35:52,029: t15.2023.10.15 val PER: 0.2076
2025-11-02 05:35:52,029: t15.2023.10.20 val PER: 0.2181
2025-11-02 05:35:52,030: t15.2023.10.22 val PER: 0.1971
2025-11-02 05:35:52,030: t15.2023.11.03 val PER: 0.2524
2025-11-02 05:35:52,030: t15.2023.11.04 val PER: 0.0478
2025-11-02 05:35:52,031: t15.2023.11.17 val PER: 0.1089
2025-11-02 05:35:52,031: t15.2023.11.19 val PER: 0.1098
2025-11-02 05:35:52,032: t15.2023.11.26 val PER: 0.2587
2025-11-02 05:35:52,032: t15.2023.12.03 val PER: 0.2069
2025-11-02 05:35:52,032: t15.2023.12.08 val PER: 0.2277
2025-11-02 05:35:52,032: t15.2023.12.10 val PER: 0.1905
2025-11-02 05:35:52,033: t15.2023.12.17 val PER: 0.2682
2025-11-02 05:35:52,033: t15.2023.12.29 val PER: 0.2313
2025-11-02 05:35:52,033: t15.2024.02.25 val PER: 0.1728
2025-11-02 05:35:52,034: t15.2024.03.08 val PER: 0.3101
2025-11-02 05:35:52,034: t15.2024.03.15 val PER: 0.3021
2025-11-02 05:35:52,034: t15.2024.03.17 val PER: 0.2294
2025-11-02 05:35:52,035: t15.2024.05.10 val PER: 0.2407
2025-11-02 05:35:52,035: t15.2024.06.14 val PER: 0.2461
2025-11-02 05:35:52,036: t15.2024.07.19 val PER: 0.3237
2025-11-02 05:35:52,036: t15.2024.07.21 val PER: 0.1710
2025-11-02 05:35:52,036: t15.2024.07.28 val PER: 0.2199
2025-11-02 05:35:52,037: t15.2025.01.10 val PER: 0.3912
2025-11-02 05:35:52,037: t15.2025.01.12 val PER: 0.2602
2025-11-02 05:35:52,037: t15.2025.03.14 val PER: 0.4053
2025-11-02 05:35:52,038: t15.2025.03.16 val PER: 0.2945
2025-11-02 05:35:52,038: t15.2025.03.30 val PER: 0.3701
2025-11-02 05:35:52,038: t15.2025.04.13 val PER: 0.3281
2025-11-02 05:35:52,084: New best test PER 0.2384 --> 0.2365
2025-11-02 05:35:52,084: Checkpointing model
2025-11-02 05:35:54,258: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:36:19,232: Train batch 54200: loss: 13.37 grad norm: 44.29 time: 0.100
2025-11-02 05:36:43,973: Train batch 54400: loss: 24.15 grad norm: 137.73 time: 0.094
2025-11-02 05:37:07,995: Train batch 54600: loss: 19.12 grad norm: 52.78 time: 0.076
2025-11-02 05:37:32,302: Train batch 54800: loss: 18.04 grad norm: 58.15 time: 0.084
2025-11-02 05:37:56,822: Train batch 55000: loss: 18.65 grad norm: 49.19 time: 0.073
2025-11-02 05:37:56,824: Running test after training batch: 55000
2025-11-02 05:38:11,714: Val batch 55000: PER (avg): 0.2357 CTC Loss (avg): 24.4112 time: 14.890
2025-11-02 05:38:11,715: t15.2023.08.13 val PER: 0.1933
2025-11-02 05:38:11,716: t15.2023.08.18 val PER: 0.1869
2025-11-02 05:38:11,716: t15.2023.08.20 val PER: 0.1875
2025-11-02 05:38:11,717: t15.2023.08.25 val PER: 0.1747
2025-11-02 05:38:11,717: t15.2023.08.27 val PER: 0.2653
2025-11-02 05:38:11,718: t15.2023.09.01 val PER: 0.1323
2025-11-02 05:38:11,718: t15.2023.09.03 val PER: 0.2328
2025-11-02 05:38:11,718: t15.2023.09.24 val PER: 0.1954
2025-11-02 05:38:11,719: t15.2023.09.29 val PER: 0.1940
2025-11-02 05:38:11,719: t15.2023.10.01 val PER: 0.2470
2025-11-02 05:38:11,720: t15.2023.10.06 val PER: 0.1755
2025-11-02 05:38:11,720: t15.2023.10.08 val PER: 0.2950
2025-11-02 05:38:11,721: t15.2023.10.13 val PER: 0.2940
2025-11-02 05:38:11,721: t15.2023.10.15 val PER: 0.2076
2025-11-02 05:38:11,722: t15.2023.10.20 val PER: 0.2148
2025-11-02 05:38:11,722: t15.2023.10.22 val PER: 0.1938
2025-11-02 05:38:11,722: t15.2023.11.03 val PER: 0.2483
2025-11-02 05:38:11,722: t15.2023.11.04 val PER: 0.0512
2025-11-02 05:38:11,723: t15.2023.11.17 val PER: 0.1042
2025-11-02 05:38:11,723: t15.2023.11.19 val PER: 0.1058
2025-11-02 05:38:11,724: t15.2023.11.26 val PER: 0.2536
2025-11-02 05:38:11,724: t15.2023.12.03 val PER: 0.2069
2025-11-02 05:38:11,724: t15.2023.12.08 val PER: 0.2297
2025-11-02 05:38:11,725: t15.2023.12.10 val PER: 0.1879
2025-11-02 05:38:11,725: t15.2023.12.17 val PER: 0.2557
2025-11-02 05:38:11,726: t15.2023.12.29 val PER: 0.2340
2025-11-02 05:38:11,726: t15.2024.02.25 val PER: 0.1784
2025-11-02 05:38:11,727: t15.2024.03.08 val PER: 0.3172
2025-11-02 05:38:11,727: t15.2024.03.15 val PER: 0.2964
2025-11-02 05:38:11,727: t15.2024.03.17 val PER: 0.2385
2025-11-02 05:38:11,728: t15.2024.05.10 val PER: 0.2199
2025-11-02 05:38:11,728: t15.2024.06.14 val PER: 0.2508
2025-11-02 05:38:11,729: t15.2024.07.19 val PER: 0.3296
2025-11-02 05:38:11,729: t15.2024.07.21 val PER: 0.1710
2025-11-02 05:38:11,729: t15.2024.07.28 val PER: 0.2206
2025-11-02 05:38:11,729: t15.2025.01.10 val PER: 0.4036
2025-11-02 05:38:11,730: t15.2025.01.12 val PER: 0.2533
2025-11-02 05:38:11,730: t15.2025.03.14 val PER: 0.4216
2025-11-02 05:38:11,731: t15.2025.03.16 val PER: 0.2984
2025-11-02 05:38:11,731: t15.2025.03.30 val PER: 0.3609
2025-11-02 05:38:11,731: t15.2025.04.13 val PER: 0.3252
2025-11-02 05:38:11,732: New best test PER 0.2365 --> 0.2357
2025-11-02 05:38:11,732: Checkpointing model
2025-11-02 05:38:13,922: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:38:38,460: Train batch 55200: loss: 21.01 grad norm: 55.12 time: 0.080
2025-11-02 05:39:02,832: Train batch 55400: loss: 14.11 grad norm: 41.35 time: 0.087
2025-11-02 05:39:26,885: Train batch 55600: loss: 15.13 grad norm: 39.81 time: 0.062
2025-11-02 05:39:51,118: Train batch 55800: loss: 17.33 grad norm: 46.81 time: 0.087
2025-11-02 05:40:15,693: Train batch 56000: loss: 17.17 grad norm: 51.50 time: 0.064
2025-11-02 05:40:15,694: Running test after training batch: 56000
2025-11-02 05:40:30,827: Val batch 56000: PER (avg): 0.2345 CTC Loss (avg): 24.2486 time: 15.132
2025-11-02 05:40:30,827: t15.2023.08.13 val PER: 0.1923
2025-11-02 05:40:30,828: t15.2023.08.18 val PER: 0.1878
2025-11-02 05:40:30,828: t15.2023.08.20 val PER: 0.1867
2025-11-02 05:40:30,829: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:40:30,829: t15.2023.08.27 val PER: 0.2621
2025-11-02 05:40:30,829: t15.2023.09.01 val PER: 0.1323
2025-11-02 05:40:30,830: t15.2023.09.03 val PER: 0.2316
2025-11-02 05:40:30,830: t15.2023.09.24 val PER: 0.1954
2025-11-02 05:40:30,831: t15.2023.09.29 val PER: 0.1966
2025-11-02 05:40:30,831: t15.2023.10.01 val PER: 0.2417
2025-11-02 05:40:30,832: t15.2023.10.06 val PER: 0.1722
2025-11-02 05:40:30,832: t15.2023.10.08 val PER: 0.2909
2025-11-02 05:40:30,832: t15.2023.10.13 val PER: 0.2917
2025-11-02 05:40:30,832: t15.2023.10.15 val PER: 0.2109
2025-11-02 05:40:30,833: t15.2023.10.20 val PER: 0.2181
2025-11-02 05:40:30,833: t15.2023.10.22 val PER: 0.1882
2025-11-02 05:40:30,833: t15.2023.11.03 val PER: 0.2517
2025-11-02 05:40:30,834: t15.2023.11.04 val PER: 0.0580
2025-11-02 05:40:30,834: t15.2023.11.17 val PER: 0.1073
2025-11-02 05:40:30,834: t15.2023.11.19 val PER: 0.1018
2025-11-02 05:40:30,834: t15.2023.11.26 val PER: 0.2514
2025-11-02 05:40:30,835: t15.2023.12.03 val PER: 0.2038
2025-11-02 05:40:30,835: t15.2023.12.08 val PER: 0.2224
2025-11-02 05:40:30,835: t15.2023.12.10 val PER: 0.1932
2025-11-02 05:40:30,836: t15.2023.12.17 val PER: 0.2568
2025-11-02 05:40:30,836: t15.2023.12.29 val PER: 0.2292
2025-11-02 05:40:30,836: t15.2024.02.25 val PER: 0.1812
2025-11-02 05:40:30,837: t15.2024.03.08 val PER: 0.3101
2025-11-02 05:40:30,837: t15.2024.03.15 val PER: 0.3014
2025-11-02 05:40:30,837: t15.2024.03.17 val PER: 0.2385
2025-11-02 05:40:30,837: t15.2024.05.10 val PER: 0.2288
2025-11-02 05:40:30,838: t15.2024.06.14 val PER: 0.2524
2025-11-02 05:40:30,838: t15.2024.07.19 val PER: 0.3263
2025-11-02 05:40:30,838: t15.2024.07.21 val PER: 0.1738
2025-11-02 05:40:30,838: t15.2024.07.28 val PER: 0.2140
2025-11-02 05:40:30,839: t15.2025.01.10 val PER: 0.3912
2025-11-02 05:40:30,839: t15.2025.01.12 val PER: 0.2494
2025-11-02 05:40:30,839: t15.2025.03.14 val PER: 0.4127
2025-11-02 05:40:30,840: t15.2025.03.16 val PER: 0.2906
2025-11-02 05:40:30,840: t15.2025.03.30 val PER: 0.3563
2025-11-02 05:40:30,840: t15.2025.04.13 val PER: 0.3352
2025-11-02 05:40:30,841: New best test PER 0.2357 --> 0.2345
2025-11-02 05:40:30,841: Checkpointing model
2025-11-02 05:40:33,114: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:40:58,071: Train batch 56200: loss: 14.88 grad norm: 39.42 time: 0.093
2025-11-02 05:41:22,397: Train batch 56400: loss: 18.85 grad norm: 58.30 time: 0.063
2025-11-02 05:41:46,707: Train batch 56600: loss: 22.03 grad norm: 78.15 time: 0.105
2025-11-02 05:42:11,020: Train batch 56800: loss: 17.96 grad norm: 54.05 time: 0.078
2025-11-02 05:42:34,965: Train batch 57000: loss: 20.71 grad norm: 82.69 time: 0.076
2025-11-02 05:42:34,966: Running test after training batch: 57000
2025-11-02 05:42:50,017: Val batch 57000: PER (avg): 0.2332 CTC Loss (avg): 24.1466 time: 15.051
2025-11-02 05:42:50,018: t15.2023.08.13 val PER: 0.1913
2025-11-02 05:42:50,018: t15.2023.08.18 val PER: 0.1836
2025-11-02 05:42:50,019: t15.2023.08.20 val PER: 0.1875
2025-11-02 05:42:50,019: t15.2023.08.25 val PER: 0.1777
2025-11-02 05:42:50,019: t15.2023.08.27 val PER: 0.2621
2025-11-02 05:42:50,020: t15.2023.09.01 val PER: 0.1331
2025-11-02 05:42:50,020: t15.2023.09.03 val PER: 0.2268
2025-11-02 05:42:50,021: t15.2023.09.24 val PER: 0.1930
2025-11-02 05:42:50,021: t15.2023.09.29 val PER: 0.1946
2025-11-02 05:42:50,021: t15.2023.10.01 val PER: 0.2391
2025-11-02 05:42:50,022: t15.2023.10.06 val PER: 0.1668
2025-11-02 05:42:50,022: t15.2023.10.08 val PER: 0.2869
2025-11-02 05:42:50,022: t15.2023.10.13 val PER: 0.2940
2025-11-02 05:42:50,023: t15.2023.10.15 val PER: 0.2136
2025-11-02 05:42:50,023: t15.2023.10.20 val PER: 0.2148
2025-11-02 05:42:50,023: t15.2023.10.22 val PER: 0.1904
2025-11-02 05:42:50,024: t15.2023.11.03 val PER: 0.2469
2025-11-02 05:42:50,024: t15.2023.11.04 val PER: 0.0614
2025-11-02 05:42:50,024: t15.2023.11.17 val PER: 0.0995
2025-11-02 05:42:50,024: t15.2023.11.19 val PER: 0.0998
2025-11-02 05:42:50,025: t15.2023.11.26 val PER: 0.2551
2025-11-02 05:42:50,025: t15.2023.12.03 val PER: 0.1985
2025-11-02 05:42:50,026: t15.2023.12.08 val PER: 0.2244
2025-11-02 05:42:50,026: t15.2023.12.10 val PER: 0.1932
2025-11-02 05:42:50,027: t15.2023.12.17 val PER: 0.2484
2025-11-02 05:42:50,027: t15.2023.12.29 val PER: 0.2272
2025-11-02 05:42:50,027: t15.2024.02.25 val PER: 0.1826
2025-11-02 05:42:50,028: t15.2024.03.08 val PER: 0.3172
2025-11-02 05:42:50,028: t15.2024.03.15 val PER: 0.3002
2025-11-02 05:42:50,028: t15.2024.03.17 val PER: 0.2371
2025-11-02 05:42:50,028: t15.2024.05.10 val PER: 0.2273
2025-11-02 05:42:50,029: t15.2024.06.14 val PER: 0.2476
2025-11-02 05:42:50,029: t15.2024.07.19 val PER: 0.3237
2025-11-02 05:42:50,029: t15.2024.07.21 val PER: 0.1662
2025-11-02 05:42:50,030: t15.2024.07.28 val PER: 0.2118
2025-11-02 05:42:50,030: t15.2025.01.10 val PER: 0.3912
2025-11-02 05:42:50,030: t15.2025.01.12 val PER: 0.2471
2025-11-02 05:42:50,031: t15.2025.03.14 val PER: 0.4186
2025-11-02 05:42:50,031: t15.2025.03.16 val PER: 0.2840
2025-11-02 05:42:50,031: t15.2025.03.30 val PER: 0.3644
2025-11-02 05:42:50,031: t15.2025.04.13 val PER: 0.3295
2025-11-02 05:42:50,032: New best test PER 0.2345 --> 0.2332
2025-11-02 05:42:50,032: Checkpointing model
2025-11-02 05:42:52,191: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:43:16,477: Train batch 57200: loss: 14.31 grad norm: 45.55 time: 0.117
2025-11-02 05:43:41,036: Train batch 57400: loss: 14.58 grad norm: 40.69 time: 0.080
2025-11-02 05:44:04,853: Train batch 57600: loss: 21.29 grad norm: 57.43 time: 0.072
2025-11-02 05:44:28,905: Train batch 57800: loss: 13.67 grad norm: 40.26 time: 0.074
2025-11-02 05:44:52,966: Train batch 58000: loss: 12.47 grad norm: 41.47 time: 0.095
2025-11-02 05:44:52,967: Running test after training batch: 58000
2025-11-02 05:45:07,320: Val batch 58000: PER (avg): 0.2331 CTC Loss (avg): 24.1120 time: 14.353
2025-11-02 05:45:07,321: t15.2023.08.13 val PER: 0.1861
2025-11-02 05:45:07,321: t15.2023.08.18 val PER: 0.1811
2025-11-02 05:45:07,321: t15.2023.08.20 val PER: 0.1867
2025-11-02 05:45:07,322: t15.2023.08.25 val PER: 0.1777
2025-11-02 05:45:07,322: t15.2023.08.27 val PER: 0.2669
2025-11-02 05:45:07,322: t15.2023.09.01 val PER: 0.1331
2025-11-02 05:45:07,323: t15.2023.09.03 val PER: 0.2316
2025-11-02 05:45:07,323: t15.2023.09.24 val PER: 0.1893
2025-11-02 05:45:07,323: t15.2023.09.29 val PER: 0.1978
2025-11-02 05:45:07,324: t15.2023.10.01 val PER: 0.2384
2025-11-02 05:45:07,324: t15.2023.10.06 val PER: 0.1690
2025-11-02 05:45:07,324: t15.2023.10.08 val PER: 0.2801
2025-11-02 05:45:07,324: t15.2023.10.13 val PER: 0.2870
2025-11-02 05:45:07,325: t15.2023.10.15 val PER: 0.2136
2025-11-02 05:45:07,325: t15.2023.10.20 val PER: 0.2047
2025-11-02 05:45:07,326: t15.2023.10.22 val PER: 0.1949
2025-11-02 05:45:07,326: t15.2023.11.03 val PER: 0.2442
2025-11-02 05:45:07,326: t15.2023.11.04 val PER: 0.0546
2025-11-02 05:45:07,326: t15.2023.11.17 val PER: 0.1042
2025-11-02 05:45:07,327: t15.2023.11.19 val PER: 0.0958
2025-11-02 05:45:07,327: t15.2023.11.26 val PER: 0.2543
2025-11-02 05:45:07,327: t15.2023.12.03 val PER: 0.2006
2025-11-02 05:45:07,327: t15.2023.12.08 val PER: 0.2217
2025-11-02 05:45:07,328: t15.2023.12.10 val PER: 0.1800
2025-11-02 05:45:07,328: t15.2023.12.17 val PER: 0.2516
2025-11-02 05:45:07,329: t15.2023.12.29 val PER: 0.2272
2025-11-02 05:45:07,329: t15.2024.02.25 val PER: 0.1840
2025-11-02 05:45:07,329: t15.2024.03.08 val PER: 0.3158
2025-11-02 05:45:07,329: t15.2024.03.15 val PER: 0.3021
2025-11-02 05:45:07,330: t15.2024.03.17 val PER: 0.2336
2025-11-02 05:45:07,330: t15.2024.05.10 val PER: 0.2318
2025-11-02 05:45:07,331: t15.2024.06.14 val PER: 0.2461
2025-11-02 05:45:07,331: t15.2024.07.19 val PER: 0.3303
2025-11-02 05:45:07,331: t15.2024.07.21 val PER: 0.1697
2025-11-02 05:45:07,332: t15.2024.07.28 val PER: 0.2154
2025-11-02 05:45:07,332: t15.2025.01.10 val PER: 0.4008
2025-11-02 05:45:07,332: t15.2025.01.12 val PER: 0.2494
2025-11-02 05:45:07,332: t15.2025.03.14 val PER: 0.4127
2025-11-02 05:45:07,333: t15.2025.03.16 val PER: 0.2971
2025-11-02 05:45:07,333: t15.2025.03.30 val PER: 0.3552
2025-11-02 05:45:07,333: t15.2025.04.13 val PER: 0.3238
2025-11-02 05:45:07,334: New best test PER 0.2332 --> 0.2331
2025-11-02 05:45:07,334: Checkpointing model
2025-11-02 05:45:09,552: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:45:34,273: Train batch 58200: loss: 17.15 grad norm: 50.00 time: 0.106
2025-11-02 05:45:58,665: Train batch 58400: loss: 12.98 grad norm: 42.80 time: 0.090
2025-11-02 05:46:22,899: Train batch 58600: loss: 14.27 grad norm: 43.32 time: 0.072
2025-11-02 05:46:47,404: Train batch 58800: loss: 20.59 grad norm: 53.99 time: 0.093
2025-11-02 05:47:12,077: Train batch 59000: loss: 12.68 grad norm: 44.69 time: 0.055
2025-11-02 05:47:12,078: Running test after training batch: 59000
2025-11-02 05:47:27,421: Val batch 59000: PER (avg): 0.2326 CTC Loss (avg): 23.9966 time: 15.343
2025-11-02 05:47:27,422: t15.2023.08.13 val PER: 0.1944
2025-11-02 05:47:27,422: t15.2023.08.18 val PER: 0.1852
2025-11-02 05:47:27,423: t15.2023.08.20 val PER: 0.1875
2025-11-02 05:47:27,423: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:47:27,424: t15.2023.08.27 val PER: 0.2669
2025-11-02 05:47:27,424: t15.2023.09.01 val PER: 0.1331
2025-11-02 05:47:27,424: t15.2023.09.03 val PER: 0.2268
2025-11-02 05:47:27,424: t15.2023.09.24 val PER: 0.1905
2025-11-02 05:47:27,425: t15.2023.09.29 val PER: 0.1959
2025-11-02 05:47:27,425: t15.2023.10.01 val PER: 0.2411
2025-11-02 05:47:27,425: t15.2023.10.06 val PER: 0.1722
2025-11-02 05:47:27,426: t15.2023.10.08 val PER: 0.2842
2025-11-02 05:47:27,426: t15.2023.10.13 val PER: 0.2816
2025-11-02 05:47:27,426: t15.2023.10.15 val PER: 0.2103
2025-11-02 05:47:27,426: t15.2023.10.20 val PER: 0.1946
2025-11-02 05:47:27,427: t15.2023.10.22 val PER: 0.1927
2025-11-02 05:47:27,427: t15.2023.11.03 val PER: 0.2490
2025-11-02 05:47:27,427: t15.2023.11.04 val PER: 0.0512
2025-11-02 05:47:27,427: t15.2023.11.17 val PER: 0.1026
2025-11-02 05:47:27,428: t15.2023.11.19 val PER: 0.1018
2025-11-02 05:47:27,428: t15.2023.11.26 val PER: 0.2522
2025-11-02 05:47:27,428: t15.2023.12.03 val PER: 0.1975
2025-11-02 05:47:27,428: t15.2023.12.08 val PER: 0.2170
2025-11-02 05:47:27,429: t15.2023.12.10 val PER: 0.1892
2025-11-02 05:47:27,429: t15.2023.12.17 val PER: 0.2547
2025-11-02 05:47:27,429: t15.2023.12.29 val PER: 0.2272
2025-11-02 05:47:27,429: t15.2024.02.25 val PER: 0.1784
2025-11-02 05:47:27,430: t15.2024.03.08 val PER: 0.3115
2025-11-02 05:47:27,430: t15.2024.03.15 val PER: 0.2996
2025-11-02 05:47:27,431: t15.2024.03.17 val PER: 0.2371
2025-11-02 05:47:27,431: t15.2024.05.10 val PER: 0.2333
2025-11-02 05:47:27,431: t15.2024.06.14 val PER: 0.2508
2025-11-02 05:47:27,432: t15.2024.07.19 val PER: 0.3303
2025-11-02 05:47:27,432: t15.2024.07.21 val PER: 0.1655
2025-11-02 05:47:27,432: t15.2024.07.28 val PER: 0.2154
2025-11-02 05:47:27,432: t15.2025.01.10 val PER: 0.3843
2025-11-02 05:47:27,433: t15.2025.01.12 val PER: 0.2456
2025-11-02 05:47:27,433: t15.2025.03.14 val PER: 0.4098
2025-11-02 05:47:27,433: t15.2025.03.16 val PER: 0.2906
2025-11-02 05:47:27,433: t15.2025.03.30 val PER: 0.3598
2025-11-02 05:47:27,434: t15.2025.04.13 val PER: 0.3267
2025-11-02 05:47:27,434: New best test PER 0.2331 --> 0.2326
2025-11-02 05:47:27,434: Checkpointing model
2025-11-02 05:47:29,335: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:47:53,647: Train batch 59200: loss: 19.66 grad norm: 59.12 time: 0.075
2025-11-02 05:48:18,429: Train batch 59400: loss: 16.43 grad norm: 49.54 time: 0.065
2025-11-02 05:48:42,344: Train batch 59600: loss: 11.14 grad norm: 41.74 time: 0.068
2025-11-02 05:49:06,683: Train batch 59800: loss: 21.30 grad norm: 55.38 time: 0.088
2025-11-02 05:49:30,674: Train batch 60000: loss: 14.76 grad norm: 45.58 time: 0.073
2025-11-02 05:49:30,675: Running test after training batch: 60000
2025-11-02 05:49:45,122: Val batch 60000: PER (avg): 0.2301 CTC Loss (avg): 23.9498 time: 14.447
2025-11-02 05:49:45,123: t15.2023.08.13 val PER: 0.1902
2025-11-02 05:49:45,124: t15.2023.08.18 val PER: 0.1844
2025-11-02 05:49:45,124: t15.2023.08.20 val PER: 0.1835
2025-11-02 05:49:45,125: t15.2023.08.25 val PER: 0.1762
2025-11-02 05:49:45,125: t15.2023.08.27 val PER: 0.2605
2025-11-02 05:49:45,126: t15.2023.09.01 val PER: 0.1282
2025-11-02 05:49:45,126: t15.2023.09.03 val PER: 0.2245
2025-11-02 05:49:45,127: t15.2023.09.24 val PER: 0.1893
2025-11-02 05:49:45,127: t15.2023.09.29 val PER: 0.1927
2025-11-02 05:49:45,127: t15.2023.10.01 val PER: 0.2371
2025-11-02 05:49:45,128: t15.2023.10.06 val PER: 0.1690
2025-11-02 05:49:45,128: t15.2023.10.08 val PER: 0.2788
2025-11-02 05:49:45,128: t15.2023.10.13 val PER: 0.2808
2025-11-02 05:49:45,129: t15.2023.10.15 val PER: 0.2063
2025-11-02 05:49:45,129: t15.2023.10.20 val PER: 0.2047
2025-11-02 05:49:45,129: t15.2023.10.22 val PER: 0.1893
2025-11-02 05:49:45,130: t15.2023.11.03 val PER: 0.2395
2025-11-02 05:49:45,130: t15.2023.11.04 val PER: 0.0512
2025-11-02 05:49:45,130: t15.2023.11.17 val PER: 0.0980
2025-11-02 05:49:45,131: t15.2023.11.19 val PER: 0.0998
2025-11-02 05:49:45,131: t15.2023.11.26 val PER: 0.2471
2025-11-02 05:49:45,131: t15.2023.12.03 val PER: 0.1933
2025-11-02 05:49:45,132: t15.2023.12.08 val PER: 0.2190
2025-11-02 05:49:45,132: t15.2023.12.10 val PER: 0.1840
2025-11-02 05:49:45,132: t15.2023.12.17 val PER: 0.2453
2025-11-02 05:49:45,133: t15.2023.12.29 val PER: 0.2286
2025-11-02 05:49:45,133: t15.2024.02.25 val PER: 0.1798
2025-11-02 05:49:45,133: t15.2024.03.08 val PER: 0.3087
2025-11-02 05:49:45,133: t15.2024.03.15 val PER: 0.2989
2025-11-02 05:49:45,134: t15.2024.03.17 val PER: 0.2350
2025-11-02 05:49:45,134: t15.2024.05.10 val PER: 0.2318
2025-11-02 05:49:45,134: t15.2024.06.14 val PER: 0.2461
2025-11-02 05:49:45,135: t15.2024.07.19 val PER: 0.3263
2025-11-02 05:49:45,135: t15.2024.07.21 val PER: 0.1628
2025-11-02 05:49:45,135: t15.2024.07.28 val PER: 0.2081
2025-11-02 05:49:45,136: t15.2025.01.10 val PER: 0.3884
2025-11-02 05:49:45,136: t15.2025.01.12 val PER: 0.2494
2025-11-02 05:49:45,136: t15.2025.03.14 val PER: 0.4068
2025-11-02 05:49:45,136: t15.2025.03.16 val PER: 0.2971
2025-11-02 05:49:45,137: t15.2025.03.30 val PER: 0.3609
2025-11-02 05:49:45,137: t15.2025.04.13 val PER: 0.3238
2025-11-02 05:49:45,137: New best test PER 0.2326 --> 0.2301
2025-11-02 05:49:45,137: Checkpointing model
2025-11-02 05:49:47,093: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:50:11,594: Train batch 60200: loss: 14.95 grad norm: 54.00 time: 0.067
2025-11-02 05:50:35,378: Train batch 60400: loss: 8.59 grad norm: 31.30 time: 0.098
2025-11-02 05:50:59,484: Train batch 60600: loss: 17.06 grad norm: 45.11 time: 0.090
2025-11-02 05:51:23,207: Train batch 60800: loss: 9.34 grad norm: 36.51 time: 0.090
2025-11-02 05:51:47,666: Train batch 61000: loss: 16.61 grad norm: 55.05 time: 0.071
2025-11-02 05:51:47,667: Running test after training batch: 61000
2025-11-02 05:52:02,822: Val batch 61000: PER (avg): 0.2294 CTC Loss (avg): 23.8269 time: 15.154
2025-11-02 05:52:02,822: t15.2023.08.13 val PER: 0.1881
2025-11-02 05:52:02,823: t15.2023.08.18 val PER: 0.1794
2025-11-02 05:52:02,823: t15.2023.08.20 val PER: 0.1851
2025-11-02 05:52:02,824: t15.2023.08.25 val PER: 0.1717
2025-11-02 05:52:02,824: t15.2023.08.27 val PER: 0.2637
2025-11-02 05:52:02,825: t15.2023.09.01 val PER: 0.1315
2025-11-02 05:52:02,825: t15.2023.09.03 val PER: 0.2197
2025-11-02 05:52:02,825: t15.2023.09.24 val PER: 0.1820
2025-11-02 05:52:02,826: t15.2023.09.29 val PER: 0.1940
2025-11-02 05:52:02,826: t15.2023.10.01 val PER: 0.2417
2025-11-02 05:52:02,827: t15.2023.10.06 val PER: 0.1722
2025-11-02 05:52:02,827: t15.2023.10.08 val PER: 0.2828
2025-11-02 05:52:02,827: t15.2023.10.13 val PER: 0.2801
2025-11-02 05:52:02,828: t15.2023.10.15 val PER: 0.2083
2025-11-02 05:52:02,828: t15.2023.10.20 val PER: 0.2148
2025-11-02 05:52:02,829: t15.2023.10.22 val PER: 0.1927
2025-11-02 05:52:02,829: t15.2023.11.03 val PER: 0.2374
2025-11-02 05:52:02,829: t15.2023.11.04 val PER: 0.0546
2025-11-02 05:52:02,830: t15.2023.11.17 val PER: 0.0995
2025-11-02 05:52:02,830: t15.2023.11.19 val PER: 0.1018
2025-11-02 05:52:02,831: t15.2023.11.26 val PER: 0.2493
2025-11-02 05:52:02,831: t15.2023.12.03 val PER: 0.1954
2025-11-02 05:52:02,832: t15.2023.12.08 val PER: 0.2204
2025-11-02 05:52:02,832: t15.2023.12.10 val PER: 0.1787
2025-11-02 05:52:02,832: t15.2023.12.17 val PER: 0.2422
2025-11-02 05:52:02,833: t15.2023.12.29 val PER: 0.2251
2025-11-02 05:52:02,833: t15.2024.02.25 val PER: 0.1756
2025-11-02 05:52:02,833: t15.2024.03.08 val PER: 0.3101
2025-11-02 05:52:02,834: t15.2024.03.15 val PER: 0.2877
2025-11-02 05:52:02,834: t15.2024.03.17 val PER: 0.2280
2025-11-02 05:52:02,834: t15.2024.05.10 val PER: 0.2318
2025-11-02 05:52:02,835: t15.2024.06.14 val PER: 0.2476
2025-11-02 05:52:02,835: t15.2024.07.19 val PER: 0.3243
2025-11-02 05:52:02,835: t15.2024.07.21 val PER: 0.1683
2025-11-02 05:52:02,836: t15.2024.07.28 val PER: 0.2132
2025-11-02 05:52:02,836: t15.2025.01.10 val PER: 0.3871
2025-11-02 05:52:02,836: t15.2025.01.12 val PER: 0.2487
2025-11-02 05:52:02,837: t15.2025.03.14 val PER: 0.3979
2025-11-02 05:52:02,837: t15.2025.03.16 val PER: 0.2840
2025-11-02 05:52:02,837: t15.2025.03.30 val PER: 0.3621
2025-11-02 05:52:02,838: t15.2025.04.13 val PER: 0.3238
2025-11-02 05:52:02,838: New best test PER 0.2301 --> 0.2294
2025-11-02 05:52:02,838: Checkpointing model
2025-11-02 05:52:04,999: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:52:29,513: Train batch 61200: loss: 10.57 grad norm: 40.20 time: 0.072
2025-11-02 05:52:52,955: Train batch 61400: loss: 8.99 grad norm: 36.91 time: 0.081
2025-11-02 05:53:17,605: Train batch 61600: loss: 12.80 grad norm: 47.36 time: 0.093
2025-11-02 05:53:41,938: Train batch 61800: loss: 13.52 grad norm: 41.94 time: 0.063
2025-11-02 05:54:06,153: Train batch 62000: loss: 11.12 grad norm: 41.00 time: 0.078
2025-11-02 05:54:06,154: Running test after training batch: 62000
2025-11-02 05:54:21,418: Val batch 62000: PER (avg): 0.2294 CTC Loss (avg): 23.7343 time: 15.264
2025-11-02 05:54:21,418: t15.2023.08.13 val PER: 0.1850
2025-11-02 05:54:21,419: t15.2023.08.18 val PER: 0.1827
2025-11-02 05:54:21,419: t15.2023.08.20 val PER: 0.1771
2025-11-02 05:54:21,419: t15.2023.08.25 val PER: 0.1717
2025-11-02 05:54:21,420: t15.2023.08.27 val PER: 0.2637
2025-11-02 05:54:21,420: t15.2023.09.01 val PER: 0.1266
2025-11-02 05:54:21,420: t15.2023.09.03 val PER: 0.2257
2025-11-02 05:54:21,420: t15.2023.09.24 val PER: 0.1881
2025-11-02 05:54:21,421: t15.2023.09.29 val PER: 0.1914
2025-11-02 05:54:21,421: t15.2023.10.01 val PER: 0.2398
2025-11-02 05:54:21,422: t15.2023.10.06 val PER: 0.1690
2025-11-02 05:54:21,422: t15.2023.10.08 val PER: 0.2842
2025-11-02 05:54:21,422: t15.2023.10.13 val PER: 0.2816
2025-11-02 05:54:21,422: t15.2023.10.15 val PER: 0.2044
2025-11-02 05:54:21,423: t15.2023.10.20 val PER: 0.2114
2025-11-02 05:54:21,423: t15.2023.10.22 val PER: 0.1871
2025-11-02 05:54:21,423: t15.2023.11.03 val PER: 0.2388
2025-11-02 05:54:21,424: t15.2023.11.04 val PER: 0.0580
2025-11-02 05:54:21,424: t15.2023.11.17 val PER: 0.0980
2025-11-02 05:54:21,424: t15.2023.11.19 val PER: 0.1018
2025-11-02 05:54:21,424: t15.2023.11.26 val PER: 0.2457
2025-11-02 05:54:21,425: t15.2023.12.03 val PER: 0.1901
2025-11-02 05:54:21,425: t15.2023.12.08 val PER: 0.2150
2025-11-02 05:54:21,425: t15.2023.12.10 val PER: 0.1787
2025-11-02 05:54:21,426: t15.2023.12.17 val PER: 0.2464
2025-11-02 05:54:21,426: t15.2023.12.29 val PER: 0.2279
2025-11-02 05:54:21,427: t15.2024.02.25 val PER: 0.1812
2025-11-02 05:54:21,427: t15.2024.03.08 val PER: 0.3115
2025-11-02 05:54:21,428: t15.2024.03.15 val PER: 0.2946
2025-11-02 05:54:21,428: t15.2024.03.17 val PER: 0.2287
2025-11-02 05:54:21,428: t15.2024.05.10 val PER: 0.2288
2025-11-02 05:54:21,429: t15.2024.06.14 val PER: 0.2524
2025-11-02 05:54:21,429: t15.2024.07.19 val PER: 0.3263
2025-11-02 05:54:21,429: t15.2024.07.21 val PER: 0.1697
2025-11-02 05:54:21,430: t15.2024.07.28 val PER: 0.2096
2025-11-02 05:54:21,430: t15.2025.01.10 val PER: 0.3926
2025-11-02 05:54:21,430: t15.2025.01.12 val PER: 0.2440
2025-11-02 05:54:21,431: t15.2025.03.14 val PER: 0.4098
2025-11-02 05:54:21,432: t15.2025.03.16 val PER: 0.2958
2025-11-02 05:54:21,432: t15.2025.03.30 val PER: 0.3529
2025-11-02 05:54:21,432: t15.2025.04.13 val PER: 0.3310
2025-11-02 05:54:21,433: New best test PER 0.2294 --> 0.2294
2025-11-02 05:54:21,433: Checkpointing model
2025-11-02 05:54:23,677: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:54:48,241: Train batch 62200: loss: 16.53 grad norm: 53.30 time: 0.102
2025-11-02 05:55:12,327: Train batch 62400: loss: 14.98 grad norm: 41.88 time: 0.082
2025-11-02 05:55:36,557: Train batch 62600: loss: 14.96 grad norm: 45.15 time: 0.099
2025-11-02 05:56:00,890: Train batch 62800: loss: 16.82 grad norm: 57.13 time: 0.097
2025-11-02 05:56:24,655: Train batch 63000: loss: 16.19 grad norm: 51.16 time: 0.109
2025-11-02 05:56:24,657: Running test after training batch: 63000
2025-11-02 05:56:39,820: Val batch 63000: PER (avg): 0.2280 CTC Loss (avg): 23.7100 time: 15.164
2025-11-02 05:56:39,821: t15.2023.08.13 val PER: 0.1830
2025-11-02 05:56:39,822: t15.2023.08.18 val PER: 0.1769
2025-11-02 05:56:39,822: t15.2023.08.20 val PER: 0.1835
2025-11-02 05:56:39,823: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:56:39,823: t15.2023.08.27 val PER: 0.2653
2025-11-02 05:56:39,823: t15.2023.09.01 val PER: 0.1274
2025-11-02 05:56:39,824: t15.2023.09.03 val PER: 0.2292
2025-11-02 05:56:39,824: t15.2023.09.24 val PER: 0.1845
2025-11-02 05:56:39,824: t15.2023.09.29 val PER: 0.1889
2025-11-02 05:56:39,825: t15.2023.10.01 val PER: 0.2398
2025-11-02 05:56:39,825: t15.2023.10.06 val PER: 0.1668
2025-11-02 05:56:39,825: t15.2023.10.08 val PER: 0.2747
2025-11-02 05:56:39,825: t15.2023.10.13 val PER: 0.2808
2025-11-02 05:56:39,826: t15.2023.10.15 val PER: 0.2011
2025-11-02 05:56:39,826: t15.2023.10.20 val PER: 0.2181
2025-11-02 05:56:39,827: t15.2023.10.22 val PER: 0.1893
2025-11-02 05:56:39,827: t15.2023.11.03 val PER: 0.2395
2025-11-02 05:56:39,827: t15.2023.11.04 val PER: 0.0546
2025-11-02 05:56:39,828: t15.2023.11.17 val PER: 0.0995
2025-11-02 05:56:39,828: t15.2023.11.19 val PER: 0.0958
2025-11-02 05:56:39,828: t15.2023.11.26 val PER: 0.2399
2025-11-02 05:56:39,828: t15.2023.12.03 val PER: 0.1891
2025-11-02 05:56:39,829: t15.2023.12.08 val PER: 0.2150
2025-11-02 05:56:39,829: t15.2023.12.10 val PER: 0.1721
2025-11-02 05:56:39,829: t15.2023.12.17 val PER: 0.2505
2025-11-02 05:56:39,830: t15.2023.12.29 val PER: 0.2286
2025-11-02 05:56:39,830: t15.2024.02.25 val PER: 0.1784
2025-11-02 05:56:39,830: t15.2024.03.08 val PER: 0.3044
2025-11-02 05:56:39,830: t15.2024.03.15 val PER: 0.2946
2025-11-02 05:56:39,831: t15.2024.03.17 val PER: 0.2322
2025-11-02 05:56:39,831: t15.2024.05.10 val PER: 0.2273
2025-11-02 05:56:39,832: t15.2024.06.14 val PER: 0.2445
2025-11-02 05:56:39,832: t15.2024.07.19 val PER: 0.3256
2025-11-02 05:56:39,832: t15.2024.07.21 val PER: 0.1669
2025-11-02 05:56:39,832: t15.2024.07.28 val PER: 0.2147
2025-11-02 05:56:39,833: t15.2025.01.10 val PER: 0.3829
2025-11-02 05:56:39,833: t15.2025.01.12 val PER: 0.2410
2025-11-02 05:56:39,833: t15.2025.03.14 val PER: 0.4053
2025-11-02 05:56:39,833: t15.2025.03.16 val PER: 0.2932
2025-11-02 05:56:39,834: t15.2025.03.30 val PER: 0.3529
2025-11-02 05:56:39,834: t15.2025.04.13 val PER: 0.3181
2025-11-02 05:56:39,834: New best test PER 0.2294 --> 0.2280
2025-11-02 05:56:39,834: Checkpointing model
2025-11-02 05:56:41,905: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:57:06,047: Train batch 63200: loss: 13.84 grad norm: 53.53 time: 0.065
2025-11-02 05:57:29,609: Train batch 63400: loss: 17.61 grad norm: 107.04 time: 0.096
2025-11-02 05:57:53,897: Train batch 63600: loss: 14.21 grad norm: 45.83 time: 0.094
2025-11-02 05:58:17,422: Train batch 63800: loss: 12.30 grad norm: 45.92 time: 0.086
2025-11-02 05:58:41,379: Train batch 64000: loss: 15.45 grad norm: 49.95 time: 0.126
2025-11-02 05:58:41,380: Running test after training batch: 64000
2025-11-02 05:58:56,323: Val batch 64000: PER (avg): 0.2274 CTC Loss (avg): 23.5953 time: 14.943
2025-11-02 05:58:56,324: t15.2023.08.13 val PER: 0.1861
2025-11-02 05:58:56,325: t15.2023.08.18 val PER: 0.1794
2025-11-02 05:58:56,325: t15.2023.08.20 val PER: 0.1811
2025-11-02 05:58:56,326: t15.2023.08.25 val PER: 0.1732
2025-11-02 05:58:56,327: t15.2023.08.27 val PER: 0.2572
2025-11-02 05:58:56,327: t15.2023.09.01 val PER: 0.1266
2025-11-02 05:58:56,328: t15.2023.09.03 val PER: 0.2221
2025-11-02 05:58:56,328: t15.2023.09.24 val PER: 0.1869
2025-11-02 05:58:56,328: t15.2023.09.29 val PER: 0.1895
2025-11-02 05:58:56,329: t15.2023.10.01 val PER: 0.2325
2025-11-02 05:58:56,329: t15.2023.10.06 val PER: 0.1636
2025-11-02 05:58:56,329: t15.2023.10.08 val PER: 0.2815
2025-11-02 05:58:56,330: t15.2023.10.13 val PER: 0.2777
2025-11-02 05:58:56,330: t15.2023.10.15 val PER: 0.2076
2025-11-02 05:58:56,330: t15.2023.10.20 val PER: 0.2047
2025-11-02 05:58:56,330: t15.2023.10.22 val PER: 0.1882
2025-11-02 05:58:56,331: t15.2023.11.03 val PER: 0.2395
2025-11-02 05:58:56,331: t15.2023.11.04 val PER: 0.0512
2025-11-02 05:58:56,332: t15.2023.11.17 val PER: 0.0933
2025-11-02 05:58:56,332: t15.2023.11.19 val PER: 0.0998
2025-11-02 05:58:56,332: t15.2023.11.26 val PER: 0.2391
2025-11-02 05:58:56,333: t15.2023.12.03 val PER: 0.1943
2025-11-02 05:58:56,333: t15.2023.12.08 val PER: 0.2130
2025-11-02 05:58:56,333: t15.2023.12.10 val PER: 0.1761
2025-11-02 05:58:56,333: t15.2023.12.17 val PER: 0.2495
2025-11-02 05:58:56,334: t15.2023.12.29 val PER: 0.2258
2025-11-02 05:58:56,334: t15.2024.02.25 val PER: 0.1742
2025-11-02 05:58:56,334: t15.2024.03.08 val PER: 0.3058
2025-11-02 05:58:56,335: t15.2024.03.15 val PER: 0.2952
2025-11-02 05:58:56,335: t15.2024.03.17 val PER: 0.2350
2025-11-02 05:58:56,335: t15.2024.05.10 val PER: 0.2199
2025-11-02 05:58:56,342: t15.2024.06.14 val PER: 0.2445
2025-11-02 05:58:56,342: t15.2024.07.19 val PER: 0.3164
2025-11-02 05:58:56,343: t15.2024.07.21 val PER: 0.1676
2025-11-02 05:58:56,343: t15.2024.07.28 val PER: 0.2110
2025-11-02 05:58:56,343: t15.2025.01.10 val PER: 0.3926
2025-11-02 05:58:56,343: t15.2025.01.12 val PER: 0.2417
2025-11-02 05:58:56,344: t15.2025.03.14 val PER: 0.4053
2025-11-02 05:58:56,344: t15.2025.03.16 val PER: 0.2893
2025-11-02 05:58:56,344: t15.2025.03.30 val PER: 0.3575
2025-11-02 05:58:56,345: t15.2025.04.13 val PER: 0.3224
2025-11-02 05:58:56,345: New best test PER 0.2280 --> 0.2274
2025-11-02 05:58:56,345: Checkpointing model
2025-11-02 05:58:58,400: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 05:59:22,922: Train batch 64200: loss: 14.76 grad norm: 45.71 time: 0.083
2025-11-02 05:59:46,837: Train batch 64400: loss: 13.73 grad norm: 46.85 time: 0.085
2025-11-02 06:00:10,944: Train batch 64600: loss: 8.42 grad norm: 37.91 time: 0.080
2025-11-02 06:00:35,368: Train batch 64800: loss: 14.18 grad norm: 47.31 time: 0.061
2025-11-02 06:01:00,000: Train batch 65000: loss: 15.31 grad norm: 57.05 time: 0.108
2025-11-02 06:01:00,010: Running test after training batch: 65000
2025-11-02 06:01:15,322: Val batch 65000: PER (avg): 0.2260 CTC Loss (avg): 23.5209 time: 15.311
2025-11-02 06:01:15,323: t15.2023.08.13 val PER: 0.1830
2025-11-02 06:01:15,323: t15.2023.08.18 val PER: 0.1735
2025-11-02 06:01:15,323: t15.2023.08.20 val PER: 0.1811
2025-11-02 06:01:15,324: t15.2023.08.25 val PER: 0.1702
2025-11-02 06:01:15,324: t15.2023.08.27 val PER: 0.2588
2025-11-02 06:01:15,325: t15.2023.09.01 val PER: 0.1250
2025-11-02 06:01:15,325: t15.2023.09.03 val PER: 0.2209
2025-11-02 06:01:15,325: t15.2023.09.24 val PER: 0.1869
2025-11-02 06:01:15,326: t15.2023.09.29 val PER: 0.1857
2025-11-02 06:01:15,327: t15.2023.10.01 val PER: 0.2285
2025-11-02 06:01:15,327: t15.2023.10.06 val PER: 0.1636
2025-11-02 06:01:15,327: t15.2023.10.08 val PER: 0.2788
2025-11-02 06:01:15,328: t15.2023.10.13 val PER: 0.2824
2025-11-02 06:01:15,328: t15.2023.10.15 val PER: 0.2037
2025-11-02 06:01:15,328: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:01:15,328: t15.2023.10.22 val PER: 0.1871
2025-11-02 06:01:15,329: t15.2023.11.03 val PER: 0.2374
2025-11-02 06:01:15,329: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:01:15,329: t15.2023.11.17 val PER: 0.0995
2025-11-02 06:01:15,330: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:01:15,330: t15.2023.11.26 val PER: 0.2442
2025-11-02 06:01:15,330: t15.2023.12.03 val PER: 0.1922
2025-11-02 06:01:15,331: t15.2023.12.08 val PER: 0.2084
2025-11-02 06:01:15,331: t15.2023.12.10 val PER: 0.1735
2025-11-02 06:01:15,332: t15.2023.12.17 val PER: 0.2464
2025-11-02 06:01:15,332: t15.2023.12.29 val PER: 0.2224
2025-11-02 06:01:15,332: t15.2024.02.25 val PER: 0.1756
2025-11-02 06:01:15,333: t15.2024.03.08 val PER: 0.3058
2025-11-02 06:01:15,333: t15.2024.03.15 val PER: 0.2927
2025-11-02 06:01:15,333: t15.2024.03.17 val PER: 0.2301
2025-11-02 06:01:15,334: t15.2024.05.10 val PER: 0.2184
2025-11-02 06:01:15,334: t15.2024.06.14 val PER: 0.2445
2025-11-02 06:01:15,334: t15.2024.07.19 val PER: 0.3223
2025-11-02 06:01:15,334: t15.2024.07.21 val PER: 0.1662
2025-11-02 06:01:15,335: t15.2024.07.28 val PER: 0.2103
2025-11-02 06:01:15,335: t15.2025.01.10 val PER: 0.3843
2025-11-02 06:01:15,335: t15.2025.01.12 val PER: 0.2379
2025-11-02 06:01:15,336: t15.2025.03.14 val PER: 0.4053
2025-11-02 06:01:15,336: t15.2025.03.16 val PER: 0.2880
2025-11-02 06:01:15,337: t15.2025.03.30 val PER: 0.3552
2025-11-02 06:01:15,337: t15.2025.04.13 val PER: 0.3181
2025-11-02 06:01:15,337: New best test PER 0.2274 --> 0.2260
2025-11-02 06:01:15,337: Checkpointing model
2025-11-02 06:01:17,522: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:01:42,419: Train batch 65200: loss: 19.95 grad norm: 64.83 time: 0.106
2025-11-02 06:02:06,003: Train batch 65400: loss: 14.80 grad norm: 53.47 time: 0.074
2025-11-02 06:02:30,156: Train batch 65600: loss: 17.02 grad norm: 48.53 time: 0.081
2025-11-02 06:02:53,726: Train batch 65800: loss: 14.57 grad norm: 54.90 time: 0.068
2025-11-02 06:03:17,932: Train batch 66000: loss: 20.98 grad norm: 74.65 time: 0.081
2025-11-02 06:03:17,933: Running test after training batch: 66000
2025-11-02 06:03:33,123: Val batch 66000: PER (avg): 0.2260 CTC Loss (avg): 23.5123 time: 15.190
2025-11-02 06:03:33,124: t15.2023.08.13 val PER: 0.1809
2025-11-02 06:03:33,124: t15.2023.08.18 val PER: 0.1794
2025-11-02 06:03:33,125: t15.2023.08.20 val PER: 0.1787
2025-11-02 06:03:33,125: t15.2023.08.25 val PER: 0.1717
2025-11-02 06:03:33,125: t15.2023.08.27 val PER: 0.2556
2025-11-02 06:03:33,126: t15.2023.09.01 val PER: 0.1258
2025-11-02 06:03:33,127: t15.2023.09.03 val PER: 0.2209
2025-11-02 06:03:33,127: t15.2023.09.24 val PER: 0.1833
2025-11-02 06:03:33,128: t15.2023.09.29 val PER: 0.1857
2025-11-02 06:03:33,128: t15.2023.10.01 val PER: 0.2338
2025-11-02 06:03:33,128: t15.2023.10.06 val PER: 0.1615
2025-11-02 06:03:33,128: t15.2023.10.08 val PER: 0.2801
2025-11-02 06:03:33,129: t15.2023.10.13 val PER: 0.2824
2025-11-02 06:03:33,129: t15.2023.10.15 val PER: 0.2011
2025-11-02 06:03:33,129: t15.2023.10.20 val PER: 0.2148
2025-11-02 06:03:33,130: t15.2023.10.22 val PER: 0.1882
2025-11-02 06:03:33,130: t15.2023.11.03 val PER: 0.2395
2025-11-02 06:03:33,130: t15.2023.11.04 val PER: 0.0614
2025-11-02 06:03:33,130: t15.2023.11.17 val PER: 0.1011
2025-11-02 06:03:33,131: t15.2023.11.19 val PER: 0.0938
2025-11-02 06:03:33,131: t15.2023.11.26 val PER: 0.2326
2025-11-02 06:03:33,132: t15.2023.12.03 val PER: 0.1943
2025-11-02 06:03:33,132: t15.2023.12.08 val PER: 0.2124
2025-11-02 06:03:33,132: t15.2023.12.10 val PER: 0.1774
2025-11-02 06:03:33,133: t15.2023.12.17 val PER: 0.2484
2025-11-02 06:03:33,133: t15.2023.12.29 val PER: 0.2176
2025-11-02 06:03:33,133: t15.2024.02.25 val PER: 0.1742
2025-11-02 06:03:33,133: t15.2024.03.08 val PER: 0.3030
2025-11-02 06:03:33,134: t15.2024.03.15 val PER: 0.2914
2025-11-02 06:03:33,134: t15.2024.03.17 val PER: 0.2280
2025-11-02 06:03:33,134: t15.2024.05.10 val PER: 0.2333
2025-11-02 06:03:33,135: t15.2024.06.14 val PER: 0.2413
2025-11-02 06:03:33,135: t15.2024.07.19 val PER: 0.3204
2025-11-02 06:03:33,183: t15.2024.07.21 val PER: 0.1662
2025-11-02 06:03:33,184: t15.2024.07.28 val PER: 0.2051
2025-11-02 06:03:33,184: t15.2025.01.10 val PER: 0.3815
2025-11-02 06:03:33,185: t15.2025.01.12 val PER: 0.2425
2025-11-02 06:03:33,185: t15.2025.03.14 val PER: 0.4083
2025-11-02 06:03:33,185: t15.2025.03.16 val PER: 0.2893
2025-11-02 06:03:33,186: t15.2025.03.30 val PER: 0.3552
2025-11-02 06:03:33,186: t15.2025.04.13 val PER: 0.3252
2025-11-02 06:03:33,186: New best test loss 23.5209 --> 23.5123
2025-11-02 06:03:33,187: Checkpointing model
2025-11-02 06:03:35,221: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:03:59,258: Train batch 66200: loss: 17.79 grad norm: 53.28 time: 0.072
2025-11-02 06:04:23,563: Train batch 66400: loss: 12.96 grad norm: 38.93 time: 0.088
2025-11-02 06:04:47,986: Train batch 66600: loss: 12.61 grad norm: 54.28 time: 0.074
2025-11-02 06:05:11,902: Train batch 66800: loss: 12.41 grad norm: 46.78 time: 0.076
2025-11-02 06:05:35,072: Train batch 67000: loss: 12.78 grad norm: 41.61 time: 0.070
2025-11-02 06:05:35,073: Running test after training batch: 67000
2025-11-02 06:05:50,023: Val batch 67000: PER (avg): 0.2243 CTC Loss (avg): 23.3710 time: 14.949
2025-11-02 06:05:50,024: t15.2023.08.13 val PER: 0.1736
2025-11-02 06:05:50,024: t15.2023.08.18 val PER: 0.1760
2025-11-02 06:05:50,025: t15.2023.08.20 val PER: 0.1795
2025-11-02 06:05:50,025: t15.2023.08.25 val PER: 0.1672
2025-11-02 06:05:50,025: t15.2023.08.27 val PER: 0.2540
2025-11-02 06:05:50,026: t15.2023.09.01 val PER: 0.1209
2025-11-02 06:05:50,027: t15.2023.09.03 val PER: 0.2197
2025-11-02 06:05:50,027: t15.2023.09.24 val PER: 0.1820
2025-11-02 06:05:50,027: t15.2023.09.29 val PER: 0.1857
2025-11-02 06:05:50,028: t15.2023.10.01 val PER: 0.2305
2025-11-02 06:05:50,028: t15.2023.10.06 val PER: 0.1647
2025-11-02 06:05:50,028: t15.2023.10.08 val PER: 0.2733
2025-11-02 06:05:50,029: t15.2023.10.13 val PER: 0.2785
2025-11-02 06:05:50,029: t15.2023.10.15 val PER: 0.2070
2025-11-02 06:05:50,029: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:05:50,030: t15.2023.10.22 val PER: 0.1860
2025-11-02 06:05:50,030: t15.2023.11.03 val PER: 0.2368
2025-11-02 06:05:50,030: t15.2023.11.04 val PER: 0.0648
2025-11-02 06:05:50,031: t15.2023.11.17 val PER: 0.0995
2025-11-02 06:05:50,031: t15.2023.11.19 val PER: 0.0918
2025-11-02 06:05:50,032: t15.2023.11.26 val PER: 0.2377
2025-11-02 06:05:50,032: t15.2023.12.03 val PER: 0.1912
2025-11-02 06:05:50,033: t15.2023.12.08 val PER: 0.2091
2025-11-02 06:05:50,033: t15.2023.12.10 val PER: 0.1761
2025-11-02 06:05:50,033: t15.2023.12.17 val PER: 0.2443
2025-11-02 06:05:50,034: t15.2023.12.29 val PER: 0.2189
2025-11-02 06:05:50,034: t15.2024.02.25 val PER: 0.1798
2025-11-02 06:05:50,034: t15.2024.03.08 val PER: 0.2987
2025-11-02 06:05:50,034: t15.2024.03.15 val PER: 0.2877
2025-11-02 06:05:50,035: t15.2024.03.17 val PER: 0.2259
2025-11-02 06:05:50,035: t15.2024.05.10 val PER: 0.2244
2025-11-02 06:05:50,035: t15.2024.06.14 val PER: 0.2429
2025-11-02 06:05:50,036: t15.2024.07.19 val PER: 0.3138
2025-11-02 06:05:50,036: t15.2024.07.21 val PER: 0.1669
2025-11-02 06:05:50,037: t15.2024.07.28 val PER: 0.2096
2025-11-02 06:05:50,037: t15.2025.01.10 val PER: 0.3857
2025-11-02 06:05:50,037: t15.2025.01.12 val PER: 0.2425
2025-11-02 06:05:50,038: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:05:50,038: t15.2025.03.16 val PER: 0.2853
2025-11-02 06:05:50,038: t15.2025.03.30 val PER: 0.3517
2025-11-02 06:05:50,038: t15.2025.04.13 val PER: 0.3167
2025-11-02 06:05:50,039: New best test PER 0.2260 --> 0.2243
2025-11-02 06:05:50,039: Checkpointing model
2025-11-02 06:05:52,311: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:06:17,357: Train batch 67200: loss: 13.53 grad norm: 47.71 time: 0.067
2025-11-02 06:06:41,324: Train batch 67400: loss: 16.28 grad norm: 59.75 time: 0.080
2025-11-02 06:07:04,933: Train batch 67600: loss: 15.72 grad norm: 54.01 time: 0.075
2025-11-02 06:07:28,597: Train batch 67800: loss: 10.99 grad norm: 44.38 time: 0.117
2025-11-02 06:07:52,553: Train batch 68000: loss: 13.40 grad norm: 48.79 time: 0.073
2025-11-02 06:07:52,554: Running test after training batch: 68000
2025-11-02 06:08:07,422: Val batch 68000: PER (avg): 0.2242 CTC Loss (avg): 23.3835 time: 14.868
2025-11-02 06:08:07,423: t15.2023.08.13 val PER: 0.1788
2025-11-02 06:08:07,423: t15.2023.08.18 val PER: 0.1760
2025-11-02 06:08:07,424: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:08:07,424: t15.2023.08.25 val PER: 0.1596
2025-11-02 06:08:07,424: t15.2023.08.27 val PER: 0.2572
2025-11-02 06:08:07,425: t15.2023.09.01 val PER: 0.1218
2025-11-02 06:08:07,425: t15.2023.09.03 val PER: 0.2197
2025-11-02 06:08:07,425: t15.2023.09.24 val PER: 0.1796
2025-11-02 06:08:07,426: t15.2023.09.29 val PER: 0.1863
2025-11-02 06:08:07,426: t15.2023.10.01 val PER: 0.2299
2025-11-02 06:08:07,427: t15.2023.10.06 val PER: 0.1604
2025-11-02 06:08:07,427: t15.2023.10.08 val PER: 0.2801
2025-11-02 06:08:07,427: t15.2023.10.13 val PER: 0.2770
2025-11-02 06:08:07,428: t15.2023.10.15 val PER: 0.2050
2025-11-02 06:08:07,428: t15.2023.10.20 val PER: 0.2148
2025-11-02 06:08:07,428: t15.2023.10.22 val PER: 0.1893
2025-11-02 06:08:07,429: t15.2023.11.03 val PER: 0.2388
2025-11-02 06:08:07,429: t15.2023.11.04 val PER: 0.0512
2025-11-02 06:08:07,429: t15.2023.11.17 val PER: 0.0995
2025-11-02 06:08:07,430: t15.2023.11.19 val PER: 0.1018
2025-11-02 06:08:07,430: t15.2023.11.26 val PER: 0.2362
2025-11-02 06:08:07,430: t15.2023.12.03 val PER: 0.1880
2025-11-02 06:08:07,431: t15.2023.12.08 val PER: 0.2084
2025-11-02 06:08:07,431: t15.2023.12.10 val PER: 0.1735
2025-11-02 06:08:07,432: t15.2023.12.17 val PER: 0.2370
2025-11-02 06:08:07,432: t15.2023.12.29 val PER: 0.2162
2025-11-02 06:08:07,433: t15.2024.02.25 val PER: 0.1798
2025-11-02 06:08:07,433: t15.2024.03.08 val PER: 0.2973
2025-11-02 06:08:07,433: t15.2024.03.15 val PER: 0.2927
2025-11-02 06:08:07,434: t15.2024.03.17 val PER: 0.2294
2025-11-02 06:08:07,434: t15.2024.05.10 val PER: 0.2259
2025-11-02 06:08:07,434: t15.2024.06.14 val PER: 0.2319
2025-11-02 06:08:07,434: t15.2024.07.19 val PER: 0.3204
2025-11-02 06:08:07,435: t15.2024.07.21 val PER: 0.1676
2025-11-02 06:08:07,435: t15.2024.07.28 val PER: 0.2081
2025-11-02 06:08:07,435: t15.2025.01.10 val PER: 0.3857
2025-11-02 06:08:07,436: t15.2025.01.12 val PER: 0.2417
2025-11-02 06:08:07,436: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:08:07,437: t15.2025.03.16 val PER: 0.2906
2025-11-02 06:08:07,437: t15.2025.03.30 val PER: 0.3437
2025-11-02 06:08:07,437: t15.2025.04.13 val PER: 0.3181
2025-11-02 06:08:07,438: New best test PER 0.2243 --> 0.2242
2025-11-02 06:08:07,438: Checkpointing model
2025-11-02 06:08:09,564: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:08:34,668: Train batch 68200: loss: 14.82 grad norm: 46.75 time: 0.104
2025-11-02 06:08:59,001: Train batch 68400: loss: 12.13 grad norm: 42.58 time: 0.101
2025-11-02 06:09:22,811: Train batch 68600: loss: 14.44 grad norm: 55.57 time: 0.086
2025-11-02 06:09:47,678: Train batch 68800: loss: 16.07 grad norm: 54.64 time: 0.089
2025-11-02 06:10:11,260: Train batch 69000: loss: 12.67 grad norm: 50.76 time: 0.077
2025-11-02 06:10:11,261: Running test after training batch: 69000
2025-11-02 06:10:26,214: Val batch 69000: PER (avg): 0.2240 CTC Loss (avg): 23.3368 time: 14.952
2025-11-02 06:10:26,215: t15.2023.08.13 val PER: 0.1798
2025-11-02 06:10:26,215: t15.2023.08.18 val PER: 0.1727
2025-11-02 06:10:26,216: t15.2023.08.20 val PER: 0.1795
2025-11-02 06:10:26,216: t15.2023.08.25 val PER: 0.1627
2025-11-02 06:10:26,216: t15.2023.08.27 val PER: 0.2572
2025-11-02 06:10:26,217: t15.2023.09.01 val PER: 0.1258
2025-11-02 06:10:26,217: t15.2023.09.03 val PER: 0.2221
2025-11-02 06:10:26,218: t15.2023.09.24 val PER: 0.1796
2025-11-02 06:10:26,218: t15.2023.09.29 val PER: 0.1812
2025-11-02 06:10:26,218: t15.2023.10.01 val PER: 0.2305
2025-11-02 06:10:26,218: t15.2023.10.06 val PER: 0.1625
2025-11-02 06:10:26,219: t15.2023.10.08 val PER: 0.2720
2025-11-02 06:10:26,219: t15.2023.10.13 val PER: 0.2777
2025-11-02 06:10:26,219: t15.2023.10.15 val PER: 0.2070
2025-11-02 06:10:26,220: t15.2023.10.20 val PER: 0.2181
2025-11-02 06:10:26,220: t15.2023.10.22 val PER: 0.1826
2025-11-02 06:10:26,220: t15.2023.11.03 val PER: 0.2361
2025-11-02 06:10:26,221: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:10:26,222: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:10:26,222: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:10:26,222: t15.2023.11.26 val PER: 0.2362
2025-11-02 06:10:26,222: t15.2023.12.03 val PER: 0.1880
2025-11-02 06:10:26,223: t15.2023.12.08 val PER: 0.2077
2025-11-02 06:10:26,223: t15.2023.12.10 val PER: 0.1721
2025-11-02 06:10:26,223: t15.2023.12.17 val PER: 0.2412
2025-11-02 06:10:26,223: t15.2023.12.29 val PER: 0.2196
2025-11-02 06:10:26,224: t15.2024.02.25 val PER: 0.1699
2025-11-02 06:10:26,224: t15.2024.03.08 val PER: 0.2959
2025-11-02 06:10:26,224: t15.2024.03.15 val PER: 0.2927
2025-11-02 06:10:26,224: t15.2024.03.17 val PER: 0.2322
2025-11-02 06:10:26,225: t15.2024.05.10 val PER: 0.2199
2025-11-02 06:10:26,225: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:10:26,225: t15.2024.07.19 val PER: 0.3171
2025-11-02 06:10:26,225: t15.2024.07.21 val PER: 0.1628
2025-11-02 06:10:26,226: t15.2024.07.28 val PER: 0.2059
2025-11-02 06:10:26,226: t15.2025.01.10 val PER: 0.3747
2025-11-02 06:10:26,226: t15.2025.01.12 val PER: 0.2440
2025-11-02 06:10:26,227: t15.2025.03.14 val PER: 0.4053
2025-11-02 06:10:26,227: t15.2025.03.16 val PER: 0.2906
2025-11-02 06:10:26,227: t15.2025.03.30 val PER: 0.3575
2025-11-02 06:10:26,227: t15.2025.04.13 val PER: 0.3267
2025-11-02 06:10:26,228: New best test PER 0.2242 --> 0.2240
2025-11-02 06:10:26,228: Checkpointing model
2025-11-02 06:10:28,446: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:10:52,856: Train batch 69200: loss: 11.68 grad norm: 42.96 time: 0.067
2025-11-02 06:11:17,308: Train batch 69400: loss: 15.96 grad norm: 50.33 time: 0.072
2025-11-02 06:11:43,009: Train batch 69600: loss: 8.97 grad norm: 39.42 time: 0.127
2025-11-02 06:12:08,361: Train batch 69800: loss: 14.45 grad norm: 50.39 time: 0.093
2025-11-02 06:12:33,843: Train batch 70000: loss: 13.03 grad norm: 51.85 time: 0.111
2025-11-02 06:12:33,844: Running test after training batch: 70000
2025-11-02 06:12:49,013: Val batch 70000: PER (avg): 0.2226 CTC Loss (avg): 23.2253 time: 15.169
2025-11-02 06:12:49,014: t15.2023.08.13 val PER: 0.1757
2025-11-02 06:12:49,015: t15.2023.08.18 val PER: 0.1710
2025-11-02 06:12:49,015: t15.2023.08.20 val PER: 0.1779
2025-11-02 06:12:49,015: t15.2023.08.25 val PER: 0.1642
2025-11-02 06:12:49,016: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:12:49,016: t15.2023.09.01 val PER: 0.1242
2025-11-02 06:12:49,017: t15.2023.09.03 val PER: 0.2245
2025-11-02 06:12:49,017: t15.2023.09.24 val PER: 0.1748
2025-11-02 06:12:49,018: t15.2023.09.29 val PER: 0.1838
2025-11-02 06:12:49,018: t15.2023.10.01 val PER: 0.2299
2025-11-02 06:12:49,018: t15.2023.10.06 val PER: 0.1604
2025-11-02 06:12:49,019: t15.2023.10.08 val PER: 0.2774
2025-11-02 06:12:49,019: t15.2023.10.13 val PER: 0.2793
2025-11-02 06:12:49,019: t15.2023.10.15 val PER: 0.2070
2025-11-02 06:12:49,019: t15.2023.10.20 val PER: 0.2081
2025-11-02 06:12:49,020: t15.2023.10.22 val PER: 0.1871
2025-11-02 06:12:49,020: t15.2023.11.03 val PER: 0.2341
2025-11-02 06:12:49,020: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:12:49,021: t15.2023.11.17 val PER: 0.0995
2025-11-02 06:12:49,021: t15.2023.11.19 val PER: 0.1038
2025-11-02 06:12:49,022: t15.2023.11.26 val PER: 0.2384
2025-11-02 06:12:49,022: t15.2023.12.03 val PER: 0.1880
2025-11-02 06:12:49,023: t15.2023.12.08 val PER: 0.2117
2025-11-02 06:12:49,023: t15.2023.12.10 val PER: 0.1682
2025-11-02 06:12:49,024: t15.2023.12.17 val PER: 0.2297
2025-11-02 06:12:49,024: t15.2023.12.29 val PER: 0.2189
2025-11-02 06:12:49,024: t15.2024.02.25 val PER: 0.1699
2025-11-02 06:12:49,025: t15.2024.03.08 val PER: 0.2959
2025-11-02 06:12:49,025: t15.2024.03.15 val PER: 0.2877
2025-11-02 06:12:49,025: t15.2024.03.17 val PER: 0.2287
2025-11-02 06:12:49,026: t15.2024.05.10 val PER: 0.2169
2025-11-02 06:12:49,026: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:12:49,026: t15.2024.07.19 val PER: 0.3164
2025-11-02 06:12:49,027: t15.2024.07.21 val PER: 0.1634
2025-11-02 06:12:49,027: t15.2024.07.28 val PER: 0.2051
2025-11-02 06:12:49,028: t15.2025.01.10 val PER: 0.3815
2025-11-02 06:12:49,028: t15.2025.01.12 val PER: 0.2363
2025-11-02 06:12:49,028: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:12:49,029: t15.2025.03.16 val PER: 0.2801
2025-11-02 06:12:49,029: t15.2025.03.30 val PER: 0.3529
2025-11-02 06:12:49,029: t15.2025.04.13 val PER: 0.3024
2025-11-02 06:12:49,030: New best test PER 0.2240 --> 0.2226
2025-11-02 06:12:49,030: Checkpointing model
2025-11-02 06:12:51,326: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:13:16,891: Train batch 70200: loss: 17.60 grad norm: 56.44 time: 0.112
2025-11-02 06:13:41,601: Train batch 70400: loss: 13.45 grad norm: 42.46 time: 0.088
2025-11-02 06:14:06,678: Train batch 70600: loss: 14.78 grad norm: 50.56 time: 0.119
2025-11-02 06:14:31,860: Train batch 70800: loss: 15.91 grad norm: 49.64 time: 0.090
2025-11-02 06:14:56,688: Train batch 71000: loss: 15.26 grad norm: 49.05 time: 0.080
2025-11-02 06:14:56,689: Running test after training batch: 71000
2025-11-02 06:15:12,026: Val batch 71000: PER (avg): 0.2227 CTC Loss (avg): 23.1958 time: 15.337
2025-11-02 06:15:12,027: t15.2023.08.13 val PER: 0.1746
2025-11-02 06:15:12,027: t15.2023.08.18 val PER: 0.1769
2025-11-02 06:15:12,028: t15.2023.08.20 val PER: 0.1795
2025-11-02 06:15:12,028: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:15:12,028: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:15:12,029: t15.2023.09.01 val PER: 0.1250
2025-11-02 06:15:12,029: t15.2023.09.03 val PER: 0.2233
2025-11-02 06:15:12,029: t15.2023.09.24 val PER: 0.1784
2025-11-02 06:15:12,030: t15.2023.09.29 val PER: 0.1844
2025-11-02 06:15:12,030: t15.2023.10.01 val PER: 0.2285
2025-11-02 06:15:12,030: t15.2023.10.06 val PER: 0.1615
2025-11-02 06:15:12,031: t15.2023.10.08 val PER: 0.2760
2025-11-02 06:15:12,031: t15.2023.10.13 val PER: 0.2801
2025-11-02 06:15:12,031: t15.2023.10.15 val PER: 0.2044
2025-11-02 06:15:12,032: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:15:12,032: t15.2023.10.22 val PER: 0.1837
2025-11-02 06:15:12,032: t15.2023.11.03 val PER: 0.2327
2025-11-02 06:15:12,033: t15.2023.11.04 val PER: 0.0614
2025-11-02 06:15:12,033: t15.2023.11.17 val PER: 0.0980
2025-11-02 06:15:12,033: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:15:12,033: t15.2023.11.26 val PER: 0.2348
2025-11-02 06:15:12,034: t15.2023.12.03 val PER: 0.1807
2025-11-02 06:15:12,034: t15.2023.12.08 val PER: 0.2097
2025-11-02 06:15:12,034: t15.2023.12.10 val PER: 0.1682
2025-11-02 06:15:12,035: t15.2023.12.17 val PER: 0.2391
2025-11-02 06:15:12,035: t15.2023.12.29 val PER: 0.2183
2025-11-02 06:15:12,035: t15.2024.02.25 val PER: 0.1699
2025-11-02 06:15:12,035: t15.2024.03.08 val PER: 0.2959
2025-11-02 06:15:12,036: t15.2024.03.15 val PER: 0.2883
2025-11-02 06:15:12,036: t15.2024.03.17 val PER: 0.2287
2025-11-02 06:15:12,036: t15.2024.05.10 val PER: 0.2214
2025-11-02 06:15:12,037: t15.2024.06.14 val PER: 0.2461
2025-11-02 06:15:12,037: t15.2024.07.19 val PER: 0.3105
2025-11-02 06:15:12,037: t15.2024.07.21 val PER: 0.1600
2025-11-02 06:15:12,037: t15.2024.07.28 val PER: 0.2051
2025-11-02 06:15:12,038: t15.2025.01.10 val PER: 0.3802
2025-11-02 06:15:12,038: t15.2025.01.12 val PER: 0.2402
2025-11-02 06:15:12,038: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:15:12,039: t15.2025.03.16 val PER: 0.2814
2025-11-02 06:15:12,039: t15.2025.03.30 val PER: 0.3598
2025-11-02 06:15:12,039: t15.2025.04.13 val PER: 0.3153
2025-11-02 06:15:36,694: Train batch 71200: loss: 16.03 grad norm: 54.23 time: 0.093
2025-11-02 06:16:01,912: Train batch 71400: loss: 12.05 grad norm: 41.31 time: 0.070
2025-11-02 06:16:26,984: Train batch 71600: loss: 12.46 grad norm: 50.51 time: 0.095
2025-11-02 06:16:51,756: Train batch 71800: loss: 14.78 grad norm: 64.58 time: 0.094
2025-11-02 06:17:16,584: Train batch 72000: loss: 15.75 grad norm: 51.29 time: 0.116
2025-11-02 06:17:16,591: Running test after training batch: 72000
2025-11-02 06:17:31,520: Val batch 72000: PER (avg): 0.2224 CTC Loss (avg): 23.1910 time: 14.929
2025-11-02 06:17:31,520: t15.2023.08.13 val PER: 0.1767
2025-11-02 06:17:31,521: t15.2023.08.18 val PER: 0.1744
2025-11-02 06:17:31,522: t15.2023.08.20 val PER: 0.1787
2025-11-02 06:17:31,523: t15.2023.08.25 val PER: 0.1702
2025-11-02 06:17:31,523: t15.2023.08.27 val PER: 0.2556
2025-11-02 06:17:31,523: t15.2023.09.01 val PER: 0.1209
2025-11-02 06:17:31,524: t15.2023.09.03 val PER: 0.2173
2025-11-02 06:17:31,524: t15.2023.09.24 val PER: 0.1796
2025-11-02 06:17:31,525: t15.2023.09.29 val PER: 0.1825
2025-11-02 06:17:31,525: t15.2023.10.01 val PER: 0.2272
2025-11-02 06:17:31,525: t15.2023.10.06 val PER: 0.1507
2025-11-02 06:17:31,526: t15.2023.10.08 val PER: 0.2720
2025-11-02 06:17:31,526: t15.2023.10.13 val PER: 0.2839
2025-11-02 06:17:31,527: t15.2023.10.15 val PER: 0.2044
2025-11-02 06:17:31,527: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:17:31,527: t15.2023.10.22 val PER: 0.1837
2025-11-02 06:17:31,528: t15.2023.11.03 val PER: 0.2313
2025-11-02 06:17:31,528: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:17:31,528: t15.2023.11.17 val PER: 0.0933
2025-11-02 06:17:31,529: t15.2023.11.19 val PER: 0.1038
2025-11-02 06:17:31,529: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:17:31,529: t15.2023.12.03 val PER: 0.1870
2025-11-02 06:17:31,530: t15.2023.12.08 val PER: 0.2097
2025-11-02 06:17:31,530: t15.2023.12.10 val PER: 0.1761
2025-11-02 06:17:31,530: t15.2023.12.17 val PER: 0.2380
2025-11-02 06:17:31,530: t15.2023.12.29 val PER: 0.2121
2025-11-02 06:17:31,531: t15.2024.02.25 val PER: 0.1728
2025-11-02 06:17:31,532: t15.2024.03.08 val PER: 0.2902
2025-11-02 06:17:31,532: t15.2024.03.15 val PER: 0.2933
2025-11-02 06:17:31,532: t15.2024.03.17 val PER: 0.2294
2025-11-02 06:17:31,533: t15.2024.05.10 val PER: 0.2155
2025-11-02 06:17:31,533: t15.2024.06.14 val PER: 0.2429
2025-11-02 06:17:31,533: t15.2024.07.19 val PER: 0.3131
2025-11-02 06:17:31,534: t15.2024.07.21 val PER: 0.1586
2025-11-02 06:17:31,534: t15.2024.07.28 val PER: 0.2066
2025-11-02 06:17:31,534: t15.2025.01.10 val PER: 0.3802
2025-11-02 06:17:31,535: t15.2025.01.12 val PER: 0.2386
2025-11-02 06:17:31,535: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:17:31,535: t15.2025.03.16 val PER: 0.2853
2025-11-02 06:17:31,535: t15.2025.03.30 val PER: 0.3609
2025-11-02 06:17:31,536: t15.2025.04.13 val PER: 0.3081
2025-11-02 06:17:31,536: New best test PER 0.2226 --> 0.2224
2025-11-02 06:17:31,537: Checkpointing model
2025-11-02 06:17:33,823: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:17:59,738: Train batch 72200: loss: 14.26 grad norm: 49.26 time: 0.096
2025-11-02 06:18:24,985: Train batch 72400: loss: 10.50 grad norm: 44.15 time: 0.097
2025-11-02 06:18:51,110: Train batch 72600: loss: 9.60 grad norm: 37.29 time: 0.092
2025-11-02 06:19:16,580: Train batch 72800: loss: 6.83 grad norm: 31.08 time: 0.082
2025-11-02 06:19:41,477: Train batch 73000: loss: 16.38 grad norm: 66.49 time: 0.116
2025-11-02 06:19:41,477: Running test after training batch: 73000
2025-11-02 06:19:56,729: Val batch 73000: PER (avg): 0.2213 CTC Loss (avg): 23.1513 time: 15.251
2025-11-02 06:19:56,730: t15.2023.08.13 val PER: 0.1819
2025-11-02 06:19:56,730: t15.2023.08.18 val PER: 0.1710
2025-11-02 06:19:56,730: t15.2023.08.20 val PER: 0.1819
2025-11-02 06:19:56,731: t15.2023.08.25 val PER: 0.1687
2025-11-02 06:19:56,731: t15.2023.08.27 val PER: 0.2476
2025-11-02 06:19:56,732: t15.2023.09.01 val PER: 0.1209
2025-11-02 06:19:56,732: t15.2023.09.03 val PER: 0.2197
2025-11-02 06:19:56,732: t15.2023.09.24 val PER: 0.1748
2025-11-02 06:19:56,733: t15.2023.09.29 val PER: 0.1806
2025-11-02 06:19:56,733: t15.2023.10.01 val PER: 0.2219
2025-11-02 06:19:56,733: t15.2023.10.06 val PER: 0.1539
2025-11-02 06:19:56,734: t15.2023.10.08 val PER: 0.2747
2025-11-02 06:19:56,734: t15.2023.10.13 val PER: 0.2770
2025-11-02 06:19:56,734: t15.2023.10.15 val PER: 0.2076
2025-11-02 06:19:56,735: t15.2023.10.20 val PER: 0.1946
2025-11-02 06:19:56,735: t15.2023.10.22 val PER: 0.1837
2025-11-02 06:19:56,735: t15.2023.11.03 val PER: 0.2307
2025-11-02 06:19:56,735: t15.2023.11.04 val PER: 0.0614
2025-11-02 06:19:56,736: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:19:56,736: t15.2023.11.19 val PER: 0.1018
2025-11-02 06:19:56,737: t15.2023.11.26 val PER: 0.2377
2025-11-02 06:19:56,737: t15.2023.12.03 val PER: 0.1859
2025-11-02 06:19:56,784: t15.2023.12.08 val PER: 0.2071
2025-11-02 06:19:56,784: t15.2023.12.10 val PER: 0.1708
2025-11-02 06:19:56,785: t15.2023.12.17 val PER: 0.2370
2025-11-02 06:19:56,785: t15.2023.12.29 val PER: 0.2148
2025-11-02 06:19:56,786: t15.2024.02.25 val PER: 0.1728
2025-11-02 06:19:56,786: t15.2024.03.08 val PER: 0.2973
2025-11-02 06:19:56,787: t15.2024.03.15 val PER: 0.2883
2025-11-02 06:19:56,787: t15.2024.03.17 val PER: 0.2259
2025-11-02 06:19:56,787: t15.2024.05.10 val PER: 0.2214
2025-11-02 06:19:56,788: t15.2024.06.14 val PER: 0.2397
2025-11-02 06:19:56,789: t15.2024.07.19 val PER: 0.3131
2025-11-02 06:19:56,789: t15.2024.07.21 val PER: 0.1586
2025-11-02 06:19:56,789: t15.2024.07.28 val PER: 0.2044
2025-11-02 06:19:56,790: t15.2025.01.10 val PER: 0.3747
2025-11-02 06:19:56,790: t15.2025.01.12 val PER: 0.2417
2025-11-02 06:19:56,790: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:19:56,791: t15.2025.03.16 val PER: 0.2788
2025-11-02 06:19:56,791: t15.2025.03.30 val PER: 0.3494
2025-11-02 06:19:56,791: t15.2025.04.13 val PER: 0.3138
2025-11-02 06:19:56,792: New best test PER 0.2224 --> 0.2213
2025-11-02 06:19:56,792: Checkpointing model
2025-11-02 06:19:58,980: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:20:24,804: Train batch 73200: loss: 16.07 grad norm: 45.51 time: 0.081
2025-11-02 06:20:50,271: Train batch 73400: loss: 12.37 grad norm: 48.15 time: 0.074
2025-11-02 06:21:15,608: Train batch 73600: loss: 8.75 grad norm: 33.72 time: 0.085
2025-11-02 06:21:42,044: Train batch 73800: loss: 14.71 grad norm: 58.70 time: 0.103
2025-11-02 06:22:07,610: Train batch 74000: loss: 9.32 grad norm: 38.28 time: 0.078
2025-11-02 06:22:07,611: Running test after training batch: 74000
2025-11-02 06:22:22,213: Val batch 74000: PER (avg): 0.2209 CTC Loss (avg): 23.1061 time: 14.601
2025-11-02 06:22:22,214: t15.2023.08.13 val PER: 0.1726
2025-11-02 06:22:22,214: t15.2023.08.18 val PER: 0.1752
2025-11-02 06:22:22,215: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:22:22,215: t15.2023.08.25 val PER: 0.1611
2025-11-02 06:22:22,215: t15.2023.08.27 val PER: 0.2524
2025-11-02 06:22:22,216: t15.2023.09.01 val PER: 0.1218
2025-11-02 06:22:22,216: t15.2023.09.03 val PER: 0.2221
2025-11-02 06:22:22,216: t15.2023.09.24 val PER: 0.1748
2025-11-02 06:22:22,217: t15.2023.09.29 val PER: 0.1844
2025-11-02 06:22:22,217: t15.2023.10.01 val PER: 0.2272
2025-11-02 06:22:22,217: t15.2023.10.06 val PER: 0.1572
2025-11-02 06:22:22,218: t15.2023.10.08 val PER: 0.2747
2025-11-02 06:22:22,218: t15.2023.10.13 val PER: 0.2777
2025-11-02 06:22:22,218: t15.2023.10.15 val PER: 0.2037
2025-11-02 06:22:22,219: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:22:22,219: t15.2023.10.22 val PER: 0.1849
2025-11-02 06:22:22,219: t15.2023.11.03 val PER: 0.2313
2025-11-02 06:22:22,219: t15.2023.11.04 val PER: 0.0614
2025-11-02 06:22:22,220: t15.2023.11.17 val PER: 0.0871
2025-11-02 06:22:22,220: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:22:22,220: t15.2023.11.26 val PER: 0.2377
2025-11-02 06:22:22,221: t15.2023.12.03 val PER: 0.1796
2025-11-02 06:22:22,221: t15.2023.12.08 val PER: 0.2064
2025-11-02 06:22:22,222: t15.2023.12.10 val PER: 0.1735
2025-11-02 06:22:22,222: t15.2023.12.17 val PER: 0.2360
2025-11-02 06:22:22,223: t15.2023.12.29 val PER: 0.2128
2025-11-02 06:22:22,223: t15.2024.02.25 val PER: 0.1657
2025-11-02 06:22:22,223: t15.2024.03.08 val PER: 0.2959
2025-11-02 06:22:22,224: t15.2024.03.15 val PER: 0.2914
2025-11-02 06:22:22,224: t15.2024.03.17 val PER: 0.2218
2025-11-02 06:22:22,224: t15.2024.05.10 val PER: 0.2273
2025-11-02 06:22:22,224: t15.2024.06.14 val PER: 0.2366
2025-11-02 06:22:22,225: t15.2024.07.19 val PER: 0.3092
2025-11-02 06:22:22,225: t15.2024.07.21 val PER: 0.1586
2025-11-02 06:22:22,225: t15.2024.07.28 val PER: 0.2007
2025-11-02 06:22:22,225: t15.2025.01.10 val PER: 0.3815
2025-11-02 06:22:22,226: t15.2025.01.12 val PER: 0.2371
2025-11-02 06:22:22,226: t15.2025.03.14 val PER: 0.4068
2025-11-02 06:22:22,227: t15.2025.03.16 val PER: 0.2853
2025-11-02 06:22:22,227: t15.2025.03.30 val PER: 0.3506
2025-11-02 06:22:22,227: t15.2025.04.13 val PER: 0.3053
2025-11-02 06:22:22,228: New best test PER 0.2213 --> 0.2209
2025-11-02 06:22:22,228: Checkpointing model
2025-11-02 06:22:24,429: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:22:49,988: Train batch 74200: loss: 12.04 grad norm: 43.77 time: 0.086
2025-11-02 06:23:14,992: Train batch 74400: loss: 15.75 grad norm: 85.49 time: 0.069
2025-11-02 06:23:40,542: Train batch 74600: loss: 16.14 grad norm: 49.82 time: 0.082
2025-11-02 06:24:05,930: Train batch 74800: loss: 18.63 grad norm: 67.04 time: 0.107
2025-11-02 06:24:31,071: Train batch 75000: loss: 12.97 grad norm: 48.16 time: 0.081
2025-11-02 06:24:31,072: Running test after training batch: 75000
2025-11-02 06:24:44,837: Val batch 75000: PER (avg): 0.2195 CTC Loss (avg): 23.0407 time: 13.764
2025-11-02 06:24:44,838: t15.2023.08.13 val PER: 0.1726
2025-11-02 06:24:44,838: t15.2023.08.18 val PER: 0.1735
2025-11-02 06:24:44,839: t15.2023.08.20 val PER: 0.1739
2025-11-02 06:24:44,839: t15.2023.08.25 val PER: 0.1642
2025-11-02 06:24:44,839: t15.2023.08.27 val PER: 0.2540
2025-11-02 06:24:44,839: t15.2023.09.01 val PER: 0.1185
2025-11-02 06:24:44,840: t15.2023.09.03 val PER: 0.2173
2025-11-02 06:24:44,840: t15.2023.09.24 val PER: 0.1748
2025-11-02 06:24:44,840: t15.2023.09.29 val PER: 0.1793
2025-11-02 06:24:44,840: t15.2023.10.01 val PER: 0.2272
2025-11-02 06:24:44,841: t15.2023.10.06 val PER: 0.1539
2025-11-02 06:24:44,884: t15.2023.10.08 val PER: 0.2747
2025-11-02 06:24:44,884: t15.2023.10.13 val PER: 0.2754
2025-11-02 06:24:44,885: t15.2023.10.15 val PER: 0.2063
2025-11-02 06:24:44,885: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:24:44,885: t15.2023.10.22 val PER: 0.1882
2025-11-02 06:24:44,886: t15.2023.11.03 val PER: 0.2313
2025-11-02 06:24:44,886: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:24:44,887: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:24:44,887: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:24:44,888: t15.2023.11.26 val PER: 0.2312
2025-11-02 06:24:44,888: t15.2023.12.03 val PER: 0.1817
2025-11-02 06:24:44,888: t15.2023.12.08 val PER: 0.2037
2025-11-02 06:24:44,889: t15.2023.12.10 val PER: 0.1682
2025-11-02 06:24:44,889: t15.2023.12.17 val PER: 0.2297
2025-11-02 06:24:44,889: t15.2023.12.29 val PER: 0.2141
2025-11-02 06:24:44,890: t15.2024.02.25 val PER: 0.1685
2025-11-02 06:24:44,890: t15.2024.03.08 val PER: 0.2930
2025-11-02 06:24:44,890: t15.2024.03.15 val PER: 0.2846
2025-11-02 06:24:44,891: t15.2024.03.17 val PER: 0.2204
2025-11-02 06:24:44,891: t15.2024.05.10 val PER: 0.2184
2025-11-02 06:24:44,892: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:24:44,892: t15.2024.07.19 val PER: 0.3164
2025-11-02 06:24:44,893: t15.2024.07.21 val PER: 0.1600
2025-11-02 06:24:44,893: t15.2024.07.28 val PER: 0.2037
2025-11-02 06:24:44,893: t15.2025.01.10 val PER: 0.3747
2025-11-02 06:24:44,894: t15.2025.01.12 val PER: 0.2333
2025-11-02 06:24:44,894: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:24:44,894: t15.2025.03.16 val PER: 0.2788
2025-11-02 06:24:44,895: t15.2025.03.30 val PER: 0.3460
2025-11-02 06:24:44,895: t15.2025.04.13 val PER: 0.3096
2025-11-02 06:24:44,895: New best test PER 0.2209 --> 0.2195
2025-11-02 06:24:44,895: Checkpointing model
2025-11-02 06:24:46,851: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:25:12,149: Train batch 75200: loss: 15.51 grad norm: 56.78 time: 0.085
2025-11-02 06:25:37,060: Train batch 75400: loss: 10.66 grad norm: 41.93 time: 0.062
2025-11-02 06:26:01,988: Train batch 75600: loss: 18.99 grad norm: 91.87 time: 0.077
2025-11-02 06:26:27,057: Train batch 75800: loss: 12.40 grad norm: 50.02 time: 0.064
2025-11-02 06:26:50,836: Train batch 76000: loss: 18.38 grad norm: 58.75 time: 0.080
2025-11-02 06:26:50,837: Running test after training batch: 76000
2025-11-02 06:27:04,718: Val batch 76000: PER (avg): 0.2198 CTC Loss (avg): 22.9991 time: 13.881
2025-11-02 06:27:04,719: t15.2023.08.13 val PER: 0.1653
2025-11-02 06:27:04,720: t15.2023.08.18 val PER: 0.1702
2025-11-02 06:27:04,720: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:27:04,720: t15.2023.08.25 val PER: 0.1611
2025-11-02 06:27:04,721: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:27:04,721: t15.2023.09.01 val PER: 0.1218
2025-11-02 06:27:04,722: t15.2023.09.03 val PER: 0.2268
2025-11-02 06:27:04,722: t15.2023.09.24 val PER: 0.1723
2025-11-02 06:27:04,723: t15.2023.09.29 val PER: 0.1793
2025-11-02 06:27:04,723: t15.2023.10.01 val PER: 0.2299
2025-11-02 06:27:04,723: t15.2023.10.06 val PER: 0.1529
2025-11-02 06:27:04,724: t15.2023.10.08 val PER: 0.2747
2025-11-02 06:27:04,724: t15.2023.10.13 val PER: 0.2731
2025-11-02 06:27:04,724: t15.2023.10.15 val PER: 0.2076
2025-11-02 06:27:04,725: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:27:04,725: t15.2023.10.22 val PER: 0.1860
2025-11-02 06:27:04,725: t15.2023.11.03 val PER: 0.2313
2025-11-02 06:27:04,726: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:27:04,726: t15.2023.11.17 val PER: 0.0855
2025-11-02 06:27:04,727: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:27:04,727: t15.2023.11.26 val PER: 0.2406
2025-11-02 06:27:04,728: t15.2023.12.03 val PER: 0.1733
2025-11-02 06:27:04,728: t15.2023.12.08 val PER: 0.2051
2025-11-02 06:27:04,728: t15.2023.12.10 val PER: 0.1708
2025-11-02 06:27:04,729: t15.2023.12.17 val PER: 0.2287
2025-11-02 06:27:04,729: t15.2023.12.29 val PER: 0.2080
2025-11-02 06:27:04,729: t15.2024.02.25 val PER: 0.1671
2025-11-02 06:27:04,729: t15.2024.03.08 val PER: 0.2959
2025-11-02 06:27:04,730: t15.2024.03.15 val PER: 0.2883
2025-11-02 06:27:04,730: t15.2024.03.17 val PER: 0.2259
2025-11-02 06:27:04,730: t15.2024.05.10 val PER: 0.2288
2025-11-02 06:27:04,731: t15.2024.06.14 val PER: 0.2350
2025-11-02 06:27:04,731: t15.2024.07.19 val PER: 0.3151
2025-11-02 06:27:04,732: t15.2024.07.21 val PER: 0.1593
2025-11-02 06:27:04,732: t15.2024.07.28 val PER: 0.2007
2025-11-02 06:27:04,732: t15.2025.01.10 val PER: 0.3815
2025-11-02 06:27:04,733: t15.2025.01.12 val PER: 0.2333
2025-11-02 06:27:04,733: t15.2025.03.14 val PER: 0.3994
2025-11-02 06:27:04,733: t15.2025.03.16 val PER: 0.2775
2025-11-02 06:27:04,734: t15.2025.03.30 val PER: 0.3483
2025-11-02 06:27:04,734: t15.2025.04.13 val PER: 0.3081
2025-11-02 06:27:29,362: Train batch 76200: loss: 7.79 grad norm: 34.45 time: 0.055
2025-11-02 06:27:53,256: Train batch 76400: loss: 11.10 grad norm: 38.13 time: 0.066
2025-11-02 06:28:17,191: Train batch 76600: loss: 15.86 grad norm: 55.56 time: 0.073
2025-11-02 06:28:41,012: Train batch 76800: loss: 9.72 grad norm: 40.24 time: 0.063
2025-11-02 06:29:04,382: Train batch 77000: loss: 12.12 grad norm: 44.07 time: 0.085
2025-11-02 06:29:04,383: Running test after training batch: 77000
2025-11-02 06:29:18,322: Val batch 77000: PER (avg): 0.2198 CTC Loss (avg): 22.9716 time: 13.938
2025-11-02 06:29:18,323: t15.2023.08.13 val PER: 0.1674
2025-11-02 06:29:18,324: t15.2023.08.18 val PER: 0.1685
2025-11-02 06:29:18,324: t15.2023.08.20 val PER: 0.1779
2025-11-02 06:29:18,324: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:29:18,325: t15.2023.08.27 val PER: 0.2492
2025-11-02 06:29:18,325: t15.2023.09.01 val PER: 0.1193
2025-11-02 06:29:18,326: t15.2023.09.03 val PER: 0.2162
2025-11-02 06:29:18,326: t15.2023.09.24 val PER: 0.1699
2025-11-02 06:29:18,327: t15.2023.09.29 val PER: 0.1793
2025-11-02 06:29:18,327: t15.2023.10.01 val PER: 0.2266
2025-11-02 06:29:18,328: t15.2023.10.06 val PER: 0.1572
2025-11-02 06:29:18,328: t15.2023.10.08 val PER: 0.2693
2025-11-02 06:29:18,328: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:29:18,328: t15.2023.10.15 val PER: 0.2063
2025-11-02 06:29:18,329: t15.2023.10.20 val PER: 0.2148
2025-11-02 06:29:18,329: t15.2023.10.22 val PER: 0.1826
2025-11-02 06:29:18,329: t15.2023.11.03 val PER: 0.2286
2025-11-02 06:29:18,330: t15.2023.11.04 val PER: 0.0648
2025-11-02 06:29:18,330: t15.2023.11.17 val PER: 0.0933
2025-11-02 06:29:18,330: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:29:18,331: t15.2023.11.26 val PER: 0.2370
2025-11-02 06:29:18,331: t15.2023.12.03 val PER: 0.1817
2025-11-02 06:29:18,331: t15.2023.12.08 val PER: 0.2051
2025-11-02 06:29:18,332: t15.2023.12.10 val PER: 0.1708
2025-11-02 06:29:18,332: t15.2023.12.17 val PER: 0.2277
2025-11-02 06:29:18,333: t15.2023.12.29 val PER: 0.2141
2025-11-02 06:29:18,333: t15.2024.02.25 val PER: 0.1713
2025-11-02 06:29:18,333: t15.2024.03.08 val PER: 0.2930
2025-11-02 06:29:18,333: t15.2024.03.15 val PER: 0.2871
2025-11-02 06:29:18,334: t15.2024.03.17 val PER: 0.2280
2025-11-02 06:29:18,334: t15.2024.05.10 val PER: 0.2169
2025-11-02 06:29:18,334: t15.2024.06.14 val PER: 0.2350
2025-11-02 06:29:18,340: t15.2024.07.19 val PER: 0.3151
2025-11-02 06:29:18,341: t15.2024.07.21 val PER: 0.1607
2025-11-02 06:29:18,341: t15.2024.07.28 val PER: 0.2074
2025-11-02 06:29:18,342: t15.2025.01.10 val PER: 0.3733
2025-11-02 06:29:18,342: t15.2025.01.12 val PER: 0.2317
2025-11-02 06:29:18,342: t15.2025.03.14 val PER: 0.4068
2025-11-02 06:29:18,343: t15.2025.03.16 val PER: 0.2749
2025-11-02 06:29:18,343: t15.2025.03.30 val PER: 0.3540
2025-11-02 06:29:18,343: t15.2025.04.13 val PER: 0.3067
2025-11-02 06:29:42,301: Train batch 77200: loss: 15.11 grad norm: 60.00 time: 0.104
2025-11-02 06:30:06,145: Train batch 77400: loss: 13.79 grad norm: 45.65 time: 0.087
2025-11-02 06:30:29,710: Train batch 77600: loss: 13.91 grad norm: 58.09 time: 0.071
2025-11-02 06:30:53,371: Train batch 77800: loss: 14.47 grad norm: 47.37 time: 0.074
2025-11-02 06:31:17,093: Train batch 78000: loss: 12.93 grad norm: 49.84 time: 0.072
2025-11-02 06:31:17,094: Running test after training batch: 78000
2025-11-02 06:31:30,919: Val batch 78000: PER (avg): 0.2191 CTC Loss (avg): 22.9194 time: 13.825
2025-11-02 06:31:30,920: t15.2023.08.13 val PER: 0.1632
2025-11-02 06:31:30,920: t15.2023.08.18 val PER: 0.1702
2025-11-02 06:31:30,921: t15.2023.08.20 val PER: 0.1755
2025-11-02 06:31:30,921: t15.2023.08.25 val PER: 0.1642
2025-11-02 06:31:30,921: t15.2023.08.27 val PER: 0.2492
2025-11-02 06:31:30,922: t15.2023.09.01 val PER: 0.1209
2025-11-02 06:31:30,922: t15.2023.09.03 val PER: 0.2162
2025-11-02 06:31:30,923: t15.2023.09.24 val PER: 0.1699
2025-11-02 06:31:30,923: t15.2023.09.29 val PER: 0.1806
2025-11-02 06:31:30,923: t15.2023.10.01 val PER: 0.2305
2025-11-02 06:31:30,924: t15.2023.10.06 val PER: 0.1561
2025-11-02 06:31:30,924: t15.2023.10.08 val PER: 0.2720
2025-11-02 06:31:30,924: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:31:30,924: t15.2023.10.15 val PER: 0.2057
2025-11-02 06:31:30,925: t15.2023.10.20 val PER: 0.2081
2025-11-02 06:31:30,925: t15.2023.10.22 val PER: 0.1804
2025-11-02 06:31:30,925: t15.2023.11.03 val PER: 0.2300
2025-11-02 06:31:30,926: t15.2023.11.04 val PER: 0.0683
2025-11-02 06:31:30,926: t15.2023.11.17 val PER: 0.0871
2025-11-02 06:31:30,926: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:31:30,927: t15.2023.11.26 val PER: 0.2420
2025-11-02 06:31:30,927: t15.2023.12.03 val PER: 0.1838
2025-11-02 06:31:30,928: t15.2023.12.08 val PER: 0.2097
2025-11-02 06:31:30,928: t15.2023.12.10 val PER: 0.1682
2025-11-02 06:31:30,928: t15.2023.12.17 val PER: 0.2235
2025-11-02 06:31:30,929: t15.2023.12.29 val PER: 0.2093
2025-11-02 06:31:30,929: t15.2024.02.25 val PER: 0.1699
2025-11-02 06:31:30,929: t15.2024.03.08 val PER: 0.2945
2025-11-02 06:31:30,930: t15.2024.03.15 val PER: 0.2821
2025-11-02 06:31:30,930: t15.2024.03.17 val PER: 0.2225
2025-11-02 06:31:30,930: t15.2024.05.10 val PER: 0.2169
2025-11-02 06:31:30,931: t15.2024.06.14 val PER: 0.2350
2025-11-02 06:31:30,931: t15.2024.07.19 val PER: 0.3131
2025-11-02 06:31:30,931: t15.2024.07.21 val PER: 0.1586
2025-11-02 06:31:30,937: t15.2024.07.28 val PER: 0.2074
2025-11-02 06:31:30,938: t15.2025.01.10 val PER: 0.3733
2025-11-02 06:31:30,938: t15.2025.01.12 val PER: 0.2286
2025-11-02 06:31:30,938: t15.2025.03.14 val PER: 0.3979
2025-11-02 06:31:30,939: t15.2025.03.16 val PER: 0.2762
2025-11-02 06:31:30,939: t15.2025.03.30 val PER: 0.3552
2025-11-02 06:31:30,939: t15.2025.04.13 val PER: 0.3039
2025-11-02 06:31:30,940: New best test PER 0.2195 --> 0.2191
2025-11-02 06:31:30,983: Checkpointing model
2025-11-02 06:31:33,020: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:31:57,391: Train batch 78200: loss: 12.33 grad norm: 57.22 time: 0.093
2025-11-02 06:32:21,741: Train batch 78400: loss: 8.76 grad norm: 38.08 time: 0.071
2025-11-02 06:32:45,413: Train batch 78600: loss: 9.17 grad norm: 37.28 time: 0.106
2025-11-02 06:33:08,969: Train batch 78800: loss: 12.19 grad norm: 44.90 time: 0.074
2025-11-02 06:33:33,139: Train batch 79000: loss: 13.25 grad norm: 48.41 time: 0.095
2025-11-02 06:33:33,140: Running test after training batch: 79000
2025-11-02 06:33:47,230: Val batch 79000: PER (avg): 0.2187 CTC Loss (avg): 22.9205 time: 14.089
2025-11-02 06:33:47,231: t15.2023.08.13 val PER: 0.1705
2025-11-02 06:33:47,231: t15.2023.08.18 val PER: 0.1668
2025-11-02 06:33:47,232: t15.2023.08.20 val PER: 0.1779
2025-11-02 06:33:47,233: t15.2023.08.25 val PER: 0.1627
2025-11-02 06:33:47,233: t15.2023.08.27 val PER: 0.2428
2025-11-02 06:33:47,234: t15.2023.09.01 val PER: 0.1169
2025-11-02 06:33:47,234: t15.2023.09.03 val PER: 0.2162
2025-11-02 06:33:47,235: t15.2023.09.24 val PER: 0.1760
2025-11-02 06:33:47,235: t15.2023.09.29 val PER: 0.1819
2025-11-02 06:33:47,235: t15.2023.10.01 val PER: 0.2285
2025-11-02 06:33:47,235: t15.2023.10.06 val PER: 0.1572
2025-11-02 06:33:47,236: t15.2023.10.08 val PER: 0.2693
2025-11-02 06:33:47,236: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:33:47,237: t15.2023.10.15 val PER: 0.2063
2025-11-02 06:33:47,237: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:33:47,238: t15.2023.10.22 val PER: 0.1849
2025-11-02 06:33:47,238: t15.2023.11.03 val PER: 0.2334
2025-11-02 06:33:47,238: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:33:47,238: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:33:47,239: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:33:47,239: t15.2023.11.26 val PER: 0.2377
2025-11-02 06:33:47,239: t15.2023.12.03 val PER: 0.1754
2025-11-02 06:33:47,240: t15.2023.12.08 val PER: 0.2044
2025-11-02 06:33:47,240: t15.2023.12.10 val PER: 0.1708
2025-11-02 06:33:47,240: t15.2023.12.17 val PER: 0.2308
2025-11-02 06:33:47,241: t15.2023.12.29 val PER: 0.2045
2025-11-02 06:33:47,241: t15.2024.02.25 val PER: 0.1615
2025-11-02 06:33:47,241: t15.2024.03.08 val PER: 0.2916
2025-11-02 06:33:47,242: t15.2024.03.15 val PER: 0.2883
2025-11-02 06:33:47,242: t15.2024.03.17 val PER: 0.2238
2025-11-02 06:33:47,243: t15.2024.05.10 val PER: 0.2199
2025-11-02 06:33:47,243: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:33:47,243: t15.2024.07.19 val PER: 0.3105
2025-11-02 06:33:47,243: t15.2024.07.21 val PER: 0.1607
2025-11-02 06:33:47,244: t15.2024.07.28 val PER: 0.2029
2025-11-02 06:33:47,244: t15.2025.01.10 val PER: 0.3650
2025-11-02 06:33:47,244: t15.2025.01.12 val PER: 0.2317
2025-11-02 06:33:47,245: t15.2025.03.14 val PER: 0.3979
2025-11-02 06:33:47,245: t15.2025.03.16 val PER: 0.2801
2025-11-02 06:33:47,245: t15.2025.03.30 val PER: 0.3529
2025-11-02 06:33:47,245: t15.2025.04.13 val PER: 0.3010
2025-11-02 06:33:47,246: New best test PER 0.2191 --> 0.2187
2025-11-02 06:33:47,246: Checkpointing model
2025-11-02 06:33:49,150: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:34:13,885: Train batch 79200: loss: 12.46 grad norm: 45.21 time: 0.058
2025-11-02 06:34:37,790: Train batch 79400: loss: 10.20 grad norm: 45.43 time: 0.079
2025-11-02 06:35:02,262: Train batch 79600: loss: 15.98 grad norm: 52.21 time: 0.088
2025-11-02 06:35:25,974: Train batch 79800: loss: 12.23 grad norm: 56.96 time: 0.091
2025-11-02 06:35:49,232: Train batch 80000: loss: 13.41 grad norm: 48.28 time: 0.067
2025-11-02 06:35:49,233: Running test after training batch: 80000
2025-11-02 06:36:02,917: Val batch 80000: PER (avg): 0.2182 CTC Loss (avg): 22.9025 time: 13.684
2025-11-02 06:36:02,917: t15.2023.08.13 val PER: 0.1684
2025-11-02 06:36:02,918: t15.2023.08.18 val PER: 0.1643
2025-11-02 06:36:02,918: t15.2023.08.20 val PER: 0.1787
2025-11-02 06:36:02,918: t15.2023.08.25 val PER: 0.1642
2025-11-02 06:36:02,919: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:36:02,919: t15.2023.09.01 val PER: 0.1185
2025-11-02 06:36:02,919: t15.2023.09.03 val PER: 0.2150
2025-11-02 06:36:02,920: t15.2023.09.24 val PER: 0.1711
2025-11-02 06:36:02,920: t15.2023.09.29 val PER: 0.1787
2025-11-02 06:36:02,920: t15.2023.10.01 val PER: 0.2226
2025-11-02 06:36:02,921: t15.2023.10.06 val PER: 0.1518
2025-11-02 06:36:02,921: t15.2023.10.08 val PER: 0.2693
2025-11-02 06:36:02,921: t15.2023.10.13 val PER: 0.2731
2025-11-02 06:36:02,922: t15.2023.10.15 val PER: 0.2024
2025-11-02 06:36:02,922: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:36:02,923: t15.2023.10.22 val PER: 0.1804
2025-11-02 06:36:02,923: t15.2023.11.03 val PER: 0.2300
2025-11-02 06:36:02,923: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:36:02,924: t15.2023.11.17 val PER: 0.0918
2025-11-02 06:36:02,924: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:36:02,924: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:36:02,925: t15.2023.12.03 val PER: 0.1754
2025-11-02 06:36:02,925: t15.2023.12.08 val PER: 0.2071
2025-11-02 06:36:02,925: t15.2023.12.10 val PER: 0.1656
2025-11-02 06:36:02,926: t15.2023.12.17 val PER: 0.2318
2025-11-02 06:36:02,926: t15.2023.12.29 val PER: 0.2121
2025-11-02 06:36:02,927: t15.2024.02.25 val PER: 0.1685
2025-11-02 06:36:02,927: t15.2024.03.08 val PER: 0.2916
2025-11-02 06:36:02,928: t15.2024.03.15 val PER: 0.2858
2025-11-02 06:36:02,928: t15.2024.03.17 val PER: 0.2238
2025-11-02 06:36:02,928: t15.2024.05.10 val PER: 0.2140
2025-11-02 06:36:02,928: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:36:02,929: t15.2024.07.19 val PER: 0.3118
2025-11-02 06:36:02,929: t15.2024.07.21 val PER: 0.1572
2025-11-02 06:36:02,935: t15.2024.07.28 val PER: 0.2037
2025-11-02 06:36:02,935: t15.2025.01.10 val PER: 0.3664
2025-11-02 06:36:02,936: t15.2025.01.12 val PER: 0.2325
2025-11-02 06:36:02,936: t15.2025.03.14 val PER: 0.3979
2025-11-02 06:36:02,937: t15.2025.03.16 val PER: 0.2814
2025-11-02 06:36:02,937: t15.2025.03.30 val PER: 0.3575
2025-11-02 06:36:02,937: t15.2025.04.13 val PER: 0.3024
2025-11-02 06:36:02,938: New best test PER 0.2187 --> 0.2182
2025-11-02 06:36:02,938: Checkpointing model
2025-11-02 06:36:04,935: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:36:29,419: Train batch 80200: loss: 16.24 grad norm: 56.61 time: 0.074
2025-11-02 06:36:53,320: Train batch 80400: loss: 12.05 grad norm: 42.89 time: 0.076
2025-11-02 06:37:16,691: Train batch 80600: loss: 13.60 grad norm: 55.10 time: 0.095
2025-11-02 06:37:40,496: Train batch 80800: loss: 14.46 grad norm: 74.97 time: 0.074
2025-11-02 06:38:04,521: Train batch 81000: loss: 13.21 grad norm: 58.42 time: 0.087
2025-11-02 06:38:04,522: Running test after training batch: 81000
2025-11-02 06:38:18,421: Val batch 81000: PER (avg): 0.2177 CTC Loss (avg): 22.8396 time: 13.899
2025-11-02 06:38:18,422: t15.2023.08.13 val PER: 0.1674
2025-11-02 06:38:18,423: t15.2023.08.18 val PER: 0.1643
2025-11-02 06:38:18,423: t15.2023.08.20 val PER: 0.1724
2025-11-02 06:38:18,423: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:38:18,424: t15.2023.08.27 val PER: 0.2444
2025-11-02 06:38:18,424: t15.2023.09.01 val PER: 0.1193
2025-11-02 06:38:18,424: t15.2023.09.03 val PER: 0.2197
2025-11-02 06:38:18,425: t15.2023.09.24 val PER: 0.1735
2025-11-02 06:38:18,425: t15.2023.09.29 val PER: 0.1800
2025-11-02 06:38:18,425: t15.2023.10.01 val PER: 0.2232
2025-11-02 06:38:18,426: t15.2023.10.06 val PER: 0.1550
2025-11-02 06:38:18,426: t15.2023.10.08 val PER: 0.2693
2025-11-02 06:38:18,427: t15.2023.10.13 val PER: 0.2692
2025-11-02 06:38:18,427: t15.2023.10.15 val PER: 0.2044
2025-11-02 06:38:18,428: t15.2023.10.20 val PER: 0.2081
2025-11-02 06:38:18,428: t15.2023.10.22 val PER: 0.1826
2025-11-02 06:38:18,428: t15.2023.11.03 val PER: 0.2286
2025-11-02 06:38:18,429: t15.2023.11.04 val PER: 0.0614
2025-11-02 06:38:18,430: t15.2023.11.17 val PER: 0.0918
2025-11-02 06:38:18,431: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:38:18,431: t15.2023.11.26 val PER: 0.2333
2025-11-02 06:38:18,432: t15.2023.12.03 val PER: 0.1733
2025-11-02 06:38:18,432: t15.2023.12.08 val PER: 0.2051
2025-11-02 06:38:18,432: t15.2023.12.10 val PER: 0.1735
2025-11-02 06:38:18,433: t15.2023.12.17 val PER: 0.2287
2025-11-02 06:38:18,433: t15.2023.12.29 val PER: 0.2114
2025-11-02 06:38:18,433: t15.2024.02.25 val PER: 0.1629
2025-11-02 06:38:18,434: t15.2024.03.08 val PER: 0.2930
2025-11-02 06:38:18,434: t15.2024.03.15 val PER: 0.2833
2025-11-02 06:38:18,434: t15.2024.03.17 val PER: 0.2211
2025-11-02 06:38:18,435: t15.2024.05.10 val PER: 0.2140
2025-11-02 06:38:18,435: t15.2024.06.14 val PER: 0.2397
2025-11-02 06:38:18,435: t15.2024.07.19 val PER: 0.3085
2025-11-02 06:38:18,435: t15.2024.07.21 val PER: 0.1545
2025-11-02 06:38:18,436: t15.2024.07.28 val PER: 0.2000
2025-11-02 06:38:18,436: t15.2025.01.10 val PER: 0.3760
2025-11-02 06:38:18,436: t15.2025.01.12 val PER: 0.2302
2025-11-02 06:38:18,437: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:38:18,437: t15.2025.03.16 val PER: 0.2853
2025-11-02 06:38:18,437: t15.2025.03.30 val PER: 0.3540
2025-11-02 06:38:18,437: t15.2025.04.13 val PER: 0.3081
2025-11-02 06:38:18,438: New best test PER 0.2182 --> 0.2177
2025-11-02 06:38:18,438: Checkpointing model
2025-11-02 06:38:20,409: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:38:44,427: Train batch 81200: loss: 12.25 grad norm: 43.11 time: 0.100
2025-11-02 06:39:08,309: Train batch 81400: loss: 9.50 grad norm: 42.15 time: 0.090
2025-11-02 06:39:32,432: Train batch 81600: loss: 13.04 grad norm: 48.98 time: 0.091
2025-11-02 06:39:55,958: Train batch 81800: loss: 13.37 grad norm: 45.70 time: 0.079
2025-11-02 06:40:19,483: Train batch 82000: loss: 12.41 grad norm: 48.43 time: 0.098
2025-11-02 06:40:19,484: Running test after training batch: 82000
2025-11-02 06:40:33,120: Val batch 82000: PER (avg): 0.2178 CTC Loss (avg): 22.8333 time: 13.635
2025-11-02 06:40:33,120: t15.2023.08.13 val PER: 0.1674
2025-11-02 06:40:33,121: t15.2023.08.18 val PER: 0.1651
2025-11-02 06:40:33,122: t15.2023.08.20 val PER: 0.1755
2025-11-02 06:40:33,122: t15.2023.08.25 val PER: 0.1611
2025-11-02 06:40:33,123: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:40:33,123: t15.2023.09.01 val PER: 0.1169
2025-11-02 06:40:33,123: t15.2023.09.03 val PER: 0.2150
2025-11-02 06:40:33,124: t15.2023.09.24 val PER: 0.1687
2025-11-02 06:40:33,124: t15.2023.09.29 val PER: 0.1800
2025-11-02 06:40:33,124: t15.2023.10.01 val PER: 0.2266
2025-11-02 06:40:33,126: t15.2023.10.06 val PER: 0.1550
2025-11-02 06:40:33,127: t15.2023.10.08 val PER: 0.2720
2025-11-02 06:40:33,127: t15.2023.10.13 val PER: 0.2723
2025-11-02 06:40:33,127: t15.2023.10.15 val PER: 0.2057
2025-11-02 06:40:33,127: t15.2023.10.20 val PER: 0.2114
2025-11-02 06:40:33,128: t15.2023.10.22 val PER: 0.1726
2025-11-02 06:40:33,128: t15.2023.11.03 val PER: 0.2307
2025-11-02 06:40:33,128: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:40:33,129: t15.2023.11.17 val PER: 0.0933
2025-11-02 06:40:33,129: t15.2023.11.19 val PER: 0.0918
2025-11-02 06:40:33,129: t15.2023.11.26 val PER: 0.2384
2025-11-02 06:40:33,129: t15.2023.12.03 val PER: 0.1765
2025-11-02 06:40:33,130: t15.2023.12.08 val PER: 0.2044
2025-11-02 06:40:33,130: t15.2023.12.10 val PER: 0.1669
2025-11-02 06:40:33,130: t15.2023.12.17 val PER: 0.2297
2025-11-02 06:40:33,131: t15.2023.12.29 val PER: 0.2100
2025-11-02 06:40:33,131: t15.2024.02.25 val PER: 0.1615
2025-11-02 06:40:33,131: t15.2024.03.08 val PER: 0.2945
2025-11-02 06:40:33,132: t15.2024.03.15 val PER: 0.2827
2025-11-02 06:40:33,132: t15.2024.03.17 val PER: 0.2238
2025-11-02 06:40:33,132: t15.2024.05.10 val PER: 0.2184
2025-11-02 06:40:33,132: t15.2024.06.14 val PER: 0.2397
2025-11-02 06:40:33,133: t15.2024.07.19 val PER: 0.3045
2025-11-02 06:40:33,133: t15.2024.07.21 val PER: 0.1607
2025-11-02 06:40:33,133: t15.2024.07.28 val PER: 0.2029
2025-11-02 06:40:33,133: t15.2025.01.10 val PER: 0.3719
2025-11-02 06:40:33,134: t15.2025.01.12 val PER: 0.2302
2025-11-02 06:40:33,134: t15.2025.03.14 val PER: 0.4009
2025-11-02 06:40:33,134: t15.2025.03.16 val PER: 0.2788
2025-11-02 06:40:33,134: t15.2025.03.30 val PER: 0.3506
2025-11-02 06:40:33,135: t15.2025.04.13 val PER: 0.3053
2025-11-02 06:40:56,969: Train batch 82200: loss: 13.86 grad norm: 47.52 time: 0.093
2025-11-02 06:41:21,217: Train batch 82400: loss: 13.09 grad norm: 59.26 time: 0.073
2025-11-02 06:41:45,137: Train batch 82600: loss: 12.45 grad norm: 55.49 time: 0.075
2025-11-02 06:42:08,801: Train batch 82800: loss: 16.41 grad norm: 64.61 time: 0.071
2025-11-02 06:42:32,215: Train batch 83000: loss: 11.90 grad norm: 46.84 time: 0.113
2025-11-02 06:42:32,216: Running test after training batch: 83000
2025-11-02 06:42:46,218: Val batch 83000: PER (avg): 0.2178 CTC Loss (avg): 22.8295 time: 14.002
2025-11-02 06:42:46,219: t15.2023.08.13 val PER: 0.1611
2025-11-02 06:42:46,220: t15.2023.08.18 val PER: 0.1718
2025-11-02 06:42:46,220: t15.2023.08.20 val PER: 0.1739
2025-11-02 06:42:46,221: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:42:46,221: t15.2023.08.27 val PER: 0.2492
2025-11-02 06:42:46,222: t15.2023.09.01 val PER: 0.1185
2025-11-02 06:42:46,222: t15.2023.09.03 val PER: 0.2138
2025-11-02 06:42:46,223: t15.2023.09.24 val PER: 0.1723
2025-11-02 06:42:46,223: t15.2023.09.29 val PER: 0.1800
2025-11-02 06:42:46,223: t15.2023.10.01 val PER: 0.2246
2025-11-02 06:42:46,224: t15.2023.10.06 val PER: 0.1529
2025-11-02 06:42:46,224: t15.2023.10.08 val PER: 0.2774
2025-11-02 06:42:46,224: t15.2023.10.13 val PER: 0.2731
2025-11-02 06:42:46,225: t15.2023.10.15 val PER: 0.2050
2025-11-02 06:42:46,225: t15.2023.10.20 val PER: 0.2081
2025-11-02 06:42:46,225: t15.2023.10.22 val PER: 0.1815
2025-11-02 06:42:46,226: t15.2023.11.03 val PER: 0.2300
2025-11-02 06:42:46,226: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:42:46,227: t15.2023.11.17 val PER: 0.0918
2025-11-02 06:42:46,227: t15.2023.11.19 val PER: 0.0978
2025-11-02 06:42:46,227: t15.2023.11.26 val PER: 0.2370
2025-11-02 06:42:46,227: t15.2023.12.03 val PER: 0.1744
2025-11-02 06:42:46,228: t15.2023.12.08 val PER: 0.2017
2025-11-02 06:42:46,228: t15.2023.12.10 val PER: 0.1656
2025-11-02 06:42:46,228: t15.2023.12.17 val PER: 0.2287
2025-11-02 06:42:46,229: t15.2023.12.29 val PER: 0.2114
2025-11-02 06:42:46,229: t15.2024.02.25 val PER: 0.1601
2025-11-02 06:42:46,229: t15.2024.03.08 val PER: 0.2930
2025-11-02 06:42:46,229: t15.2024.03.15 val PER: 0.2846
2025-11-02 06:42:46,230: t15.2024.03.17 val PER: 0.2238
2025-11-02 06:42:46,230: t15.2024.05.10 val PER: 0.2080
2025-11-02 06:42:46,230: t15.2024.06.14 val PER: 0.2429
2025-11-02 06:42:46,230: t15.2024.07.19 val PER: 0.3085
2025-11-02 06:42:46,231: t15.2024.07.21 val PER: 0.1552
2025-11-02 06:42:46,231: t15.2024.07.28 val PER: 0.2022
2025-11-02 06:42:46,232: t15.2025.01.10 val PER: 0.3719
2025-11-02 06:42:46,232: t15.2025.01.12 val PER: 0.2279
2025-11-02 06:42:46,232: t15.2025.03.14 val PER: 0.3964
2025-11-02 06:42:46,232: t15.2025.03.16 val PER: 0.2866
2025-11-02 06:42:46,233: t15.2025.03.30 val PER: 0.3529
2025-11-02 06:42:46,233: t15.2025.04.13 val PER: 0.3067
2025-11-02 06:43:09,707: Train batch 83200: loss: 14.15 grad norm: 56.50 time: 0.100
2025-11-02 06:43:33,544: Train batch 83400: loss: 15.24 grad norm: 58.57 time: 0.078
2025-11-02 06:43:57,609: Train batch 83600: loss: 16.28 grad norm: 54.12 time: 0.079
2025-11-02 06:44:21,192: Train batch 83800: loss: 9.58 grad norm: 38.24 time: 0.080
2025-11-02 06:44:45,314: Train batch 84000: loss: 11.30 grad norm: 43.50 time: 0.080
2025-11-02 06:44:45,315: Running test after training batch: 84000
2025-11-02 06:44:59,522: Val batch 84000: PER (avg): 0.2168 CTC Loss (avg): 22.7735 time: 14.207
2025-11-02 06:44:59,523: t15.2023.08.13 val PER: 0.1674
2025-11-02 06:44:59,523: t15.2023.08.18 val PER: 0.1643
2025-11-02 06:44:59,524: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:44:59,524: t15.2023.08.25 val PER: 0.1687
2025-11-02 06:44:59,524: t15.2023.08.27 val PER: 0.2524
2025-11-02 06:44:59,525: t15.2023.09.01 val PER: 0.1169
2025-11-02 06:44:59,525: t15.2023.09.03 val PER: 0.2114
2025-11-02 06:44:59,525: t15.2023.09.24 val PER: 0.1723
2025-11-02 06:44:59,525: t15.2023.09.29 val PER: 0.1812
2025-11-02 06:44:59,526: t15.2023.10.01 val PER: 0.2226
2025-11-02 06:44:59,526: t15.2023.10.06 val PER: 0.1518
2025-11-02 06:44:59,527: t15.2023.10.08 val PER: 0.2679
2025-11-02 06:44:59,527: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:44:59,528: t15.2023.10.15 val PER: 0.2063
2025-11-02 06:44:59,528: t15.2023.10.20 val PER: 0.1980
2025-11-02 06:44:59,528: t15.2023.10.22 val PER: 0.1793
2025-11-02 06:44:59,529: t15.2023.11.03 val PER: 0.2293
2025-11-02 06:44:59,529: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:44:59,529: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:44:59,529: t15.2023.11.19 val PER: 0.0918
2025-11-02 06:44:59,530: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:44:59,530: t15.2023.12.03 val PER: 0.1723
2025-11-02 06:44:59,530: t15.2023.12.08 val PER: 0.1971
2025-11-02 06:44:59,531: t15.2023.12.10 val PER: 0.1669
2025-11-02 06:44:59,531: t15.2023.12.17 val PER: 0.2245
2025-11-02 06:44:59,532: t15.2023.12.29 val PER: 0.2086
2025-11-02 06:44:59,532: t15.2024.02.25 val PER: 0.1629
2025-11-02 06:44:59,532: t15.2024.03.08 val PER: 0.2930
2025-11-02 06:44:59,532: t15.2024.03.15 val PER: 0.2852
2025-11-02 06:44:59,533: t15.2024.03.17 val PER: 0.2218
2025-11-02 06:44:59,533: t15.2024.05.10 val PER: 0.2169
2025-11-02 06:44:59,533: t15.2024.06.14 val PER: 0.2397
2025-11-02 06:44:59,534: t15.2024.07.19 val PER: 0.3072
2025-11-02 06:44:59,534: t15.2024.07.21 val PER: 0.1566
2025-11-02 06:44:59,535: t15.2024.07.28 val PER: 0.2037
2025-11-02 06:44:59,535: t15.2025.01.10 val PER: 0.3747
2025-11-02 06:44:59,535: t15.2025.01.12 val PER: 0.2263
2025-11-02 06:44:59,536: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:44:59,536: t15.2025.03.16 val PER: 0.2749
2025-11-02 06:44:59,537: t15.2025.03.30 val PER: 0.3506
2025-11-02 06:44:59,537: t15.2025.04.13 val PER: 0.3039
2025-11-02 06:44:59,537: New best test PER 0.2177 --> 0.2168
2025-11-02 06:44:59,538: Checkpointing model
2025-11-02 06:45:01,439: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:45:26,125: Train batch 84200: loss: 12.78 grad norm: 47.54 time: 0.093
2025-11-02 06:45:50,387: Train batch 84400: loss: 11.43 grad norm: 61.78 time: 0.085
2025-11-02 06:46:13,742: Train batch 84600: loss: 11.83 grad norm: 45.90 time: 0.087
2025-11-02 06:46:37,408: Train batch 84800: loss: 13.06 grad norm: 53.88 time: 0.075
2025-11-02 06:47:00,215: Train batch 85000: loss: 16.14 grad norm: 67.82 time: 0.085
2025-11-02 06:47:00,215: Running test after training batch: 85000
2025-11-02 06:47:13,020: Val batch 85000: PER (avg): 0.2165 CTC Loss (avg): 22.7339 time: 12.804
2025-11-02 06:47:13,020: t15.2023.08.13 val PER: 0.1632
2025-11-02 06:47:13,021: t15.2023.08.18 val PER: 0.1702
2025-11-02 06:47:13,021: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:47:13,021: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:47:13,022: t15.2023.08.27 val PER: 0.2460
2025-11-02 06:47:13,022: t15.2023.09.01 val PER: 0.1193
2025-11-02 06:47:13,022: t15.2023.09.03 val PER: 0.2173
2025-11-02 06:47:13,023: t15.2023.09.24 val PER: 0.1760
2025-11-02 06:47:13,023: t15.2023.09.29 val PER: 0.1787
2025-11-02 06:47:13,023: t15.2023.10.01 val PER: 0.2279
2025-11-02 06:47:13,023: t15.2023.10.06 val PER: 0.1518
2025-11-02 06:47:13,024: t15.2023.10.08 val PER: 0.2706
2025-11-02 06:47:13,024: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:47:13,024: t15.2023.10.15 val PER: 0.2083
2025-11-02 06:47:13,024: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:47:13,024: t15.2023.10.22 val PER: 0.1793
2025-11-02 06:47:13,025: t15.2023.11.03 val PER: 0.2280
2025-11-02 06:47:13,025: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:47:13,025: t15.2023.11.17 val PER: 0.0902
2025-11-02 06:47:13,025: t15.2023.11.19 val PER: 0.0958
2025-11-02 06:47:13,026: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:47:13,026: t15.2023.12.03 val PER: 0.1691
2025-11-02 06:47:13,026: t15.2023.12.08 val PER: 0.1991
2025-11-02 06:47:13,026: t15.2023.12.10 val PER: 0.1669
2025-11-02 06:47:13,027: t15.2023.12.17 val PER: 0.2277
2025-11-02 06:47:13,027: t15.2023.12.29 val PER: 0.2038
2025-11-02 06:47:13,027: t15.2024.02.25 val PER: 0.1601
2025-11-02 06:47:13,027: t15.2024.03.08 val PER: 0.2888
2025-11-02 06:47:13,027: t15.2024.03.15 val PER: 0.2821
2025-11-02 06:47:13,028: t15.2024.03.17 val PER: 0.2232
2025-11-02 06:47:13,028: t15.2024.05.10 val PER: 0.2140
2025-11-02 06:47:13,028: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:47:13,028: t15.2024.07.19 val PER: 0.3026
2025-11-02 06:47:13,029: t15.2024.07.21 val PER: 0.1559
2025-11-02 06:47:13,029: t15.2024.07.28 val PER: 0.2015
2025-11-02 06:47:13,029: t15.2025.01.10 val PER: 0.3705
2025-11-02 06:47:13,029: t15.2025.01.12 val PER: 0.2279
2025-11-02 06:47:13,029: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:47:13,030: t15.2025.03.16 val PER: 0.2762
2025-11-02 06:47:13,030: t15.2025.03.30 val PER: 0.3494
2025-11-02 06:47:13,030: t15.2025.04.13 val PER: 0.2967
2025-11-02 06:47:13,030: New best test PER 0.2168 --> 0.2165
2025-11-02 06:47:13,030: Checkpointing model
2025-11-02 06:47:15,184: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:47:39,484: Train batch 85200: loss: 9.92 grad norm: 43.73 time: 0.067
2025-11-02 06:48:03,536: Train batch 85400: loss: 13.83 grad norm: 54.08 time: 0.087
2025-11-02 06:48:27,237: Train batch 85600: loss: 14.07 grad norm: 56.95 time: 0.086
2025-11-02 06:48:50,920: Train batch 85800: loss: 14.68 grad norm: 48.17 time: 0.121
2025-11-02 06:49:14,497: Train batch 86000: loss: 11.27 grad norm: 52.15 time: 0.080
2025-11-02 06:49:14,499: Running test after training batch: 86000
2025-11-02 06:49:28,322: Val batch 86000: PER (avg): 0.2159 CTC Loss (avg): 22.7185 time: 13.823
2025-11-02 06:49:28,323: t15.2023.08.13 val PER: 0.1601
2025-11-02 06:49:28,323: t15.2023.08.18 val PER: 0.1651
2025-11-02 06:49:28,323: t15.2023.08.20 val PER: 0.1716
2025-11-02 06:49:28,324: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:49:28,324: t15.2023.08.27 val PER: 0.2508
2025-11-02 06:49:28,325: t15.2023.09.01 val PER: 0.1169
2025-11-02 06:49:28,325: t15.2023.09.03 val PER: 0.2114
2025-11-02 06:49:28,325: t15.2023.09.24 val PER: 0.1699
2025-11-02 06:49:28,326: t15.2023.09.29 val PER: 0.1774
2025-11-02 06:49:28,326: t15.2023.10.01 val PER: 0.2252
2025-11-02 06:49:28,327: t15.2023.10.06 val PER: 0.1496
2025-11-02 06:49:28,327: t15.2023.10.08 val PER: 0.2706
2025-11-02 06:49:28,327: t15.2023.10.13 val PER: 0.2715
2025-11-02 06:49:28,328: t15.2023.10.15 val PER: 0.2076
2025-11-02 06:49:28,328: t15.2023.10.20 val PER: 0.2013
2025-11-02 06:49:28,328: t15.2023.10.22 val PER: 0.1771
2025-11-02 06:49:28,329: t15.2023.11.03 val PER: 0.2300
2025-11-02 06:49:28,329: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:49:28,329: t15.2023.11.17 val PER: 0.0902
2025-11-02 06:49:28,329: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:49:28,330: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:49:28,330: t15.2023.12.03 val PER: 0.1702
2025-11-02 06:49:28,330: t15.2023.12.08 val PER: 0.1984
2025-11-02 06:49:28,331: t15.2023.12.10 val PER: 0.1656
2025-11-02 06:49:28,332: t15.2023.12.17 val PER: 0.2297
2025-11-02 06:49:28,332: t15.2023.12.29 val PER: 0.2066
2025-11-02 06:49:28,332: t15.2024.02.25 val PER: 0.1615
2025-11-02 06:49:28,332: t15.2024.03.08 val PER: 0.2845
2025-11-02 06:49:28,333: t15.2024.03.15 val PER: 0.2783
2025-11-02 06:49:28,333: t15.2024.03.17 val PER: 0.2259
2025-11-02 06:49:28,333: t15.2024.05.10 val PER: 0.2169
2025-11-02 06:49:28,334: t15.2024.06.14 val PER: 0.2366
2025-11-02 06:49:28,334: t15.2024.07.19 val PER: 0.3013
2025-11-02 06:49:28,334: t15.2024.07.21 val PER: 0.1572
2025-11-02 06:49:28,335: t15.2024.07.28 val PER: 0.1985
2025-11-02 06:49:28,335: t15.2025.01.10 val PER: 0.3733
2025-11-02 06:49:28,335: t15.2025.01.12 val PER: 0.2279
2025-11-02 06:49:28,335: t15.2025.03.14 val PER: 0.4024
2025-11-02 06:49:28,336: t15.2025.03.16 val PER: 0.2736
2025-11-02 06:49:28,336: t15.2025.03.30 val PER: 0.3517
2025-11-02 06:49:28,336: t15.2025.04.13 val PER: 0.3039
2025-11-02 06:49:28,337: New best test PER 0.2165 --> 0.2159
2025-11-02 06:49:28,337: Checkpointing model
2025-11-02 06:49:30,516: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:49:54,792: Train batch 86200: loss: 13.81 grad norm: 56.67 time: 0.076
2025-11-02 06:50:18,955: Train batch 86400: loss: 16.01 grad norm: 63.45 time: 0.103
2025-11-02 06:50:42,810: Train batch 86600: loss: 10.60 grad norm: 44.56 time: 0.084
2025-11-02 06:51:06,861: Train batch 86800: loss: 10.58 grad norm: 43.65 time: 0.085
2025-11-02 06:51:30,462: Train batch 87000: loss: 7.71 grad norm: 37.53 time: 0.063
2025-11-02 06:51:30,463: Running test after training batch: 87000
2025-11-02 06:51:44,318: Val batch 87000: PER (avg): 0.2155 CTC Loss (avg): 22.7243 time: 13.855
2025-11-02 06:51:44,319: t15.2023.08.13 val PER: 0.1590
2025-11-02 06:51:44,319: t15.2023.08.18 val PER: 0.1668
2025-11-02 06:51:44,320: t15.2023.08.20 val PER: 0.1724
2025-11-02 06:51:44,320: t15.2023.08.25 val PER: 0.1672
2025-11-02 06:51:44,321: t15.2023.08.27 val PER: 0.2540
2025-11-02 06:51:44,321: t15.2023.09.01 val PER: 0.1209
2025-11-02 06:51:44,322: t15.2023.09.03 val PER: 0.2102
2025-11-02 06:51:44,322: t15.2023.09.24 val PER: 0.1699
2025-11-02 06:51:44,322: t15.2023.09.29 val PER: 0.1800
2025-11-02 06:51:44,323: t15.2023.10.01 val PER: 0.2266
2025-11-02 06:51:44,323: t15.2023.10.06 val PER: 0.1485
2025-11-02 06:51:44,323: t15.2023.10.08 val PER: 0.2706
2025-11-02 06:51:44,324: t15.2023.10.13 val PER: 0.2700
2025-11-02 06:51:44,324: t15.2023.10.15 val PER: 0.2076
2025-11-02 06:51:44,325: t15.2023.10.20 val PER: 0.2013
2025-11-02 06:51:44,325: t15.2023.10.22 val PER: 0.1815
2025-11-02 06:51:44,325: t15.2023.11.03 val PER: 0.2266
2025-11-02 06:51:44,326: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:51:44,326: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:51:44,327: t15.2023.11.19 val PER: 0.0958
2025-11-02 06:51:44,327: t15.2023.11.26 val PER: 0.2384
2025-11-02 06:51:44,327: t15.2023.12.03 val PER: 0.1681
2025-11-02 06:51:44,327: t15.2023.12.08 val PER: 0.1997
2025-11-02 06:51:44,328: t15.2023.12.10 val PER: 0.1695
2025-11-02 06:51:44,328: t15.2023.12.17 val PER: 0.2235
2025-11-02 06:51:44,328: t15.2023.12.29 val PER: 0.2052
2025-11-02 06:51:44,329: t15.2024.02.25 val PER: 0.1601
2025-11-02 06:51:44,329: t15.2024.03.08 val PER: 0.2873
2025-11-02 06:51:44,329: t15.2024.03.15 val PER: 0.2758
2025-11-02 06:51:44,330: t15.2024.03.17 val PER: 0.2176
2025-11-02 06:51:44,330: t15.2024.05.10 val PER: 0.2095
2025-11-02 06:51:44,330: t15.2024.06.14 val PER: 0.2319
2025-11-02 06:51:44,331: t15.2024.07.19 val PER: 0.3032
2025-11-02 06:51:44,331: t15.2024.07.21 val PER: 0.1538
2025-11-02 06:51:44,332: t15.2024.07.28 val PER: 0.1985
2025-11-02 06:51:44,332: t15.2025.01.10 val PER: 0.3788
2025-11-02 06:51:44,332: t15.2025.01.12 val PER: 0.2294
2025-11-02 06:51:44,332: t15.2025.03.14 val PER: 0.4009
2025-11-02 06:51:44,333: t15.2025.03.16 val PER: 0.2788
2025-11-02 06:51:44,333: t15.2025.03.30 val PER: 0.3460
2025-11-02 06:51:44,333: t15.2025.04.13 val PER: 0.3010
2025-11-02 06:51:44,333: New best test PER 0.2159 --> 0.2155
2025-11-02 06:51:44,334: Checkpointing model
2025-11-02 06:51:46,450: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:52:10,407: Train batch 87200: loss: 10.54 grad norm: 40.62 time: 0.124
2025-11-02 06:52:33,977: Train batch 87400: loss: 10.87 grad norm: 49.47 time: 0.109
2025-11-02 06:52:57,447: Train batch 87600: loss: 12.63 grad norm: 52.76 time: 0.094
2025-11-02 06:53:21,110: Train batch 87800: loss: 14.00 grad norm: 69.44 time: 0.071
2025-11-02 06:53:44,693: Train batch 88000: loss: 9.31 grad norm: 38.70 time: 0.091
2025-11-02 06:53:44,693: Running test after training batch: 88000
2025-11-02 06:53:58,732: Val batch 88000: PER (avg): 0.2165 CTC Loss (avg): 22.6990 time: 14.038
2025-11-02 06:53:58,733: t15.2023.08.13 val PER: 0.1611
2025-11-02 06:53:58,733: t15.2023.08.18 val PER: 0.1651
2025-11-02 06:53:58,734: t15.2023.08.20 val PER: 0.1747
2025-11-02 06:53:58,734: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:53:58,735: t15.2023.08.27 val PER: 0.2524
2025-11-02 06:53:58,735: t15.2023.09.01 val PER: 0.1177
2025-11-02 06:53:58,783: t15.2023.09.03 val PER: 0.2126
2025-11-02 06:53:58,784: t15.2023.09.24 val PER: 0.1687
2025-11-02 06:53:58,784: t15.2023.09.29 val PER: 0.1774
2025-11-02 06:53:58,785: t15.2023.10.01 val PER: 0.2312
2025-11-02 06:53:58,785: t15.2023.10.06 val PER: 0.1550
2025-11-02 06:53:58,786: t15.2023.10.08 val PER: 0.2733
2025-11-02 06:53:58,787: t15.2023.10.13 val PER: 0.2731
2025-11-02 06:53:58,787: t15.2023.10.15 val PER: 0.2083
2025-11-02 06:53:58,787: t15.2023.10.20 val PER: 0.2013
2025-11-02 06:53:58,788: t15.2023.10.22 val PER: 0.1804
2025-11-02 06:53:58,788: t15.2023.11.03 val PER: 0.2280
2025-11-02 06:53:58,788: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:53:58,789: t15.2023.11.17 val PER: 0.0886
2025-11-02 06:53:58,789: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:53:58,789: t15.2023.11.26 val PER: 0.2362
2025-11-02 06:53:58,790: t15.2023.12.03 val PER: 0.1744
2025-11-02 06:53:58,790: t15.2023.12.08 val PER: 0.2017
2025-11-02 06:53:58,790: t15.2023.12.10 val PER: 0.1629
2025-11-02 06:53:58,791: t15.2023.12.17 val PER: 0.2287
2025-11-02 06:53:58,791: t15.2023.12.29 val PER: 0.2059
2025-11-02 06:53:58,792: t15.2024.02.25 val PER: 0.1601
2025-11-02 06:53:58,792: t15.2024.03.08 val PER: 0.2873
2025-11-02 06:53:58,792: t15.2024.03.15 val PER: 0.2739
2025-11-02 06:53:58,793: t15.2024.03.17 val PER: 0.2232
2025-11-02 06:53:58,793: t15.2024.05.10 val PER: 0.2199
2025-11-02 06:53:58,793: t15.2024.06.14 val PER: 0.2366
2025-11-02 06:53:58,793: t15.2024.07.19 val PER: 0.3039
2025-11-02 06:53:58,794: t15.2024.07.21 val PER: 0.1524
2025-11-02 06:53:58,794: t15.2024.07.28 val PER: 0.2015
2025-11-02 06:53:58,794: t15.2025.01.10 val PER: 0.3719
2025-11-02 06:53:58,795: t15.2025.01.12 val PER: 0.2279
2025-11-02 06:53:58,795: t15.2025.03.14 val PER: 0.4009
2025-11-02 06:53:58,795: t15.2025.03.16 val PER: 0.2801
2025-11-02 06:53:58,795: t15.2025.03.30 val PER: 0.3506
2025-11-02 06:53:58,796: t15.2025.04.13 val PER: 0.3067
2025-11-02 06:54:22,035: Train batch 88200: loss: 14.33 grad norm: 49.46 time: 0.124
2025-11-02 06:54:45,879: Train batch 88400: loss: 14.70 grad norm: 52.17 time: 0.078
2025-11-02 06:55:09,195: Train batch 88600: loss: 16.95 grad norm: 102.06 time: 0.094
2025-11-02 06:55:32,944: Train batch 88800: loss: 13.79 grad norm: 54.45 time: 0.090
2025-11-02 06:55:56,783: Train batch 89000: loss: 8.42 grad norm: 40.72 time: 0.095
2025-11-02 06:55:56,783: Running test after training batch: 89000
2025-11-02 06:56:09,616: Val batch 89000: PER (avg): 0.2162 CTC Loss (avg): 22.6887 time: 12.832
2025-11-02 06:56:09,617: t15.2023.08.13 val PER: 0.1653
2025-11-02 06:56:09,617: t15.2023.08.18 val PER: 0.1651
2025-11-02 06:56:09,618: t15.2023.08.20 val PER: 0.1724
2025-11-02 06:56:09,618: t15.2023.08.25 val PER: 0.1657
2025-11-02 06:56:09,619: t15.2023.08.27 val PER: 0.2524
2025-11-02 06:56:09,619: t15.2023.09.01 val PER: 0.1201
2025-11-02 06:56:09,620: t15.2023.09.03 val PER: 0.2114
2025-11-02 06:56:09,620: t15.2023.09.24 val PER: 0.1699
2025-11-02 06:56:09,621: t15.2023.09.29 val PER: 0.1819
2025-11-02 06:56:09,621: t15.2023.10.01 val PER: 0.2266
2025-11-02 06:56:09,622: t15.2023.10.06 val PER: 0.1475
2025-11-02 06:56:09,622: t15.2023.10.08 val PER: 0.2747
2025-11-02 06:56:09,622: t15.2023.10.13 val PER: 0.2723
2025-11-02 06:56:09,623: t15.2023.10.15 val PER: 0.2050
2025-11-02 06:56:09,623: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:56:09,623: t15.2023.10.22 val PER: 0.1826
2025-11-02 06:56:09,624: t15.2023.11.03 val PER: 0.2307
2025-11-02 06:56:09,624: t15.2023.11.04 val PER: 0.0546
2025-11-02 06:56:09,624: t15.2023.11.17 val PER: 0.0871
2025-11-02 06:56:09,624: t15.2023.11.19 val PER: 0.0998
2025-11-02 06:56:09,625: t15.2023.11.26 val PER: 0.2355
2025-11-02 06:56:09,625: t15.2023.12.03 val PER: 0.1712
2025-11-02 06:56:09,625: t15.2023.12.08 val PER: 0.2004
2025-11-02 06:56:09,626: t15.2023.12.10 val PER: 0.1656
2025-11-02 06:56:09,627: t15.2023.12.17 val PER: 0.2287
2025-11-02 06:56:09,627: t15.2023.12.29 val PER: 0.2032
2025-11-02 06:56:09,627: t15.2024.02.25 val PER: 0.1587
2025-11-02 06:56:09,628: t15.2024.03.08 val PER: 0.2916
2025-11-02 06:56:09,628: t15.2024.03.15 val PER: 0.2770
2025-11-02 06:56:09,628: t15.2024.03.17 val PER: 0.2197
2025-11-02 06:56:09,628: t15.2024.05.10 val PER: 0.2155
2025-11-02 06:56:09,629: t15.2024.06.14 val PER: 0.2350
2025-11-02 06:56:09,629: t15.2024.07.19 val PER: 0.3032
2025-11-02 06:56:09,630: t15.2024.07.21 val PER: 0.1531
2025-11-02 06:56:09,630: t15.2024.07.28 val PER: 0.2022
2025-11-02 06:56:09,630: t15.2025.01.10 val PER: 0.3678
2025-11-02 06:56:09,630: t15.2025.01.12 val PER: 0.2279
2025-11-02 06:56:09,631: t15.2025.03.14 val PER: 0.4068
2025-11-02 06:56:09,631: t15.2025.03.16 val PER: 0.2801
2025-11-02 06:56:09,632: t15.2025.03.30 val PER: 0.3506
2025-11-02 06:56:09,632: t15.2025.04.13 val PER: 0.3039
2025-11-02 06:56:33,936: Train batch 89200: loss: 12.55 grad norm: 55.20 time: 0.078
2025-11-02 06:56:57,012: Train batch 89400: loss: 10.11 grad norm: 39.57 time: 0.078
2025-11-02 06:57:20,249: Train batch 89600: loss: 16.45 grad norm: 61.44 time: 0.104
2025-11-02 06:57:43,799: Train batch 89800: loss: 12.73 grad norm: 47.22 time: 0.073
2025-11-02 06:58:07,643: Train batch 90000: loss: 13.87 grad norm: 55.18 time: 0.068
2025-11-02 06:58:07,644: Running test after training batch: 90000
2025-11-02 06:58:19,513: Val batch 90000: PER (avg): 0.2148 CTC Loss (avg): 22.6714 time: 11.868
2025-11-02 06:58:19,514: t15.2023.08.13 val PER: 0.1570
2025-11-02 06:58:19,514: t15.2023.08.18 val PER: 0.1643
2025-11-02 06:58:19,515: t15.2023.08.20 val PER: 0.1724
2025-11-02 06:58:19,515: t15.2023.08.25 val PER: 0.1642
2025-11-02 06:58:19,516: t15.2023.08.27 val PER: 0.2476
2025-11-02 06:58:19,516: t15.2023.09.01 val PER: 0.1153
2025-11-02 06:58:19,517: t15.2023.09.03 val PER: 0.2138
2025-11-02 06:58:19,517: t15.2023.09.24 val PER: 0.1687
2025-11-02 06:58:19,517: t15.2023.09.29 val PER: 0.1819
2025-11-02 06:58:19,518: t15.2023.10.01 val PER: 0.2259
2025-11-02 06:58:19,518: t15.2023.10.06 val PER: 0.1529
2025-11-02 06:58:19,519: t15.2023.10.08 val PER: 0.2720
2025-11-02 06:58:19,519: t15.2023.10.13 val PER: 0.2754
2025-11-02 06:58:19,519: t15.2023.10.15 val PER: 0.2063
2025-11-02 06:58:19,520: t15.2023.10.20 val PER: 0.2047
2025-11-02 06:58:19,520: t15.2023.10.22 val PER: 0.1759
2025-11-02 06:58:19,520: t15.2023.11.03 val PER: 0.2286
2025-11-02 06:58:19,520: t15.2023.11.04 val PER: 0.0580
2025-11-02 06:58:19,521: t15.2023.11.17 val PER: 0.0871
2025-11-02 06:58:19,521: t15.2023.11.19 val PER: 0.0958
2025-11-02 06:58:19,522: t15.2023.11.26 val PER: 0.2370
2025-11-02 06:58:19,522: t15.2023.12.03 val PER: 0.1712
2025-11-02 06:58:19,522: t15.2023.12.08 val PER: 0.1971
2025-11-02 06:58:19,522: t15.2023.12.10 val PER: 0.1643
2025-11-02 06:58:19,523: t15.2023.12.17 val PER: 0.2245
2025-11-02 06:58:19,523: t15.2023.12.29 val PER: 0.2025
2025-11-02 06:58:19,523: t15.2024.02.25 val PER: 0.1643
2025-11-02 06:58:19,523: t15.2024.03.08 val PER: 0.2888
2025-11-02 06:58:19,524: t15.2024.03.15 val PER: 0.2745
2025-11-02 06:58:19,524: t15.2024.03.17 val PER: 0.2190
2025-11-02 06:58:19,524: t15.2024.05.10 val PER: 0.2125
2025-11-02 06:58:19,525: t15.2024.06.14 val PER: 0.2382
2025-11-02 06:58:19,525: t15.2024.07.19 val PER: 0.3006
2025-11-02 06:58:19,525: t15.2024.07.21 val PER: 0.1538
2025-11-02 06:58:19,525: t15.2024.07.28 val PER: 0.1941
2025-11-02 06:58:19,527: t15.2025.01.10 val PER: 0.3705
2025-11-02 06:58:19,527: t15.2025.01.12 val PER: 0.2263
2025-11-02 06:58:19,528: t15.2025.03.14 val PER: 0.4068
2025-11-02 06:58:19,528: t15.2025.03.16 val PER: 0.2801
2025-11-02 06:58:19,528: t15.2025.03.30 val PER: 0.3448
2025-11-02 06:58:19,529: t15.2025.04.13 val PER: 0.2924
2025-11-02 06:58:19,529: New best test PER 0.2155 --> 0.2148
2025-11-02 06:58:19,529: Checkpointing model
2025-11-02 06:58:21,210: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 06:58:44,541: Train batch 90200: loss: 18.72 grad norm: 60.74 time: 0.097
2025-11-02 06:59:07,062: Train batch 90400: loss: 10.23 grad norm: 43.88 time: 0.085
2025-11-02 06:59:30,535: Train batch 90600: loss: 11.65 grad norm: 50.48 time: 0.090
2025-11-02 06:59:54,582: Train batch 90800: loss: 14.54 grad norm: 64.13 time: 0.063
2025-11-02 07:00:19,787: Train batch 91000: loss: 14.90 grad norm: 55.03 time: 0.066
2025-11-02 07:00:19,788: Running test after training batch: 91000
2025-11-02 07:00:31,233: Val batch 91000: PER (avg): 0.2148 CTC Loss (avg): 22.6420 time: 11.445
2025-11-02 07:00:31,234: t15.2023.08.13 val PER: 0.1580
2025-11-02 07:00:31,235: t15.2023.08.18 val PER: 0.1676
2025-11-02 07:00:31,235: t15.2023.08.20 val PER: 0.1684
2025-11-02 07:00:31,235: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:00:31,236: t15.2023.08.27 val PER: 0.2508
2025-11-02 07:00:31,236: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:00:31,237: t15.2023.09.03 val PER: 0.2126
2025-11-02 07:00:31,237: t15.2023.09.24 val PER: 0.1699
2025-11-02 07:00:31,237: t15.2023.09.29 val PER: 0.1768
2025-11-02 07:00:31,284: t15.2023.10.01 val PER: 0.2239
2025-11-02 07:00:31,284: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:00:31,284: t15.2023.10.08 val PER: 0.2747
2025-11-02 07:00:31,285: t15.2023.10.13 val PER: 0.2723
2025-11-02 07:00:31,285: t15.2023.10.15 val PER: 0.2057
2025-11-02 07:00:31,286: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:00:31,286: t15.2023.10.22 val PER: 0.1782
2025-11-02 07:00:31,287: t15.2023.11.03 val PER: 0.2280
2025-11-02 07:00:31,288: t15.2023.11.04 val PER: 0.0478
2025-11-02 07:00:31,288: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:00:31,288: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:00:31,289: t15.2023.11.26 val PER: 0.2362
2025-11-02 07:00:31,290: t15.2023.12.03 val PER: 0.1723
2025-11-02 07:00:31,290: t15.2023.12.08 val PER: 0.2011
2025-11-02 07:00:31,290: t15.2023.12.10 val PER: 0.1643
2025-11-02 07:00:31,291: t15.2023.12.17 val PER: 0.2235
2025-11-02 07:00:31,291: t15.2023.12.29 val PER: 0.2045
2025-11-02 07:00:31,292: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:00:31,292: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:00:31,292: t15.2024.03.15 val PER: 0.2777
2025-11-02 07:00:31,293: t15.2024.03.17 val PER: 0.2211
2025-11-02 07:00:31,293: t15.2024.05.10 val PER: 0.2169
2025-11-02 07:00:31,293: t15.2024.06.14 val PER: 0.2397
2025-11-02 07:00:31,293: t15.2024.07.19 val PER: 0.3013
2025-11-02 07:00:31,294: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:00:31,294: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:00:31,295: t15.2025.01.10 val PER: 0.3802
2025-11-02 07:00:31,295: t15.2025.01.12 val PER: 0.2263
2025-11-02 07:00:31,295: t15.2025.03.14 val PER: 0.4038
2025-11-02 07:00:31,296: t15.2025.03.16 val PER: 0.2736
2025-11-02 07:00:31,296: t15.2025.03.30 val PER: 0.3471
2025-11-02 07:00:31,297: t15.2025.04.13 val PER: 0.2996
2025-11-02 07:00:55,850: Train batch 91200: loss: 7.79 grad norm: 33.72 time: 0.089
2025-11-02 07:01:20,407: Train batch 91400: loss: 12.20 grad norm: 44.71 time: 0.107
2025-11-02 07:01:45,141: Train batch 91600: loss: 14.53 grad norm: 67.07 time: 0.090
2025-11-02 07:02:09,835: Train batch 91800: loss: 13.34 grad norm: 47.29 time: 0.072
2025-11-02 07:02:34,385: Train batch 92000: loss: 9.24 grad norm: 38.39 time: 0.078
2025-11-02 07:02:34,386: Running test after training batch: 92000
2025-11-02 07:02:45,714: Val batch 92000: PER (avg): 0.2149 CTC Loss (avg): 22.6458 time: 11.328
2025-11-02 07:02:45,715: t15.2023.08.13 val PER: 0.1622
2025-11-02 07:02:45,716: t15.2023.08.18 val PER: 0.1651
2025-11-02 07:02:45,717: t15.2023.08.20 val PER: 0.1700
2025-11-02 07:02:45,717: t15.2023.08.25 val PER: 0.1642
2025-11-02 07:02:45,717: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:02:45,718: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:02:45,718: t15.2023.09.03 val PER: 0.2114
2025-11-02 07:02:45,718: t15.2023.09.24 val PER: 0.1748
2025-11-02 07:02:45,719: t15.2023.09.29 val PER: 0.1761
2025-11-02 07:02:45,719: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:02:45,719: t15.2023.10.06 val PER: 0.1518
2025-11-02 07:02:45,720: t15.2023.10.08 val PER: 0.2720
2025-11-02 07:02:45,720: t15.2023.10.13 val PER: 0.2669
2025-11-02 07:02:45,720: t15.2023.10.15 val PER: 0.2070
2025-11-02 07:02:45,720: t15.2023.10.20 val PER: 0.2114
2025-11-02 07:02:45,721: t15.2023.10.22 val PER: 0.1815
2025-11-02 07:02:45,721: t15.2023.11.03 val PER: 0.2266
2025-11-02 07:02:45,722: t15.2023.11.04 val PER: 0.0512
2025-11-02 07:02:45,722: t15.2023.11.17 val PER: 0.0871
2025-11-02 07:02:45,722: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:02:45,723: t15.2023.11.26 val PER: 0.2326
2025-11-02 07:02:45,723: t15.2023.12.03 val PER: 0.1733
2025-11-02 07:02:45,723: t15.2023.12.08 val PER: 0.1991
2025-11-02 07:02:45,723: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:02:45,724: t15.2023.12.17 val PER: 0.2256
2025-11-02 07:02:45,724: t15.2023.12.29 val PER: 0.2018
2025-11-02 07:02:45,724: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:02:45,725: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:02:45,725: t15.2024.03.15 val PER: 0.2821
2025-11-02 07:02:45,725: t15.2024.03.17 val PER: 0.2204
2025-11-02 07:02:45,725: t15.2024.05.10 val PER: 0.2155
2025-11-02 07:02:45,726: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:02:45,726: t15.2024.07.19 val PER: 0.3026
2025-11-02 07:02:45,727: t15.2024.07.21 val PER: 0.1538
2025-11-02 07:02:45,727: t15.2024.07.28 val PER: 0.1963
2025-11-02 07:02:45,727: t15.2025.01.10 val PER: 0.3747
2025-11-02 07:02:45,727: t15.2025.01.12 val PER: 0.2294
2025-11-02 07:02:45,728: t15.2025.03.14 val PER: 0.4038
2025-11-02 07:02:45,728: t15.2025.03.16 val PER: 0.2709
2025-11-02 07:02:45,728: t15.2025.03.30 val PER: 0.3483
2025-11-02 07:02:45,728: t15.2025.04.13 val PER: 0.2939
2025-11-02 07:03:10,075: Train batch 92200: loss: 14.56 grad norm: 59.18 time: 0.082
2025-11-02 07:03:34,292: Train batch 92400: loss: 9.39 grad norm: 42.03 time: 0.073
2025-11-02 07:03:58,869: Train batch 92600: loss: 12.87 grad norm: 48.11 time: 0.077
2025-11-02 07:04:23,354: Train batch 92800: loss: 12.22 grad norm: 53.97 time: 0.089
2025-11-02 07:04:48,375: Train batch 93000: loss: 14.64 grad norm: 63.07 time: 0.075
2025-11-02 07:04:48,377: Running test after training batch: 93000
2025-11-02 07:04:59,936: Val batch 93000: PER (avg): 0.2142 CTC Loss (avg): 22.6400 time: 11.559
2025-11-02 07:04:59,937: t15.2023.08.13 val PER: 0.1622
2025-11-02 07:04:59,938: t15.2023.08.18 val PER: 0.1651
2025-11-02 07:04:59,938: t15.2023.08.20 val PER: 0.1716
2025-11-02 07:04:59,938: t15.2023.08.25 val PER: 0.1657
2025-11-02 07:04:59,939: t15.2023.08.27 val PER: 0.2428
2025-11-02 07:04:59,939: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:04:59,939: t15.2023.09.03 val PER: 0.2126
2025-11-02 07:04:59,940: t15.2023.09.24 val PER: 0.1687
2025-11-02 07:04:59,940: t15.2023.09.29 val PER: 0.1774
2025-11-02 07:04:59,940: t15.2023.10.01 val PER: 0.2252
2025-11-02 07:04:59,940: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:04:59,941: t15.2023.10.08 val PER: 0.2720
2025-11-02 07:04:59,941: t15.2023.10.13 val PER: 0.2700
2025-11-02 07:04:59,942: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:04:59,942: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:04:59,942: t15.2023.10.22 val PER: 0.1782
2025-11-02 07:04:59,943: t15.2023.11.03 val PER: 0.2280
2025-11-02 07:04:59,943: t15.2023.11.04 val PER: 0.0478
2025-11-02 07:04:59,943: t15.2023.11.17 val PER: 0.0871
2025-11-02 07:04:59,943: t15.2023.11.19 val PER: 0.0998
2025-11-02 07:04:59,944: t15.2023.11.26 val PER: 0.2319
2025-11-02 07:04:59,944: t15.2023.12.03 val PER: 0.1765
2025-11-02 07:04:59,944: t15.2023.12.08 val PER: 0.1991
2025-11-02 07:04:59,944: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:04:59,945: t15.2023.12.17 val PER: 0.2308
2025-11-02 07:04:59,945: t15.2023.12.29 val PER: 0.2038
2025-11-02 07:04:59,945: t15.2024.02.25 val PER: 0.1615
2025-11-02 07:04:59,945: t15.2024.03.08 val PER: 0.2817
2025-11-02 07:04:59,946: t15.2024.03.15 val PER: 0.2795
2025-11-02 07:04:59,946: t15.2024.03.17 val PER: 0.2204
2025-11-02 07:04:59,947: t15.2024.05.10 val PER: 0.2065
2025-11-02 07:04:59,947: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:04:59,947: t15.2024.07.19 val PER: 0.3013
2025-11-02 07:04:59,947: t15.2024.07.21 val PER: 0.1531
2025-11-02 07:04:59,948: t15.2024.07.28 val PER: 0.1956
2025-11-02 07:04:59,948: t15.2025.01.10 val PER: 0.3678
2025-11-02 07:04:59,948: t15.2025.01.12 val PER: 0.2256
2025-11-02 07:04:59,948: t15.2025.03.14 val PER: 0.3994
2025-11-02 07:04:59,949: t15.2025.03.16 val PER: 0.2723
2025-11-02 07:04:59,949: t15.2025.03.30 val PER: 0.3460
2025-11-02 07:04:59,949: t15.2025.04.13 val PER: 0.2910
2025-11-02 07:04:59,949: New best test PER 0.2148 --> 0.2142
2025-11-02 07:04:59,950: Checkpointing model
2025-11-02 07:05:01,690: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:05:26,566: Train batch 93200: loss: 9.90 grad norm: 48.04 time: 0.085
2025-11-02 07:05:52,048: Train batch 93400: loss: 11.48 grad norm: 47.00 time: 0.081
2025-11-02 07:06:16,868: Train batch 93600: loss: 13.67 grad norm: 69.59 time: 0.069
2025-11-02 07:06:42,555: Train batch 93800: loss: 11.57 grad norm: 47.28 time: 0.065
2025-11-02 07:07:06,844: Train batch 94000: loss: 14.45 grad norm: 60.66 time: 0.075
2025-11-02 07:07:06,845: Running test after training batch: 94000
2025-11-02 07:07:17,820: Val batch 94000: PER (avg): 0.2143 CTC Loss (avg): 22.6332 time: 10.975
2025-11-02 07:07:17,821: t15.2023.08.13 val PER: 0.1549
2025-11-02 07:07:17,821: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:07:17,822: t15.2023.08.20 val PER: 0.1724
2025-11-02 07:07:17,822: t15.2023.08.25 val PER: 0.1642
2025-11-02 07:07:17,822: t15.2023.08.27 val PER: 0.2395
2025-11-02 07:07:17,823: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:07:17,823: t15.2023.09.03 val PER: 0.2126
2025-11-02 07:07:17,823: t15.2023.09.24 val PER: 0.1699
2025-11-02 07:07:17,823: t15.2023.09.29 val PER: 0.1723
2025-11-02 07:07:17,824: t15.2023.10.01 val PER: 0.2285
2025-11-02 07:07:17,824: t15.2023.10.06 val PER: 0.1496
2025-11-02 07:07:17,824: t15.2023.10.08 val PER: 0.2720
2025-11-02 07:07:17,824: t15.2023.10.13 val PER: 0.2692
2025-11-02 07:07:17,824: t15.2023.10.15 val PER: 0.2030
2025-11-02 07:07:17,825: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:07:17,825: t15.2023.10.22 val PER: 0.1782
2025-11-02 07:07:17,825: t15.2023.11.03 val PER: 0.2286
2025-11-02 07:07:17,825: t15.2023.11.04 val PER: 0.0512
2025-11-02 07:07:17,826: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:07:17,827: t15.2023.11.19 val PER: 0.0998
2025-11-02 07:07:17,827: t15.2023.11.26 val PER: 0.2355
2025-11-02 07:07:17,827: t15.2023.12.03 val PER: 0.1733
2025-11-02 07:07:17,827: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:07:17,827: t15.2023.12.10 val PER: 0.1629
2025-11-02 07:07:17,828: t15.2023.12.17 val PER: 0.2225
2025-11-02 07:07:17,828: t15.2023.12.29 val PER: 0.2045
2025-11-02 07:07:17,828: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:07:17,828: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:07:17,828: t15.2024.03.15 val PER: 0.2764
2025-11-02 07:07:17,829: t15.2024.03.17 val PER: 0.2197
2025-11-02 07:07:17,829: t15.2024.05.10 val PER: 0.2169
2025-11-02 07:07:17,829: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:07:17,829: t15.2024.07.19 val PER: 0.3019
2025-11-02 07:07:17,830: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:07:17,830: t15.2024.07.28 val PER: 0.1934
2025-11-02 07:07:17,830: t15.2025.01.10 val PER: 0.3747
2025-11-02 07:07:17,830: t15.2025.01.12 val PER: 0.2240
2025-11-02 07:07:17,830: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:07:17,831: t15.2025.03.16 val PER: 0.2709
2025-11-02 07:07:17,831: t15.2025.03.30 val PER: 0.3563
2025-11-02 07:07:17,831: t15.2025.04.13 val PER: 0.2953
2025-11-02 07:07:43,317: Train batch 94200: loss: 14.05 grad norm: 49.89 time: 0.062
2025-11-02 07:08:08,453: Train batch 94400: loss: 6.49 grad norm: 39.74 time: 0.080
2025-11-02 07:08:33,393: Train batch 94600: loss: 8.72 grad norm: 39.93 time: 0.089
2025-11-02 07:08:59,067: Train batch 94800: loss: 13.93 grad norm: 54.84 time: 0.079
2025-11-02 07:09:24,869: Train batch 95000: loss: 10.55 grad norm: 49.18 time: 0.068
2025-11-02 07:09:24,870: Running test after training batch: 95000
2025-11-02 07:09:35,322: Val batch 95000: PER (avg): 0.2137 CTC Loss (avg): 22.6076 time: 10.452
2025-11-02 07:09:35,322: t15.2023.08.13 val PER: 0.1580
2025-11-02 07:09:35,323: t15.2023.08.18 val PER: 0.1660
2025-11-02 07:09:35,323: t15.2023.08.20 val PER: 0.1692
2025-11-02 07:09:35,323: t15.2023.08.25 val PER: 0.1596
2025-11-02 07:09:35,324: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:09:35,324: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:09:35,324: t15.2023.09.03 val PER: 0.2114
2025-11-02 07:09:35,325: t15.2023.09.24 val PER: 0.1675
2025-11-02 07:09:35,325: t15.2023.09.29 val PER: 0.1774
2025-11-02 07:09:35,325: t15.2023.10.01 val PER: 0.2285
2025-11-02 07:09:35,326: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:09:35,326: t15.2023.10.08 val PER: 0.2679
2025-11-02 07:09:35,327: t15.2023.10.13 val PER: 0.2692
2025-11-02 07:09:35,327: t15.2023.10.15 val PER: 0.2050
2025-11-02 07:09:35,327: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:09:35,327: t15.2023.10.22 val PER: 0.1804
2025-11-02 07:09:35,327: t15.2023.11.03 val PER: 0.2273
2025-11-02 07:09:35,328: t15.2023.11.04 val PER: 0.0546
2025-11-02 07:09:35,328: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:09:35,328: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:09:35,328: t15.2023.11.26 val PER: 0.2333
2025-11-02 07:09:35,328: t15.2023.12.03 val PER: 0.1723
2025-11-02 07:09:35,329: t15.2023.12.08 val PER: 0.1977
2025-11-02 07:09:35,329: t15.2023.12.10 val PER: 0.1643
2025-11-02 07:09:35,329: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:09:35,329: t15.2023.12.29 val PER: 0.2011
2025-11-02 07:09:35,330: t15.2024.02.25 val PER: 0.1601
2025-11-02 07:09:35,330: t15.2024.03.08 val PER: 0.2845
2025-11-02 07:09:35,330: t15.2024.03.15 val PER: 0.2727
2025-11-02 07:09:35,330: t15.2024.03.17 val PER: 0.2197
2025-11-02 07:09:35,330: t15.2024.05.10 val PER: 0.2140
2025-11-02 07:09:35,331: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:09:35,332: t15.2024.07.19 val PER: 0.3026
2025-11-02 07:09:35,332: t15.2024.07.21 val PER: 0.1531
2025-11-02 07:09:35,332: t15.2024.07.28 val PER: 0.1941
2025-11-02 07:09:35,332: t15.2025.01.10 val PER: 0.3719
2025-11-02 07:09:35,332: t15.2025.01.12 val PER: 0.2263
2025-11-02 07:09:35,333: t15.2025.03.14 val PER: 0.3979
2025-11-02 07:09:35,333: t15.2025.03.16 val PER: 0.2762
2025-11-02 07:09:35,333: t15.2025.03.30 val PER: 0.3448
2025-11-02 07:09:35,333: t15.2025.04.13 val PER: 0.2910
2025-11-02 07:09:35,333: New best test PER 0.2142 --> 0.2137
2025-11-02 07:09:35,334: Checkpointing model
2025-11-02 07:09:36,574: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:10:01,688: Train batch 95200: loss: 9.50 grad norm: 36.63 time: 0.083
2025-11-02 07:10:26,768: Train batch 95400: loss: 16.13 grad norm: 72.28 time: 0.077
2025-11-02 07:10:52,655: Train batch 95600: loss: 10.48 grad norm: 50.25 time: 0.054
2025-11-02 07:11:18,112: Train batch 95800: loss: 13.34 grad norm: 45.41 time: 0.074
2025-11-02 07:11:43,897: Train batch 96000: loss: 11.20 grad norm: 46.36 time: 0.112
2025-11-02 07:11:43,898: Running test after training batch: 96000
2025-11-02 07:11:55,824: Val batch 96000: PER (avg): 0.2137 CTC Loss (avg): 22.6110 time: 11.925
2025-11-02 07:11:55,824: t15.2023.08.13 val PER: 0.1538
2025-11-02 07:11:55,825: t15.2023.08.18 val PER: 0.1668
2025-11-02 07:11:55,825: t15.2023.08.20 val PER: 0.1692
2025-11-02 07:11:55,825: t15.2023.08.25 val PER: 0.1642
2025-11-02 07:11:55,826: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:11:55,826: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:11:55,827: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:11:55,827: t15.2023.09.24 val PER: 0.1687
2025-11-02 07:11:55,827: t15.2023.09.29 val PER: 0.1768
2025-11-02 07:11:55,828: t15.2023.10.01 val PER: 0.2279
2025-11-02 07:11:55,828: t15.2023.10.06 val PER: 0.1529
2025-11-02 07:11:55,828: t15.2023.10.08 val PER: 0.2706
2025-11-02 07:11:55,828: t15.2023.10.13 val PER: 0.2692
2025-11-02 07:11:55,829: t15.2023.10.15 val PER: 0.2057
2025-11-02 07:11:55,829: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:11:55,829: t15.2023.10.22 val PER: 0.1748
2025-11-02 07:11:55,830: t15.2023.11.03 val PER: 0.2273
2025-11-02 07:11:55,830: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:11:55,830: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:11:55,830: t15.2023.11.19 val PER: 0.0918
2025-11-02 07:11:55,831: t15.2023.11.26 val PER: 0.2341
2025-11-02 07:11:55,831: t15.2023.12.03 val PER: 0.1712
2025-11-02 07:11:55,831: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:11:55,832: t15.2023.12.10 val PER: 0.1643
2025-11-02 07:11:55,832: t15.2023.12.17 val PER: 0.2225
2025-11-02 07:11:55,832: t15.2023.12.29 val PER: 0.2045
2025-11-02 07:11:55,833: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:11:55,833: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:11:55,833: t15.2024.03.15 val PER: 0.2795
2025-11-02 07:11:55,834: t15.2024.03.17 val PER: 0.2197
2025-11-02 07:11:55,834: t15.2024.05.10 val PER: 0.2080
2025-11-02 07:11:55,834: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:11:55,835: t15.2024.07.19 val PER: 0.3006
2025-11-02 07:11:55,835: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:11:55,835: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:11:55,835: t15.2025.01.10 val PER: 0.3691
2025-11-02 07:11:55,836: t15.2025.01.12 val PER: 0.2279
2025-11-02 07:11:55,836: t15.2025.03.14 val PER: 0.4009
2025-11-02 07:11:55,836: t15.2025.03.16 val PER: 0.2696
2025-11-02 07:11:55,837: t15.2025.03.30 val PER: 0.3471
2025-11-02 07:11:55,837: t15.2025.04.13 val PER: 0.2939
2025-11-02 07:12:20,771: Train batch 96200: loss: 14.22 grad norm: 55.04 time: 0.083
2025-11-02 07:12:45,977: Train batch 96400: loss: 22.68 grad norm: 83.39 time: 0.095
2025-11-02 07:13:10,119: Train batch 96600: loss: 11.95 grad norm: 47.69 time: 0.080
2025-11-02 07:13:35,709: Train batch 96800: loss: 13.41 grad norm: 47.91 time: 0.072
2025-11-02 07:14:01,840: Train batch 97000: loss: 15.46 grad norm: 57.29 time: 0.089
2025-11-02 07:14:01,841: Running test after training batch: 97000
2025-11-02 07:14:13,124: Val batch 97000: PER (avg): 0.2141 CTC Loss (avg): 22.5842 time: 11.282
2025-11-02 07:14:13,126: t15.2023.08.13 val PER: 0.1580
2025-11-02 07:14:13,126: t15.2023.08.18 val PER: 0.1676
2025-11-02 07:14:13,127: t15.2023.08.20 val PER: 0.1676
2025-11-02 07:14:13,128: t15.2023.08.25 val PER: 0.1611
2025-11-02 07:14:13,129: t15.2023.08.27 val PER: 0.2428
2025-11-02 07:14:13,129: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:14:13,129: t15.2023.09.03 val PER: 0.2067
2025-11-02 07:14:13,129: t15.2023.09.24 val PER: 0.1675
2025-11-02 07:14:13,130: t15.2023.09.29 val PER: 0.1761
2025-11-02 07:14:13,130: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:14:13,130: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:14:13,130: t15.2023.10.08 val PER: 0.2733
2025-11-02 07:14:13,130: t15.2023.10.13 val PER: 0.2700
2025-11-02 07:14:13,131: t15.2023.10.15 val PER: 0.2083
2025-11-02 07:14:13,131: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:14:13,131: t15.2023.10.22 val PER: 0.1737
2025-11-02 07:14:13,132: t15.2023.11.03 val PER: 0.2266
2025-11-02 07:14:13,132: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:14:13,132: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:14:13,132: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:14:13,133: t15.2023.11.26 val PER: 0.2370
2025-11-02 07:14:13,133: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:14:13,133: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:14:13,133: t15.2023.12.10 val PER: 0.1656
2025-11-02 07:14:13,133: t15.2023.12.17 val PER: 0.2235
2025-11-02 07:14:13,134: t15.2023.12.29 val PER: 0.2045
2025-11-02 07:14:13,134: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:14:13,134: t15.2024.03.08 val PER: 0.2859
2025-11-02 07:14:13,134: t15.2024.03.15 val PER: 0.2777
2025-11-02 07:14:13,134: t15.2024.03.17 val PER: 0.2211
2025-11-02 07:14:13,135: t15.2024.05.10 val PER: 0.2095
2025-11-02 07:14:13,135: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:14:13,135: t15.2024.07.19 val PER: 0.2986
2025-11-02 07:14:13,135: t15.2024.07.21 val PER: 0.1531
2025-11-02 07:14:13,135: t15.2024.07.28 val PER: 0.1904
2025-11-02 07:14:13,136: t15.2025.01.10 val PER: 0.3788
2025-11-02 07:14:13,136: t15.2025.01.12 val PER: 0.2294
2025-11-02 07:14:13,137: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:14:13,137: t15.2025.03.16 val PER: 0.2736
2025-11-02 07:14:13,137: t15.2025.03.30 val PER: 0.3506
2025-11-02 07:14:13,137: t15.2025.04.13 val PER: 0.2939
2025-11-02 07:14:37,841: Train batch 97200: loss: 12.81 grad norm: 63.95 time: 0.070
2025-11-02 07:15:03,747: Train batch 97400: loss: 14.47 grad norm: 52.10 time: 0.098
2025-11-02 07:15:28,905: Train batch 97600: loss: 11.46 grad norm: 59.24 time: 0.074
2025-11-02 07:15:53,851: Train batch 97800: loss: 13.76 grad norm: 48.98 time: 0.113
2025-11-02 07:16:18,781: Train batch 98000: loss: 17.46 grad norm: 62.81 time: 0.070
2025-11-02 07:16:18,782: Running test after training batch: 98000
2025-11-02 07:16:30,424: Val batch 98000: PER (avg): 0.2134 CTC Loss (avg): 22.5715 time: 11.642
2025-11-02 07:16:30,425: t15.2023.08.13 val PER: 0.1528
2025-11-02 07:16:30,425: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:16:30,425: t15.2023.08.20 val PER: 0.1708
2025-11-02 07:16:30,426: t15.2023.08.25 val PER: 0.1611
2025-11-02 07:16:30,426: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:16:30,427: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:16:30,427: t15.2023.09.03 val PER: 0.2138
2025-11-02 07:16:30,427: t15.2023.09.24 val PER: 0.1723
2025-11-02 07:16:30,427: t15.2023.09.29 val PER: 0.1761
2025-11-02 07:16:30,427: t15.2023.10.01 val PER: 0.2279
2025-11-02 07:16:30,428: t15.2023.10.06 val PER: 0.1496
2025-11-02 07:16:30,428: t15.2023.10.08 val PER: 0.2720
2025-11-02 07:16:30,428: t15.2023.10.13 val PER: 0.2708
2025-11-02 07:16:30,428: t15.2023.10.15 val PER: 0.2070
2025-11-02 07:16:30,429: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:16:30,429: t15.2023.10.22 val PER: 0.1759
2025-11-02 07:16:30,429: t15.2023.11.03 val PER: 0.2300
2025-11-02 07:16:30,429: t15.2023.11.04 val PER: 0.0512
2025-11-02 07:16:30,430: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:16:30,430: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:16:30,430: t15.2023.11.26 val PER: 0.2333
2025-11-02 07:16:30,430: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:16:30,430: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:16:30,431: t15.2023.12.10 val PER: 0.1656
2025-11-02 07:16:30,431: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:16:30,431: t15.2023.12.29 val PER: 0.2025
2025-11-02 07:16:30,432: t15.2024.02.25 val PER: 0.1559
2025-11-02 07:16:30,432: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:16:30,432: t15.2024.03.15 val PER: 0.2758
2025-11-02 07:16:30,432: t15.2024.03.17 val PER: 0.2155
2025-11-02 07:16:30,433: t15.2024.05.10 val PER: 0.2065
2025-11-02 07:16:30,433: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:16:30,433: t15.2024.07.19 val PER: 0.2986
2025-11-02 07:16:30,433: t15.2024.07.21 val PER: 0.1538
2025-11-02 07:16:30,433: t15.2024.07.28 val PER: 0.1912
2025-11-02 07:16:30,434: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:16:30,434: t15.2025.01.12 val PER: 0.2248
2025-11-02 07:16:30,434: t15.2025.03.14 val PER: 0.3979
2025-11-02 07:16:30,434: t15.2025.03.16 val PER: 0.2696
2025-11-02 07:16:30,434: t15.2025.03.30 val PER: 0.3471
2025-11-02 07:16:30,435: t15.2025.04.13 val PER: 0.2924
2025-11-02 07:16:30,435: New best test PER 0.2137 --> 0.2134
2025-11-02 07:16:30,435: Checkpointing model
2025-11-02 07:16:31,886: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:16:57,637: Train batch 98200: loss: 8.33 grad norm: 39.80 time: 0.075
2025-11-02 07:17:23,035: Train batch 98400: loss: 14.70 grad norm: 56.81 time: 0.102
2025-11-02 07:17:48,435: Train batch 98600: loss: 11.47 grad norm: 43.71 time: 0.075
2025-11-02 07:18:13,452: Train batch 98800: loss: 15.39 grad norm: 58.77 time: 0.064
2025-11-02 07:18:38,947: Train batch 99000: loss: 11.70 grad norm: 41.45 time: 0.060
2025-11-02 07:18:38,947: Running test after training batch: 99000
2025-11-02 07:18:51,228: Val batch 99000: PER (avg): 0.2135 CTC Loss (avg): 22.5601 time: 12.280
2025-11-02 07:18:51,229: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:18:51,230: t15.2023.08.18 val PER: 0.1668
2025-11-02 07:18:51,230: t15.2023.08.20 val PER: 0.1716
2025-11-02 07:18:51,231: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:18:51,231: t15.2023.08.27 val PER: 0.2476
2025-11-02 07:18:51,232: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:18:51,232: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:18:51,232: t15.2023.09.24 val PER: 0.1699
2025-11-02 07:18:51,232: t15.2023.09.29 val PER: 0.1742
2025-11-02 07:18:51,233: t15.2023.10.01 val PER: 0.2252
2025-11-02 07:18:51,233: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:18:51,233: t15.2023.10.08 val PER: 0.2639
2025-11-02 07:18:51,234: t15.2023.10.13 val PER: 0.2700
2025-11-02 07:18:51,234: t15.2023.10.15 val PER: 0.2057
2025-11-02 07:18:51,234: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:18:51,234: t15.2023.10.22 val PER: 0.1771
2025-11-02 07:18:51,235: t15.2023.11.03 val PER: 0.2246
2025-11-02 07:18:51,235: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:18:51,235: t15.2023.11.17 val PER: 0.0886
2025-11-02 07:18:51,236: t15.2023.11.19 val PER: 0.0998
2025-11-02 07:18:51,236: t15.2023.11.26 val PER: 0.2348
2025-11-02 07:18:51,236: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:18:51,237: t15.2023.12.08 val PER: 0.1964
2025-11-02 07:18:51,237: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:18:51,237: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:18:51,237: t15.2023.12.29 val PER: 0.2025
2025-11-02 07:18:51,238: t15.2024.02.25 val PER: 0.1601
2025-11-02 07:18:51,238: t15.2024.03.08 val PER: 0.2902
2025-11-02 07:18:51,238: t15.2024.03.15 val PER: 0.2770
2025-11-02 07:18:51,239: t15.2024.03.17 val PER: 0.2176
2025-11-02 07:18:51,239: t15.2024.05.10 val PER: 0.2140
2025-11-02 07:18:51,240: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:18:51,240: t15.2024.07.19 val PER: 0.3019
2025-11-02 07:18:51,240: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:18:51,241: t15.2024.07.28 val PER: 0.1897
2025-11-02 07:18:51,241: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:18:51,241: t15.2025.01.12 val PER: 0.2256
2025-11-02 07:18:51,242: t15.2025.03.14 val PER: 0.4053
2025-11-02 07:18:51,242: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:18:51,242: t15.2025.03.30 val PER: 0.3471
2025-11-02 07:18:51,243: t15.2025.04.13 val PER: 0.2981
2025-11-02 07:19:16,739: Train batch 99200: loss: 6.40 grad norm: 33.38 time: 0.074
2025-11-02 07:19:42,078: Train batch 99400: loss: 13.68 grad norm: 43.62 time: 0.070
2025-11-02 07:20:07,767: Train batch 99600: loss: 14.38 grad norm: 70.39 time: 0.084
2025-11-02 07:20:33,291: Train batch 99800: loss: 10.68 grad norm: 49.32 time: 0.097
2025-11-02 07:20:58,545: Train batch 100000: loss: 8.88 grad norm: 41.18 time: 0.058
2025-11-02 07:20:58,547: Running test after training batch: 100000
2025-11-02 07:21:10,936: Val batch 100000: PER (avg): 0.2134 CTC Loss (avg): 22.5609 time: 12.388
2025-11-02 07:21:10,936: t15.2023.08.13 val PER: 0.1590
2025-11-02 07:21:10,937: t15.2023.08.18 val PER: 0.1635
2025-11-02 07:21:10,937: t15.2023.08.20 val PER: 0.1708
2025-11-02 07:21:10,937: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:21:10,938: t15.2023.08.27 val PER: 0.2492
2025-11-02 07:21:10,938: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:21:10,938: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:21:10,939: t15.2023.09.24 val PER: 0.1675
2025-11-02 07:21:10,939: t15.2023.09.29 val PER: 0.1755
2025-11-02 07:21:10,939: t15.2023.10.01 val PER: 0.2285
2025-11-02 07:21:10,939: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:21:10,940: t15.2023.10.08 val PER: 0.2693
2025-11-02 07:21:10,984: t15.2023.10.13 val PER: 0.2708
2025-11-02 07:21:10,984: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:21:10,984: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:21:10,985: t15.2023.10.22 val PER: 0.1748
2025-11-02 07:21:10,985: t15.2023.11.03 val PER: 0.2259
2025-11-02 07:21:10,985: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:21:10,985: t15.2023.11.17 val PER: 0.0871
2025-11-02 07:21:10,986: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:21:10,986: t15.2023.11.26 val PER: 0.2348
2025-11-02 07:21:10,986: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:21:10,987: t15.2023.12.08 val PER: 0.1977
2025-11-02 07:21:10,987: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:21:10,987: t15.2023.12.17 val PER: 0.2256
2025-11-02 07:21:10,987: t15.2023.12.29 val PER: 0.2032
2025-11-02 07:21:10,988: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:21:10,988: t15.2024.03.08 val PER: 0.2802
2025-11-02 07:21:10,988: t15.2024.03.15 val PER: 0.2795
2025-11-02 07:21:10,988: t15.2024.03.17 val PER: 0.2148
2025-11-02 07:21:10,989: t15.2024.05.10 val PER: 0.2080
2025-11-02 07:21:10,989: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:21:10,989: t15.2024.07.19 val PER: 0.2980
2025-11-02 07:21:10,989: t15.2024.07.21 val PER: 0.1566
2025-11-02 07:21:10,989: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:21:10,990: t15.2025.01.10 val PER: 0.3760
2025-11-02 07:21:10,990: t15.2025.01.12 val PER: 0.2286
2025-11-02 07:21:10,991: t15.2025.03.14 val PER: 0.3994
2025-11-02 07:21:10,991: t15.2025.03.16 val PER: 0.2723
2025-11-02 07:21:10,991: t15.2025.03.30 val PER: 0.3414
2025-11-02 07:21:10,992: t15.2025.04.13 val PER: 0.2967
2025-11-02 07:21:36,081: Train batch 100200: loss: 13.27 grad norm: 53.03 time: 0.068
2025-11-02 07:22:01,642: Train batch 100400: loss: 9.61 grad norm: 44.96 time: 0.074
2025-11-02 07:22:27,090: Train batch 100600: loss: 7.85 grad norm: 34.31 time: 0.074
2025-11-02 07:22:53,841: Train batch 100800: loss: 9.37 grad norm: 46.07 time: 0.107
2025-11-02 07:23:19,485: Train batch 101000: loss: 14.31 grad norm: 53.47 time: 0.073
2025-11-02 07:23:19,486: Running test after training batch: 101000
2025-11-02 07:23:31,123: Val batch 101000: PER (avg): 0.2130 CTC Loss (avg): 22.5577 time: 11.637
2025-11-02 07:23:31,124: t15.2023.08.13 val PER: 0.1528
2025-11-02 07:23:31,124: t15.2023.08.18 val PER: 0.1668
2025-11-02 07:23:31,125: t15.2023.08.20 val PER: 0.1700
2025-11-02 07:23:31,126: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:23:31,126: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:23:31,126: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:23:31,126: t15.2023.09.03 val PER: 0.2090
2025-11-02 07:23:31,127: t15.2023.09.24 val PER: 0.1675
2025-11-02 07:23:31,127: t15.2023.09.29 val PER: 0.1749
2025-11-02 07:23:31,127: t15.2023.10.01 val PER: 0.2272
2025-11-02 07:23:31,127: t15.2023.10.06 val PER: 0.1529
2025-11-02 07:23:31,128: t15.2023.10.08 val PER: 0.2774
2025-11-02 07:23:31,128: t15.2023.10.13 val PER: 0.2684
2025-11-02 07:23:31,128: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:23:31,128: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:23:31,129: t15.2023.10.22 val PER: 0.1748
2025-11-02 07:23:31,129: t15.2023.11.03 val PER: 0.2280
2025-11-02 07:23:31,129: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:23:31,129: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:23:31,129: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:23:31,130: t15.2023.11.26 val PER: 0.2355
2025-11-02 07:23:31,130: t15.2023.12.03 val PER: 0.1712
2025-11-02 07:23:31,130: t15.2023.12.08 val PER: 0.1991
2025-11-02 07:23:31,130: t15.2023.12.10 val PER: 0.1603
2025-11-02 07:23:31,131: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:23:31,131: t15.2023.12.29 val PER: 0.2025
2025-11-02 07:23:31,131: t15.2024.02.25 val PER: 0.1601
2025-11-02 07:23:31,131: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:23:31,131: t15.2024.03.15 val PER: 0.2789
2025-11-02 07:23:31,132: t15.2024.03.17 val PER: 0.2169
2025-11-02 07:23:31,132: t15.2024.05.10 val PER: 0.2095
2025-11-02 07:23:31,132: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:23:31,132: t15.2024.07.19 val PER: 0.2947
2025-11-02 07:23:31,132: t15.2024.07.21 val PER: 0.1524
2025-11-02 07:23:31,133: t15.2024.07.28 val PER: 0.1897
2025-11-02 07:23:31,133: t15.2025.01.10 val PER: 0.3719
2025-11-02 07:23:31,133: t15.2025.01.12 val PER: 0.2240
2025-11-02 07:23:31,133: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:23:31,134: t15.2025.03.16 val PER: 0.2696
2025-11-02 07:23:31,134: t15.2025.03.30 val PER: 0.3414
2025-11-02 07:23:31,134: t15.2025.04.13 val PER: 0.2910
2025-11-02 07:23:31,134: New best test PER 0.2134 --> 0.2130
2025-11-02 07:23:31,134: Checkpointing model
2025-11-02 07:23:32,428: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:23:57,930: Train batch 101200: loss: 16.89 grad norm: 71.79 time: 0.064
2025-11-02 07:24:23,712: Train batch 101400: loss: 13.44 grad norm: 49.00 time: 0.079
2025-11-02 07:24:49,724: Train batch 101600: loss: 13.30 grad norm: 48.18 time: 0.066
2025-11-02 07:25:16,224: Train batch 101800: loss: 15.63 grad norm: 57.02 time: 0.087
2025-11-02 07:25:42,822: Train batch 102000: loss: 11.35 grad norm: 49.33 time: 0.069
2025-11-02 07:25:42,823: Running test after training batch: 102000
2025-11-02 07:25:55,263: Val batch 102000: PER (avg): 0.2129 CTC Loss (avg): 22.5505 time: 12.440
2025-11-02 07:25:55,263: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:25:55,284: t15.2023.08.18 val PER: 0.1643
2025-11-02 07:25:55,286: t15.2023.08.20 val PER: 0.1708
2025-11-02 07:25:55,286: t15.2023.08.25 val PER: 0.1596
2025-11-02 07:25:55,288: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:25:55,288: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:25:55,289: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:25:55,289: t15.2023.09.24 val PER: 0.1638
2025-11-02 07:25:55,289: t15.2023.09.29 val PER: 0.1736
2025-11-02 07:25:55,289: t15.2023.10.01 val PER: 0.2279
2025-11-02 07:25:55,290: t15.2023.10.06 val PER: 0.1518
2025-11-02 07:25:55,290: t15.2023.10.08 val PER: 0.2693
2025-11-02 07:25:55,290: t15.2023.10.13 val PER: 0.2708
2025-11-02 07:25:55,291: t15.2023.10.15 val PER: 0.2050
2025-11-02 07:25:55,291: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:25:55,291: t15.2023.10.22 val PER: 0.1759
2025-11-02 07:25:55,291: t15.2023.11.03 val PER: 0.2286
2025-11-02 07:25:55,291: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:25:55,292: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:25:55,292: t15.2023.11.19 val PER: 0.0938
2025-11-02 07:25:55,292: t15.2023.11.26 val PER: 0.2333
2025-11-02 07:25:55,292: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:25:55,292: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:25:55,293: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:25:55,293: t15.2023.12.17 val PER: 0.2214
2025-11-02 07:25:55,293: t15.2023.12.29 val PER: 0.2011
2025-11-02 07:25:55,293: t15.2024.02.25 val PER: 0.1615
2025-11-02 07:25:55,293: t15.2024.03.08 val PER: 0.2916
2025-11-02 07:25:55,294: t15.2024.03.15 val PER: 0.2739
2025-11-02 07:25:55,294: t15.2024.03.17 val PER: 0.2141
2025-11-02 07:25:55,294: t15.2024.05.10 val PER: 0.2125
2025-11-02 07:25:55,294: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:25:55,295: t15.2024.07.19 val PER: 0.3019
2025-11-02 07:25:55,295: t15.2024.07.21 val PER: 0.1531
2025-11-02 07:25:55,295: t15.2024.07.28 val PER: 0.1934
2025-11-02 07:25:55,296: t15.2025.01.10 val PER: 0.3678
2025-11-02 07:25:55,296: t15.2025.01.12 val PER: 0.2256
2025-11-02 07:25:55,297: t15.2025.03.14 val PER: 0.4009
2025-11-02 07:25:55,297: t15.2025.03.16 val PER: 0.2736
2025-11-02 07:25:55,297: t15.2025.03.30 val PER: 0.3402
2025-11-02 07:25:55,298: t15.2025.04.13 val PER: 0.2896
2025-11-02 07:25:55,298: New best test PER 0.2130 --> 0.2129
2025-11-02 07:25:55,298: Checkpointing model
2025-11-02 07:25:56,552: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:26:21,728: Train batch 102200: loss: 13.06 grad norm: 54.49 time: 0.075
2025-11-02 07:26:46,850: Train batch 102400: loss: 14.09 grad norm: 59.47 time: 0.080
2025-11-02 07:27:12,135: Train batch 102600: loss: 16.82 grad norm: 58.58 time: 0.066
2025-11-02 07:27:36,778: Train batch 102800: loss: 13.85 grad norm: 50.69 time: 0.112
2025-11-02 07:28:01,319: Train batch 103000: loss: 10.47 grad norm: 50.24 time: 0.064
2025-11-02 07:28:01,321: Running test after training batch: 103000
2025-11-02 07:28:13,458: Val batch 103000: PER (avg): 0.2129 CTC Loss (avg): 22.5500 time: 12.137
2025-11-02 07:28:13,459: t15.2023.08.13 val PER: 0.1580
2025-11-02 07:28:13,459: t15.2023.08.18 val PER: 0.1710
2025-11-02 07:28:13,459: t15.2023.08.20 val PER: 0.1660
2025-11-02 07:28:13,460: t15.2023.08.25 val PER: 0.1611
2025-11-02 07:28:13,460: t15.2023.08.27 val PER: 0.2412
2025-11-02 07:28:13,460: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:28:13,461: t15.2023.09.03 val PER: 0.2126
2025-11-02 07:28:13,484: t15.2023.09.24 val PER: 0.1663
2025-11-02 07:28:13,484: t15.2023.09.29 val PER: 0.1729
2025-11-02 07:28:13,484: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:28:13,484: t15.2023.10.06 val PER: 0.1496
2025-11-02 07:28:13,485: t15.2023.10.08 val PER: 0.2679
2025-11-02 07:28:13,485: t15.2023.10.13 val PER: 0.2676
2025-11-02 07:28:13,485: t15.2023.10.15 val PER: 0.2070
2025-11-02 07:28:13,486: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:28:13,486: t15.2023.10.22 val PER: 0.1793
2025-11-02 07:28:13,486: t15.2023.11.03 val PER: 0.2252
2025-11-02 07:28:13,486: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:28:13,486: t15.2023.11.17 val PER: 0.0824
2025-11-02 07:28:13,487: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:28:13,487: t15.2023.11.26 val PER: 0.2341
2025-11-02 07:28:13,487: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:28:13,488: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:28:13,488: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:28:13,488: t15.2023.12.17 val PER: 0.2256
2025-11-02 07:28:13,488: t15.2023.12.29 val PER: 0.2045
2025-11-02 07:28:13,488: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:28:13,489: t15.2024.03.08 val PER: 0.2916
2025-11-02 07:28:13,489: t15.2024.03.15 val PER: 0.2745
2025-11-02 07:28:13,489: t15.2024.03.17 val PER: 0.2169
2025-11-02 07:28:13,489: t15.2024.05.10 val PER: 0.2110
2025-11-02 07:28:13,489: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:28:13,490: t15.2024.07.19 val PER: 0.3006
2025-11-02 07:28:13,490: t15.2024.07.21 val PER: 0.1497
2025-11-02 07:28:13,490: t15.2024.07.28 val PER: 0.1904
2025-11-02 07:28:13,491: t15.2025.01.10 val PER: 0.3678
2025-11-02 07:28:13,491: t15.2025.01.12 val PER: 0.2232
2025-11-02 07:28:13,491: t15.2025.03.14 val PER: 0.4053
2025-11-02 07:28:13,491: t15.2025.03.16 val PER: 0.2657
2025-11-02 07:28:13,491: t15.2025.03.30 val PER: 0.3460
2025-11-02 07:28:13,492: t15.2025.04.13 val PER: 0.2910
2025-11-02 07:28:13,492: New best test PER 0.2129 --> 0.2129
2025-11-02 07:28:13,492: Checkpointing model
2025-11-02 07:28:14,854: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:28:39,910: Train batch 103200: loss: 14.11 grad norm: 53.10 time: 0.096
2025-11-02 07:29:05,236: Train batch 103400: loss: 11.56 grad norm: 44.09 time: 0.083
2025-11-02 07:29:30,133: Train batch 103600: loss: 8.43 grad norm: 37.37 time: 0.055
2025-11-02 07:29:55,886: Train batch 103800: loss: 15.09 grad norm: 51.84 time: 0.081
2025-11-02 07:30:20,135: Train batch 104000: loss: 9.83 grad norm: 51.88 time: 0.073
2025-11-02 07:30:20,136: Running test after training batch: 104000
2025-11-02 07:30:32,326: Val batch 104000: PER (avg): 0.2130 CTC Loss (avg): 22.5266 time: 12.190
2025-11-02 07:30:32,327: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:30:32,327: t15.2023.08.18 val PER: 0.1702
2025-11-02 07:30:32,328: t15.2023.08.20 val PER: 0.1692
2025-11-02 07:30:32,328: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:30:32,328: t15.2023.08.27 val PER: 0.2428
2025-11-02 07:30:32,328: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:30:32,329: t15.2023.09.03 val PER: 0.2078
2025-11-02 07:30:32,329: t15.2023.09.24 val PER: 0.1663
2025-11-02 07:30:32,329: t15.2023.09.29 val PER: 0.1749
2025-11-02 07:30:32,329: t15.2023.10.01 val PER: 0.2292
2025-11-02 07:30:32,330: t15.2023.10.06 val PER: 0.1518
2025-11-02 07:30:32,330: t15.2023.10.08 val PER: 0.2625
2025-11-02 07:30:32,331: t15.2023.10.13 val PER: 0.2692
2025-11-02 07:30:32,331: t15.2023.10.15 val PER: 0.2024
2025-11-02 07:30:32,331: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:30:32,331: t15.2023.10.22 val PER: 0.1715
2025-11-02 07:30:32,332: t15.2023.11.03 val PER: 0.2246
2025-11-02 07:30:32,332: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:30:32,332: t15.2023.11.17 val PER: 0.0824
2025-11-02 07:30:32,332: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:30:32,333: t15.2023.11.26 val PER: 0.2348
2025-11-02 07:30:32,333: t15.2023.12.03 val PER: 0.1712
2025-11-02 07:30:32,333: t15.2023.12.08 val PER: 0.1997
2025-11-02 07:30:32,333: t15.2023.12.10 val PER: 0.1629
2025-11-02 07:30:32,334: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:30:32,334: t15.2023.12.29 val PER: 0.2025
2025-11-02 07:30:32,334: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:30:32,334: t15.2024.03.08 val PER: 0.2902
2025-11-02 07:30:32,334: t15.2024.03.15 val PER: 0.2758
2025-11-02 07:30:32,335: t15.2024.03.17 val PER: 0.2211
2025-11-02 07:30:32,335: t15.2024.05.10 val PER: 0.2110
2025-11-02 07:30:32,335: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:30:32,336: t15.2024.07.19 val PER: 0.3006
2025-11-02 07:30:32,336: t15.2024.07.21 val PER: 0.1490
2025-11-02 07:30:32,336: t15.2024.07.28 val PER: 0.1934
2025-11-02 07:30:32,336: t15.2025.01.10 val PER: 0.3747
2025-11-02 07:30:32,336: t15.2025.01.12 val PER: 0.2225
2025-11-02 07:30:32,337: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:30:32,337: t15.2025.03.16 val PER: 0.2683
2025-11-02 07:30:32,337: t15.2025.03.30 val PER: 0.3425
2025-11-02 07:30:32,338: t15.2025.04.13 val PER: 0.2924
2025-11-02 07:30:55,829: Train batch 104200: loss: 14.51 grad norm: 57.34 time: 0.057
2025-11-02 07:31:21,869: Train batch 104400: loss: 10.16 grad norm: 45.08 time: 0.064
2025-11-02 07:31:46,953: Train batch 104600: loss: 11.11 grad norm: 46.58 time: 0.105
2025-11-02 07:32:11,497: Train batch 104800: loss: 15.20 grad norm: 56.80 time: 0.081
2025-11-02 07:32:35,170: Train batch 105000: loss: 12.03 grad norm: 49.41 time: 0.071
2025-11-02 07:32:35,171: Running test after training batch: 105000
2025-11-02 07:32:46,558: Val batch 105000: PER (avg): 0.2132 CTC Loss (avg): 22.5369 time: 11.387
2025-11-02 07:32:46,559: t15.2023.08.13 val PER: 0.1601
2025-11-02 07:32:46,559: t15.2023.08.18 val PER: 0.1693
2025-11-02 07:32:46,559: t15.2023.08.20 val PER: 0.1652
2025-11-02 07:32:46,560: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:32:46,584: t15.2023.08.27 val PER: 0.2476
2025-11-02 07:32:46,584: t15.2023.09.01 val PER: 0.1128
2025-11-02 07:32:46,584: t15.2023.09.03 val PER: 0.2114
2025-11-02 07:32:46,585: t15.2023.09.24 val PER: 0.1650
2025-11-02 07:32:46,585: t15.2023.09.29 val PER: 0.1780
2025-11-02 07:32:46,586: t15.2023.10.01 val PER: 0.2252
2025-11-02 07:32:46,586: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:32:46,586: t15.2023.10.08 val PER: 0.2693
2025-11-02 07:32:46,587: t15.2023.10.13 val PER: 0.2700
2025-11-02 07:32:46,587: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:32:46,587: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:32:46,587: t15.2023.10.22 val PER: 0.1748
2025-11-02 07:32:46,588: t15.2023.11.03 val PER: 0.2286
2025-11-02 07:32:46,588: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:32:46,588: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:32:46,588: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:32:46,589: t15.2023.11.26 val PER: 0.2355
2025-11-02 07:32:46,589: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:32:46,589: t15.2023.12.08 val PER: 0.1971
2025-11-02 07:32:46,589: t15.2023.12.10 val PER: 0.1590
2025-11-02 07:32:46,590: t15.2023.12.17 val PER: 0.2235
2025-11-02 07:32:46,590: t15.2023.12.29 val PER: 0.2032
2025-11-02 07:32:46,590: t15.2024.02.25 val PER: 0.1559
2025-11-02 07:32:46,591: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:32:46,591: t15.2024.03.15 val PER: 0.2720
2025-11-02 07:32:46,592: t15.2024.03.17 val PER: 0.2204
2025-11-02 07:32:46,592: t15.2024.05.10 val PER: 0.2155
2025-11-02 07:32:46,592: t15.2024.06.14 val PER: 0.2397
2025-11-02 07:32:46,592: t15.2024.07.19 val PER: 0.2999
2025-11-02 07:32:46,593: t15.2024.07.21 val PER: 0.1510
2025-11-02 07:32:46,593: t15.2024.07.28 val PER: 0.1919
2025-11-02 07:32:46,593: t15.2025.01.10 val PER: 0.3747
2025-11-02 07:32:46,593: t15.2025.01.12 val PER: 0.2232
2025-11-02 07:32:46,593: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:32:46,594: t15.2025.03.16 val PER: 0.2683
2025-11-02 07:32:46,594: t15.2025.03.30 val PER: 0.3483
2025-11-02 07:32:46,594: t15.2025.04.13 val PER: 0.2924
2025-11-02 07:33:11,960: Train batch 105200: loss: 11.82 grad norm: 51.45 time: 0.067
2025-11-02 07:33:37,906: Train batch 105400: loss: 10.72 grad norm: 52.16 time: 0.088
2025-11-02 07:34:03,410: Train batch 105600: loss: 11.42 grad norm: 50.34 time: 0.070
2025-11-02 07:34:28,647: Train batch 105800: loss: 10.20 grad norm: 45.44 time: 0.078
2025-11-02 07:34:53,830: Train batch 106000: loss: 9.69 grad norm: 46.52 time: 0.078
2025-11-02 07:34:53,831: Running test after training batch: 106000
2025-11-02 07:35:05,518: Val batch 106000: PER (avg): 0.2129 CTC Loss (avg): 22.5467 time: 11.687
2025-11-02 07:35:05,519: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:35:05,520: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:35:05,520: t15.2023.08.20 val PER: 0.1684
2025-11-02 07:35:05,521: t15.2023.08.25 val PER: 0.1642
2025-11-02 07:35:05,521: t15.2023.08.27 val PER: 0.2460
2025-11-02 07:35:05,521: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:35:05,521: t15.2023.09.03 val PER: 0.2138
2025-11-02 07:35:05,522: t15.2023.09.24 val PER: 0.1663
2025-11-02 07:35:05,522: t15.2023.09.29 val PER: 0.1755
2025-11-02 07:35:05,522: t15.2023.10.01 val PER: 0.2279
2025-11-02 07:35:05,523: t15.2023.10.06 val PER: 0.1464
2025-11-02 07:35:05,524: t15.2023.10.08 val PER: 0.2625
2025-11-02 07:35:05,524: t15.2023.10.13 val PER: 0.2692
2025-11-02 07:35:05,524: t15.2023.10.15 val PER: 0.2024
2025-11-02 07:35:05,525: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:35:05,525: t15.2023.10.22 val PER: 0.1793
2025-11-02 07:35:05,526: t15.2023.11.03 val PER: 0.2259
2025-11-02 07:35:05,526: t15.2023.11.04 val PER: 0.0546
2025-11-02 07:35:05,526: t15.2023.11.17 val PER: 0.0855
2025-11-02 07:35:05,526: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:35:05,527: t15.2023.11.26 val PER: 0.2319
2025-11-02 07:35:05,527: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:35:05,527: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:35:05,527: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:35:05,528: t15.2023.12.17 val PER: 0.2204
2025-11-02 07:35:05,528: t15.2023.12.29 val PER: 0.2018
2025-11-02 07:35:05,528: t15.2024.02.25 val PER: 0.1559
2025-11-02 07:35:05,528: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:35:05,528: t15.2024.03.15 val PER: 0.2758
2025-11-02 07:35:05,529: t15.2024.03.17 val PER: 0.2176
2025-11-02 07:35:05,529: t15.2024.05.10 val PER: 0.2140
2025-11-02 07:35:05,529: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:35:05,529: t15.2024.07.19 val PER: 0.2966
2025-11-02 07:35:05,530: t15.2024.07.21 val PER: 0.1510
2025-11-02 07:35:05,530: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:35:05,530: t15.2025.01.10 val PER: 0.3774
2025-11-02 07:35:05,531: t15.2025.01.12 val PER: 0.2232
2025-11-02 07:35:05,531: t15.2025.03.14 val PER: 0.4038
2025-11-02 07:35:05,531: t15.2025.03.16 val PER: 0.2683
2025-11-02 07:35:05,531: t15.2025.03.30 val PER: 0.3460
2025-11-02 07:35:05,532: t15.2025.04.13 val PER: 0.2939
2025-11-02 07:35:31,124: Train batch 106200: loss: 12.67 grad norm: 50.33 time: 0.067
2025-11-02 07:35:57,215: Train batch 106400: loss: 10.97 grad norm: 51.64 time: 0.068
2025-11-02 07:36:23,377: Train batch 106600: loss: 11.94 grad norm: 47.01 time: 0.057
2025-11-02 07:36:49,367: Train batch 106800: loss: 10.21 grad norm: 41.96 time: 0.058
2025-11-02 07:37:14,972: Train batch 107000: loss: 13.60 grad norm: 49.25 time: 0.075
2025-11-02 07:37:14,973: Running test after training batch: 107000
2025-11-02 07:37:26,123: Val batch 107000: PER (avg): 0.2131 CTC Loss (avg): 22.5298 time: 11.150
2025-11-02 07:37:26,124: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:37:26,124: t15.2023.08.18 val PER: 0.1693
2025-11-02 07:37:26,124: t15.2023.08.20 val PER: 0.1676
2025-11-02 07:37:26,124: t15.2023.08.25 val PER: 0.1672
2025-11-02 07:37:26,125: t15.2023.08.27 val PER: 0.2476
2025-11-02 07:37:26,125: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:37:26,126: t15.2023.09.03 val PER: 0.2067
2025-11-02 07:37:26,126: t15.2023.09.24 val PER: 0.1638
2025-11-02 07:37:26,126: t15.2023.09.29 val PER: 0.1761
2025-11-02 07:37:26,126: t15.2023.10.01 val PER: 0.2259
2025-11-02 07:37:26,127: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:37:26,127: t15.2023.10.08 val PER: 0.2598
2025-11-02 07:37:26,127: t15.2023.10.13 val PER: 0.2669
2025-11-02 07:37:26,127: t15.2023.10.15 val PER: 0.2063
2025-11-02 07:37:26,128: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:37:26,128: t15.2023.10.22 val PER: 0.1815
2025-11-02 07:37:26,128: t15.2023.11.03 val PER: 0.2280
2025-11-02 07:37:26,128: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:37:26,128: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:37:26,129: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:37:26,129: t15.2023.11.26 val PER: 0.2341
2025-11-02 07:37:26,129: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:37:26,129: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:37:26,129: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:37:26,130: t15.2023.12.17 val PER: 0.2245
2025-11-02 07:37:26,130: t15.2023.12.29 val PER: 0.2004
2025-11-02 07:37:26,130: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:37:26,131: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:37:26,131: t15.2024.03.15 val PER: 0.2758
2025-11-02 07:37:26,131: t15.2024.03.17 val PER: 0.2169
2025-11-02 07:37:26,131: t15.2024.05.10 val PER: 0.2125
2025-11-02 07:37:26,131: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:37:26,132: t15.2024.07.19 val PER: 0.3006
2025-11-02 07:37:26,132: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:37:26,132: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:37:26,132: t15.2025.01.10 val PER: 0.3733
2025-11-02 07:37:26,133: t15.2025.01.12 val PER: 0.2240
2025-11-02 07:37:26,133: t15.2025.03.14 val PER: 0.4038
2025-11-02 07:37:26,133: t15.2025.03.16 val PER: 0.2709
2025-11-02 07:37:26,133: t15.2025.03.30 val PER: 0.3448
2025-11-02 07:37:26,133: t15.2025.04.13 val PER: 0.2953
2025-11-02 07:37:51,163: Train batch 107200: loss: 12.31 grad norm: 51.88 time: 0.076
2025-11-02 07:38:21,364: Train batch 107400: loss: 8.18 grad norm: 41.26 time: 0.068
2025-11-02 07:38:55,012: Train batch 107600: loss: 11.34 grad norm: 43.70 time: 0.086
2025-11-02 07:39:27,891: Train batch 107800: loss: 12.80 grad norm: 57.78 time: 0.079
2025-11-02 07:40:01,026: Train batch 108000: loss: 9.23 grad norm: 37.72 time: 0.101
2025-11-02 07:40:01,027: Running test after training batch: 108000
2025-11-02 07:40:15,621: Val batch 108000: PER (avg): 0.2125 CTC Loss (avg): 22.5160 time: 14.594
2025-11-02 07:40:15,622: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:40:15,623: t15.2023.08.18 val PER: 0.1643
2025-11-02 07:40:15,623: t15.2023.08.20 val PER: 0.1708
2025-11-02 07:40:15,623: t15.2023.08.25 val PER: 0.1672
2025-11-02 07:40:15,624: t15.2023.08.27 val PER: 0.2460
2025-11-02 07:40:15,624: t15.2023.09.01 val PER: 0.1136
2025-11-02 07:40:15,624: t15.2023.09.03 val PER: 0.2078
2025-11-02 07:40:15,625: t15.2023.09.24 val PER: 0.1626
2025-11-02 07:40:15,625: t15.2023.09.29 val PER: 0.1717
2025-11-02 07:40:15,625: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:40:15,626: t15.2023.10.06 val PER: 0.1485
2025-11-02 07:40:15,626: t15.2023.10.08 val PER: 0.2639
2025-11-02 07:40:15,626: t15.2023.10.13 val PER: 0.2684
2025-11-02 07:40:15,626: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:40:15,627: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:40:15,627: t15.2023.10.22 val PER: 0.1793
2025-11-02 07:40:15,627: t15.2023.11.03 val PER: 0.2252
2025-11-02 07:40:15,627: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:40:15,628: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:40:15,628: t15.2023.11.19 val PER: 0.0978
2025-11-02 07:40:15,628: t15.2023.11.26 val PER: 0.2326
2025-11-02 07:40:15,628: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:40:15,628: t15.2023.12.08 val PER: 0.1997
2025-11-02 07:40:15,629: t15.2023.12.10 val PER: 0.1629
2025-11-02 07:40:15,629: t15.2023.12.17 val PER: 0.2214
2025-11-02 07:40:15,629: t15.2023.12.29 val PER: 0.2018
2025-11-02 07:40:15,629: t15.2024.02.25 val PER: 0.1601
2025-11-02 07:40:15,630: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:40:15,630: t15.2024.03.15 val PER: 0.2752
2025-11-02 07:40:15,630: t15.2024.03.17 val PER: 0.2141
2025-11-02 07:40:15,631: t15.2024.05.10 val PER: 0.2184
2025-11-02 07:40:15,631: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:40:15,631: t15.2024.07.19 val PER: 0.2993
2025-11-02 07:40:15,631: t15.2024.07.21 val PER: 0.1503
2025-11-02 07:40:15,632: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:40:15,632: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:40:15,632: t15.2025.01.12 val PER: 0.2225
2025-11-02 07:40:15,632: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:40:15,633: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:40:15,633: t15.2025.03.30 val PER: 0.3414
2025-11-02 07:40:15,633: t15.2025.04.13 val PER: 0.2953
2025-11-02 07:40:15,633: New best test PER 0.2129 --> 0.2125
2025-11-02 07:40:15,633: Checkpointing model
2025-11-02 07:40:16,892: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:40:41,334: Train batch 108200: loss: 15.16 grad norm: 59.84 time: 0.078
2025-11-02 07:41:07,419: Train batch 108400: loss: 10.33 grad norm: 46.71 time: 0.058
2025-11-02 07:41:34,411: Train batch 108600: loss: 19.73 grad norm: 68.11 time: 0.069
2025-11-02 07:42:02,574: Train batch 108800: loss: 10.36 grad norm: 41.52 time: 0.080
2025-11-02 07:42:29,924: Train batch 109000: loss: 12.29 grad norm: 49.63 time: 0.098
2025-11-02 07:42:29,925: Running test after training batch: 109000
2025-11-02 07:42:41,347: Val batch 109000: PER (avg): 0.2127 CTC Loss (avg): 22.5189 time: 11.422
2025-11-02 07:42:41,348: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:42:41,348: t15.2023.08.18 val PER: 0.1668
2025-11-02 07:42:41,349: t15.2023.08.20 val PER: 0.1700
2025-11-02 07:42:41,349: t15.2023.08.25 val PER: 0.1657
2025-11-02 07:42:41,384: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:42:41,384: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:42:41,385: t15.2023.09.03 val PER: 0.2114
2025-11-02 07:42:41,386: t15.2023.09.24 val PER: 0.1663
2025-11-02 07:42:41,386: t15.2023.09.29 val PER: 0.1717
2025-11-02 07:42:41,386: t15.2023.10.01 val PER: 0.2259
2025-11-02 07:42:41,387: t15.2023.10.06 val PER: 0.1507
2025-11-02 07:42:41,387: t15.2023.10.08 val PER: 0.2612
2025-11-02 07:42:41,388: t15.2023.10.13 val PER: 0.2676
2025-11-02 07:42:41,388: t15.2023.10.15 val PER: 0.2057
2025-11-02 07:42:41,388: t15.2023.10.20 val PER: 0.2047
2025-11-02 07:42:41,388: t15.2023.10.22 val PER: 0.1782
2025-11-02 07:42:41,389: t15.2023.11.03 val PER: 0.2239
2025-11-02 07:42:41,389: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:42:41,390: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:42:41,390: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:42:41,391: t15.2023.11.26 val PER: 0.2333
2025-11-02 07:42:41,391: t15.2023.12.03 val PER: 0.1712
2025-11-02 07:42:41,392: t15.2023.12.08 val PER: 0.1991
2025-11-02 07:42:41,392: t15.2023.12.10 val PER: 0.1629
2025-11-02 07:42:41,392: t15.2023.12.17 val PER: 0.2266
2025-11-02 07:42:41,393: t15.2023.12.29 val PER: 0.2032
2025-11-02 07:42:41,393: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:42:41,393: t15.2024.03.08 val PER: 0.2859
2025-11-02 07:42:41,394: t15.2024.03.15 val PER: 0.2764
2025-11-02 07:42:41,394: t15.2024.03.17 val PER: 0.2134
2025-11-02 07:42:41,394: t15.2024.05.10 val PER: 0.2110
2025-11-02 07:42:41,395: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:42:41,395: t15.2024.07.19 val PER: 0.2999
2025-11-02 07:42:41,396: t15.2024.07.21 val PER: 0.1510
2025-11-02 07:42:41,396: t15.2024.07.28 val PER: 0.1934
2025-11-02 07:42:41,397: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:42:41,397: t15.2025.01.12 val PER: 0.2232
2025-11-02 07:42:41,398: t15.2025.03.14 val PER: 0.4009
2025-11-02 07:42:41,398: t15.2025.03.16 val PER: 0.2644
2025-11-02 07:42:41,398: t15.2025.03.30 val PER: 0.3425
2025-11-02 07:42:41,399: t15.2025.04.13 val PER: 0.2953
2025-11-02 07:43:09,250: Train batch 109200: loss: 13.04 grad norm: 53.91 time: 0.050
2025-11-02 07:43:34,142: Train batch 109400: loss: 14.26 grad norm: 52.02 time: 0.092
2025-11-02 07:43:58,699: Train batch 109600: loss: 10.01 grad norm: 50.74 time: 0.068
2025-11-02 07:44:24,571: Train batch 109800: loss: 12.35 grad norm: 91.53 time: 0.081
2025-11-02 07:44:50,515: Train batch 110000: loss: 13.21 grad norm: 48.85 time: 0.056
2025-11-02 07:44:50,516: Running test after training batch: 110000
2025-11-02 07:45:04,574: Val batch 110000: PER (avg): 0.2122 CTC Loss (avg): 22.5150 time: 14.058
2025-11-02 07:45:04,575: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:45:04,575: t15.2023.08.18 val PER: 0.1710
2025-11-02 07:45:04,576: t15.2023.08.20 val PER: 0.1676
2025-11-02 07:45:04,576: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:45:04,576: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:45:04,576: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:45:04,577: t15.2023.09.03 val PER: 0.2090
2025-11-02 07:45:04,577: t15.2023.09.24 val PER: 0.1626
2025-11-02 07:45:04,577: t15.2023.09.29 val PER: 0.1717
2025-11-02 07:45:04,583: t15.2023.10.01 val PER: 0.2279
2025-11-02 07:45:04,584: t15.2023.10.06 val PER: 0.1485
2025-11-02 07:45:04,584: t15.2023.10.08 val PER: 0.2693
2025-11-02 07:45:04,584: t15.2023.10.13 val PER: 0.2708
2025-11-02 07:45:04,585: t15.2023.10.15 val PER: 0.2024
2025-11-02 07:45:04,585: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:45:04,586: t15.2023.10.22 val PER: 0.1793
2025-11-02 07:45:04,586: t15.2023.11.03 val PER: 0.2232
2025-11-02 07:45:04,586: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:45:04,586: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:45:04,587: t15.2023.11.19 val PER: 0.0918
2025-11-02 07:45:04,587: t15.2023.11.26 val PER: 0.2333
2025-11-02 07:45:04,587: t15.2023.12.03 val PER: 0.1691
2025-11-02 07:45:04,588: t15.2023.12.08 val PER: 0.1964
2025-11-02 07:45:04,588: t15.2023.12.10 val PER: 0.1629
2025-11-02 07:45:04,588: t15.2023.12.17 val PER: 0.2225
2025-11-02 07:45:04,588: t15.2023.12.29 val PER: 0.1997
2025-11-02 07:45:04,589: t15.2024.02.25 val PER: 0.1559
2025-11-02 07:45:04,589: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:45:04,589: t15.2024.03.15 val PER: 0.2745
2025-11-02 07:45:04,589: t15.2024.03.17 val PER: 0.2148
2025-11-02 07:45:04,590: t15.2024.05.10 val PER: 0.2125
2025-11-02 07:45:04,590: t15.2024.06.14 val PER: 0.2382
2025-11-02 07:45:04,590: t15.2024.07.19 val PER: 0.3013
2025-11-02 07:45:04,591: t15.2024.07.21 val PER: 0.1497
2025-11-02 07:45:04,591: t15.2024.07.28 val PER: 0.1919
2025-11-02 07:45:04,591: t15.2025.01.10 val PER: 0.3691
2025-11-02 07:45:04,591: t15.2025.01.12 val PER: 0.2202
2025-11-02 07:45:04,592: t15.2025.03.14 val PER: 0.3994
2025-11-02 07:45:04,592: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:45:04,592: t15.2025.03.30 val PER: 0.3448
2025-11-02 07:45:04,592: t15.2025.04.13 val PER: 0.2953
2025-11-02 07:45:04,593: New best test PER 0.2125 --> 0.2122
2025-11-02 07:45:04,593: Checkpointing model
2025-11-02 07:45:06,504: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:45:36,622: Train batch 110200: loss: 15.44 grad norm: 60.08 time: 0.059
2025-11-02 07:46:06,624: Train batch 110400: loss: 13.01 grad norm: 52.68 time: 0.097
2025-11-02 07:46:37,763: Train batch 110600: loss: 12.30 grad norm: 50.78 time: 0.080
2025-11-02 07:47:06,894: Train batch 110800: loss: 10.83 grad norm: 48.67 time: 0.088
2025-11-02 07:47:34,903: Train batch 111000: loss: 15.06 grad norm: 56.95 time: 0.100
2025-11-02 07:47:34,904: Running test after training batch: 111000
2025-11-02 07:47:52,056: Val batch 111000: PER (avg): 0.2123 CTC Loss (avg): 22.5109 time: 17.152
2025-11-02 07:47:52,057: t15.2023.08.13 val PER: 0.1559
2025-11-02 07:47:52,057: t15.2023.08.18 val PER: 0.1693
2025-11-02 07:47:52,058: t15.2023.08.20 val PER: 0.1668
2025-11-02 07:47:52,058: t15.2023.08.25 val PER: 0.1596
2025-11-02 07:47:52,058: t15.2023.08.27 val PER: 0.2460
2025-11-02 07:47:52,059: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:47:52,059: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:47:52,059: t15.2023.09.24 val PER: 0.1626
2025-11-02 07:47:52,060: t15.2023.09.29 val PER: 0.1736
2025-11-02 07:47:52,060: t15.2023.10.01 val PER: 0.2239
2025-11-02 07:47:52,061: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:47:52,061: t15.2023.10.08 val PER: 0.2666
2025-11-02 07:47:52,061: t15.2023.10.13 val PER: 0.2684
2025-11-02 07:47:52,062: t15.2023.10.15 val PER: 0.2017
2025-11-02 07:47:52,062: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:47:52,062: t15.2023.10.22 val PER: 0.1771
2025-11-02 07:47:52,063: t15.2023.11.03 val PER: 0.2259
2025-11-02 07:47:52,063: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:47:52,064: t15.2023.11.17 val PER: 0.0840
2025-11-02 07:47:52,064: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:47:52,064: t15.2023.11.26 val PER: 0.2312
2025-11-02 07:47:52,064: t15.2023.12.03 val PER: 0.1702
2025-11-02 07:47:52,065: t15.2023.12.08 val PER: 0.1964
2025-11-02 07:47:52,065: t15.2023.12.10 val PER: 0.1656
2025-11-02 07:47:52,066: t15.2023.12.17 val PER: 0.2266
2025-11-02 07:47:52,066: t15.2023.12.29 val PER: 0.2018
2025-11-02 07:47:52,066: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:47:52,067: t15.2024.03.08 val PER: 0.2873
2025-11-02 07:47:52,067: t15.2024.03.15 val PER: 0.2733
2025-11-02 07:47:52,068: t15.2024.03.17 val PER: 0.2141
2025-11-02 07:47:52,068: t15.2024.05.10 val PER: 0.2140
2025-11-02 07:47:52,068: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:47:52,069: t15.2024.07.19 val PER: 0.3039
2025-11-02 07:47:52,069: t15.2024.07.21 val PER: 0.1510
2025-11-02 07:47:52,070: t15.2024.07.28 val PER: 0.1926
2025-11-02 07:47:52,070: t15.2025.01.10 val PER: 0.3691
2025-11-02 07:47:52,071: t15.2025.01.12 val PER: 0.2240
2025-11-02 07:47:52,071: t15.2025.03.14 val PER: 0.3979
2025-11-02 07:47:52,071: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:47:52,072: t15.2025.03.30 val PER: 0.3448
2025-11-02 07:47:52,072: t15.2025.04.13 val PER: 0.2924
2025-11-02 07:48:22,277: Train batch 111200: loss: 9.56 grad norm: 46.29 time: 0.084
2025-11-02 07:48:54,218: Train batch 111400: loss: 7.45 grad norm: 37.87 time: 0.095
2025-11-02 07:49:25,241: Train batch 111600: loss: 14.57 grad norm: 64.55 time: 0.118
2025-11-02 07:49:56,080: Train batch 111800: loss: 13.09 grad norm: 52.22 time: 0.107
2025-11-02 07:50:29,932: Train batch 112000: loss: 8.93 grad norm: 38.40 time: 0.060
2025-11-02 07:50:29,933: Running test after training batch: 112000
2025-11-02 07:50:46,449: Val batch 112000: PER (avg): 0.2120 CTC Loss (avg): 22.4998 time: 16.516
2025-11-02 07:50:46,450: t15.2023.08.13 val PER: 0.1570
2025-11-02 07:50:46,451: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:50:46,451: t15.2023.08.20 val PER: 0.1684
2025-11-02 07:50:46,452: t15.2023.08.25 val PER: 0.1627
2025-11-02 07:50:46,452: t15.2023.08.27 val PER: 0.2444
2025-11-02 07:50:46,453: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:50:46,453: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:50:46,453: t15.2023.09.24 val PER: 0.1638
2025-11-02 07:50:46,454: t15.2023.09.29 val PER: 0.1710
2025-11-02 07:50:46,454: t15.2023.10.01 val PER: 0.2259
2025-11-02 07:50:46,454: t15.2023.10.06 val PER: 0.1453
2025-11-02 07:50:46,455: t15.2023.10.08 val PER: 0.2652
2025-11-02 07:50:46,455: t15.2023.10.13 val PER: 0.2708
2025-11-02 07:50:46,456: t15.2023.10.15 val PER: 0.2017
2025-11-02 07:50:46,456: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:50:46,456: t15.2023.10.22 val PER: 0.1793
2025-11-02 07:50:46,456: t15.2023.11.03 val PER: 0.2239
2025-11-02 07:50:46,457: t15.2023.11.04 val PER: 0.0580
2025-11-02 07:50:46,457: t15.2023.11.17 val PER: 0.0824
2025-11-02 07:50:46,457: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:50:46,457: t15.2023.11.26 val PER: 0.2326
2025-11-02 07:50:46,458: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:50:46,458: t15.2023.12.08 val PER: 0.1977
2025-11-02 07:50:46,458: t15.2023.12.10 val PER: 0.1643
2025-11-02 07:50:46,459: t15.2023.12.17 val PER: 0.2235
2025-11-02 07:50:46,459: t15.2023.12.29 val PER: 0.1984
2025-11-02 07:50:46,459: t15.2024.02.25 val PER: 0.1559
2025-11-02 07:50:46,459: t15.2024.03.08 val PER: 0.2845
2025-11-02 07:50:46,460: t15.2024.03.15 val PER: 0.2733
2025-11-02 07:50:46,460: t15.2024.03.17 val PER: 0.2162
2025-11-02 07:50:46,461: t15.2024.05.10 val PER: 0.2125
2025-11-02 07:50:46,461: t15.2024.06.14 val PER: 0.2350
2025-11-02 07:50:46,461: t15.2024.07.19 val PER: 0.3019
2025-11-02 07:50:46,462: t15.2024.07.21 val PER: 0.1517
2025-11-02 07:50:46,462: t15.2024.07.28 val PER: 0.1919
2025-11-02 07:50:46,462: t15.2025.01.10 val PER: 0.3691
2025-11-02 07:50:46,462: t15.2025.01.12 val PER: 0.2209
2025-11-02 07:50:46,463: t15.2025.03.14 val PER: 0.3964
2025-11-02 07:50:46,463: t15.2025.03.16 val PER: 0.2683
2025-11-02 07:50:46,463: t15.2025.03.30 val PER: 0.3437
2025-11-02 07:50:46,463: t15.2025.04.13 val PER: 0.2981
2025-11-02 07:50:46,464: New best test PER 0.2122 --> 0.2120
2025-11-02 07:50:46,464: Checkpointing model
2025-11-02 07:50:48,710: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:51:17,986: Train batch 112200: loss: 14.61 grad norm: 74.92 time: 0.076
2025-11-02 07:51:47,774: Train batch 112400: loss: 10.04 grad norm: 48.97 time: 0.073
2025-11-02 07:52:19,397: Train batch 112600: loss: 13.63 grad norm: 57.06 time: 0.095
2025-11-02 07:52:50,419: Train batch 112800: loss: 12.65 grad norm: 52.33 time: 0.089
2025-11-02 07:53:20,638: Train batch 113000: loss: 9.99 grad norm: 47.79 time: 0.083
2025-11-02 07:53:20,639: Running test after training batch: 113000
2025-11-02 07:53:34,964: Val batch 113000: PER (avg): 0.2118 CTC Loss (avg): 22.4977 time: 14.323
2025-11-02 07:53:34,965: t15.2023.08.13 val PER: 0.1549
2025-11-02 07:53:34,966: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:53:34,966: t15.2023.08.20 val PER: 0.1660
2025-11-02 07:53:34,966: t15.2023.08.25 val PER: 0.1611
2025-11-02 07:53:34,967: t15.2023.08.27 val PER: 0.2460
2025-11-02 07:53:34,967: t15.2023.09.01 val PER: 0.1144
2025-11-02 07:53:34,967: t15.2023.09.03 val PER: 0.2102
2025-11-02 07:53:34,968: t15.2023.09.24 val PER: 0.1687
2025-11-02 07:53:34,968: t15.2023.09.29 val PER: 0.1710
2025-11-02 07:53:34,968: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:53:34,969: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:53:34,969: t15.2023.10.08 val PER: 0.2666
2025-11-02 07:53:34,969: t15.2023.10.13 val PER: 0.2700
2025-11-02 07:53:34,969: t15.2023.10.15 val PER: 0.2030
2025-11-02 07:53:34,970: t15.2023.10.20 val PER: 0.2013
2025-11-02 07:53:34,970: t15.2023.10.22 val PER: 0.1771
2025-11-02 07:53:34,971: t15.2023.11.03 val PER: 0.2259
2025-11-02 07:53:34,971: t15.2023.11.04 val PER: 0.0614
2025-11-02 07:53:34,971: t15.2023.11.17 val PER: 0.0824
2025-11-02 07:53:34,972: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:53:34,972: t15.2023.11.26 val PER: 0.2326
2025-11-02 07:53:34,972: t15.2023.12.03 val PER: 0.1681
2025-11-02 07:53:34,973: t15.2023.12.08 val PER: 0.1984
2025-11-02 07:53:34,973: t15.2023.12.10 val PER: 0.1656
2025-11-02 07:53:34,973: t15.2023.12.17 val PER: 0.2204
2025-11-02 07:53:34,984: t15.2023.12.29 val PER: 0.2018
2025-11-02 07:53:34,984: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:53:34,984: t15.2024.03.08 val PER: 0.2888
2025-11-02 07:53:34,985: t15.2024.03.15 val PER: 0.2702
2025-11-02 07:53:34,985: t15.2024.03.17 val PER: 0.2134
2025-11-02 07:53:34,986: t15.2024.05.10 val PER: 0.2140
2025-11-02 07:53:34,986: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:53:34,986: t15.2024.07.19 val PER: 0.3019
2025-11-02 07:53:34,987: t15.2024.07.21 val PER: 0.1497
2025-11-02 07:53:34,987: t15.2024.07.28 val PER: 0.1919
2025-11-02 07:53:34,987: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:53:34,988: t15.2025.01.12 val PER: 0.2186
2025-11-02 07:53:34,988: t15.2025.03.14 val PER: 0.3994
2025-11-02 07:53:34,988: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:53:34,989: t15.2025.03.30 val PER: 0.3402
2025-11-02 07:53:34,989: t15.2025.04.13 val PER: 0.2867
2025-11-02 07:53:34,990: New best test PER 0.2120 --> 0.2118
2025-11-02 07:53:34,990: Checkpointing model
2025-11-02 07:53:36,733: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:54:06,765: Train batch 113200: loss: 12.10 grad norm: 45.75 time: 0.048
2025-11-02 07:54:38,375: Train batch 113400: loss: 8.89 grad norm: 41.70 time: 0.069
2025-11-02 07:55:08,680: Train batch 113600: loss: 11.06 grad norm: 43.92 time: 0.138
2025-11-02 07:55:38,386: Train batch 113800: loss: 7.32 grad norm: 42.09 time: 0.064
2025-11-02 07:56:05,588: Train batch 114000: loss: 12.89 grad norm: 56.36 time: 0.104
2025-11-02 07:56:05,589: Running test after training batch: 114000
2025-11-02 07:56:17,739: Val batch 114000: PER (avg): 0.2112 CTC Loss (avg): 22.5039 time: 12.149
2025-11-02 07:56:17,740: t15.2023.08.13 val PER: 0.1528
2025-11-02 07:56:17,741: t15.2023.08.18 val PER: 0.1685
2025-11-02 07:56:17,741: t15.2023.08.20 val PER: 0.1668
2025-11-02 07:56:17,741: t15.2023.08.25 val PER: 0.1596
2025-11-02 07:56:17,742: t15.2023.08.27 val PER: 0.2428
2025-11-02 07:56:17,742: t15.2023.09.01 val PER: 0.1153
2025-11-02 07:56:17,742: t15.2023.09.03 val PER: 0.2067
2025-11-02 07:56:17,743: t15.2023.09.24 val PER: 0.1687
2025-11-02 07:56:17,743: t15.2023.09.29 val PER: 0.1710
2025-11-02 07:56:17,743: t15.2023.10.01 val PER: 0.2266
2025-11-02 07:56:17,743: t15.2023.10.06 val PER: 0.1475
2025-11-02 07:56:17,744: t15.2023.10.08 val PER: 0.2652
2025-11-02 07:56:17,744: t15.2023.10.13 val PER: 0.2661
2025-11-02 07:56:17,744: t15.2023.10.15 val PER: 0.2017
2025-11-02 07:56:17,744: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:56:17,745: t15.2023.10.22 val PER: 0.1759
2025-11-02 07:56:17,745: t15.2023.11.03 val PER: 0.2266
2025-11-02 07:56:17,745: t15.2023.11.04 val PER: 0.0614
2025-11-02 07:56:17,746: t15.2023.11.17 val PER: 0.0809
2025-11-02 07:56:17,746: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:56:17,746: t15.2023.11.26 val PER: 0.2326
2025-11-02 07:56:17,747: t15.2023.12.03 val PER: 0.1691
2025-11-02 07:56:17,747: t15.2023.12.08 val PER: 0.1971
2025-11-02 07:56:17,747: t15.2023.12.10 val PER: 0.1616
2025-11-02 07:56:17,747: t15.2023.12.17 val PER: 0.2204
2025-11-02 07:56:17,747: t15.2023.12.29 val PER: 0.1990
2025-11-02 07:56:17,748: t15.2024.02.25 val PER: 0.1587
2025-11-02 07:56:17,748: t15.2024.03.08 val PER: 0.2916
2025-11-02 07:56:17,748: t15.2024.03.15 val PER: 0.2708
2025-11-02 07:56:17,748: t15.2024.03.17 val PER: 0.2127
2025-11-02 07:56:17,749: t15.2024.05.10 val PER: 0.2125
2025-11-02 07:56:17,749: t15.2024.06.14 val PER: 0.2334
2025-11-02 07:56:17,749: t15.2024.07.19 val PER: 0.3006
2025-11-02 07:56:17,749: t15.2024.07.21 val PER: 0.1497
2025-11-02 07:56:17,750: t15.2024.07.28 val PER: 0.1897
2025-11-02 07:56:17,750: t15.2025.01.10 val PER: 0.3705
2025-11-02 07:56:17,750: t15.2025.01.12 val PER: 0.2179
2025-11-02 07:56:17,751: t15.2025.03.14 val PER: 0.4009
2025-11-02 07:56:17,751: t15.2025.03.16 val PER: 0.2670
2025-11-02 07:56:17,751: t15.2025.03.30 val PER: 0.3402
2025-11-02 07:56:17,751: t15.2025.04.13 val PER: 0.2896
2025-11-02 07:56:17,752: New best test PER 0.2118 --> 0.2112
2025-11-02 07:56:17,752: Checkpointing model
2025-11-02 07:56:19,127: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 07:56:44,421: Train batch 114200: loss: 14.19 grad norm: 57.41 time: 0.094
2025-11-02 07:57:09,820: Train batch 114400: loss: 16.57 grad norm: 67.16 time: 0.065
2025-11-02 07:57:34,619: Train batch 114600: loss: 12.80 grad norm: 51.21 time: 0.061
2025-11-02 07:58:00,481: Train batch 114800: loss: 10.10 grad norm: 44.92 time: 0.061
2025-11-02 07:58:26,325: Train batch 115000: loss: 12.57 grad norm: 80.41 time: 0.070
2025-11-02 07:58:26,325: Running test after training batch: 115000
2025-11-02 07:58:37,750: Val batch 115000: PER (avg): 0.2120 CTC Loss (avg): 22.4974 time: 11.424
2025-11-02 07:58:37,750: t15.2023.08.13 val PER: 0.1528
2025-11-02 07:58:37,750: t15.2023.08.18 val PER: 0.1710
2025-11-02 07:58:37,751: t15.2023.08.20 val PER: 0.1660
2025-11-02 07:58:37,751: t15.2023.08.25 val PER: 0.1672
2025-11-02 07:58:37,751: t15.2023.08.27 val PER: 0.2428
2025-11-02 07:58:37,751: t15.2023.09.01 val PER: 0.1161
2025-11-02 07:58:37,752: t15.2023.09.03 val PER: 0.2090
2025-11-02 07:58:37,752: t15.2023.09.24 val PER: 0.1663
2025-11-02 07:58:37,752: t15.2023.09.29 val PER: 0.1723
2025-11-02 07:58:37,784: t15.2023.10.01 val PER: 0.2285
2025-11-02 07:58:37,785: t15.2023.10.06 val PER: 0.1518
2025-11-02 07:58:37,785: t15.2023.10.08 val PER: 0.2666
2025-11-02 07:58:37,786: t15.2023.10.13 val PER: 0.2661
2025-11-02 07:58:37,786: t15.2023.10.15 val PER: 0.2037
2025-11-02 07:58:37,786: t15.2023.10.20 val PER: 0.2081
2025-11-02 07:58:37,786: t15.2023.10.22 val PER: 0.1748
2025-11-02 07:58:37,787: t15.2023.11.03 val PER: 0.2280
2025-11-02 07:58:37,788: t15.2023.11.04 val PER: 0.0614
2025-11-02 07:58:37,788: t15.2023.11.17 val PER: 0.0809
2025-11-02 07:58:37,790: t15.2023.11.19 val PER: 0.0958
2025-11-02 07:58:37,790: t15.2023.11.26 val PER: 0.2304
2025-11-02 07:58:37,791: t15.2023.12.03 val PER: 0.1712
2025-11-02 07:58:37,791: t15.2023.12.08 val PER: 0.1971
2025-11-02 07:58:37,791: t15.2023.12.10 val PER: 0.1643
2025-11-02 07:58:37,791: t15.2023.12.17 val PER: 0.2204
2025-11-02 07:58:37,792: t15.2023.12.29 val PER: 0.2011
2025-11-02 07:58:37,792: t15.2024.02.25 val PER: 0.1573
2025-11-02 07:58:37,792: t15.2024.03.08 val PER: 0.2916
2025-11-02 07:58:37,792: t15.2024.03.15 val PER: 0.2714
2025-11-02 07:58:37,793: t15.2024.03.17 val PER: 0.2113
2025-11-02 07:58:37,793: t15.2024.05.10 val PER: 0.2065
2025-11-02 07:58:37,793: t15.2024.06.14 val PER: 0.2366
2025-11-02 07:58:37,793: t15.2024.07.19 val PER: 0.3032
2025-11-02 07:58:37,793: t15.2024.07.21 val PER: 0.1503
2025-11-02 07:58:37,794: t15.2024.07.28 val PER: 0.1897
2025-11-02 07:58:37,794: t15.2025.01.10 val PER: 0.3678
2025-11-02 07:58:37,794: t15.2025.01.12 val PER: 0.2202
2025-11-02 07:58:37,794: t15.2025.03.14 val PER: 0.4024
2025-11-02 07:58:37,795: t15.2025.03.16 val PER: 0.2709
2025-11-02 07:58:37,795: t15.2025.03.30 val PER: 0.3414
2025-11-02 07:58:37,795: t15.2025.04.13 val PER: 0.2882
2025-11-02 07:59:03,582: Train batch 115200: loss: 10.52 grad norm: 46.76 time: 0.099
2025-11-02 07:59:29,063: Train batch 115400: loss: 13.68 grad norm: 59.50 time: 0.068
2025-11-02 07:59:55,208: Train batch 115600: loss: 13.49 grad norm: 64.97 time: 0.063
2025-11-02 08:00:20,917: Train batch 115800: loss: 11.79 grad norm: 57.94 time: 0.081
2025-11-02 08:00:46,378: Train batch 116000: loss: 9.28 grad norm: 43.12 time: 0.084
2025-11-02 08:00:46,379: Running test after training batch: 116000
2025-11-02 08:00:56,912: Val batch 116000: PER (avg): 0.2121 CTC Loss (avg): 22.5026 time: 10.533
2025-11-02 08:00:56,915: t15.2023.08.13 val PER: 0.1538
2025-11-02 08:00:56,916: t15.2023.08.18 val PER: 0.1710
2025-11-02 08:00:56,916: t15.2023.08.20 val PER: 0.1676
2025-11-02 08:00:56,916: t15.2023.08.25 val PER: 0.1611
2025-11-02 08:00:56,916: t15.2023.08.27 val PER: 0.2412
2025-11-02 08:00:56,917: t15.2023.09.01 val PER: 0.1153
2025-11-02 08:00:56,917: t15.2023.09.03 val PER: 0.2078
2025-11-02 08:00:56,917: t15.2023.09.24 val PER: 0.1663
2025-11-02 08:00:56,917: t15.2023.09.29 val PER: 0.1729
2025-11-02 08:00:56,918: t15.2023.10.01 val PER: 0.2252
2025-11-02 08:00:56,918: t15.2023.10.06 val PER: 0.1496
2025-11-02 08:00:56,918: t15.2023.10.08 val PER: 0.2639
2025-11-02 08:00:56,918: t15.2023.10.13 val PER: 0.2676
2025-11-02 08:00:56,918: t15.2023.10.15 val PER: 0.2057
2025-11-02 08:00:56,919: t15.2023.10.20 val PER: 0.2047
2025-11-02 08:00:56,919: t15.2023.10.22 val PER: 0.1737
2025-11-02 08:00:56,919: t15.2023.11.03 val PER: 0.2252
2025-11-02 08:00:56,919: t15.2023.11.04 val PER: 0.0614
2025-11-02 08:00:56,920: t15.2023.11.17 val PER: 0.0824
2025-11-02 08:00:56,920: t15.2023.11.19 val PER: 0.0978
2025-11-02 08:00:56,920: t15.2023.11.26 val PER: 0.2326
2025-11-02 08:00:56,921: t15.2023.12.03 val PER: 0.1723
2025-11-02 08:00:56,921: t15.2023.12.08 val PER: 0.1971
2025-11-02 08:00:56,921: t15.2023.12.10 val PER: 0.1656
2025-11-02 08:00:56,921: t15.2023.12.17 val PER: 0.2214
2025-11-02 08:00:56,922: t15.2023.12.29 val PER: 0.2011
2025-11-02 08:00:56,922: t15.2024.02.25 val PER: 0.1587
2025-11-02 08:00:56,922: t15.2024.03.08 val PER: 0.2945
2025-11-02 08:00:56,922: t15.2024.03.15 val PER: 0.2727
2025-11-02 08:00:56,922: t15.2024.03.17 val PER: 0.2113
2025-11-02 08:00:56,923: t15.2024.05.10 val PER: 0.2125
2025-11-02 08:00:56,923: t15.2024.06.14 val PER: 0.2350
2025-11-02 08:00:56,923: t15.2024.07.19 val PER: 0.2999
2025-11-02 08:00:56,923: t15.2024.07.21 val PER: 0.1545
2025-11-02 08:00:56,924: t15.2024.07.28 val PER: 0.1897
2025-11-02 08:00:56,924: t15.2025.01.10 val PER: 0.3691
2025-11-02 08:00:56,924: t15.2025.01.12 val PER: 0.2194
2025-11-02 08:00:56,924: t15.2025.03.14 val PER: 0.4024
2025-11-02 08:00:56,925: t15.2025.03.16 val PER: 0.2696
2025-11-02 08:00:56,925: t15.2025.03.30 val PER: 0.3425
2025-11-02 08:00:56,925: t15.2025.04.13 val PER: 0.2924
2025-11-02 08:01:23,091: Train batch 116200: loss: 16.57 grad norm: 57.56 time: 0.069
2025-11-02 08:01:48,731: Train batch 116400: loss: 8.50 grad norm: 37.24 time: 0.079
2025-11-02 08:02:13,943: Train batch 116600: loss: 12.11 grad norm: 51.56 time: 0.079
2025-11-02 08:02:39,411: Train batch 116800: loss: 11.94 grad norm: 55.29 time: 0.067
2025-11-02 08:03:04,333: Train batch 117000: loss: 12.86 grad norm: 52.39 time: 0.120
2025-11-02 08:03:04,334: Running test after training batch: 117000
2025-11-02 08:03:16,129: Val batch 117000: PER (avg): 0.2119 CTC Loss (avg): 22.5090 time: 11.795
2025-11-02 08:03:16,130: t15.2023.08.13 val PER: 0.1528
2025-11-02 08:03:16,130: t15.2023.08.18 val PER: 0.1685
2025-11-02 08:03:16,130: t15.2023.08.20 val PER: 0.1668
2025-11-02 08:03:16,131: t15.2023.08.25 val PER: 0.1627
2025-11-02 08:03:16,131: t15.2023.08.27 val PER: 0.2428
2025-11-02 08:03:16,131: t15.2023.09.01 val PER: 0.1136
2025-11-02 08:03:16,132: t15.2023.09.03 val PER: 0.2078
2025-11-02 08:03:16,132: t15.2023.09.24 val PER: 0.1663
2025-11-02 08:03:16,132: t15.2023.09.29 val PER: 0.1736
2025-11-02 08:03:16,132: t15.2023.10.01 val PER: 0.2272
2025-11-02 08:03:16,133: t15.2023.10.06 val PER: 0.1496
2025-11-02 08:03:16,133: t15.2023.10.08 val PER: 0.2639
2025-11-02 08:03:16,133: t15.2023.10.13 val PER: 0.2669
2025-11-02 08:03:16,133: t15.2023.10.15 val PER: 0.2024
2025-11-02 08:03:16,134: t15.2023.10.20 val PER: 0.2013
2025-11-02 08:03:16,134: t15.2023.10.22 val PER: 0.1737
2025-11-02 08:03:16,134: t15.2023.11.03 val PER: 0.2259
2025-11-02 08:03:16,134: t15.2023.11.04 val PER: 0.0614
2025-11-02 08:03:16,135: t15.2023.11.17 val PER: 0.0824
2025-11-02 08:03:16,135: t15.2023.11.19 val PER: 0.0978
2025-11-02 08:03:16,136: t15.2023.11.26 val PER: 0.2319
2025-11-02 08:03:16,136: t15.2023.12.03 val PER: 0.1723
2025-11-02 08:03:16,136: t15.2023.12.08 val PER: 0.1991
2025-11-02 08:03:16,136: t15.2023.12.10 val PER: 0.1629
2025-11-02 08:03:16,136: t15.2023.12.17 val PER: 0.2235
2025-11-02 08:03:16,137: t15.2023.12.29 val PER: 0.2052
2025-11-02 08:03:16,137: t15.2024.02.25 val PER: 0.1573
2025-11-02 08:03:16,137: t15.2024.03.08 val PER: 0.2945
2025-11-02 08:03:16,137: t15.2024.03.15 val PER: 0.2714
2025-11-02 08:03:16,137: t15.2024.03.17 val PER: 0.2106
2025-11-02 08:03:16,138: t15.2024.05.10 val PER: 0.2095
2025-11-02 08:03:16,138: t15.2024.06.14 val PER: 0.2366
2025-11-02 08:03:16,138: t15.2024.07.19 val PER: 0.3013
2025-11-02 08:03:16,138: t15.2024.07.21 val PER: 0.1531
2025-11-02 08:03:16,138: t15.2024.07.28 val PER: 0.1912
2025-11-02 08:03:16,138: t15.2025.01.10 val PER: 0.3678
2025-11-02 08:03:16,139: t15.2025.01.12 val PER: 0.2202
2025-11-02 08:03:16,139: t15.2025.03.14 val PER: 0.4009
2025-11-02 08:03:16,139: t15.2025.03.16 val PER: 0.2670
2025-11-02 08:03:16,139: t15.2025.03.30 val PER: 0.3414
2025-11-02 08:03:16,140: t15.2025.04.13 val PER: 0.2896
2025-11-02 08:03:40,120: Train batch 117200: loss: 19.36 grad norm: 75.67 time: 0.086
2025-11-02 08:04:05,485: Train batch 117400: loss: 8.81 grad norm: 38.05 time: 0.072
2025-11-02 08:04:30,834: Train batch 117600: loss: 12.04 grad norm: 47.23 time: 0.062
2025-11-02 08:04:55,628: Train batch 117800: loss: 12.73 grad norm: 70.04 time: 0.085
2025-11-02 08:05:20,635: Train batch 118000: loss: 8.84 grad norm: 39.92 time: 0.078
2025-11-02 08:05:20,636: Running test after training batch: 118000
2025-11-02 08:05:33,225: Val batch 118000: PER (avg): 0.2117 CTC Loss (avg): 22.4989 time: 12.589
2025-11-02 08:05:33,228: t15.2023.08.13 val PER: 0.1559
2025-11-02 08:05:33,228: t15.2023.08.18 val PER: 0.1685
2025-11-02 08:05:33,229: t15.2023.08.20 val PER: 0.1676
2025-11-02 08:05:33,231: t15.2023.08.25 val PER: 0.1611
2025-11-02 08:05:33,231: t15.2023.08.27 val PER: 0.2428
2025-11-02 08:05:33,231: t15.2023.09.01 val PER: 0.1136
2025-11-02 08:05:33,231: t15.2023.09.03 val PER: 0.2078
2025-11-02 08:05:33,232: t15.2023.09.24 val PER: 0.1650
2025-11-02 08:05:33,232: t15.2023.09.29 val PER: 0.1742
2025-11-02 08:05:33,232: t15.2023.10.01 val PER: 0.2266
2025-11-02 08:05:33,232: t15.2023.10.06 val PER: 0.1496
2025-11-02 08:05:33,232: t15.2023.10.08 val PER: 0.2652
2025-11-02 08:05:33,233: t15.2023.10.13 val PER: 0.2676
2025-11-02 08:05:33,233: t15.2023.10.15 val PER: 0.2030
2025-11-02 08:05:33,233: t15.2023.10.20 val PER: 0.2013
2025-11-02 08:05:33,233: t15.2023.10.22 val PER: 0.1748
2025-11-02 08:05:33,233: t15.2023.11.03 val PER: 0.2239
2025-11-02 08:05:33,234: t15.2023.11.04 val PER: 0.0614
2025-11-02 08:05:33,234: t15.2023.11.17 val PER: 0.0809
2025-11-02 08:05:33,234: t15.2023.11.19 val PER: 0.0958
2025-11-02 08:05:33,234: t15.2023.11.26 val PER: 0.2312
2025-11-02 08:05:33,235: t15.2023.12.03 val PER: 0.1712
2025-11-02 08:05:33,235: t15.2023.12.08 val PER: 0.1964
2025-11-02 08:05:33,235: t15.2023.12.10 val PER: 0.1643
2025-11-02 08:05:33,235: t15.2023.12.17 val PER: 0.2256
2025-11-02 08:05:33,236: t15.2023.12.29 val PER: 0.2025
2025-11-02 08:05:33,236: t15.2024.02.25 val PER: 0.1559
2025-11-02 08:05:33,236: t15.2024.03.08 val PER: 0.2888
2025-11-02 08:05:33,237: t15.2024.03.15 val PER: 0.2720
2025-11-02 08:05:33,237: t15.2024.03.17 val PER: 0.2127
2025-11-02 08:05:33,237: t15.2024.05.10 val PER: 0.2065
2025-11-02 08:05:33,238: t15.2024.06.14 val PER: 0.2350
2025-11-02 08:05:33,239: t15.2024.07.19 val PER: 0.3019
2025-11-02 08:05:33,239: t15.2024.07.21 val PER: 0.1503
2025-11-02 08:05:33,239: t15.2024.07.28 val PER: 0.1897
2025-11-02 08:05:33,240: t15.2025.01.10 val PER: 0.3678
2025-11-02 08:05:33,240: t15.2025.01.12 val PER: 0.2217
2025-11-02 08:05:33,241: t15.2025.03.14 val PER: 0.3994
2025-11-02 08:05:33,241: t15.2025.03.16 val PER: 0.2670
2025-11-02 08:05:33,241: t15.2025.03.30 val PER: 0.3471
2025-11-02 08:05:33,241: t15.2025.04.13 val PER: 0.2882
2025-11-02 08:05:58,456: Train batch 118200: loss: 11.59 grad norm: 45.46 time: 0.092
2025-11-02 08:06:23,085: Train batch 118400: loss: 15.46 grad norm: 52.43 time: 0.076
2025-11-02 08:06:47,722: Train batch 118600: loss: 12.12 grad norm: 46.93 time: 0.075
2025-11-02 08:07:12,545: Train batch 118800: loss: 9.59 grad norm: 41.64 time: 0.070
2025-11-02 08:07:38,205: Train batch 119000: loss: 10.76 grad norm: 49.24 time: 0.083
2025-11-02 08:07:38,206: Running test after training batch: 119000
2025-11-02 08:07:50,621: Val batch 119000: PER (avg): 0.2117 CTC Loss (avg): 22.4855 time: 12.415
2025-11-02 08:07:50,622: t15.2023.08.13 val PER: 0.1549
2025-11-02 08:07:50,622: t15.2023.08.18 val PER: 0.1660
2025-11-02 08:07:50,623: t15.2023.08.20 val PER: 0.1676
2025-11-02 08:07:50,623: t15.2023.08.25 val PER: 0.1611
2025-11-02 08:07:50,623: t15.2023.08.27 val PER: 0.2428
2025-11-02 08:07:50,624: t15.2023.09.01 val PER: 0.1136
2025-11-02 08:07:50,624: t15.2023.09.03 val PER: 0.2043
2025-11-02 08:07:50,624: t15.2023.09.24 val PER: 0.1650
2025-11-02 08:07:50,624: t15.2023.09.29 val PER: 0.1736
2025-11-02 08:07:50,625: t15.2023.10.01 val PER: 0.2252
2025-11-02 08:07:50,625: t15.2023.10.06 val PER: 0.1496
2025-11-02 08:07:50,626: t15.2023.10.08 val PER: 0.2625
2025-11-02 08:07:50,626: t15.2023.10.13 val PER: 0.2684
2025-11-02 08:07:50,626: t15.2023.10.15 val PER: 0.2044
2025-11-02 08:07:50,626: t15.2023.10.20 val PER: 0.2047
2025-11-02 08:07:50,627: t15.2023.10.22 val PER: 0.1759
2025-11-02 08:07:50,627: t15.2023.11.03 val PER: 0.2246
2025-11-02 08:07:50,627: t15.2023.11.04 val PER: 0.0614
2025-11-02 08:07:50,627: t15.2023.11.17 val PER: 0.0840
2025-11-02 08:07:50,628: t15.2023.11.19 val PER: 0.0938
2025-11-02 08:07:50,628: t15.2023.11.26 val PER: 0.2290
2025-11-02 08:07:50,628: t15.2023.12.03 val PER: 0.1681
2025-11-02 08:07:50,628: t15.2023.12.08 val PER: 0.1984
2025-11-02 08:07:50,628: t15.2023.12.10 val PER: 0.1643
2025-11-02 08:07:50,629: t15.2023.12.17 val PER: 0.2225
2025-11-02 08:07:50,629: t15.2023.12.29 val PER: 0.2011
2025-11-02 08:07:50,629: t15.2024.02.25 val PER: 0.1573
2025-11-02 08:07:50,629: t15.2024.03.08 val PER: 0.2945
2025-11-02 08:07:50,629: t15.2024.03.15 val PER: 0.2739
2025-11-02 08:07:50,630: t15.2024.03.17 val PER: 0.2134
2025-11-02 08:07:50,630: t15.2024.05.10 val PER: 0.2125
2025-11-02 08:07:50,630: t15.2024.06.14 val PER: 0.2350
2025-11-02 08:07:50,631: t15.2024.07.19 val PER: 0.2993
2025-11-02 08:07:50,631: t15.2024.07.21 val PER: 0.1503
2025-11-02 08:07:50,631: t15.2024.07.28 val PER: 0.1926
2025-11-02 08:07:50,631: t15.2025.01.10 val PER: 0.3691
2025-11-02 08:07:50,631: t15.2025.01.12 val PER: 0.2202
2025-11-02 08:07:50,632: t15.2025.03.14 val PER: 0.4009
2025-11-02 08:07:50,632: t15.2025.03.16 val PER: 0.2683
2025-11-02 08:07:50,632: t15.2025.03.30 val PER: 0.3425
2025-11-02 08:07:50,632: t15.2025.04.13 val PER: 0.2896
2025-11-02 08:08:16,038: Train batch 119200: loss: 7.90 grad norm: 42.80 time: 0.062
2025-11-02 08:08:41,336: Train batch 119400: loss: 18.44 grad norm: 62.65 time: 0.065
2025-11-02 08:09:06,451: Train batch 119600: loss: 17.17 grad norm: 72.00 time: 0.067
2025-11-02 08:09:31,767: Train batch 119800: loss: 8.76 grad norm: 47.97 time: 0.073
2025-11-02 08:09:57,087: Running test after training batch: 119999
2025-11-02 08:10:08,426: Val batch 119999: PER (avg): 0.2115 CTC Loss (avg): 22.4829 time: 11.331
2025-11-02 08:10:08,429: t15.2023.08.13 val PER: 0.1559
2025-11-02 08:10:08,429: t15.2023.08.18 val PER: 0.1668
2025-11-02 08:10:08,430: t15.2023.08.20 val PER: 0.1684
2025-11-02 08:10:08,430: t15.2023.08.25 val PER: 0.1611
2025-11-02 08:10:08,431: t15.2023.08.27 val PER: 0.2444
2025-11-02 08:10:08,431: t15.2023.09.01 val PER: 0.1128
2025-11-02 08:10:08,431: t15.2023.09.03 val PER: 0.2043
2025-11-02 08:10:08,431: t15.2023.09.24 val PER: 0.1626
2025-11-02 08:10:08,432: t15.2023.09.29 val PER: 0.1704
2025-11-02 08:10:08,432: t15.2023.10.01 val PER: 0.2272
2025-11-02 08:10:08,432: t15.2023.10.06 val PER: 0.1496
2025-11-02 08:10:08,432: t15.2023.10.08 val PER: 0.2652
2025-11-02 08:10:08,433: t15.2023.10.13 val PER: 0.2684
2025-11-02 08:10:08,433: t15.2023.10.15 val PER: 0.2037
2025-11-02 08:10:08,433: t15.2023.10.20 val PER: 0.2047
2025-11-02 08:10:08,433: t15.2023.10.22 val PER: 0.1748
2025-11-02 08:10:08,433: t15.2023.11.03 val PER: 0.2225
2025-11-02 08:10:08,434: t15.2023.11.04 val PER: 0.0546
2025-11-02 08:10:08,434: t15.2023.11.17 val PER: 0.0809
2025-11-02 08:10:08,434: t15.2023.11.19 val PER: 0.0958
2025-11-02 08:10:08,434: t15.2023.11.26 val PER: 0.2297
2025-11-02 08:10:08,434: t15.2023.12.03 val PER: 0.1670
2025-11-02 08:10:08,435: t15.2023.12.08 val PER: 0.1957
2025-11-02 08:10:08,435: t15.2023.12.10 val PER: 0.1629
2025-11-02 08:10:08,435: t15.2023.12.17 val PER: 0.2245
2025-11-02 08:10:08,436: t15.2023.12.29 val PER: 0.2004
2025-11-02 08:10:08,436: t15.2024.02.25 val PER: 0.1573
2025-11-02 08:10:08,436: t15.2024.03.08 val PER: 0.2873
2025-11-02 08:10:08,436: t15.2024.03.15 val PER: 0.2727
2025-11-02 08:10:08,436: t15.2024.03.17 val PER: 0.2148
2025-11-02 08:10:08,437: t15.2024.05.10 val PER: 0.2155
2025-11-02 08:10:08,437: t15.2024.06.14 val PER: 0.2334
2025-11-02 08:10:08,437: t15.2024.07.19 val PER: 0.2980
2025-11-02 08:10:08,437: t15.2024.07.21 val PER: 0.1503
2025-11-02 08:10:08,437: t15.2024.07.28 val PER: 0.1926
2025-11-02 08:10:08,438: t15.2025.01.10 val PER: 0.3678
2025-11-02 08:10:08,438: t15.2025.01.12 val PER: 0.2232
2025-11-02 08:10:08,438: t15.2025.03.14 val PER: 0.4038
2025-11-02 08:10:08,439: t15.2025.03.16 val PER: 0.2683
2025-11-02 08:10:08,439: t15.2025.03.30 val PER: 0.3448
2025-11-02 08:10:08,439: t15.2025.04.13 val PER: 0.2939
2025-11-02 08:10:08,518: Best avg val PER achieved: 0.21120
2025-11-02 08:10:08,519: Total training time: 279.51 minutes
2025-11-02 08:10:09,762: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/final_checkpoint_batch_119999
