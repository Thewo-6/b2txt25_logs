2025-11-02 10:30:04,476: Using device: cuda:0
2025-11-02 10:30:06,397: Using torch.compile
2025-11-02 10:30:07,775: Initialized RNN decoding model
2025-11-02 10:30:07,775: OptimizedModule(
  (_orig_mod): GRUDecoder(
    (day_layer_activation): Softsign()
    (day_weights): ParameterList(
        (0): Parameter containing: [torch.float32 of size 512x512]
        (1): Parameter containing: [torch.float32 of size 512x512]
        (2): Parameter containing: [torch.float32 of size 512x512]
        (3): Parameter containing: [torch.float32 of size 512x512]
        (4): Parameter containing: [torch.float32 of size 512x512]
        (5): Parameter containing: [torch.float32 of size 512x512]
        (6): Parameter containing: [torch.float32 of size 512x512]
        (7): Parameter containing: [torch.float32 of size 512x512]
        (8): Parameter containing: [torch.float32 of size 512x512]
        (9): Parameter containing: [torch.float32 of size 512x512]
        (10): Parameter containing: [torch.float32 of size 512x512]
        (11): Parameter containing: [torch.float32 of size 512x512]
        (12): Parameter containing: [torch.float32 of size 512x512]
        (13): Parameter containing: [torch.float32 of size 512x512]
        (14): Parameter containing: [torch.float32 of size 512x512]
        (15): Parameter containing: [torch.float32 of size 512x512]
        (16): Parameter containing: [torch.float32 of size 512x512]
        (17): Parameter containing: [torch.float32 of size 512x512]
        (18): Parameter containing: [torch.float32 of size 512x512]
        (19): Parameter containing: [torch.float32 of size 512x512]
        (20): Parameter containing: [torch.float32 of size 512x512]
        (21): Parameter containing: [torch.float32 of size 512x512]
        (22): Parameter containing: [torch.float32 of size 512x512]
        (23): Parameter containing: [torch.float32 of size 512x512]
        (24): Parameter containing: [torch.float32 of size 512x512]
        (25): Parameter containing: [torch.float32 of size 512x512]
        (26): Parameter containing: [torch.float32 of size 512x512]
        (27): Parameter containing: [torch.float32 of size 512x512]
        (28): Parameter containing: [torch.float32 of size 512x512]
        (29): Parameter containing: [torch.float32 of size 512x512]
        (30): Parameter containing: [torch.float32 of size 512x512]
        (31): Parameter containing: [torch.float32 of size 512x512]
        (32): Parameter containing: [torch.float32 of size 512x512]
        (33): Parameter containing: [torch.float32 of size 512x512]
        (34): Parameter containing: [torch.float32 of size 512x512]
        (35): Parameter containing: [torch.float32 of size 512x512]
        (36): Parameter containing: [torch.float32 of size 512x512]
        (37): Parameter containing: [torch.float32 of size 512x512]
        (38): Parameter containing: [torch.float32 of size 512x512]
        (39): Parameter containing: [torch.float32 of size 512x512]
        (40): Parameter containing: [torch.float32 of size 512x512]
        (41): Parameter containing: [torch.float32 of size 512x512]
        (42): Parameter containing: [torch.float32 of size 512x512]
        (43): Parameter containing: [torch.float32 of size 512x512]
        (44): Parameter containing: [torch.float32 of size 512x512]
    )
    (day_biases): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x512]
        (1): Parameter containing: [torch.float32 of size 1x512]
        (2): Parameter containing: [torch.float32 of size 1x512]
        (3): Parameter containing: [torch.float32 of size 1x512]
        (4): Parameter containing: [torch.float32 of size 1x512]
        (5): Parameter containing: [torch.float32 of size 1x512]
        (6): Parameter containing: [torch.float32 of size 1x512]
        (7): Parameter containing: [torch.float32 of size 1x512]
        (8): Parameter containing: [torch.float32 of size 1x512]
        (9): Parameter containing: [torch.float32 of size 1x512]
        (10): Parameter containing: [torch.float32 of size 1x512]
        (11): Parameter containing: [torch.float32 of size 1x512]
        (12): Parameter containing: [torch.float32 of size 1x512]
        (13): Parameter containing: [torch.float32 of size 1x512]
        (14): Parameter containing: [torch.float32 of size 1x512]
        (15): Parameter containing: [torch.float32 of size 1x512]
        (16): Parameter containing: [torch.float32 of size 1x512]
        (17): Parameter containing: [torch.float32 of size 1x512]
        (18): Parameter containing: [torch.float32 of size 1x512]
        (19): Parameter containing: [torch.float32 of size 1x512]
        (20): Parameter containing: [torch.float32 of size 1x512]
        (21): Parameter containing: [torch.float32 of size 1x512]
        (22): Parameter containing: [torch.float32 of size 1x512]
        (23): Parameter containing: [torch.float32 of size 1x512]
        (24): Parameter containing: [torch.float32 of size 1x512]
        (25): Parameter containing: [torch.float32 of size 1x512]
        (26): Parameter containing: [torch.float32 of size 1x512]
        (27): Parameter containing: [torch.float32 of size 1x512]
        (28): Parameter containing: [torch.float32 of size 1x512]
        (29): Parameter containing: [torch.float32 of size 1x512]
        (30): Parameter containing: [torch.float32 of size 1x512]
        (31): Parameter containing: [torch.float32 of size 1x512]
        (32): Parameter containing: [torch.float32 of size 1x512]
        (33): Parameter containing: [torch.float32 of size 1x512]
        (34): Parameter containing: [torch.float32 of size 1x512]
        (35): Parameter containing: [torch.float32 of size 1x512]
        (36): Parameter containing: [torch.float32 of size 1x512]
        (37): Parameter containing: [torch.float32 of size 1x512]
        (38): Parameter containing: [torch.float32 of size 1x512]
        (39): Parameter containing: [torch.float32 of size 1x512]
        (40): Parameter containing: [torch.float32 of size 1x512]
        (41): Parameter containing: [torch.float32 of size 1x512]
        (42): Parameter containing: [torch.float32 of size 1x512]
        (43): Parameter containing: [torch.float32 of size 1x512]
        (44): Parameter containing: [torch.float32 of size 1x512]
    )
    (day_layer_dropout): Dropout(p=0.2, inplace=False)
    (gru): GRU(10240, 768, num_layers=5, batch_first=True, dropout=0.25)
    (out): Linear(in_features=768, out_features=41, bias=True)
  )
)
2025-11-02 10:30:07,777: Model has 51,393,065 parameters
2025-11-02 10:30:07,777: Model has 11,819,520 day-specific parameters | 23.00% of total parameters
2025-11-02 10:30:27,335: Successfully initialized datasets
2025-11-02 10:30:32,521: Train batch 0: loss: 750.86 grad norm: 358.66 time: 2.603
2025-11-02 10:30:32,522: Running test after training batch: 0
2025-11-02 10:31:04,035: Val batch 0: PER (avg): 1.2817 CTC Loss (avg): 708.2872 time: 31.513
2025-11-02 10:31:04,036: t15.2023.08.13 val PER: 1.1975
2025-11-02 10:31:04,036: t15.2023.08.18 val PER: 1.2682
2025-11-02 10:31:04,036: t15.2023.08.20 val PER: 1.1819
2025-11-02 10:31:04,037: t15.2023.08.25 val PER: 1.2861
2025-11-02 10:31:04,037: t15.2023.08.27 val PER: 1.1158
2025-11-02 10:31:04,037: t15.2023.09.01 val PER: 1.2394
2025-11-02 10:31:04,038: t15.2023.09.03 val PER: 1.1318
2025-11-02 10:31:04,038: t15.2023.09.24 val PER: 1.4090
2025-11-02 10:31:04,038: t15.2023.09.29 val PER: 1.3746
2025-11-02 10:31:04,038: t15.2023.10.01 val PER: 1.1301
2025-11-02 10:31:04,039: t15.2023.10.06 val PER: 1.3348
2025-11-02 10:31:04,039: t15.2023.10.08 val PER: 1.0650
2025-11-02 10:31:04,039: t15.2023.10.13 val PER: 1.3126
2025-11-02 10:31:04,039: t15.2023.10.15 val PER: 1.3415
2025-11-02 10:31:04,040: t15.2023.10.20 val PER: 1.3322
2025-11-02 10:31:04,040: t15.2023.10.22 val PER: 1.2483
2025-11-02 10:31:04,040: t15.2023.11.03 val PER: 1.3833
2025-11-02 10:31:04,040: t15.2023.11.04 val PER: 1.6451
2025-11-02 10:31:04,040: t15.2023.11.17 val PER: 1.7278
2025-11-02 10:31:04,041: t15.2023.11.19 val PER: 1.4431
2025-11-02 10:31:04,041: t15.2023.11.26 val PER: 1.3406
2025-11-02 10:31:04,041: t15.2023.12.03 val PER: 1.2342
2025-11-02 10:31:04,042: t15.2023.12.08 val PER: 1.3276
2025-11-02 10:31:04,042: t15.2023.12.10 val PER: 1.4389
2025-11-02 10:31:04,042: t15.2023.12.17 val PER: 1.1019
2025-11-02 10:31:04,042: t15.2023.12.29 val PER: 1.2176
2025-11-02 10:31:04,043: t15.2024.02.25 val PER: 1.2570
2025-11-02 10:31:04,043: t15.2024.03.08 val PER: 1.1152
2025-11-02 10:31:04,043: t15.2024.03.15 val PER: 1.1513
2025-11-02 10:31:04,043: t15.2024.03.17 val PER: 1.2371
2025-11-02 10:31:04,043: t15.2024.05.10 val PER: 1.3001
2025-11-02 10:31:04,044: t15.2024.06.14 val PER: 1.4401
2025-11-02 10:31:04,044: t15.2024.07.19 val PER: 1.0066
2025-11-02 10:31:04,044: t15.2024.07.21 val PER: 1.4490
2025-11-02 10:31:04,044: t15.2024.07.28 val PER: 1.4324
2025-11-02 10:31:04,044: t15.2025.01.10 val PER: 1.0152
2025-11-02 10:31:04,045: t15.2025.01.12 val PER: 1.5135
2025-11-02 10:31:04,045: t15.2025.03.14 val PER: 1.0311
2025-11-02 10:31:04,045: t15.2025.03.16 val PER: 1.5445
2025-11-02 10:31:04,045: t15.2025.03.30 val PER: 1.2333
2025-11-02 10:31:04,045: t15.2025.04.13 val PER: 1.3695
2025-11-02 10:31:04,046: New best test PER inf --> 1.2817
2025-11-02 10:31:04,046: Checkpointing model
2025-11-02 10:31:05,339: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:31:34,854: Train batch 200: loss: 524.25 grad norm: 601.29 time: 0.080
2025-11-02 10:32:00,697: Train batch 400: loss: 129.48 grad norm: 246.65 time: 0.075
2025-11-02 10:32:25,042: Train batch 600: loss: 96.83 grad norm: 30.34 time: 0.063
2025-11-02 10:32:50,112: Train batch 800: loss: 89.15 grad norm: 33.35 time: 0.075
2025-11-02 10:33:15,912: Train batch 1000: loss: 87.71 grad norm: 36.45 time: 0.101
2025-11-02 10:33:15,913: Running test after training batch: 1000
2025-11-02 10:33:28,019: Val batch 1000: PER (avg): 0.7313 CTC Loss (avg): 86.5950 time: 12.105
2025-11-02 10:33:28,019: t15.2023.08.13 val PER: 0.7173
2025-11-02 10:33:28,019: t15.2023.08.18 val PER: 0.7016
2025-11-02 10:33:28,020: t15.2023.08.20 val PER: 0.7029
2025-11-02 10:33:28,020: t15.2023.08.25 val PER: 0.6913
2025-11-02 10:33:28,020: t15.2023.08.27 val PER: 0.7476
2025-11-02 10:33:28,020: t15.2023.09.01 val PER: 0.6769
2025-11-02 10:33:28,021: t15.2023.09.03 val PER: 0.7197
2025-11-02 10:33:28,021: t15.2023.09.24 val PER: 0.6942
2025-11-02 10:33:28,021: t15.2023.09.29 val PER: 0.7033
2025-11-02 10:33:28,021: t15.2023.10.01 val PER: 0.7259
2025-11-02 10:33:28,022: t15.2023.10.06 val PER: 0.6889
2025-11-02 10:33:28,022: t15.2023.10.08 val PER: 0.7267
2025-11-02 10:33:28,022: t15.2023.10.13 val PER: 0.7254
2025-11-02 10:33:28,022: t15.2023.10.15 val PER: 0.7014
2025-11-02 10:33:28,023: t15.2023.10.20 val PER: 0.7081
2025-11-02 10:33:28,023: t15.2023.10.22 val PER: 0.6993
2025-11-02 10:33:28,023: t15.2023.11.03 val PER: 0.6981
2025-11-02 10:33:28,023: t15.2023.11.04 val PER: 0.6962
2025-11-02 10:33:28,023: t15.2023.11.17 val PER: 0.6641
2025-11-02 10:33:28,024: t15.2023.11.19 val PER: 0.6667
2025-11-02 10:33:28,024: t15.2023.11.26 val PER: 0.7210
2025-11-02 10:33:28,024: t15.2023.12.03 val PER: 0.7122
2025-11-02 10:33:28,024: t15.2023.12.08 val PER: 0.7284
2025-11-02 10:33:28,025: t15.2023.12.10 val PER: 0.7135
2025-11-02 10:33:28,025: t15.2023.12.17 val PER: 0.7994
2025-11-02 10:33:28,025: t15.2023.12.29 val PER: 0.7742
2025-11-02 10:33:28,025: t15.2024.02.25 val PER: 0.7121
2025-11-02 10:33:28,025: t15.2024.03.08 val PER: 0.7952
2025-11-02 10:33:28,026: t15.2024.03.15 val PER: 0.7573
2025-11-02 10:33:28,026: t15.2024.03.17 val PER: 0.7294
2025-11-02 10:33:28,026: t15.2024.05.10 val PER: 0.7207
2025-11-02 10:33:28,026: t15.2024.06.14 val PER: 0.7177
2025-11-02 10:33:28,027: t15.2024.07.19 val PER: 0.8273
2025-11-02 10:33:28,027: t15.2024.07.21 val PER: 0.7103
2025-11-02 10:33:28,027: t15.2024.07.28 val PER: 0.7169
2025-11-02 10:33:28,027: t15.2025.01.10 val PER: 0.8499
2025-11-02 10:33:28,027: t15.2025.01.12 val PER: 0.7252
2025-11-02 10:33:28,028: t15.2025.03.14 val PER: 0.8817
2025-11-02 10:33:28,028: t15.2025.03.16 val PER: 0.7291
2025-11-02 10:33:28,028: t15.2025.03.30 val PER: 0.8437
2025-11-02 10:33:28,028: t15.2025.04.13 val PER: 0.7646
2025-11-02 10:33:28,029: New best test PER 1.2817 --> 0.7313
2025-11-02 10:33:28,029: Checkpointing model
2025-11-02 10:33:29,332: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:33:54,448: Train batch 1200: loss: 87.12 grad norm: 50.60 time: 0.080
2025-11-02 10:34:20,820: Train batch 1400: loss: 60.56 grad norm: 36.96 time: 0.054
2025-11-02 10:34:47,953: Train batch 1600: loss: 65.79 grad norm: 48.20 time: 0.097
2025-11-02 10:35:14,613: Train batch 1800: loss: 83.29 grad norm: 70.40 time: 0.079
2025-11-02 10:35:40,868: Train batch 2000: loss: 75.07 grad norm: 69.09 time: 0.056
2025-11-02 10:35:40,869: Running test after training batch: 2000
2025-11-02 10:35:53,725: Val batch 2000: PER (avg): 0.5903 CTC Loss (avg): 66.3729 time: 12.856
2025-11-02 10:35:53,726: t15.2023.08.13 val PER: 0.5561
2025-11-02 10:35:53,726: t15.2023.08.18 val PER: 0.5457
2025-11-02 10:35:53,727: t15.2023.08.20 val PER: 0.5417
2025-11-02 10:35:53,727: t15.2023.08.25 val PER: 0.5572
2025-11-02 10:35:53,727: t15.2023.08.27 val PER: 0.6367
2025-11-02 10:35:53,728: t15.2023.09.01 val PER: 0.5252
2025-11-02 10:35:53,728: t15.2023.09.03 val PER: 0.5867
2025-11-02 10:35:53,728: t15.2023.09.24 val PER: 0.5400
2025-11-02 10:35:53,728: t15.2023.09.29 val PER: 0.5737
2025-11-02 10:35:53,729: t15.2023.10.01 val PER: 0.5984
2025-11-02 10:35:53,729: t15.2023.10.06 val PER: 0.5565
2025-11-02 10:35:53,729: t15.2023.10.08 val PER: 0.6333
2025-11-02 10:35:53,729: t15.2023.10.13 val PER: 0.6462
2025-11-02 10:35:53,730: t15.2023.10.15 val PER: 0.5867
2025-11-02 10:35:53,730: t15.2023.10.20 val PER: 0.5503
2025-11-02 10:35:53,730: t15.2023.10.22 val PER: 0.5390
2025-11-02 10:35:53,730: t15.2023.11.03 val PER: 0.5719
2025-11-02 10:35:53,730: t15.2023.11.04 val PER: 0.3857
2025-11-02 10:35:53,731: t15.2023.11.17 val PER: 0.4852
2025-11-02 10:35:53,731: t15.2023.11.19 val PER: 0.4691
2025-11-02 10:35:53,732: t15.2023.11.26 val PER: 0.6181
2025-11-02 10:35:53,732: t15.2023.12.03 val PER: 0.5819
2025-11-02 10:35:53,732: t15.2023.12.08 val PER: 0.5672
2025-11-02 10:35:53,732: t15.2023.12.10 val PER: 0.5716
2025-11-02 10:35:53,732: t15.2023.12.17 val PER: 0.6268
2025-11-02 10:35:53,733: t15.2023.12.29 val PER: 0.6115
2025-11-02 10:35:53,733: t15.2024.02.25 val PER: 0.5576
2025-11-02 10:35:53,733: t15.2024.03.08 val PER: 0.6316
2025-11-02 10:35:53,733: t15.2024.03.15 val PER: 0.6141
2025-11-02 10:35:53,733: t15.2024.03.17 val PER: 0.5948
2025-11-02 10:35:53,734: t15.2024.05.10 val PER: 0.5854
2025-11-02 10:35:53,734: t15.2024.06.14 val PER: 0.5584
2025-11-02 10:35:53,734: t15.2024.07.19 val PER: 0.6744
2025-11-02 10:35:53,734: t15.2024.07.21 val PER: 0.5655
2025-11-02 10:35:53,735: t15.2024.07.28 val PER: 0.5735
2025-11-02 10:35:53,735: t15.2025.01.10 val PER: 0.7369
2025-11-02 10:35:53,735: t15.2025.01.12 val PER: 0.5958
2025-11-02 10:35:53,735: t15.2025.03.14 val PER: 0.7411
2025-11-02 10:35:53,735: t15.2025.03.16 val PER: 0.6270
2025-11-02 10:35:53,736: t15.2025.03.30 val PER: 0.6851
2025-11-02 10:35:53,736: t15.2025.04.13 val PER: 0.6106
2025-11-02 10:35:53,737: New best test PER 0.7313 --> 0.5903
2025-11-02 10:35:53,737: Checkpointing model
2025-11-02 10:35:55,012: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:36:20,653: Train batch 2200: loss: 54.13 grad norm: 39.48 time: 0.066
2025-11-02 10:36:47,882: Train batch 2400: loss: 63.93 grad norm: 54.32 time: 0.080
2025-11-02 10:37:15,705: Train batch 2600: loss: 72.00 grad norm: 97.57 time: 0.067
2025-11-02 10:37:42,899: Train batch 2800: loss: 51.00 grad norm: 59.55 time: 0.066
2025-11-02 10:38:10,995: Train batch 3000: loss: 64.38 grad norm: 47.89 time: 0.071
2025-11-02 10:38:10,996: Running test after training batch: 3000
2025-11-02 10:38:25,057: Val batch 3000: PER (avg): 0.5129 CTC Loss (avg): 55.8371 time: 14.060
2025-11-02 10:38:25,058: t15.2023.08.13 val PER: 0.4823
2025-11-02 10:38:25,058: t15.2023.08.18 val PER: 0.4736
2025-11-02 10:38:25,059: t15.2023.08.20 val PER: 0.4662
2025-11-02 10:38:25,059: t15.2023.08.25 val PER: 0.4684
2025-11-02 10:38:25,059: t15.2023.08.27 val PER: 0.5563
2025-11-02 10:38:25,062: t15.2023.09.01 val PER: 0.4326
2025-11-02 10:38:25,062: t15.2023.09.03 val PER: 0.5059
2025-11-02 10:38:25,062: t15.2023.09.24 val PER: 0.4636
2025-11-02 10:38:25,062: t15.2023.09.29 val PER: 0.4837
2025-11-02 10:38:25,063: t15.2023.10.01 val PER: 0.5357
2025-11-02 10:38:25,063: t15.2023.10.06 val PER: 0.4682
2025-11-02 10:38:25,063: t15.2023.10.08 val PER: 0.5480
2025-11-02 10:38:25,064: t15.2023.10.13 val PER: 0.5904
2025-11-02 10:38:25,064: t15.2023.10.15 val PER: 0.5030
2025-11-02 10:38:25,064: t15.2023.10.20 val PER: 0.5034
2025-11-02 10:38:25,064: t15.2023.10.22 val PER: 0.4543
2025-11-02 10:38:25,065: t15.2023.11.03 val PER: 0.4830
2025-11-02 10:38:25,065: t15.2023.11.04 val PER: 0.2969
2025-11-02 10:38:25,065: t15.2023.11.17 val PER: 0.3935
2025-11-02 10:38:25,065: t15.2023.11.19 val PER: 0.3932
2025-11-02 10:38:25,066: t15.2023.11.26 val PER: 0.5594
2025-11-02 10:38:25,068: t15.2023.12.03 val PER: 0.5000
2025-11-02 10:38:25,068: t15.2023.12.08 val PER: 0.4987
2025-11-02 10:38:25,068: t15.2023.12.10 val PER: 0.4928
2025-11-02 10:38:25,068: t15.2023.12.17 val PER: 0.5125
2025-11-02 10:38:25,069: t15.2023.12.29 val PER: 0.5209
2025-11-02 10:38:25,069: t15.2024.02.25 val PER: 0.4635
2025-11-02 10:38:25,069: t15.2024.03.08 val PER: 0.5576
2025-11-02 10:38:25,070: t15.2024.03.15 val PER: 0.5503
2025-11-02 10:38:25,070: t15.2024.03.17 val PER: 0.5014
2025-11-02 10:38:25,070: t15.2024.05.10 val PER: 0.4978
2025-11-02 10:38:25,070: t15.2024.06.14 val PER: 0.5158
2025-11-02 10:38:25,072: t15.2024.07.19 val PER: 0.5999
2025-11-02 10:38:25,073: t15.2024.07.21 val PER: 0.4779
2025-11-02 10:38:25,075: t15.2024.07.28 val PER: 0.4963
2025-11-02 10:38:25,076: t15.2025.01.10 val PER: 0.6584
2025-11-02 10:38:25,077: t15.2025.01.12 val PER: 0.5242
2025-11-02 10:38:25,078: t15.2025.03.14 val PER: 0.6686
2025-11-02 10:38:25,078: t15.2025.03.16 val PER: 0.5798
2025-11-02 10:38:25,080: t15.2025.03.30 val PER: 0.6414
2025-11-02 10:38:25,080: t15.2025.04.13 val PER: 0.5407
2025-11-02 10:38:25,081: New best test PER 0.5903 --> 0.5129
2025-11-02 10:38:25,085: Checkpointing model
2025-11-02 10:38:26,569: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:38:52,788: Train batch 3200: loss: 51.37 grad norm: 44.85 time: 0.065
2025-11-02 10:39:20,326: Train batch 3400: loss: 50.91 grad norm: 64.47 time: 0.070
2025-11-02 10:39:47,360: Train batch 3600: loss: 54.97 grad norm: 82.81 time: 0.083
2025-11-02 10:40:14,342: Train batch 3800: loss: 62.36 grad norm: 56.10 time: 0.055
2025-11-02 10:40:41,627: Train batch 4000: loss: 29.43 grad norm: 35.96 time: 0.050
2025-11-02 10:40:41,628: Running test after training batch: 4000
2025-11-02 10:40:53,718: Val batch 4000: PER (avg): 0.4439 CTC Loss (avg): 47.6958 time: 12.090
2025-11-02 10:40:53,719: t15.2023.08.13 val PER: 0.4158
2025-11-02 10:40:53,720: t15.2023.08.18 val PER: 0.3990
2025-11-02 10:40:53,720: t15.2023.08.20 val PER: 0.3820
2025-11-02 10:40:53,721: t15.2023.08.25 val PER: 0.3614
2025-11-02 10:40:53,723: t15.2023.08.27 val PER: 0.4662
2025-11-02 10:40:53,723: t15.2023.09.01 val PER: 0.3628
2025-11-02 10:40:53,724: t15.2023.09.03 val PER: 0.4347
2025-11-02 10:40:53,724: t15.2023.09.24 val PER: 0.3677
2025-11-02 10:40:53,724: t15.2023.09.29 val PER: 0.4071
2025-11-02 10:40:53,724: t15.2023.10.01 val PER: 0.4604
2025-11-02 10:40:53,725: t15.2023.10.06 val PER: 0.3929
2025-11-02 10:40:53,725: t15.2023.10.08 val PER: 0.4831
2025-11-02 10:40:53,725: t15.2023.10.13 val PER: 0.5275
2025-11-02 10:40:53,726: t15.2023.10.15 val PER: 0.4338
2025-11-02 10:40:53,726: t15.2023.10.20 val PER: 0.4262
2025-11-02 10:40:53,726: t15.2023.10.22 val PER: 0.3931
2025-11-02 10:40:53,727: t15.2023.11.03 val PER: 0.4172
2025-11-02 10:40:53,727: t15.2023.11.04 val PER: 0.2423
2025-11-02 10:40:53,727: t15.2023.11.17 val PER: 0.3266
2025-11-02 10:40:53,727: t15.2023.11.19 val PER: 0.3114
2025-11-02 10:40:53,728: t15.2023.11.26 val PER: 0.4971
2025-11-02 10:40:53,728: t15.2023.12.03 val PER: 0.4265
2025-11-02 10:40:53,728: t15.2023.12.08 val PER: 0.4374
2025-11-02 10:40:53,729: t15.2023.12.10 val PER: 0.4100
2025-11-02 10:40:53,729: t15.2023.12.17 val PER: 0.4335
2025-11-02 10:40:53,729: t15.2023.12.29 val PER: 0.4633
2025-11-02 10:40:53,729: t15.2024.02.25 val PER: 0.4003
2025-11-02 10:40:53,730: t15.2024.03.08 val PER: 0.5178
2025-11-02 10:40:53,730: t15.2024.03.15 val PER: 0.4747
2025-11-02 10:40:53,730: t15.2024.03.17 val PER: 0.4449
2025-11-02 10:40:53,730: t15.2024.05.10 val PER: 0.4458
2025-11-02 10:40:53,731: t15.2024.06.14 val PER: 0.4353
2025-11-02 10:40:53,731: t15.2024.07.19 val PER: 0.5438
2025-11-02 10:40:53,732: t15.2024.07.21 val PER: 0.4103
2025-11-02 10:40:53,732: t15.2024.07.28 val PER: 0.4338
2025-11-02 10:40:53,732: t15.2025.01.10 val PER: 0.5771
2025-11-02 10:40:53,732: t15.2025.01.12 val PER: 0.4426
2025-11-02 10:40:53,733: t15.2025.03.14 val PER: 0.6213
2025-11-02 10:40:53,733: t15.2025.03.16 val PER: 0.5209
2025-11-02 10:40:53,733: t15.2025.03.30 val PER: 0.5816
2025-11-02 10:40:53,733: t15.2025.04.13 val PER: 0.4879
2025-11-02 10:40:53,734: New best test PER 0.5129 --> 0.4439
2025-11-02 10:40:53,734: Checkpointing model
2025-11-02 10:40:54,995: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:41:21,151: Train batch 4200: loss: 47.88 grad norm: 62.10 time: 0.070
2025-11-02 10:41:47,656: Train batch 4400: loss: 36.29 grad norm: 30.78 time: 0.086
2025-11-02 10:42:13,421: Train batch 4600: loss: 48.41 grad norm: 51.85 time: 0.071
2025-11-02 10:42:40,274: Train batch 4800: loss: 30.37 grad norm: 31.37 time: 0.072
2025-11-02 10:43:07,343: Train batch 5000: loss: 44.34 grad norm: 41.05 time: 0.074
2025-11-02 10:43:07,344: Running test after training batch: 5000
2025-11-02 10:43:19,931: Val batch 5000: PER (avg): 0.3915 CTC Loss (avg): 40.8910 time: 12.586
2025-11-02 10:43:19,932: t15.2023.08.13 val PER: 0.3545
2025-11-02 10:43:19,932: t15.2023.08.18 val PER: 0.3462
2025-11-02 10:43:19,932: t15.2023.08.20 val PER: 0.3352
2025-11-02 10:43:19,933: t15.2023.08.25 val PER: 0.3072
2025-11-02 10:43:19,933: t15.2023.08.27 val PER: 0.4277
2025-11-02 10:43:19,933: t15.2023.09.01 val PER: 0.3036
2025-11-02 10:43:19,933: t15.2023.09.03 val PER: 0.3907
2025-11-02 10:43:19,934: t15.2023.09.24 val PER: 0.3362
2025-11-02 10:43:19,934: t15.2023.09.29 val PER: 0.3510
2025-11-02 10:43:19,934: t15.2023.10.01 val PER: 0.4194
2025-11-02 10:43:19,934: t15.2023.10.06 val PER: 0.3283
2025-11-02 10:43:19,935: t15.2023.10.08 val PER: 0.4506
2025-11-02 10:43:19,935: t15.2023.10.13 val PER: 0.4600
2025-11-02 10:43:19,935: t15.2023.10.15 val PER: 0.3876
2025-11-02 10:43:19,935: t15.2023.10.20 val PER: 0.3826
2025-11-02 10:43:19,936: t15.2023.10.22 val PER: 0.3463
2025-11-02 10:43:19,936: t15.2023.11.03 val PER: 0.3758
2025-11-02 10:43:19,937: t15.2023.11.04 val PER: 0.1877
2025-11-02 10:43:19,937: t15.2023.11.17 val PER: 0.2691
2025-11-02 10:43:19,937: t15.2023.11.19 val PER: 0.2335
2025-11-02 10:43:19,937: t15.2023.11.26 val PER: 0.4406
2025-11-02 10:43:19,937: t15.2023.12.03 val PER: 0.3782
2025-11-02 10:43:19,938: t15.2023.12.08 val PER: 0.3915
2025-11-02 10:43:19,938: t15.2023.12.10 val PER: 0.3417
2025-11-02 10:43:19,938: t15.2023.12.17 val PER: 0.3815
2025-11-02 10:43:19,938: t15.2023.12.29 val PER: 0.3946
2025-11-02 10:43:19,939: t15.2024.02.25 val PER: 0.3258
2025-11-02 10:43:19,939: t15.2024.03.08 val PER: 0.4637
2025-11-02 10:43:19,939: t15.2024.03.15 val PER: 0.4165
2025-11-02 10:43:19,939: t15.2024.03.17 val PER: 0.3982
2025-11-02 10:43:19,940: t15.2024.05.10 val PER: 0.4027
2025-11-02 10:43:19,940: t15.2024.06.14 val PER: 0.3801
2025-11-02 10:43:19,940: t15.2024.07.19 val PER: 0.4891
2025-11-02 10:43:19,941: t15.2024.07.21 val PER: 0.3579
2025-11-02 10:43:19,941: t15.2024.07.28 val PER: 0.3853
2025-11-02 10:43:19,941: t15.2025.01.10 val PER: 0.5331
2025-11-02 10:43:19,942: t15.2025.01.12 val PER: 0.4065
2025-11-02 10:43:19,942: t15.2025.03.14 val PER: 0.5577
2025-11-02 10:43:19,942: t15.2025.03.16 val PER: 0.4490
2025-11-02 10:43:19,943: t15.2025.03.30 val PER: 0.5276
2025-11-02 10:43:19,943: t15.2025.04.13 val PER: 0.4394
2025-11-02 10:43:19,943: New best test PER 0.4439 --> 0.3915
2025-11-02 10:43:19,943: Checkpointing model
2025-11-02 10:43:21,229: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:43:48,707: Train batch 5200: loss: 37.15 grad norm: 39.30 time: 0.056
2025-11-02 10:44:17,731: Train batch 5400: loss: 34.26 grad norm: 42.26 time: 0.058
2025-11-02 10:44:43,794: Train batch 5600: loss: 38.54 grad norm: 47.80 time: 0.077
2025-11-02 10:45:11,850: Train batch 5800: loss: 41.53 grad norm: 65.28 time: 0.057
2025-11-02 10:45:38,736: Train batch 6000: loss: 27.29 grad norm: 33.69 time: 0.056
2025-11-02 10:45:38,737: Running test after training batch: 6000
2025-11-02 10:45:51,726: Val batch 6000: PER (avg): 0.3488 CTC Loss (avg): 36.1916 time: 12.989
2025-11-02 10:45:51,727: t15.2023.08.13 val PER: 0.3170
2025-11-02 10:45:51,727: t15.2023.08.18 val PER: 0.2909
2025-11-02 10:45:51,728: t15.2023.08.20 val PER: 0.2851
2025-11-02 10:45:51,728: t15.2023.08.25 val PER: 0.2816
2025-11-02 10:45:51,728: t15.2023.08.27 val PER: 0.3666
2025-11-02 10:45:51,729: t15.2023.09.01 val PER: 0.2638
2025-11-02 10:45:51,729: t15.2023.09.03 val PER: 0.3337
2025-11-02 10:45:51,729: t15.2023.09.24 val PER: 0.2998
2025-11-02 10:45:51,729: t15.2023.09.29 val PER: 0.3031
2025-11-02 10:45:51,730: t15.2023.10.01 val PER: 0.3771
2025-11-02 10:45:51,730: t15.2023.10.06 val PER: 0.2896
2025-11-02 10:45:51,731: t15.2023.10.08 val PER: 0.4235
2025-11-02 10:45:51,732: t15.2023.10.13 val PER: 0.4306
2025-11-02 10:45:51,732: t15.2023.10.15 val PER: 0.3395
2025-11-02 10:45:51,733: t15.2023.10.20 val PER: 0.3322
2025-11-02 10:45:51,733: t15.2023.10.22 val PER: 0.2962
2025-11-02 10:45:51,733: t15.2023.11.03 val PER: 0.3433
2025-11-02 10:45:51,733: t15.2023.11.04 val PER: 0.1433
2025-11-02 10:45:51,733: t15.2023.11.17 val PER: 0.2037
2025-11-02 10:45:51,733: t15.2023.11.19 val PER: 0.2036
2025-11-02 10:45:51,734: t15.2023.11.26 val PER: 0.4043
2025-11-02 10:45:51,734: t15.2023.12.03 val PER: 0.3487
2025-11-02 10:45:51,734: t15.2023.12.08 val PER: 0.3475
2025-11-02 10:45:51,734: t15.2023.12.10 val PER: 0.2904
2025-11-02 10:45:51,734: t15.2023.12.17 val PER: 0.3410
2025-11-02 10:45:51,735: t15.2023.12.29 val PER: 0.3583
2025-11-02 10:45:51,735: t15.2024.02.25 val PER: 0.2697
2025-11-02 10:45:51,735: t15.2024.03.08 val PER: 0.4225
2025-11-02 10:45:51,736: t15.2024.03.15 val PER: 0.3884
2025-11-02 10:45:51,736: t15.2024.03.17 val PER: 0.3515
2025-11-02 10:45:51,736: t15.2024.05.10 val PER: 0.3611
2025-11-02 10:45:51,736: t15.2024.06.14 val PER: 0.3423
2025-11-02 10:45:51,736: t15.2024.07.19 val PER: 0.4384
2025-11-02 10:45:51,737: t15.2024.07.21 val PER: 0.3117
2025-11-02 10:45:51,737: t15.2024.07.28 val PER: 0.3316
2025-11-02 10:45:51,737: t15.2025.01.10 val PER: 0.4848
2025-11-02 10:45:51,737: t15.2025.01.12 val PER: 0.3772
2025-11-02 10:45:51,737: t15.2025.03.14 val PER: 0.5311
2025-11-02 10:45:51,738: t15.2025.03.16 val PER: 0.3927
2025-11-02 10:45:51,738: t15.2025.03.30 val PER: 0.4667
2025-11-02 10:45:51,738: t15.2025.04.13 val PER: 0.4037
2025-11-02 10:45:51,738: New best test PER 0.3915 --> 0.3488
2025-11-02 10:45:51,738: Checkpointing model
2025-11-02 10:45:53,057: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:46:20,937: Train batch 6200: loss: 26.35 grad norm: 52.28 time: 0.060
2025-11-02 10:46:48,338: Train batch 6400: loss: 26.97 grad norm: 46.91 time: 0.079
2025-11-02 10:47:15,293: Train batch 6600: loss: 31.64 grad norm: 64.41 time: 0.065
2025-11-02 10:47:42,805: Train batch 6800: loss: 20.56 grad norm: 37.85 time: 0.061
2025-11-02 10:48:09,928: Train batch 7000: loss: 32.10 grad norm: 39.67 time: 0.065
2025-11-02 10:48:09,929: Running test after training batch: 7000
2025-11-02 10:48:22,837: Val batch 7000: PER (avg): 0.3151 CTC Loss (avg): 32.4464 time: 12.908
2025-11-02 10:48:22,838: t15.2023.08.13 val PER: 0.2900
2025-11-02 10:48:22,838: t15.2023.08.18 val PER: 0.2590
2025-11-02 10:48:22,838: t15.2023.08.20 val PER: 0.2550
2025-11-02 10:48:22,839: t15.2023.08.25 val PER: 0.2425
2025-11-02 10:48:22,839: t15.2023.08.27 val PER: 0.3441
2025-11-02 10:48:22,839: t15.2023.09.01 val PER: 0.2216
2025-11-02 10:48:22,839: t15.2023.09.03 val PER: 0.3171
2025-11-02 10:48:22,840: t15.2023.09.24 val PER: 0.2561
2025-11-02 10:48:22,840: t15.2023.09.29 val PER: 0.2808
2025-11-02 10:48:22,841: t15.2023.10.01 val PER: 0.3388
2025-11-02 10:48:22,884: t15.2023.10.06 val PER: 0.2626
2025-11-02 10:48:22,884: t15.2023.10.08 val PER: 0.3857
2025-11-02 10:48:22,884: t15.2023.10.13 val PER: 0.3809
2025-11-02 10:48:22,884: t15.2023.10.15 val PER: 0.2993
2025-11-02 10:48:22,885: t15.2023.10.20 val PER: 0.2953
2025-11-02 10:48:22,885: t15.2023.10.22 val PER: 0.2528
2025-11-02 10:48:22,885: t15.2023.11.03 val PER: 0.3053
2025-11-02 10:48:22,886: t15.2023.11.04 val PER: 0.1160
2025-11-02 10:48:22,886: t15.2023.11.17 val PER: 0.1820
2025-11-02 10:48:22,886: t15.2023.11.19 val PER: 0.1537
2025-11-02 10:48:22,887: t15.2023.11.26 val PER: 0.3551
2025-11-02 10:48:22,887: t15.2023.12.03 val PER: 0.3099
2025-11-02 10:48:22,887: t15.2023.12.08 val PER: 0.3142
2025-11-02 10:48:22,887: t15.2023.12.10 val PER: 0.2602
2025-11-02 10:48:22,887: t15.2023.12.17 val PER: 0.3170
2025-11-02 10:48:22,888: t15.2023.12.29 val PER: 0.3185
2025-11-02 10:48:22,888: t15.2024.02.25 val PER: 0.2500
2025-11-02 10:48:22,888: t15.2024.03.08 val PER: 0.3698
2025-11-02 10:48:22,888: t15.2024.03.15 val PER: 0.3615
2025-11-02 10:48:22,888: t15.2024.03.17 val PER: 0.3243
2025-11-02 10:48:22,889: t15.2024.05.10 val PER: 0.3269
2025-11-02 10:48:22,889: t15.2024.06.14 val PER: 0.3028
2025-11-02 10:48:22,889: t15.2024.07.19 val PER: 0.4100
2025-11-02 10:48:22,889: t15.2024.07.21 val PER: 0.2717
2025-11-02 10:48:22,890: t15.2024.07.28 val PER: 0.3103
2025-11-02 10:48:22,890: t15.2025.01.10 val PER: 0.4738
2025-11-02 10:48:22,890: t15.2025.01.12 val PER: 0.3457
2025-11-02 10:48:22,890: t15.2025.03.14 val PER: 0.4970
2025-11-02 10:48:22,891: t15.2025.03.16 val PER: 0.3521
2025-11-02 10:48:22,891: t15.2025.03.30 val PER: 0.4241
2025-11-02 10:48:22,891: t15.2025.04.13 val PER: 0.3795
2025-11-02 10:48:22,891: New best test PER 0.3488 --> 0.3151
2025-11-02 10:48:22,892: Checkpointing model
2025-11-02 10:48:24,120: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:48:51,633: Train batch 7200: loss: 28.85 grad norm: 42.55 time: 0.066
2025-11-02 10:49:19,877: Train batch 7400: loss: 20.13 grad norm: 35.56 time: 0.088
2025-11-02 10:49:46,654: Train batch 7600: loss: 22.97 grad norm: 38.20 time: 0.068
2025-11-02 10:50:14,017: Train batch 7800: loss: 19.67 grad norm: 32.77 time: 0.067
2025-11-02 10:50:41,285: Train batch 8000: loss: 17.73 grad norm: 47.92 time: 0.067
2025-11-02 10:50:41,286: Running test after training batch: 8000
2025-11-02 10:50:53,129: Val batch 8000: PER (avg): 0.2883 CTC Loss (avg): 29.8783 time: 11.843
2025-11-02 10:50:53,130: t15.2023.08.13 val PER: 0.2547
2025-11-02 10:50:53,131: t15.2023.08.18 val PER: 0.2347
2025-11-02 10:50:53,131: t15.2023.08.20 val PER: 0.2303
2025-11-02 10:50:53,132: t15.2023.08.25 val PER: 0.2199
2025-11-02 10:50:53,132: t15.2023.08.27 val PER: 0.3119
2025-11-02 10:50:53,132: t15.2023.09.01 val PER: 0.1851
2025-11-02 10:50:53,132: t15.2023.09.03 val PER: 0.2838
2025-11-02 10:50:53,133: t15.2023.09.24 val PER: 0.2391
2025-11-02 10:50:53,134: t15.2023.09.29 val PER: 0.2546
2025-11-02 10:50:53,135: t15.2023.10.01 val PER: 0.2992
2025-11-02 10:50:53,135: t15.2023.10.06 val PER: 0.2347
2025-11-02 10:50:53,135: t15.2023.10.08 val PER: 0.3437
2025-11-02 10:50:53,136: t15.2023.10.13 val PER: 0.3654
2025-11-02 10:50:53,136: t15.2023.10.15 val PER: 0.2703
2025-11-02 10:50:53,136: t15.2023.10.20 val PER: 0.2819
2025-11-02 10:50:53,136: t15.2023.10.22 val PER: 0.2383
2025-11-02 10:50:53,137: t15.2023.11.03 val PER: 0.2883
2025-11-02 10:50:53,137: t15.2023.11.04 val PER: 0.0853
2025-11-02 10:50:53,137: t15.2023.11.17 val PER: 0.1509
2025-11-02 10:50:53,137: t15.2023.11.19 val PER: 0.1317
2025-11-02 10:50:53,138: t15.2023.11.26 val PER: 0.3290
2025-11-02 10:50:53,138: t15.2023.12.03 val PER: 0.2731
2025-11-02 10:50:53,138: t15.2023.12.08 val PER: 0.2843
2025-11-02 10:50:53,138: t15.2023.12.10 val PER: 0.2339
2025-11-02 10:50:53,139: t15.2023.12.17 val PER: 0.2900
2025-11-02 10:50:53,139: t15.2023.12.29 val PER: 0.2944
2025-11-02 10:50:53,139: t15.2024.02.25 val PER: 0.2219
2025-11-02 10:50:53,139: t15.2024.03.08 val PER: 0.3656
2025-11-02 10:50:53,139: t15.2024.03.15 val PER: 0.3446
2025-11-02 10:50:53,140: t15.2024.03.17 val PER: 0.2936
2025-11-02 10:50:53,140: t15.2024.05.10 val PER: 0.2972
2025-11-02 10:50:53,140: t15.2024.06.14 val PER: 0.2934
2025-11-02 10:50:53,140: t15.2024.07.19 val PER: 0.3823
2025-11-02 10:50:53,141: t15.2024.07.21 val PER: 0.2414
2025-11-02 10:50:53,141: t15.2024.07.28 val PER: 0.2809
2025-11-02 10:50:53,141: t15.2025.01.10 val PER: 0.4394
2025-11-02 10:50:53,141: t15.2025.01.12 val PER: 0.3064
2025-11-02 10:50:53,141: t15.2025.03.14 val PER: 0.4571
2025-11-02 10:50:53,142: t15.2025.03.16 val PER: 0.3207
2025-11-02 10:50:53,142: t15.2025.03.30 val PER: 0.4034
2025-11-02 10:50:53,142: t15.2025.04.13 val PER: 0.3752
2025-11-02 10:50:53,142: New best test PER 0.3151 --> 0.2883
2025-11-02 10:50:53,142: Checkpointing model
2025-11-02 10:50:54,423: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:51:21,922: Train batch 8200: loss: 26.13 grad norm: 45.19 time: 0.058
2025-11-02 10:51:48,347: Train batch 8400: loss: 24.65 grad norm: 42.25 time: 0.071
2025-11-02 10:52:15,314: Train batch 8600: loss: 24.56 grad norm: 52.99 time: 0.061
2025-11-02 10:52:42,046: Train batch 8800: loss: 30.30 grad norm: 142.15 time: 0.100
2025-11-02 10:53:08,939: Train batch 9000: loss: 21.31 grad norm: 39.12 time: 0.082
2025-11-02 10:53:08,941: Running test after training batch: 9000
2025-11-02 10:53:22,109: Val batch 9000: PER (avg): 0.2700 CTC Loss (avg): 27.6474 time: 13.168
2025-11-02 10:53:22,110: t15.2023.08.13 val PER: 0.2474
2025-11-02 10:53:22,111: t15.2023.08.18 val PER: 0.2255
2025-11-02 10:53:22,111: t15.2023.08.20 val PER: 0.2017
2025-11-02 10:53:22,111: t15.2023.08.25 val PER: 0.2108
2025-11-02 10:53:22,111: t15.2023.08.27 val PER: 0.2878
2025-11-02 10:53:22,112: t15.2023.09.01 val PER: 0.1745
2025-11-02 10:53:22,112: t15.2023.09.03 val PER: 0.2577
2025-11-02 10:53:22,112: t15.2023.09.24 val PER: 0.1978
2025-11-02 10:53:22,112: t15.2023.09.29 val PER: 0.2348
2025-11-02 10:53:22,113: t15.2023.10.01 val PER: 0.2840
2025-11-02 10:53:22,113: t15.2023.10.06 val PER: 0.2153
2025-11-02 10:53:22,113: t15.2023.10.08 val PER: 0.3234
2025-11-02 10:53:22,113: t15.2023.10.13 val PER: 0.3359
2025-11-02 10:53:22,114: t15.2023.10.15 val PER: 0.2610
2025-11-02 10:53:22,114: t15.2023.10.20 val PER: 0.2416
2025-11-02 10:53:22,114: t15.2023.10.22 val PER: 0.2227
2025-11-02 10:53:22,114: t15.2023.11.03 val PER: 0.2775
2025-11-02 10:53:22,115: t15.2023.11.04 val PER: 0.0819
2025-11-02 10:53:22,116: t15.2023.11.17 val PER: 0.1431
2025-11-02 10:53:22,116: t15.2023.11.19 val PER: 0.1198
2025-11-02 10:53:22,116: t15.2023.11.26 val PER: 0.3043
2025-11-02 10:53:22,116: t15.2023.12.03 val PER: 0.2416
2025-11-02 10:53:22,116: t15.2023.12.08 val PER: 0.2676
2025-11-02 10:53:22,117: t15.2023.12.10 val PER: 0.2221
2025-11-02 10:53:22,117: t15.2023.12.17 val PER: 0.2755
2025-11-02 10:53:22,117: t15.2023.12.29 val PER: 0.2759
2025-11-02 10:53:22,118: t15.2024.02.25 val PER: 0.2177
2025-11-02 10:53:22,118: t15.2024.03.08 val PER: 0.3343
2025-11-02 10:53:22,118: t15.2024.03.15 val PER: 0.3196
2025-11-02 10:53:22,118: t15.2024.03.17 val PER: 0.2880
2025-11-02 10:53:22,119: t15.2024.05.10 val PER: 0.2823
2025-11-02 10:53:22,119: t15.2024.06.14 val PER: 0.2713
2025-11-02 10:53:22,119: t15.2024.07.19 val PER: 0.3612
2025-11-02 10:53:22,119: t15.2024.07.21 val PER: 0.2110
2025-11-02 10:53:22,120: t15.2024.07.28 val PER: 0.2662
2025-11-02 10:53:22,120: t15.2025.01.10 val PER: 0.4284
2025-11-02 10:53:22,120: t15.2025.01.12 val PER: 0.2964
2025-11-02 10:53:22,121: t15.2025.03.14 val PER: 0.4393
2025-11-02 10:53:22,121: t15.2025.03.16 val PER: 0.3063
2025-11-02 10:53:22,121: t15.2025.03.30 val PER: 0.3897
2025-11-02 10:53:22,121: t15.2025.04.13 val PER: 0.3310
2025-11-02 10:53:22,122: New best test PER 0.2883 --> 0.2700
2025-11-02 10:53:22,122: Checkpointing model
2025-11-02 10:53:23,460: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:53:50,243: Train batch 9200: loss: 23.30 grad norm: 43.41 time: 0.068
2025-11-02 10:54:17,648: Train batch 9400: loss: 18.37 grad norm: 40.16 time: 0.101
2025-11-02 10:54:44,604: Train batch 9600: loss: 22.85 grad norm: 39.20 time: 0.068
2025-11-02 10:55:11,548: Train batch 9800: loss: 21.56 grad norm: 49.67 time: 0.068
2025-11-02 10:55:37,328: Train batch 10000: loss: 20.47 grad norm: 49.79 time: 0.074
2025-11-02 10:55:37,329: Running test after training batch: 10000
2025-11-02 10:55:51,634: Val batch 10000: PER (avg): 0.2537 CTC Loss (avg): 26.0841 time: 14.305
2025-11-02 10:55:51,637: t15.2023.08.13 val PER: 0.2131
2025-11-02 10:55:51,637: t15.2023.08.18 val PER: 0.2045
2025-11-02 10:55:51,638: t15.2023.08.20 val PER: 0.2002
2025-11-02 10:55:51,638: t15.2023.08.25 val PER: 0.1792
2025-11-02 10:55:51,638: t15.2023.08.27 val PER: 0.2717
2025-11-02 10:55:51,639: t15.2023.09.01 val PER: 0.1542
2025-11-02 10:55:51,639: t15.2023.09.03 val PER: 0.2494
2025-11-02 10:55:51,639: t15.2023.09.24 val PER: 0.2051
2025-11-02 10:55:51,639: t15.2023.09.29 val PER: 0.2125
2025-11-02 10:55:51,640: t15.2023.10.01 val PER: 0.2602
2025-11-02 10:55:51,640: t15.2023.10.06 val PER: 0.1873
2025-11-02 10:55:51,641: t15.2023.10.08 val PER: 0.3139
2025-11-02 10:55:51,641: t15.2023.10.13 val PER: 0.3220
2025-11-02 10:55:51,641: t15.2023.10.15 val PER: 0.2432
2025-11-02 10:55:51,641: t15.2023.10.20 val PER: 0.2550
2025-11-02 10:55:51,642: t15.2023.10.22 val PER: 0.2060
2025-11-02 10:55:51,642: t15.2023.11.03 val PER: 0.2619
2025-11-02 10:55:51,642: t15.2023.11.04 val PER: 0.0751
2025-11-02 10:55:51,642: t15.2023.11.17 val PER: 0.1275
2025-11-02 10:55:51,643: t15.2023.11.19 val PER: 0.1158
2025-11-02 10:55:51,643: t15.2023.11.26 val PER: 0.2826
2025-11-02 10:55:51,643: t15.2023.12.03 val PER: 0.2216
2025-11-02 10:55:51,643: t15.2023.12.08 val PER: 0.2543
2025-11-02 10:55:51,644: t15.2023.12.10 val PER: 0.2037
2025-11-02 10:55:51,644: t15.2023.12.17 val PER: 0.2536
2025-11-02 10:55:51,644: t15.2023.12.29 val PER: 0.2505
2025-11-02 10:55:51,644: t15.2024.02.25 val PER: 0.1882
2025-11-02 10:55:51,645: t15.2024.03.08 val PER: 0.3286
2025-11-02 10:55:51,645: t15.2024.03.15 val PER: 0.3189
2025-11-02 10:55:51,646: t15.2024.03.17 val PER: 0.2685
2025-11-02 10:55:51,646: t15.2024.05.10 val PER: 0.2585
2025-11-02 10:55:51,646: t15.2024.06.14 val PER: 0.2697
2025-11-02 10:55:51,646: t15.2024.07.19 val PER: 0.3467
2025-11-02 10:55:51,647: t15.2024.07.21 val PER: 0.1903
2025-11-02 10:55:51,647: t15.2024.07.28 val PER: 0.2478
2025-11-02 10:55:51,647: t15.2025.01.10 val PER: 0.4174
2025-11-02 10:55:51,647: t15.2025.01.12 val PER: 0.2648
2025-11-02 10:55:51,648: t15.2025.03.14 val PER: 0.4423
2025-11-02 10:55:51,648: t15.2025.03.16 val PER: 0.2919
2025-11-02 10:55:51,648: t15.2025.03.30 val PER: 0.3747
2025-11-02 10:55:51,648: t15.2025.04.13 val PER: 0.3295
2025-11-02 10:55:51,649: New best test PER 0.2700 --> 0.2537
2025-11-02 10:55:51,649: Checkpointing model
2025-11-02 10:55:53,140: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:56:20,060: Train batch 10200: loss: 16.79 grad norm: 35.59 time: 0.063
2025-11-02 10:56:46,385: Train batch 10400: loss: 15.96 grad norm: 42.07 time: 0.075
2025-11-02 10:57:13,450: Train batch 10600: loss: 17.68 grad norm: 40.31 time: 0.088
2025-11-02 10:57:40,779: Train batch 10800: loss: 17.56 grad norm: 40.88 time: 0.061
2025-11-02 10:58:07,823: Train batch 11000: loss: 24.68 grad norm: 58.87 time: 0.101
2025-11-02 10:58:07,824: Running test after training batch: 11000
2025-11-02 10:58:21,325: Val batch 11000: PER (avg): 0.2416 CTC Loss (avg): 24.8188 time: 13.501
2025-11-02 10:58:21,326: t15.2023.08.13 val PER: 0.2048
2025-11-02 10:58:21,327: t15.2023.08.18 val PER: 0.1836
2025-11-02 10:58:21,327: t15.2023.08.20 val PER: 0.1898
2025-11-02 10:58:21,327: t15.2023.08.25 val PER: 0.1747
2025-11-02 10:58:21,328: t15.2023.08.27 val PER: 0.2508
2025-11-02 10:58:21,329: t15.2023.09.01 val PER: 0.1437
2025-11-02 10:58:21,329: t15.2023.09.03 val PER: 0.2375
2025-11-02 10:58:21,329: t15.2023.09.24 val PER: 0.1954
2025-11-02 10:58:21,329: t15.2023.09.29 val PER: 0.2017
2025-11-02 10:58:21,330: t15.2023.10.01 val PER: 0.2517
2025-11-02 10:58:21,330: t15.2023.10.06 val PER: 0.1776
2025-11-02 10:58:21,331: t15.2023.10.08 val PER: 0.3004
2025-11-02 10:58:21,331: t15.2023.10.13 val PER: 0.3057
2025-11-02 10:58:21,331: t15.2023.10.15 val PER: 0.2367
2025-11-02 10:58:21,331: t15.2023.10.20 val PER: 0.2349
2025-11-02 10:58:21,331: t15.2023.10.22 val PER: 0.1915
2025-11-02 10:58:21,332: t15.2023.11.03 val PER: 0.2598
2025-11-02 10:58:21,332: t15.2023.11.04 val PER: 0.0580
2025-11-02 10:58:21,332: t15.2023.11.17 val PER: 0.1104
2025-11-02 10:58:21,332: t15.2023.11.19 val PER: 0.1138
2025-11-02 10:58:21,333: t15.2023.11.26 val PER: 0.2754
2025-11-02 10:58:21,333: t15.2023.12.03 val PER: 0.2132
2025-11-02 10:58:21,333: t15.2023.12.08 val PER: 0.2370
2025-11-02 10:58:21,333: t15.2023.12.10 val PER: 0.1866
2025-11-02 10:58:21,334: t15.2023.12.17 val PER: 0.2484
2025-11-02 10:58:21,334: t15.2023.12.29 val PER: 0.2368
2025-11-02 10:58:21,334: t15.2024.02.25 val PER: 0.1910
2025-11-02 10:58:21,334: t15.2024.03.08 val PER: 0.3073
2025-11-02 10:58:21,335: t15.2024.03.15 val PER: 0.3008
2025-11-02 10:58:21,335: t15.2024.03.17 val PER: 0.2580
2025-11-02 10:58:21,335: t15.2024.05.10 val PER: 0.2392
2025-11-02 10:58:21,336: t15.2024.06.14 val PER: 0.2618
2025-11-02 10:58:21,336: t15.2024.07.19 val PER: 0.3316
2025-11-02 10:58:21,336: t15.2024.07.21 val PER: 0.1848
2025-11-02 10:58:21,336: t15.2024.07.28 val PER: 0.2301
2025-11-02 10:58:21,337: t15.2025.01.10 val PER: 0.3912
2025-11-02 10:58:21,337: t15.2025.01.12 val PER: 0.2525
2025-11-02 10:58:21,337: t15.2025.03.14 val PER: 0.4172
2025-11-02 10:58:21,337: t15.2025.03.16 val PER: 0.2853
2025-11-02 10:58:21,338: t15.2025.03.30 val PER: 0.3621
2025-11-02 10:58:21,338: t15.2025.04.13 val PER: 0.3195
2025-11-02 10:58:21,338: New best test PER 0.2537 --> 0.2416
2025-11-02 10:58:21,339: Checkpointing model
2025-11-02 10:58:22,694: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 10:58:49,411: Train batch 11200: loss: 18.42 grad norm: 46.29 time: 0.097
2025-11-02 10:59:16,360: Train batch 11400: loss: 14.84 grad norm: 40.51 time: 0.062
2025-11-02 10:59:44,346: Train batch 11600: loss: 11.17 grad norm: 28.66 time: 0.085
2025-11-02 11:00:11,869: Train batch 11800: loss: 18.41 grad norm: 45.34 time: 0.085
2025-11-02 11:00:39,124: Train batch 12000: loss: 10.23 grad norm: 32.29 time: 0.061
2025-11-02 11:00:39,125: Running test after training batch: 12000
2025-11-02 11:00:52,570: Val batch 12000: PER (avg): 0.2301 CTC Loss (avg): 23.9426 time: 13.444
2025-11-02 11:00:52,571: t15.2023.08.13 val PER: 0.1954
2025-11-02 11:00:52,572: t15.2023.08.18 val PER: 0.1769
2025-11-02 11:00:52,572: t15.2023.08.20 val PER: 0.1930
2025-11-02 11:00:52,572: t15.2023.08.25 val PER: 0.1611
2025-11-02 11:00:52,572: t15.2023.08.27 val PER: 0.2749
2025-11-02 11:00:52,573: t15.2023.09.01 val PER: 0.1339
2025-11-02 11:00:52,573: t15.2023.09.03 val PER: 0.2268
2025-11-02 11:00:52,573: t15.2023.09.24 val PER: 0.1772
2025-11-02 11:00:52,574: t15.2023.09.29 val PER: 0.1883
2025-11-02 11:00:52,585: t15.2023.10.01 val PER: 0.2404
2025-11-02 11:00:52,586: t15.2023.10.06 val PER: 0.1722
2025-11-02 11:00:52,586: t15.2023.10.08 val PER: 0.3031
2025-11-02 11:00:52,587: t15.2023.10.13 val PER: 0.2832
2025-11-02 11:00:52,587: t15.2023.10.15 val PER: 0.2228
2025-11-02 11:00:52,587: t15.2023.10.20 val PER: 0.2248
2025-11-02 11:00:52,587: t15.2023.10.22 val PER: 0.1849
2025-11-02 11:00:52,587: t15.2023.11.03 val PER: 0.2374
2025-11-02 11:00:52,588: t15.2023.11.04 val PER: 0.0546
2025-11-02 11:00:52,588: t15.2023.11.17 val PER: 0.0933
2025-11-02 11:00:52,588: t15.2023.11.19 val PER: 0.1118
2025-11-02 11:00:52,589: t15.2023.11.26 val PER: 0.2536
2025-11-02 11:00:52,589: t15.2023.12.03 val PER: 0.1880
2025-11-02 11:00:52,589: t15.2023.12.08 val PER: 0.2217
2025-11-02 11:00:52,589: t15.2023.12.10 val PER: 0.1813
2025-11-02 11:00:52,589: t15.2023.12.17 val PER: 0.2287
2025-11-02 11:00:52,590: t15.2023.12.29 val PER: 0.2265
2025-11-02 11:00:52,590: t15.2024.02.25 val PER: 0.1854
2025-11-02 11:00:52,590: t15.2024.03.08 val PER: 0.3030
2025-11-02 11:00:52,591: t15.2024.03.15 val PER: 0.2877
2025-11-02 11:00:52,591: t15.2024.03.17 val PER: 0.2364
2025-11-02 11:00:52,591: t15.2024.05.10 val PER: 0.2229
2025-11-02 11:00:52,591: t15.2024.06.14 val PER: 0.2508
2025-11-02 11:00:52,591: t15.2024.07.19 val PER: 0.3177
2025-11-02 11:00:52,592: t15.2024.07.21 val PER: 0.1641
2025-11-02 11:00:52,592: t15.2024.07.28 val PER: 0.2213
2025-11-02 11:00:52,592: t15.2025.01.10 val PER: 0.3857
2025-11-02 11:00:52,592: t15.2025.01.12 val PER: 0.2410
2025-11-02 11:00:52,592: t15.2025.03.14 val PER: 0.4068
2025-11-02 11:00:52,593: t15.2025.03.16 val PER: 0.2788
2025-11-02 11:00:52,593: t15.2025.03.30 val PER: 0.3690
2025-11-02 11:00:52,593: t15.2025.04.13 val PER: 0.3053
2025-11-02 11:00:52,593: New best test PER 0.2416 --> 0.2301
2025-11-02 11:00:52,593: Checkpointing model
2025-11-02 11:00:54,085: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:01:19,489: Train batch 12200: loss: 13.91 grad norm: 43.52 time: 0.087
2025-11-02 11:01:45,522: Train batch 12400: loss: 12.76 grad norm: 61.04 time: 0.090
2025-11-02 11:02:11,182: Train batch 12600: loss: 12.01 grad norm: 36.46 time: 0.063
2025-11-02 11:02:35,780: Train batch 12800: loss: 17.60 grad norm: 49.61 time: 0.080
2025-11-02 11:03:01,480: Train batch 13000: loss: 16.92 grad norm: 47.40 time: 0.076
2025-11-02 11:03:01,481: Running test after training batch: 13000
2025-11-02 11:03:15,142: Val batch 13000: PER (avg): 0.2254 CTC Loss (avg): 23.0773 time: 13.660
2025-11-02 11:03:15,143: t15.2023.08.13 val PER: 0.1861
2025-11-02 11:03:15,143: t15.2023.08.18 val PER: 0.1760
2025-11-02 11:03:15,144: t15.2023.08.20 val PER: 0.1739
2025-11-02 11:03:15,184: t15.2023.08.25 val PER: 0.1581
2025-11-02 11:03:15,184: t15.2023.08.27 val PER: 0.2637
2025-11-02 11:03:15,184: t15.2023.09.01 val PER: 0.1250
2025-11-02 11:03:15,185: t15.2023.09.03 val PER: 0.2292
2025-11-02 11:03:15,185: t15.2023.09.24 val PER: 0.1796
2025-11-02 11:03:15,186: t15.2023.09.29 val PER: 0.1895
2025-11-02 11:03:15,186: t15.2023.10.01 val PER: 0.2378
2025-11-02 11:03:15,186: t15.2023.10.06 val PER: 0.1701
2025-11-02 11:03:15,187: t15.2023.10.08 val PER: 0.2760
2025-11-02 11:03:15,187: t15.2023.10.13 val PER: 0.2816
2025-11-02 11:03:15,187: t15.2023.10.15 val PER: 0.2248
2025-11-02 11:03:15,188: t15.2023.10.20 val PER: 0.2081
2025-11-02 11:03:15,188: t15.2023.10.22 val PER: 0.1737
2025-11-02 11:03:15,188: t15.2023.11.03 val PER: 0.2368
2025-11-02 11:03:15,188: t15.2023.11.04 val PER: 0.0410
2025-11-02 11:03:15,189: t15.2023.11.17 val PER: 0.0995
2025-11-02 11:03:15,189: t15.2023.11.19 val PER: 0.0958
2025-11-02 11:03:15,189: t15.2023.11.26 val PER: 0.2565
2025-11-02 11:03:15,189: t15.2023.12.03 val PER: 0.1933
2025-11-02 11:03:15,190: t15.2023.12.08 val PER: 0.2224
2025-11-02 11:03:15,190: t15.2023.12.10 val PER: 0.1827
2025-11-02 11:03:15,191: t15.2023.12.17 val PER: 0.2443
2025-11-02 11:03:15,191: t15.2023.12.29 val PER: 0.2203
2025-11-02 11:03:15,191: t15.2024.02.25 val PER: 0.1784
2025-11-02 11:03:15,192: t15.2024.03.08 val PER: 0.2945
2025-11-02 11:03:15,192: t15.2024.03.15 val PER: 0.2852
2025-11-02 11:03:15,192: t15.2024.03.17 val PER: 0.2329
2025-11-02 11:03:15,192: t15.2024.05.10 val PER: 0.2184
2025-11-02 11:03:15,193: t15.2024.06.14 val PER: 0.2382
2025-11-02 11:03:15,193: t15.2024.07.19 val PER: 0.2999
2025-11-02 11:03:15,193: t15.2024.07.21 val PER: 0.1641
2025-11-02 11:03:15,193: t15.2024.07.28 val PER: 0.2074
2025-11-02 11:03:15,194: t15.2025.01.10 val PER: 0.3733
2025-11-02 11:03:15,194: t15.2025.01.12 val PER: 0.2340
2025-11-02 11:03:15,194: t15.2025.03.14 val PER: 0.4053
2025-11-02 11:03:15,195: t15.2025.03.16 val PER: 0.2723
2025-11-02 11:03:15,195: t15.2025.03.30 val PER: 0.3575
2025-11-02 11:03:15,196: t15.2025.04.13 val PER: 0.3010
2025-11-02 11:03:15,196: New best test PER 0.2301 --> 0.2254
2025-11-02 11:03:15,196: Checkpointing model
2025-11-02 11:03:16,624: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:03:40,976: Train batch 13200: loss: 14.41 grad norm: 41.73 time: 0.060
2025-11-02 11:04:04,686: Train batch 13400: loss: 11.51 grad norm: 35.45 time: 0.071
2025-11-02 11:04:29,482: Train batch 13600: loss: 14.62 grad norm: 43.64 time: 0.070
2025-11-02 11:04:53,735: Train batch 13800: loss: 12.70 grad norm: 46.05 time: 0.068
2025-11-02 11:05:18,491: Train batch 14000: loss: 11.76 grad norm: 35.24 time: 0.062
2025-11-02 11:05:18,492: Running test after training batch: 14000
2025-11-02 11:05:32,412: Val batch 14000: PER (avg): 0.2171 CTC Loss (avg): 22.4700 time: 13.920
2025-11-02 11:05:32,413: t15.2023.08.13 val PER: 0.1746
2025-11-02 11:05:32,413: t15.2023.08.18 val PER: 0.1685
2025-11-02 11:05:32,414: t15.2023.08.20 val PER: 0.1739
2025-11-02 11:05:32,414: t15.2023.08.25 val PER: 0.1611
2025-11-02 11:05:32,415: t15.2023.08.27 val PER: 0.2733
2025-11-02 11:05:32,415: t15.2023.09.01 val PER: 0.1169
2025-11-02 11:05:32,416: t15.2023.09.03 val PER: 0.2114
2025-11-02 11:05:32,416: t15.2023.09.24 val PER: 0.1663
2025-11-02 11:05:32,416: t15.2023.09.29 val PER: 0.1768
2025-11-02 11:05:32,417: t15.2023.10.01 val PER: 0.2391
2025-11-02 11:05:32,417: t15.2023.10.06 val PER: 0.1561
2025-11-02 11:05:32,418: t15.2023.10.08 val PER: 0.2896
2025-11-02 11:05:32,419: t15.2023.10.13 val PER: 0.2731
2025-11-02 11:05:32,419: t15.2023.10.15 val PER: 0.2116
2025-11-02 11:05:32,420: t15.2023.10.20 val PER: 0.1846
2025-11-02 11:05:32,421: t15.2023.10.22 val PER: 0.1837
2025-11-02 11:05:32,421: t15.2023.11.03 val PER: 0.2313
2025-11-02 11:05:32,421: t15.2023.11.04 val PER: 0.0375
2025-11-02 11:05:32,422: t15.2023.11.17 val PER: 0.0824
2025-11-02 11:05:32,422: t15.2023.11.19 val PER: 0.0898
2025-11-02 11:05:32,423: t15.2023.11.26 val PER: 0.2355
2025-11-02 11:05:32,424: t15.2023.12.03 val PER: 0.1660
2025-11-02 11:05:32,425: t15.2023.12.08 val PER: 0.2004
2025-11-02 11:05:32,426: t15.2023.12.10 val PER: 0.1682
2025-11-02 11:05:32,426: t15.2023.12.17 val PER: 0.2173
2025-11-02 11:05:32,426: t15.2023.12.29 val PER: 0.2128
2025-11-02 11:05:32,427: t15.2024.02.25 val PER: 0.1629
2025-11-02 11:05:32,427: t15.2024.03.08 val PER: 0.2959
2025-11-02 11:05:32,427: t15.2024.03.15 val PER: 0.2814
2025-11-02 11:05:32,428: t15.2024.03.17 val PER: 0.2245
2025-11-02 11:05:32,428: t15.2024.05.10 val PER: 0.2065
2025-11-02 11:05:32,428: t15.2024.06.14 val PER: 0.2366
2025-11-02 11:05:32,429: t15.2024.07.19 val PER: 0.2933
2025-11-02 11:05:32,429: t15.2024.07.21 val PER: 0.1545
2025-11-02 11:05:32,429: t15.2024.07.28 val PER: 0.2000
2025-11-02 11:05:32,430: t15.2025.01.10 val PER: 0.3788
2025-11-02 11:05:32,431: t15.2025.01.12 val PER: 0.2302
2025-11-02 11:05:32,431: t15.2025.03.14 val PER: 0.4024
2025-11-02 11:05:32,431: t15.2025.03.16 val PER: 0.2762
2025-11-02 11:05:32,431: t15.2025.03.30 val PER: 0.3483
2025-11-02 11:05:32,432: t15.2025.04.13 val PER: 0.2924
2025-11-02 11:05:32,432: New best test PER 0.2254 --> 0.2171
2025-11-02 11:05:32,432: Checkpointing model
2025-11-02 11:05:34,291: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:05:59,397: Train batch 14200: loss: 11.93 grad norm: 45.98 time: 0.078
2025-11-02 11:06:24,299: Train batch 14400: loss: 9.02 grad norm: 32.21 time: 0.073
2025-11-02 11:06:49,989: Train batch 14600: loss: 14.61 grad norm: 45.35 time: 0.084
2025-11-02 11:07:14,459: Train batch 14800: loss: 13.00 grad norm: 40.70 time: 0.057
2025-11-02 11:07:39,272: Train batch 15000: loss: 17.16 grad norm: 52.11 time: 0.071
2025-11-02 11:07:39,273: Running test after training batch: 15000
2025-11-02 11:07:50,851: Val batch 15000: PER (avg): 0.2113 CTC Loss (avg): 22.1625 time: 11.577
2025-11-02 11:07:50,852: t15.2023.08.13 val PER: 0.1726
2025-11-02 11:07:50,852: t15.2023.08.18 val PER: 0.1626
2025-11-02 11:07:50,852: t15.2023.08.20 val PER: 0.1620
2025-11-02 11:07:50,853: t15.2023.08.25 val PER: 0.1446
2025-11-02 11:07:50,853: t15.2023.08.27 val PER: 0.2621
2025-11-02 11:07:50,854: t15.2023.09.01 val PER: 0.1136
2025-11-02 11:07:50,854: t15.2023.09.03 val PER: 0.2126
2025-11-02 11:07:50,854: t15.2023.09.24 val PER: 0.1650
2025-11-02 11:07:50,855: t15.2023.09.29 val PER: 0.1761
2025-11-02 11:07:50,855: t15.2023.10.01 val PER: 0.2285
2025-11-02 11:07:50,856: t15.2023.10.06 val PER: 0.1507
2025-11-02 11:07:50,856: t15.2023.10.08 val PER: 0.2747
2025-11-02 11:07:50,856: t15.2023.10.13 val PER: 0.2669
2025-11-02 11:07:50,856: t15.2023.10.15 val PER: 0.2090
2025-11-02 11:07:50,857: t15.2023.10.20 val PER: 0.1913
2025-11-02 11:07:50,857: t15.2023.10.22 val PER: 0.1704
2025-11-02 11:07:50,857: t15.2023.11.03 val PER: 0.2347
2025-11-02 11:07:50,857: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:07:50,857: t15.2023.11.17 val PER: 0.0762
2025-11-02 11:07:50,884: t15.2023.11.19 val PER: 0.0938
2025-11-02 11:07:50,884: t15.2023.11.26 val PER: 0.2217
2025-11-02 11:07:50,884: t15.2023.12.03 val PER: 0.1691
2025-11-02 11:07:50,884: t15.2023.12.08 val PER: 0.1931
2025-11-02 11:07:50,885: t15.2023.12.10 val PER: 0.1643
2025-11-02 11:07:50,885: t15.2023.12.17 val PER: 0.2214
2025-11-02 11:07:50,886: t15.2023.12.29 val PER: 0.1997
2025-11-02 11:07:50,886: t15.2024.02.25 val PER: 0.1573
2025-11-02 11:07:50,886: t15.2024.03.08 val PER: 0.2817
2025-11-02 11:07:50,887: t15.2024.03.15 val PER: 0.2689
2025-11-02 11:07:50,887: t15.2024.03.17 val PER: 0.2169
2025-11-02 11:07:50,887: t15.2024.05.10 val PER: 0.2021
2025-11-02 11:07:50,887: t15.2024.06.14 val PER: 0.2366
2025-11-02 11:07:50,888: t15.2024.07.19 val PER: 0.2940
2025-11-02 11:07:50,888: t15.2024.07.21 val PER: 0.1510
2025-11-02 11:07:50,888: t15.2024.07.28 val PER: 0.1949
2025-11-02 11:07:50,888: t15.2025.01.10 val PER: 0.3788
2025-11-02 11:07:50,888: t15.2025.01.12 val PER: 0.2117
2025-11-02 11:07:50,889: t15.2025.03.14 val PER: 0.3876
2025-11-02 11:07:50,889: t15.2025.03.16 val PER: 0.2775
2025-11-02 11:07:50,889: t15.2025.03.30 val PER: 0.3483
2025-11-02 11:07:50,889: t15.2025.04.13 val PER: 0.2839
2025-11-02 11:07:50,889: New best test PER 0.2171 --> 0.2113
2025-11-02 11:07:50,889: Checkpointing model
2025-11-02 11:07:52,124: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:08:17,448: Train batch 15200: loss: 11.80 grad norm: 98.40 time: 0.099
2025-11-02 11:08:41,950: Train batch 15400: loss: 12.75 grad norm: 49.27 time: 0.106
2025-11-02 11:09:07,201: Train batch 15600: loss: 11.62 grad norm: 46.84 time: 0.078
2025-11-02 11:09:32,852: Train batch 15800: loss: 9.07 grad norm: 41.24 time: 0.073
2025-11-02 11:09:57,877: Train batch 16000: loss: 12.83 grad norm: 42.85 time: 0.065
2025-11-02 11:09:57,878: Running test after training batch: 16000
2025-11-02 11:10:09,007: Val batch 16000: PER (avg): 0.2057 CTC Loss (avg): 21.8949 time: 11.129
2025-11-02 11:10:09,008: t15.2023.08.13 val PER: 0.1549
2025-11-02 11:10:09,008: t15.2023.08.18 val PER: 0.1517
2025-11-02 11:10:09,009: t15.2023.08.20 val PER: 0.1525
2025-11-02 11:10:09,009: t15.2023.08.25 val PER: 0.1431
2025-11-02 11:10:09,009: t15.2023.08.27 val PER: 0.2444
2025-11-02 11:10:09,009: t15.2023.09.01 val PER: 0.1080
2025-11-02 11:10:09,010: t15.2023.09.03 val PER: 0.2150
2025-11-02 11:10:09,010: t15.2023.09.24 val PER: 0.1578
2025-11-02 11:10:09,011: t15.2023.09.29 val PER: 0.1736
2025-11-02 11:10:09,011: t15.2023.10.01 val PER: 0.2166
2025-11-02 11:10:09,011: t15.2023.10.06 val PER: 0.1582
2025-11-02 11:10:09,011: t15.2023.10.08 val PER: 0.2760
2025-11-02 11:10:09,012: t15.2023.10.13 val PER: 0.2599
2025-11-02 11:10:09,012: t15.2023.10.15 val PER: 0.1984
2025-11-02 11:10:09,012: t15.2023.10.20 val PER: 0.1779
2025-11-02 11:10:09,012: t15.2023.10.22 val PER: 0.1648
2025-11-02 11:10:09,013: t15.2023.11.03 val PER: 0.2286
2025-11-02 11:10:09,013: t15.2023.11.04 val PER: 0.0410
2025-11-02 11:10:09,013: t15.2023.11.17 val PER: 0.0793
2025-11-02 11:10:09,013: t15.2023.11.19 val PER: 0.0818
2025-11-02 11:10:09,014: t15.2023.11.26 val PER: 0.2152
2025-11-02 11:10:09,014: t15.2023.12.03 val PER: 0.1618
2025-11-02 11:10:09,014: t15.2023.12.08 val PER: 0.1851
2025-11-02 11:10:09,014: t15.2023.12.10 val PER: 0.1511
2025-11-02 11:10:09,014: t15.2023.12.17 val PER: 0.2048
2025-11-02 11:10:09,015: t15.2023.12.29 val PER: 0.1997
2025-11-02 11:10:09,015: t15.2024.02.25 val PER: 0.1517
2025-11-02 11:10:09,016: t15.2024.03.08 val PER: 0.2760
2025-11-02 11:10:09,016: t15.2024.03.15 val PER: 0.2633
2025-11-02 11:10:09,016: t15.2024.03.17 val PER: 0.2078
2025-11-02 11:10:09,016: t15.2024.05.10 val PER: 0.2140
2025-11-02 11:10:09,017: t15.2024.06.14 val PER: 0.2397
2025-11-02 11:10:09,017: t15.2024.07.19 val PER: 0.2802
2025-11-02 11:10:09,017: t15.2024.07.21 val PER: 0.1559
2025-11-02 11:10:09,017: t15.2024.07.28 val PER: 0.1919
2025-11-02 11:10:09,017: t15.2025.01.10 val PER: 0.3554
2025-11-02 11:10:09,018: t15.2025.01.12 val PER: 0.2148
2025-11-02 11:10:09,018: t15.2025.03.14 val PER: 0.4024
2025-11-02 11:10:09,018: t15.2025.03.16 val PER: 0.2670
2025-11-02 11:10:09,018: t15.2025.03.30 val PER: 0.3529
2025-11-02 11:10:09,019: t15.2025.04.13 val PER: 0.2753
2025-11-02 11:10:09,019: New best test PER 0.2113 --> 0.2057
2025-11-02 11:10:09,019: Checkpointing model
2025-11-02 11:10:10,627: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:10:35,601: Train batch 16200: loss: 8.99 grad norm: 42.10 time: 0.081
2025-11-02 11:11:00,420: Train batch 16400: loss: 8.99 grad norm: 46.30 time: 0.072
2025-11-02 11:11:25,836: Train batch 16600: loss: 9.87 grad norm: 36.73 time: 0.072
2025-11-02 11:11:51,030: Train batch 16800: loss: 12.19 grad norm: 48.51 time: 0.077
2025-11-02 11:12:16,017: Train batch 17000: loss: 10.13 grad norm: 43.69 time: 0.096
2025-11-02 11:12:16,018: Running test after training batch: 17000
2025-11-02 11:12:29,519: Val batch 17000: PER (avg): 0.2016 CTC Loss (avg): 21.6980 time: 13.501
2025-11-02 11:12:29,521: t15.2023.08.13 val PER: 0.1601
2025-11-02 11:12:29,521: t15.2023.08.18 val PER: 0.1517
2025-11-02 11:12:29,522: t15.2023.08.20 val PER: 0.1477
2025-11-02 11:12:29,522: t15.2023.08.25 val PER: 0.1446
2025-11-02 11:12:29,523: t15.2023.08.27 val PER: 0.2428
2025-11-02 11:12:29,523: t15.2023.09.01 val PER: 0.1015
2025-11-02 11:12:29,524: t15.2023.09.03 val PER: 0.2043
2025-11-02 11:12:29,524: t15.2023.09.24 val PER: 0.1493
2025-11-02 11:12:29,524: t15.2023.09.29 val PER: 0.1691
2025-11-02 11:12:29,525: t15.2023.10.01 val PER: 0.2120
2025-11-02 11:12:29,526: t15.2023.10.06 val PER: 0.1475
2025-11-02 11:12:29,526: t15.2023.10.08 val PER: 0.2625
2025-11-02 11:12:29,526: t15.2023.10.13 val PER: 0.2622
2025-11-02 11:12:29,527: t15.2023.10.15 val PER: 0.1898
2025-11-02 11:12:29,527: t15.2023.10.20 val PER: 0.1913
2025-11-02 11:12:29,528: t15.2023.10.22 val PER: 0.1659
2025-11-02 11:12:29,528: t15.2023.11.03 val PER: 0.2218
2025-11-02 11:12:29,529: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:12:29,529: t15.2023.11.17 val PER: 0.0715
2025-11-02 11:12:29,529: t15.2023.11.19 val PER: 0.0878
2025-11-02 11:12:29,530: t15.2023.11.26 val PER: 0.2072
2025-11-02 11:12:29,530: t15.2023.12.03 val PER: 0.1660
2025-11-02 11:12:29,531: t15.2023.12.08 val PER: 0.1804
2025-11-02 11:12:29,531: t15.2023.12.10 val PER: 0.1551
2025-11-02 11:12:29,531: t15.2023.12.17 val PER: 0.2089
2025-11-02 11:12:29,532: t15.2023.12.29 val PER: 0.1935
2025-11-02 11:12:29,532: t15.2024.02.25 val PER: 0.1531
2025-11-02 11:12:29,532: t15.2024.03.08 val PER: 0.2916
2025-11-02 11:12:29,533: t15.2024.03.15 val PER: 0.2577
2025-11-02 11:12:29,533: t15.2024.03.17 val PER: 0.1960
2025-11-02 11:12:29,533: t15.2024.05.10 val PER: 0.2184
2025-11-02 11:12:29,533: t15.2024.06.14 val PER: 0.2303
2025-11-02 11:12:29,534: t15.2024.07.19 val PER: 0.2828
2025-11-02 11:12:29,534: t15.2024.07.21 val PER: 0.1421
2025-11-02 11:12:29,535: t15.2024.07.28 val PER: 0.1846
2025-11-02 11:12:29,536: t15.2025.01.10 val PER: 0.3457
2025-11-02 11:12:29,536: t15.2025.01.12 val PER: 0.2040
2025-11-02 11:12:29,536: t15.2025.03.14 val PER: 0.3935
2025-11-02 11:12:29,536: t15.2025.03.16 val PER: 0.2631
2025-11-02 11:12:29,537: t15.2025.03.30 val PER: 0.3494
2025-11-02 11:12:29,537: t15.2025.04.13 val PER: 0.2739
2025-11-02 11:12:29,537: New best test PER 0.2057 --> 0.2016
2025-11-02 11:12:29,538: Checkpointing model
2025-11-02 11:12:31,249: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:12:57,018: Train batch 17200: loss: 9.85 grad norm: 52.52 time: 0.080
2025-11-02 11:13:21,424: Train batch 17400: loss: 11.33 grad norm: 50.73 time: 0.105
2025-11-02 11:13:46,382: Train batch 17600: loss: 7.99 grad norm: 38.74 time: 0.074
2025-11-02 11:14:11,603: Train batch 17800: loss: 10.32 grad norm: 42.48 time: 0.112
2025-11-02 11:14:36,987: Train batch 18000: loss: 9.17 grad norm: 38.25 time: 0.069
2025-11-02 11:14:36,988: Running test after training batch: 18000
2025-11-02 11:14:49,914: Val batch 18000: PER (avg): 0.1973 CTC Loss (avg): 21.5496 time: 12.926
2025-11-02 11:14:49,915: t15.2023.08.13 val PER: 0.1538
2025-11-02 11:14:49,915: t15.2023.08.18 val PER: 0.1350
2025-11-02 11:14:49,916: t15.2023.08.20 val PER: 0.1398
2025-11-02 11:14:49,916: t15.2023.08.25 val PER: 0.1476
2025-11-02 11:14:49,917: t15.2023.08.27 val PER: 0.2412
2025-11-02 11:14:49,917: t15.2023.09.01 val PER: 0.0950
2025-11-02 11:14:49,917: t15.2023.09.03 val PER: 0.2031
2025-11-02 11:14:49,918: t15.2023.09.24 val PER: 0.1456
2025-11-02 11:14:49,918: t15.2023.09.29 val PER: 0.1691
2025-11-02 11:14:49,918: t15.2023.10.01 val PER: 0.2147
2025-11-02 11:14:49,919: t15.2023.10.06 val PER: 0.1356
2025-11-02 11:14:49,919: t15.2023.10.08 val PER: 0.2544
2025-11-02 11:14:49,919: t15.2023.10.13 val PER: 0.2576
2025-11-02 11:14:49,920: t15.2023.10.15 val PER: 0.1918
2025-11-02 11:14:49,920: t15.2023.10.20 val PER: 0.2047
2025-11-02 11:14:49,921: t15.2023.10.22 val PER: 0.1459
2025-11-02 11:14:49,921: t15.2023.11.03 val PER: 0.2198
2025-11-02 11:14:49,921: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:14:49,921: t15.2023.11.17 val PER: 0.0638
2025-11-02 11:14:49,922: t15.2023.11.19 val PER: 0.0798
2025-11-02 11:14:49,922: t15.2023.11.26 val PER: 0.2094
2025-11-02 11:14:49,922: t15.2023.12.03 val PER: 0.1471
2025-11-02 11:14:49,923: t15.2023.12.08 val PER: 0.1771
2025-11-02 11:14:49,923: t15.2023.12.10 val PER: 0.1472
2025-11-02 11:14:49,923: t15.2023.12.17 val PER: 0.1944
2025-11-02 11:14:49,923: t15.2023.12.29 val PER: 0.1846
2025-11-02 11:14:49,924: t15.2024.02.25 val PER: 0.1489
2025-11-02 11:14:49,924: t15.2024.03.08 val PER: 0.2745
2025-11-02 11:14:49,924: t15.2024.03.15 val PER: 0.2589
2025-11-02 11:14:49,925: t15.2024.03.17 val PER: 0.1960
2025-11-02 11:14:49,925: t15.2024.05.10 val PER: 0.2110
2025-11-02 11:14:49,926: t15.2024.06.14 val PER: 0.2271
2025-11-02 11:14:49,926: t15.2024.07.19 val PER: 0.2742
2025-11-02 11:14:49,926: t15.2024.07.21 val PER: 0.1352
2025-11-02 11:14:49,927: t15.2024.07.28 val PER: 0.1875
2025-11-02 11:14:49,927: t15.2025.01.10 val PER: 0.3485
2025-11-02 11:14:49,927: t15.2025.01.12 val PER: 0.1994
2025-11-02 11:14:49,927: t15.2025.03.14 val PER: 0.4083
2025-11-02 11:14:49,928: t15.2025.03.16 val PER: 0.2657
2025-11-02 11:14:49,928: t15.2025.03.30 val PER: 0.3264
2025-11-02 11:14:49,928: t15.2025.04.13 val PER: 0.2967
2025-11-02 11:14:49,928: New best test PER 0.2016 --> 0.1973
2025-11-02 11:14:49,929: Checkpointing model
2025-11-02 11:14:51,742: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:15:17,865: Train batch 18200: loss: 9.54 grad norm: 40.05 time: 0.111
2025-11-02 11:15:43,081: Train batch 18400: loss: 8.41 grad norm: 41.40 time: 0.107
2025-11-02 11:16:07,642: Train batch 18600: loss: 6.27 grad norm: 37.57 time: 0.107
2025-11-02 11:16:33,668: Train batch 18800: loss: 7.41 grad norm: 39.44 time: 0.083
2025-11-02 11:16:58,929: Train batch 19000: loss: 9.12 grad norm: 40.39 time: 0.093
2025-11-02 11:16:58,930: Running test after training batch: 19000
2025-11-02 11:17:12,314: Val batch 19000: PER (avg): 0.1934 CTC Loss (avg): 21.1682 time: 13.383
2025-11-02 11:17:12,314: t15.2023.08.13 val PER: 0.1528
2025-11-02 11:17:12,315: t15.2023.08.18 val PER: 0.1433
2025-11-02 11:17:12,315: t15.2023.08.20 val PER: 0.1398
2025-11-02 11:17:12,316: t15.2023.08.25 val PER: 0.1386
2025-11-02 11:17:12,316: t15.2023.08.27 val PER: 0.2347
2025-11-02 11:17:12,316: t15.2023.09.01 val PER: 0.0950
2025-11-02 11:17:12,317: t15.2023.09.03 val PER: 0.1912
2025-11-02 11:17:12,317: t15.2023.09.24 val PER: 0.1481
2025-11-02 11:17:12,317: t15.2023.09.29 val PER: 0.1621
2025-11-02 11:17:12,317: t15.2023.10.01 val PER: 0.2107
2025-11-02 11:17:12,318: t15.2023.10.06 val PER: 0.1302
2025-11-02 11:17:12,318: t15.2023.10.08 val PER: 0.2571
2025-11-02 11:17:12,318: t15.2023.10.13 val PER: 0.2521
2025-11-02 11:17:12,318: t15.2023.10.15 val PER: 0.1806
2025-11-02 11:17:12,319: t15.2023.10.20 val PER: 0.1946
2025-11-02 11:17:12,319: t15.2023.10.22 val PER: 0.1481
2025-11-02 11:17:12,319: t15.2023.11.03 val PER: 0.2062
2025-11-02 11:17:12,319: t15.2023.11.04 val PER: 0.0375
2025-11-02 11:17:12,320: t15.2023.11.17 val PER: 0.0653
2025-11-02 11:17:12,320: t15.2023.11.19 val PER: 0.0818
2025-11-02 11:17:12,321: t15.2023.11.26 val PER: 0.1986
2025-11-02 11:17:12,321: t15.2023.12.03 val PER: 0.1607
2025-11-02 11:17:12,321: t15.2023.12.08 val PER: 0.1704
2025-11-02 11:17:12,321: t15.2023.12.10 val PER: 0.1472
2025-11-02 11:17:12,322: t15.2023.12.17 val PER: 0.1861
2025-11-02 11:17:12,322: t15.2023.12.29 val PER: 0.1853
2025-11-02 11:17:12,322: t15.2024.02.25 val PER: 0.1461
2025-11-02 11:17:12,322: t15.2024.03.08 val PER: 0.2674
2025-11-02 11:17:12,323: t15.2024.03.15 val PER: 0.2495
2025-11-02 11:17:12,323: t15.2024.03.17 val PER: 0.1813
2025-11-02 11:17:12,323: t15.2024.05.10 val PER: 0.2006
2025-11-02 11:17:12,323: t15.2024.06.14 val PER: 0.2208
2025-11-02 11:17:12,324: t15.2024.07.19 val PER: 0.2716
2025-11-02 11:17:12,324: t15.2024.07.21 val PER: 0.1331
2025-11-02 11:17:12,324: t15.2024.07.28 val PER: 0.1831
2025-11-02 11:17:12,325: t15.2025.01.10 val PER: 0.3567
2025-11-02 11:17:12,325: t15.2025.01.12 val PER: 0.2048
2025-11-02 11:17:12,326: t15.2025.03.14 val PER: 0.3964
2025-11-02 11:17:12,326: t15.2025.03.16 val PER: 0.2382
2025-11-02 11:17:12,326: t15.2025.03.30 val PER: 0.3494
2025-11-02 11:17:12,326: t15.2025.04.13 val PER: 0.2810
2025-11-02 11:17:12,327: New best test PER 0.1973 --> 0.1934
2025-11-02 11:17:12,327: Checkpointing model
2025-11-02 11:17:13,781: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:17:38,669: Train batch 19200: loss: 3.20 grad norm: 27.29 time: 0.065
2025-11-02 11:18:02,331: Train batch 19400: loss: 5.16 grad norm: 33.10 time: 0.080
2025-11-02 11:18:27,819: Train batch 19600: loss: 10.68 grad norm: 47.16 time: 0.088
2025-11-02 11:18:53,395: Train batch 19800: loss: 8.00 grad norm: 41.45 time: 0.108
2025-11-02 11:19:17,780: Train batch 20000: loss: 11.49 grad norm: 53.76 time: 0.081
2025-11-02 11:19:17,781: Running test after training batch: 20000
2025-11-02 11:19:30,333: Val batch 20000: PER (avg): 0.1947 CTC Loss (avg): 21.5843 time: 12.552
2025-11-02 11:19:30,333: t15.2023.08.13 val PER: 0.1455
2025-11-02 11:19:30,334: t15.2023.08.18 val PER: 0.1417
2025-11-02 11:19:30,334: t15.2023.08.20 val PER: 0.1414
2025-11-02 11:19:30,334: t15.2023.08.25 val PER: 0.1446
2025-11-02 11:19:30,335: t15.2023.08.27 val PER: 0.2235
2025-11-02 11:19:30,335: t15.2023.09.01 val PER: 0.1063
2025-11-02 11:19:30,336: t15.2023.09.03 val PER: 0.2007
2025-11-02 11:19:30,336: t15.2023.09.24 val PER: 0.1420
2025-11-02 11:19:30,336: t15.2023.09.29 val PER: 0.1634
2025-11-02 11:19:30,336: t15.2023.10.01 val PER: 0.2074
2025-11-02 11:19:30,337: t15.2023.10.06 val PER: 0.1313
2025-11-02 11:19:30,337: t15.2023.10.08 val PER: 0.2503
2025-11-02 11:19:30,337: t15.2023.10.13 val PER: 0.2521
2025-11-02 11:19:30,337: t15.2023.10.15 val PER: 0.1786
2025-11-02 11:19:30,338: t15.2023.10.20 val PER: 0.1980
2025-11-02 11:19:30,338: t15.2023.10.22 val PER: 0.1459
2025-11-02 11:19:30,338: t15.2023.11.03 val PER: 0.2096
2025-11-02 11:19:30,338: t15.2023.11.04 val PER: 0.0444
2025-11-02 11:19:30,339: t15.2023.11.17 val PER: 0.0653
2025-11-02 11:19:30,339: t15.2023.11.19 val PER: 0.0818
2025-11-02 11:19:30,339: t15.2023.11.26 val PER: 0.1870
2025-11-02 11:19:30,339: t15.2023.12.03 val PER: 0.1439
2025-11-02 11:19:30,340: t15.2023.12.08 val PER: 0.1698
2025-11-02 11:19:30,341: t15.2023.12.10 val PER: 0.1432
2025-11-02 11:19:30,341: t15.2023.12.17 val PER: 0.1965
2025-11-02 11:19:30,341: t15.2023.12.29 val PER: 0.1784
2025-11-02 11:19:30,341: t15.2024.02.25 val PER: 0.1601
2025-11-02 11:19:30,341: t15.2024.03.08 val PER: 0.2845
2025-11-02 11:19:30,342: t15.2024.03.15 val PER: 0.2595
2025-11-02 11:19:30,342: t15.2024.03.17 val PER: 0.1932
2025-11-02 11:19:30,342: t15.2024.05.10 val PER: 0.2065
2025-11-02 11:19:30,342: t15.2024.06.14 val PER: 0.2224
2025-11-02 11:19:30,343: t15.2024.07.19 val PER: 0.2769
2025-11-02 11:19:30,343: t15.2024.07.21 val PER: 0.1400
2025-11-02 11:19:30,343: t15.2024.07.28 val PER: 0.1949
2025-11-02 11:19:30,343: t15.2025.01.10 val PER: 0.3540
2025-11-02 11:19:30,343: t15.2025.01.12 val PER: 0.2040
2025-11-02 11:19:30,344: t15.2025.03.14 val PER: 0.3920
2025-11-02 11:19:30,344: t15.2025.03.16 val PER: 0.2592
2025-11-02 11:19:30,344: t15.2025.03.30 val PER: 0.3310
2025-11-02 11:19:30,344: t15.2025.04.13 val PER: 0.2825
2025-11-02 11:19:54,988: Train batch 20200: loss: 3.88 grad norm: 24.59 time: 0.059
2025-11-02 11:20:19,892: Train batch 20400: loss: 7.60 grad norm: 40.33 time: 0.079
2025-11-02 11:20:44,904: Train batch 20600: loss: 8.04 grad norm: 41.78 time: 0.075
2025-11-02 11:21:09,979: Train batch 20800: loss: 8.80 grad norm: 44.51 time: 0.097
2025-11-02 11:21:34,219: Train batch 21000: loss: 6.67 grad norm: 36.15 time: 0.065
2025-11-02 11:21:34,221: Running test after training batch: 21000
2025-11-02 11:21:46,584: Val batch 21000: PER (avg): 0.1931 CTC Loss (avg): 21.5655 time: 12.363
2025-11-02 11:21:46,587: t15.2023.08.13 val PER: 0.1435
2025-11-02 11:21:46,587: t15.2023.08.18 val PER: 0.1383
2025-11-02 11:21:46,588: t15.2023.08.20 val PER: 0.1303
2025-11-02 11:21:46,588: t15.2023.08.25 val PER: 0.1476
2025-11-02 11:21:46,589: t15.2023.08.27 val PER: 0.2267
2025-11-02 11:21:46,589: t15.2023.09.01 val PER: 0.1006
2025-11-02 11:21:46,590: t15.2023.09.03 val PER: 0.1971
2025-11-02 11:21:46,591: t15.2023.09.24 val PER: 0.1493
2025-11-02 11:21:46,591: t15.2023.09.29 val PER: 0.1538
2025-11-02 11:21:46,591: t15.2023.10.01 val PER: 0.2048
2025-11-02 11:21:46,591: t15.2023.10.06 val PER: 0.1313
2025-11-02 11:21:46,592: t15.2023.10.08 val PER: 0.2409
2025-11-02 11:21:46,592: t15.2023.10.13 val PER: 0.2583
2025-11-02 11:21:46,592: t15.2023.10.15 val PER: 0.1833
2025-11-02 11:21:46,592: t15.2023.10.20 val PER: 0.2114
2025-11-02 11:21:46,592: t15.2023.10.22 val PER: 0.1537
2025-11-02 11:21:46,593: t15.2023.11.03 val PER: 0.2157
2025-11-02 11:21:46,593: t15.2023.11.04 val PER: 0.0375
2025-11-02 11:21:46,593: t15.2023.11.17 val PER: 0.0591
2025-11-02 11:21:46,593: t15.2023.11.19 val PER: 0.0778
2025-11-02 11:21:46,594: t15.2023.11.26 val PER: 0.1913
2025-11-02 11:21:46,594: t15.2023.12.03 val PER: 0.1460
2025-11-02 11:21:46,594: t15.2023.12.08 val PER: 0.1658
2025-11-02 11:21:46,594: t15.2023.12.10 val PER: 0.1380
2025-11-02 11:21:46,594: t15.2023.12.17 val PER: 0.1975
2025-11-02 11:21:46,595: t15.2023.12.29 val PER: 0.1791
2025-11-02 11:21:46,595: t15.2024.02.25 val PER: 0.1461
2025-11-02 11:21:46,596: t15.2024.03.08 val PER: 0.2688
2025-11-02 11:21:46,596: t15.2024.03.15 val PER: 0.2595
2025-11-02 11:21:46,596: t15.2024.03.17 val PER: 0.1939
2025-11-02 11:21:46,596: t15.2024.05.10 val PER: 0.1917
2025-11-02 11:21:46,596: t15.2024.06.14 val PER: 0.2287
2025-11-02 11:21:46,597: t15.2024.07.19 val PER: 0.2742
2025-11-02 11:21:46,597: t15.2024.07.21 val PER: 0.1386
2025-11-02 11:21:46,597: t15.2024.07.28 val PER: 0.1919
2025-11-02 11:21:46,597: t15.2025.01.10 val PER: 0.3499
2025-11-02 11:21:46,598: t15.2025.01.12 val PER: 0.1994
2025-11-02 11:21:46,598: t15.2025.03.14 val PER: 0.3905
2025-11-02 11:21:46,598: t15.2025.03.16 val PER: 0.2408
2025-11-02 11:21:46,598: t15.2025.03.30 val PER: 0.3460
2025-11-02 11:21:46,599: t15.2025.04.13 val PER: 0.2796
2025-11-02 11:21:46,599: New best test PER 0.1934 --> 0.1931
2025-11-02 11:21:46,599: Checkpointing model
2025-11-02 11:21:48,112: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:22:14,073: Train batch 21200: loss: 6.47 grad norm: 38.93 time: 0.063
2025-11-02 11:22:39,136: Train batch 21400: loss: 9.35 grad norm: 51.21 time: 0.092
2025-11-02 11:23:05,515: Train batch 21600: loss: 10.75 grad norm: 59.01 time: 0.085
2025-11-02 11:23:31,419: Train batch 21800: loss: 7.76 grad norm: 41.56 time: 0.064
2025-11-02 11:23:56,525: Train batch 22000: loss: 9.49 grad norm: 60.14 time: 0.076
2025-11-02 11:23:56,526: Running test after training batch: 22000
2025-11-02 11:24:10,636: Val batch 22000: PER (avg): 0.1897 CTC Loss (avg): 21.5217 time: 14.110
2025-11-02 11:24:10,637: t15.2023.08.13 val PER: 0.1466
2025-11-02 11:24:10,637: t15.2023.08.18 val PER: 0.1341
2025-11-02 11:24:10,637: t15.2023.08.20 val PER: 0.1342
2025-11-02 11:24:10,638: t15.2023.08.25 val PER: 0.1370
2025-11-02 11:24:10,638: t15.2023.08.27 val PER: 0.2170
2025-11-02 11:24:10,638: t15.2023.09.01 val PER: 0.0958
2025-11-02 11:24:10,638: t15.2023.09.03 val PER: 0.1924
2025-11-02 11:24:10,639: t15.2023.09.24 val PER: 0.1420
2025-11-02 11:24:10,683: t15.2023.09.29 val PER: 0.1583
2025-11-02 11:24:10,684: t15.2023.10.01 val PER: 0.2021
2025-11-02 11:24:10,684: t15.2023.10.06 val PER: 0.1346
2025-11-02 11:24:10,684: t15.2023.10.08 val PER: 0.2490
2025-11-02 11:24:10,685: t15.2023.10.13 val PER: 0.2498
2025-11-02 11:24:10,685: t15.2023.10.15 val PER: 0.1721
2025-11-02 11:24:10,685: t15.2023.10.20 val PER: 0.2081
2025-11-02 11:24:10,686: t15.2023.10.22 val PER: 0.1526
2025-11-02 11:24:10,686: t15.2023.11.03 val PER: 0.2212
2025-11-02 11:24:10,686: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:24:10,686: t15.2023.11.17 val PER: 0.0575
2025-11-02 11:24:10,687: t15.2023.11.19 val PER: 0.0838
2025-11-02 11:24:10,687: t15.2023.11.26 val PER: 0.1826
2025-11-02 11:24:10,687: t15.2023.12.03 val PER: 0.1366
2025-11-02 11:24:10,687: t15.2023.12.08 val PER: 0.1684
2025-11-02 11:24:10,687: t15.2023.12.10 val PER: 0.1288
2025-11-02 11:24:10,688: t15.2023.12.17 val PER: 0.1892
2025-11-02 11:24:10,688: t15.2023.12.29 val PER: 0.1778
2025-11-02 11:24:10,688: t15.2024.02.25 val PER: 0.1489
2025-11-02 11:24:10,688: t15.2024.03.08 val PER: 0.2745
2025-11-02 11:24:10,688: t15.2024.03.15 val PER: 0.2564
2025-11-02 11:24:10,689: t15.2024.03.17 val PER: 0.1778
2025-11-02 11:24:10,689: t15.2024.05.10 val PER: 0.1961
2025-11-02 11:24:10,689: t15.2024.06.14 val PER: 0.2145
2025-11-02 11:24:10,689: t15.2024.07.19 val PER: 0.2729
2025-11-02 11:24:10,689: t15.2024.07.21 val PER: 0.1338
2025-11-02 11:24:10,690: t15.2024.07.28 val PER: 0.1831
2025-11-02 11:24:10,690: t15.2025.01.10 val PER: 0.3416
2025-11-02 11:24:10,691: t15.2025.01.12 val PER: 0.1925
2025-11-02 11:24:10,691: t15.2025.03.14 val PER: 0.3905
2025-11-02 11:24:10,691: t15.2025.03.16 val PER: 0.2513
2025-11-02 11:24:10,691: t15.2025.03.30 val PER: 0.3310
2025-11-02 11:24:10,691: t15.2025.04.13 val PER: 0.2739
2025-11-02 11:24:10,692: New best test PER 0.1931 --> 0.1897
2025-11-02 11:24:10,692: Checkpointing model
2025-11-02 11:24:12,117: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:24:37,514: Train batch 22200: loss: 6.32 grad norm: 37.53 time: 0.064
2025-11-02 11:25:04,085: Train batch 22400: loss: 6.36 grad norm: 41.82 time: 0.061
2025-11-02 11:25:29,637: Train batch 22600: loss: 5.97 grad norm: 36.60 time: 0.058
2025-11-02 11:25:55,203: Train batch 22800: loss: 4.70 grad norm: 34.66 time: 0.065
2025-11-02 11:26:21,751: Train batch 23000: loss: 6.16 grad norm: 38.86 time: 0.123
2025-11-02 11:26:21,752: Running test after training batch: 23000
2025-11-02 11:26:33,840: Val batch 23000: PER (avg): 0.1880 CTC Loss (avg): 21.8142 time: 12.088
2025-11-02 11:26:33,841: t15.2023.08.13 val PER: 0.1351
2025-11-02 11:26:33,841: t15.2023.08.18 val PER: 0.1425
2025-11-02 11:26:33,841: t15.2023.08.20 val PER: 0.1279
2025-11-02 11:26:33,841: t15.2023.08.25 val PER: 0.1355
2025-11-02 11:26:33,842: t15.2023.08.27 val PER: 0.2235
2025-11-02 11:26:33,842: t15.2023.09.01 val PER: 0.0933
2025-11-02 11:26:33,842: t15.2023.09.03 val PER: 0.1900
2025-11-02 11:26:33,842: t15.2023.09.24 val PER: 0.1432
2025-11-02 11:26:33,843: t15.2023.09.29 val PER: 0.1551
2025-11-02 11:26:33,843: t15.2023.10.01 val PER: 0.1982
2025-11-02 11:26:33,885: t15.2023.10.06 val PER: 0.1216
2025-11-02 11:26:33,885: t15.2023.10.08 val PER: 0.2436
2025-11-02 11:26:33,885: t15.2023.10.13 val PER: 0.2452
2025-11-02 11:26:33,886: t15.2023.10.15 val PER: 0.1793
2025-11-02 11:26:33,886: t15.2023.10.20 val PER: 0.1946
2025-11-02 11:26:33,886: t15.2023.10.22 val PER: 0.1626
2025-11-02 11:26:33,887: t15.2023.11.03 val PER: 0.2035
2025-11-02 11:26:33,887: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:26:33,887: t15.2023.11.17 val PER: 0.0591
2025-11-02 11:26:33,887: t15.2023.11.19 val PER: 0.0719
2025-11-02 11:26:33,888: t15.2023.11.26 val PER: 0.1841
2025-11-02 11:26:33,888: t15.2023.12.03 val PER: 0.1334
2025-11-02 11:26:33,888: t15.2023.12.08 val PER: 0.1684
2025-11-02 11:26:33,888: t15.2023.12.10 val PER: 0.1393
2025-11-02 11:26:33,889: t15.2023.12.17 val PER: 0.1902
2025-11-02 11:26:33,889: t15.2023.12.29 val PER: 0.1771
2025-11-02 11:26:33,889: t15.2024.02.25 val PER: 0.1475
2025-11-02 11:26:33,890: t15.2024.03.08 val PER: 0.2660
2025-11-02 11:26:33,890: t15.2024.03.15 val PER: 0.2539
2025-11-02 11:26:33,891: t15.2024.03.17 val PER: 0.1750
2025-11-02 11:26:33,891: t15.2024.05.10 val PER: 0.1991
2025-11-02 11:26:33,891: t15.2024.06.14 val PER: 0.2082
2025-11-02 11:26:33,891: t15.2024.07.19 val PER: 0.2716
2025-11-02 11:26:33,891: t15.2024.07.21 val PER: 0.1317
2025-11-02 11:26:33,892: t15.2024.07.28 val PER: 0.1875
2025-11-02 11:26:33,892: t15.2025.01.10 val PER: 0.3499
2025-11-02 11:26:33,892: t15.2025.01.12 val PER: 0.1971
2025-11-02 11:26:33,892: t15.2025.03.14 val PER: 0.4009
2025-11-02 11:26:33,893: t15.2025.03.16 val PER: 0.2382
2025-11-02 11:26:33,893: t15.2025.03.30 val PER: 0.3207
2025-11-02 11:26:33,893: t15.2025.04.13 val PER: 0.2696
2025-11-02 11:26:33,893: New best test PER 0.1897 --> 0.1880
2025-11-02 11:26:33,894: Checkpointing model
2025-11-02 11:26:35,268: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:27:01,505: Train batch 23200: loss: 5.39 grad norm: 33.39 time: 0.058
2025-11-02 11:27:27,067: Train batch 23400: loss: 8.89 grad norm: 49.03 time: 0.072
2025-11-02 11:27:53,691: Train batch 23600: loss: 3.82 grad norm: 37.72 time: 0.063
2025-11-02 11:28:21,115: Train batch 23800: loss: 7.94 grad norm: 45.69 time: 0.096
2025-11-02 11:28:46,326: Train batch 24000: loss: 5.29 grad norm: 33.38 time: 0.075
2025-11-02 11:28:46,327: Running test after training batch: 24000
2025-11-02 11:28:59,335: Val batch 24000: PER (avg): 0.1872 CTC Loss (avg): 21.9406 time: 13.008
2025-11-02 11:28:59,335: t15.2023.08.13 val PER: 0.1320
2025-11-02 11:28:59,336: t15.2023.08.18 val PER: 0.1391
2025-11-02 11:28:59,338: t15.2023.08.20 val PER: 0.1350
2025-11-02 11:28:59,338: t15.2023.08.25 val PER: 0.1355
2025-11-02 11:28:59,338: t15.2023.08.27 val PER: 0.2186
2025-11-02 11:28:59,339: t15.2023.09.01 val PER: 0.1006
2025-11-02 11:28:59,339: t15.2023.09.03 val PER: 0.1888
2025-11-02 11:28:59,339: t15.2023.09.24 val PER: 0.1456
2025-11-02 11:28:59,340: t15.2023.09.29 val PER: 0.1551
2025-11-02 11:28:59,340: t15.2023.10.01 val PER: 0.1922
2025-11-02 11:28:59,340: t15.2023.10.06 val PER: 0.1216
2025-11-02 11:28:59,341: t15.2023.10.08 val PER: 0.2558
2025-11-02 11:28:59,341: t15.2023.10.13 val PER: 0.2467
2025-11-02 11:28:59,341: t15.2023.10.15 val PER: 0.1747
2025-11-02 11:28:59,342: t15.2023.10.20 val PER: 0.1946
2025-11-02 11:28:59,342: t15.2023.10.22 val PER: 0.1481
2025-11-02 11:28:59,343: t15.2023.11.03 val PER: 0.1974
2025-11-02 11:28:59,343: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:28:59,343: t15.2023.11.17 val PER: 0.0513
2025-11-02 11:28:59,344: t15.2023.11.19 val PER: 0.0778
2025-11-02 11:28:59,344: t15.2023.11.26 val PER: 0.1732
2025-11-02 11:28:59,344: t15.2023.12.03 val PER: 0.1345
2025-11-02 11:28:59,344: t15.2023.12.08 val PER: 0.1611
2025-11-02 11:28:59,344: t15.2023.12.10 val PER: 0.1406
2025-11-02 11:28:59,345: t15.2023.12.17 val PER: 0.1902
2025-11-02 11:28:59,345: t15.2023.12.29 val PER: 0.1661
2025-11-02 11:28:59,346: t15.2024.02.25 val PER: 0.1447
2025-11-02 11:28:59,346: t15.2024.03.08 val PER: 0.2660
2025-11-02 11:28:59,346: t15.2024.03.15 val PER: 0.2614
2025-11-02 11:28:59,346: t15.2024.03.17 val PER: 0.1722
2025-11-02 11:28:59,346: t15.2024.05.10 val PER: 0.2006
2025-11-02 11:28:59,347: t15.2024.06.14 val PER: 0.2192
2025-11-02 11:28:59,347: t15.2024.07.19 val PER: 0.2670
2025-11-02 11:28:59,347: t15.2024.07.21 val PER: 0.1297
2025-11-02 11:28:59,347: t15.2024.07.28 val PER: 0.1846
2025-11-02 11:28:59,348: t15.2025.01.10 val PER: 0.3567
2025-11-02 11:28:59,348: t15.2025.01.12 val PER: 0.1955
2025-11-02 11:28:59,348: t15.2025.03.14 val PER: 0.3950
2025-11-02 11:28:59,348: t15.2025.03.16 val PER: 0.2539
2025-11-02 11:28:59,348: t15.2025.03.30 val PER: 0.3299
2025-11-02 11:28:59,349: t15.2025.04.13 val PER: 0.2853
2025-11-02 11:28:59,349: New best test PER 0.1880 --> 0.1872
2025-11-02 11:28:59,349: Checkpointing model
2025-11-02 11:29:00,604: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:29:25,932: Train batch 24200: loss: 7.09 grad norm: 61.18 time: 0.078
2025-11-02 11:29:52,930: Train batch 24400: loss: 5.90 grad norm: 40.27 time: 0.072
2025-11-02 11:30:18,777: Train batch 24600: loss: 6.98 grad norm: 49.57 time: 0.096
2025-11-02 11:30:43,197: Train batch 24800: loss: 5.00 grad norm: 43.89 time: 0.061
2025-11-02 11:31:08,440: Train batch 25000: loss: 5.48 grad norm: 44.72 time: 0.063
2025-11-02 11:31:08,441: Running test after training batch: 25000
2025-11-02 11:31:20,527: Val batch 25000: PER (avg): 0.1851 CTC Loss (avg): 22.0533 time: 12.086
2025-11-02 11:31:20,527: t15.2023.08.13 val PER: 0.1310
2025-11-02 11:31:20,528: t15.2023.08.18 val PER: 0.1408
2025-11-02 11:31:20,528: t15.2023.08.20 val PER: 0.1255
2025-11-02 11:31:20,528: t15.2023.08.25 val PER: 0.1386
2025-11-02 11:31:20,529: t15.2023.08.27 val PER: 0.1945
2025-11-02 11:31:20,529: t15.2023.09.01 val PER: 0.0885
2025-11-02 11:31:20,529: t15.2023.09.03 val PER: 0.1817
2025-11-02 11:31:20,529: t15.2023.09.24 val PER: 0.1432
2025-11-02 11:31:20,529: t15.2023.09.29 val PER: 0.1512
2025-11-02 11:31:20,531: t15.2023.10.01 val PER: 0.1982
2025-11-02 11:31:20,531: t15.2023.10.06 val PER: 0.1335
2025-11-02 11:31:20,532: t15.2023.10.08 val PER: 0.2382
2025-11-02 11:31:20,532: t15.2023.10.13 val PER: 0.2420
2025-11-02 11:31:20,532: t15.2023.10.15 val PER: 0.1839
2025-11-02 11:31:20,532: t15.2023.10.20 val PER: 0.2013
2025-11-02 11:31:20,533: t15.2023.10.22 val PER: 0.1526
2025-11-02 11:31:20,533: t15.2023.11.03 val PER: 0.1995
2025-11-02 11:31:20,533: t15.2023.11.04 val PER: 0.0375
2025-11-02 11:31:20,533: t15.2023.11.17 val PER: 0.0575
2025-11-02 11:31:20,534: t15.2023.11.19 val PER: 0.0699
2025-11-02 11:31:20,534: t15.2023.11.26 val PER: 0.1710
2025-11-02 11:31:20,534: t15.2023.12.03 val PER: 0.1355
2025-11-02 11:31:20,534: t15.2023.12.08 val PER: 0.1571
2025-11-02 11:31:20,534: t15.2023.12.10 val PER: 0.1353
2025-11-02 11:31:20,534: t15.2023.12.17 val PER: 0.1965
2025-11-02 11:31:20,535: t15.2023.12.29 val PER: 0.1675
2025-11-02 11:31:20,535: t15.2024.02.25 val PER: 0.1531
2025-11-02 11:31:20,535: t15.2024.03.08 val PER: 0.2532
2025-11-02 11:31:20,535: t15.2024.03.15 val PER: 0.2620
2025-11-02 11:31:20,536: t15.2024.03.17 val PER: 0.1750
2025-11-02 11:31:20,536: t15.2024.05.10 val PER: 0.1887
2025-11-02 11:31:20,536: t15.2024.06.14 val PER: 0.2161
2025-11-02 11:31:20,536: t15.2024.07.19 val PER: 0.2571
2025-11-02 11:31:20,536: t15.2024.07.21 val PER: 0.1269
2025-11-02 11:31:20,537: t15.2024.07.28 val PER: 0.1846
2025-11-02 11:31:20,537: t15.2025.01.10 val PER: 0.3526
2025-11-02 11:31:20,537: t15.2025.01.12 val PER: 0.1986
2025-11-02 11:31:20,537: t15.2025.03.14 val PER: 0.3817
2025-11-02 11:31:20,538: t15.2025.03.16 val PER: 0.2343
2025-11-02 11:31:20,538: t15.2025.03.30 val PER: 0.3253
2025-11-02 11:31:20,538: t15.2025.04.13 val PER: 0.2796
2025-11-02 11:31:20,538: New best test PER 0.1872 --> 0.1851
2025-11-02 11:31:20,538: Checkpointing model
2025-11-02 11:31:21,967: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:31:47,995: Train batch 25200: loss: 4.40 grad norm: 36.42 time: 0.068
2025-11-02 11:32:13,725: Train batch 25400: loss: 5.62 grad norm: 42.40 time: 0.117
2025-11-02 11:32:38,905: Train batch 25600: loss: 4.67 grad norm: 36.37 time: 0.056
2025-11-02 11:33:05,131: Train batch 25800: loss: 4.61 grad norm: 43.34 time: 0.062
2025-11-02 11:33:30,454: Train batch 26000: loss: 3.87 grad norm: 37.57 time: 0.057
2025-11-02 11:33:30,455: Running test after training batch: 26000
2025-11-02 11:33:43,132: Val batch 26000: PER (avg): 0.1836 CTC Loss (avg): 22.1798 time: 12.677
2025-11-02 11:33:43,133: t15.2023.08.13 val PER: 0.1216
2025-11-02 11:33:43,134: t15.2023.08.18 val PER: 0.1299
2025-11-02 11:33:43,134: t15.2023.08.20 val PER: 0.1279
2025-11-02 11:33:43,134: t15.2023.08.25 val PER: 0.1355
2025-11-02 11:33:43,135: t15.2023.08.27 val PER: 0.2010
2025-11-02 11:33:43,135: t15.2023.09.01 val PER: 0.0958
2025-11-02 11:33:43,135: t15.2023.09.03 val PER: 0.1912
2025-11-02 11:33:43,136: t15.2023.09.24 val PER: 0.1505
2025-11-02 11:33:43,136: t15.2023.09.29 val PER: 0.1519
2025-11-02 11:33:43,136: t15.2023.10.01 val PER: 0.1975
2025-11-02 11:33:43,137: t15.2023.10.06 val PER: 0.1302
2025-11-02 11:33:43,137: t15.2023.10.08 val PER: 0.2409
2025-11-02 11:33:43,137: t15.2023.10.13 val PER: 0.2436
2025-11-02 11:33:43,137: t15.2023.10.15 val PER: 0.1740
2025-11-02 11:33:43,138: t15.2023.10.20 val PER: 0.1980
2025-11-02 11:33:43,138: t15.2023.10.22 val PER: 0.1425
2025-11-02 11:33:43,138: t15.2023.11.03 val PER: 0.2042
2025-11-02 11:33:43,138: t15.2023.11.04 val PER: 0.0307
2025-11-02 11:33:43,139: t15.2023.11.17 val PER: 0.0591
2025-11-02 11:33:43,139: t15.2023.11.19 val PER: 0.0659
2025-11-02 11:33:43,139: t15.2023.11.26 val PER: 0.1667
2025-11-02 11:33:43,140: t15.2023.12.03 val PER: 0.1282
2025-11-02 11:33:43,140: t15.2023.12.08 val PER: 0.1538
2025-11-02 11:33:43,141: t15.2023.12.10 val PER: 0.1380
2025-11-02 11:33:43,141: t15.2023.12.17 val PER: 0.1996
2025-11-02 11:33:43,141: t15.2023.12.29 val PER: 0.1654
2025-11-02 11:33:43,141: t15.2024.02.25 val PER: 0.1517
2025-11-02 11:33:43,141: t15.2024.03.08 val PER: 0.2461
2025-11-02 11:33:43,142: t15.2024.03.15 val PER: 0.2564
2025-11-02 11:33:43,142: t15.2024.03.17 val PER: 0.1688
2025-11-02 11:33:43,142: t15.2024.05.10 val PER: 0.1768
2025-11-02 11:33:43,142: t15.2024.06.14 val PER: 0.2177
2025-11-02 11:33:43,143: t15.2024.07.19 val PER: 0.2597
2025-11-02 11:33:43,143: t15.2024.07.21 val PER: 0.1283
2025-11-02 11:33:43,143: t15.2024.07.28 val PER: 0.1824
2025-11-02 11:33:43,143: t15.2025.01.10 val PER: 0.3375
2025-11-02 11:33:43,144: t15.2025.01.12 val PER: 0.1971
2025-11-02 11:33:43,144: t15.2025.03.14 val PER: 0.3876
2025-11-02 11:33:43,144: t15.2025.03.16 val PER: 0.2461
2025-11-02 11:33:43,144: t15.2025.03.30 val PER: 0.3126
2025-11-02 11:33:43,145: t15.2025.04.13 val PER: 0.2910
2025-11-02 11:33:43,145: New best test PER 0.1851 --> 0.1836
2025-11-02 11:33:43,145: Checkpointing model
2025-11-02 11:33:44,536: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:34:11,004: Train batch 26200: loss: 4.62 grad norm: 35.89 time: 0.100
2025-11-02 11:34:36,044: Train batch 26400: loss: 3.45 grad norm: 27.37 time: 0.074
2025-11-02 11:35:01,631: Train batch 26600: loss: 6.05 grad norm: 49.69 time: 0.076
2025-11-02 11:35:26,426: Train batch 26800: loss: 4.81 grad norm: 43.68 time: 0.065
2025-11-02 11:35:51,559: Train batch 27000: loss: 6.27 grad norm: 43.68 time: 0.059
2025-11-02 11:35:51,559: Running test after training batch: 27000
2025-11-02 11:36:04,029: Val batch 27000: PER (avg): 0.1836 CTC Loss (avg): 22.5177 time: 12.469
2025-11-02 11:36:04,029: t15.2023.08.13 val PER: 0.1247
2025-11-02 11:36:04,030: t15.2023.08.18 val PER: 0.1266
2025-11-02 11:36:04,030: t15.2023.08.20 val PER: 0.1231
2025-11-02 11:36:04,031: t15.2023.08.25 val PER: 0.1265
2025-11-02 11:36:04,031: t15.2023.08.27 val PER: 0.1994
2025-11-02 11:36:04,031: t15.2023.09.01 val PER: 0.0925
2025-11-02 11:36:04,031: t15.2023.09.03 val PER: 0.1829
2025-11-02 11:36:04,032: t15.2023.09.24 val PER: 0.1396
2025-11-02 11:36:04,032: t15.2023.09.29 val PER: 0.1544
2025-11-02 11:36:04,032: t15.2023.10.01 val PER: 0.2028
2025-11-02 11:36:04,032: t15.2023.10.06 val PER: 0.1227
2025-11-02 11:36:04,033: t15.2023.10.08 val PER: 0.2382
2025-11-02 11:36:04,033: t15.2023.10.13 val PER: 0.2296
2025-11-02 11:36:04,033: t15.2023.10.15 val PER: 0.1753
2025-11-02 11:36:04,033: t15.2023.10.20 val PER: 0.2148
2025-11-02 11:36:04,033: t15.2023.10.22 val PER: 0.1370
2025-11-02 11:36:04,034: t15.2023.11.03 val PER: 0.2062
2025-11-02 11:36:04,034: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:36:04,034: t15.2023.11.17 val PER: 0.0544
2025-11-02 11:36:04,034: t15.2023.11.19 val PER: 0.0639
2025-11-02 11:36:04,035: t15.2023.11.26 val PER: 0.1681
2025-11-02 11:36:04,035: t15.2023.12.03 val PER: 0.1324
2025-11-02 11:36:04,035: t15.2023.12.08 val PER: 0.1591
2025-11-02 11:36:04,036: t15.2023.12.10 val PER: 0.1248
2025-11-02 11:36:04,036: t15.2023.12.17 val PER: 0.1923
2025-11-02 11:36:04,036: t15.2023.12.29 val PER: 0.1784
2025-11-02 11:36:04,036: t15.2024.02.25 val PER: 0.1489
2025-11-02 11:36:04,036: t15.2024.03.08 val PER: 0.2504
2025-11-02 11:36:04,037: t15.2024.03.15 val PER: 0.2564
2025-11-02 11:36:04,037: t15.2024.03.17 val PER: 0.1688
2025-11-02 11:36:04,037: t15.2024.05.10 val PER: 0.1887
2025-11-02 11:36:04,037: t15.2024.06.14 val PER: 0.2129
2025-11-02 11:36:04,037: t15.2024.07.19 val PER: 0.2657
2025-11-02 11:36:04,038: t15.2024.07.21 val PER: 0.1283
2025-11-02 11:36:04,038: t15.2024.07.28 val PER: 0.1853
2025-11-02 11:36:04,038: t15.2025.01.10 val PER: 0.3430
2025-11-02 11:36:04,039: t15.2025.01.12 val PER: 0.1901
2025-11-02 11:36:04,039: t15.2025.03.14 val PER: 0.4024
2025-11-02 11:36:04,039: t15.2025.03.16 val PER: 0.2408
2025-11-02 11:36:04,039: t15.2025.03.30 val PER: 0.3253
2025-11-02 11:36:04,040: t15.2025.04.13 val PER: 0.2896
2025-11-02 11:36:04,040: New best test PER 0.1836 --> 0.1836
2025-11-02 11:36:04,040: Checkpointing model
2025-11-02 11:36:05,424: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:36:31,292: Train batch 27200: loss: 3.84 grad norm: 34.89 time: 0.067
2025-11-02 11:36:56,861: Train batch 27400: loss: 6.32 grad norm: 46.19 time: 0.080
2025-11-02 11:37:22,117: Train batch 27600: loss: 4.80 grad norm: 36.11 time: 0.078
2025-11-02 11:37:47,622: Train batch 27800: loss: 5.29 grad norm: 49.06 time: 0.095
2025-11-02 11:38:13,004: Train batch 28000: loss: 3.78 grad norm: 33.88 time: 0.070
2025-11-02 11:38:13,005: Running test after training batch: 28000
2025-11-02 11:38:25,632: Val batch 28000: PER (avg): 0.1824 CTC Loss (avg): 22.8195 time: 12.627
2025-11-02 11:38:25,633: t15.2023.08.13 val PER: 0.1227
2025-11-02 11:38:25,633: t15.2023.08.18 val PER: 0.1341
2025-11-02 11:38:25,635: t15.2023.08.20 val PER: 0.1255
2025-11-02 11:38:25,635: t15.2023.08.25 val PER: 0.1386
2025-11-02 11:38:25,636: t15.2023.08.27 val PER: 0.1977
2025-11-02 11:38:25,636: t15.2023.09.01 val PER: 0.0950
2025-11-02 11:38:25,636: t15.2023.09.03 val PER: 0.1971
2025-11-02 11:38:25,636: t15.2023.09.24 val PER: 0.1408
2025-11-02 11:38:25,637: t15.2023.09.29 val PER: 0.1506
2025-11-02 11:38:25,637: t15.2023.10.01 val PER: 0.2001
2025-11-02 11:38:25,637: t15.2023.10.06 val PER: 0.1184
2025-11-02 11:38:25,637: t15.2023.10.08 val PER: 0.2355
2025-11-02 11:38:25,637: t15.2023.10.13 val PER: 0.2296
2025-11-02 11:38:25,638: t15.2023.10.15 val PER: 0.1747
2025-11-02 11:38:25,638: t15.2023.10.20 val PER: 0.2013
2025-11-02 11:38:25,638: t15.2023.10.22 val PER: 0.1347
2025-11-02 11:38:25,639: t15.2023.11.03 val PER: 0.1913
2025-11-02 11:38:25,639: t15.2023.11.04 val PER: 0.0375
2025-11-02 11:38:25,639: t15.2023.11.17 val PER: 0.0544
2025-11-02 11:38:25,639: t15.2023.11.19 val PER: 0.0679
2025-11-02 11:38:25,640: t15.2023.11.26 val PER: 0.1630
2025-11-02 11:38:25,640: t15.2023.12.03 val PER: 0.1418
2025-11-02 11:38:25,640: t15.2023.12.08 val PER: 0.1565
2025-11-02 11:38:25,641: t15.2023.12.10 val PER: 0.1248
2025-11-02 11:38:25,641: t15.2023.12.17 val PER: 0.1861
2025-11-02 11:38:25,641: t15.2023.12.29 val PER: 0.1695
2025-11-02 11:38:25,641: t15.2024.02.25 val PER: 0.1447
2025-11-02 11:38:25,642: t15.2024.03.08 val PER: 0.2489
2025-11-02 11:38:25,642: t15.2024.03.15 val PER: 0.2464
2025-11-02 11:38:25,642: t15.2024.03.17 val PER: 0.1667
2025-11-02 11:38:25,643: t15.2024.05.10 val PER: 0.1932
2025-11-02 11:38:25,643: t15.2024.06.14 val PER: 0.2192
2025-11-02 11:38:25,643: t15.2024.07.19 val PER: 0.2676
2025-11-02 11:38:25,643: t15.2024.07.21 val PER: 0.1221
2025-11-02 11:38:25,644: t15.2024.07.28 val PER: 0.1816
2025-11-02 11:38:25,644: t15.2025.01.10 val PER: 0.3526
2025-11-02 11:38:25,644: t15.2025.01.12 val PER: 0.1925
2025-11-02 11:38:25,644: t15.2025.03.14 val PER: 0.3979
2025-11-02 11:38:25,645: t15.2025.03.16 val PER: 0.2552
2025-11-02 11:38:25,645: t15.2025.03.30 val PER: 0.3276
2025-11-02 11:38:25,646: t15.2025.04.13 val PER: 0.2725
2025-11-02 11:38:25,646: New best test PER 0.1836 --> 0.1824
2025-11-02 11:38:25,646: Checkpointing model
2025-11-02 11:38:27,036: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:38:53,128: Train batch 28200: loss: 4.03 grad norm: 38.98 time: 0.070
2025-11-02 11:39:18,360: Train batch 28400: loss: 4.97 grad norm: 45.11 time: 0.094
2025-11-02 11:39:43,495: Train batch 28600: loss: 6.34 grad norm: 42.52 time: 0.081
2025-11-02 11:40:09,761: Train batch 28800: loss: 4.09 grad norm: 32.39 time: 0.073
2025-11-02 11:40:35,628: Train batch 29000: loss: 3.29 grad norm: 35.19 time: 0.086
2025-11-02 11:40:35,629: Running test after training batch: 29000
2025-11-02 11:40:47,852: Val batch 29000: PER (avg): 0.1809 CTC Loss (avg): 22.8895 time: 12.222
2025-11-02 11:40:47,852: t15.2023.08.13 val PER: 0.1247
2025-11-02 11:40:47,852: t15.2023.08.18 val PER: 0.1366
2025-11-02 11:40:47,853: t15.2023.08.20 val PER: 0.1199
2025-11-02 11:40:47,853: t15.2023.08.25 val PER: 0.1355
2025-11-02 11:40:47,853: t15.2023.08.27 val PER: 0.2074
2025-11-02 11:40:47,854: t15.2023.09.01 val PER: 0.0852
2025-11-02 11:40:47,854: t15.2023.09.03 val PER: 0.1805
2025-11-02 11:40:47,854: t15.2023.09.24 val PER: 0.1347
2025-11-02 11:40:47,854: t15.2023.09.29 val PER: 0.1449
2025-11-02 11:40:47,854: t15.2023.10.01 val PER: 0.1988
2025-11-02 11:40:47,884: t15.2023.10.06 val PER: 0.1173
2025-11-02 11:40:47,884: t15.2023.10.08 val PER: 0.2382
2025-11-02 11:40:47,884: t15.2023.10.13 val PER: 0.2304
2025-11-02 11:40:47,885: t15.2023.10.15 val PER: 0.1786
2025-11-02 11:40:47,885: t15.2023.10.20 val PER: 0.2013
2025-11-02 11:40:47,886: t15.2023.10.22 val PER: 0.1392
2025-11-02 11:40:47,886: t15.2023.11.03 val PER: 0.1995
2025-11-02 11:40:47,886: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:40:47,886: t15.2023.11.17 val PER: 0.0560
2025-11-02 11:40:47,887: t15.2023.11.19 val PER: 0.0699
2025-11-02 11:40:47,887: t15.2023.11.26 val PER: 0.1645
2025-11-02 11:40:47,887: t15.2023.12.03 val PER: 0.1261
2025-11-02 11:40:47,888: t15.2023.12.08 val PER: 0.1531
2025-11-02 11:40:47,888: t15.2023.12.10 val PER: 0.1327
2025-11-02 11:40:47,888: t15.2023.12.17 val PER: 0.1840
2025-11-02 11:40:47,888: t15.2023.12.29 val PER: 0.1702
2025-11-02 11:40:47,888: t15.2024.02.25 val PER: 0.1447
2025-11-02 11:40:47,889: t15.2024.03.08 val PER: 0.2390
2025-11-02 11:40:47,889: t15.2024.03.15 val PER: 0.2470
2025-11-02 11:40:47,889: t15.2024.03.17 val PER: 0.1653
2025-11-02 11:40:47,889: t15.2024.05.10 val PER: 0.1887
2025-11-02 11:40:47,889: t15.2024.06.14 val PER: 0.2177
2025-11-02 11:40:47,890: t15.2024.07.19 val PER: 0.2643
2025-11-02 11:40:47,891: t15.2024.07.21 val PER: 0.1207
2025-11-02 11:40:47,891: t15.2024.07.28 val PER: 0.1824
2025-11-02 11:40:47,891: t15.2025.01.10 val PER: 0.3402
2025-11-02 11:40:47,891: t15.2025.01.12 val PER: 0.1894
2025-11-02 11:40:47,892: t15.2025.03.14 val PER: 0.3994
2025-11-02 11:40:47,892: t15.2025.03.16 val PER: 0.2369
2025-11-02 11:40:47,892: t15.2025.03.30 val PER: 0.3287
2025-11-02 11:40:47,892: t15.2025.04.13 val PER: 0.2882
2025-11-02 11:40:47,892: New best test PER 0.1824 --> 0.1809
2025-11-02 11:40:47,893: Checkpointing model
2025-11-02 11:40:49,372: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:41:14,630: Train batch 29200: loss: 4.31 grad norm: 41.22 time: 0.073
2025-11-02 11:41:39,096: Train batch 29400: loss: 3.36 grad norm: 38.68 time: 0.086
2025-11-02 11:42:03,957: Train batch 29600: loss: 2.70 grad norm: 30.62 time: 0.116
2025-11-02 11:42:29,201: Train batch 29800: loss: 3.65 grad norm: 34.53 time: 0.089
2025-11-02 11:42:54,503: Train batch 30000: loss: 4.62 grad norm: 50.43 time: 0.077
2025-11-02 11:42:54,504: Running test after training batch: 30000
2025-11-02 11:43:06,935: Val batch 30000: PER (avg): 0.1808 CTC Loss (avg): 23.1948 time: 12.431
2025-11-02 11:43:06,936: t15.2023.08.13 val PER: 0.1216
2025-11-02 11:43:06,936: t15.2023.08.18 val PER: 0.1341
2025-11-02 11:43:06,937: t15.2023.08.20 val PER: 0.1231
2025-11-02 11:43:06,937: t15.2023.08.25 val PER: 0.1310
2025-11-02 11:43:06,937: t15.2023.08.27 val PER: 0.1994
2025-11-02 11:43:06,938: t15.2023.09.01 val PER: 0.0852
2025-11-02 11:43:06,938: t15.2023.09.03 val PER: 0.1924
2025-11-02 11:43:06,941: t15.2023.09.24 val PER: 0.1311
2025-11-02 11:43:06,941: t15.2023.09.29 val PER: 0.1487
2025-11-02 11:43:06,942: t15.2023.10.01 val PER: 0.1929
2025-11-02 11:43:06,942: t15.2023.10.06 val PER: 0.1130
2025-11-02 11:43:06,942: t15.2023.10.08 val PER: 0.2300
2025-11-02 11:43:06,943: t15.2023.10.13 val PER: 0.2296
2025-11-02 11:43:06,943: t15.2023.10.15 val PER: 0.1767
2025-11-02 11:43:06,943: t15.2023.10.20 val PER: 0.2013
2025-11-02 11:43:06,943: t15.2023.10.22 val PER: 0.1425
2025-11-02 11:43:06,944: t15.2023.11.03 val PER: 0.1995
2025-11-02 11:43:06,944: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:43:06,944: t15.2023.11.17 val PER: 0.0653
2025-11-02 11:43:06,945: t15.2023.11.19 val PER: 0.0699
2025-11-02 11:43:06,945: t15.2023.11.26 val PER: 0.1681
2025-11-02 11:43:06,946: t15.2023.12.03 val PER: 0.1282
2025-11-02 11:43:06,946: t15.2023.12.08 val PER: 0.1525
2025-11-02 11:43:06,946: t15.2023.12.10 val PER: 0.1327
2025-11-02 11:43:06,946: t15.2023.12.17 val PER: 0.1913
2025-11-02 11:43:06,947: t15.2023.12.29 val PER: 0.1620
2025-11-02 11:43:06,947: t15.2024.02.25 val PER: 0.1348
2025-11-02 11:43:06,947: t15.2024.03.08 val PER: 0.2532
2025-11-02 11:43:06,947: t15.2024.03.15 val PER: 0.2483
2025-11-02 11:43:06,948: t15.2024.03.17 val PER: 0.1688
2025-11-02 11:43:06,948: t15.2024.05.10 val PER: 0.1947
2025-11-02 11:43:06,948: t15.2024.06.14 val PER: 0.2082
2025-11-02 11:43:06,948: t15.2024.07.19 val PER: 0.2742
2025-11-02 11:43:06,949: t15.2024.07.21 val PER: 0.1221
2025-11-02 11:43:06,949: t15.2024.07.28 val PER: 0.1750
2025-11-02 11:43:06,949: t15.2025.01.10 val PER: 0.3444
2025-11-02 11:43:06,949: t15.2025.01.12 val PER: 0.1948
2025-11-02 11:43:06,950: t15.2025.03.14 val PER: 0.3817
2025-11-02 11:43:06,950: t15.2025.03.16 val PER: 0.2343
2025-11-02 11:43:06,951: t15.2025.03.30 val PER: 0.3218
2025-11-02 11:43:06,951: t15.2025.04.13 val PER: 0.2882
2025-11-02 11:43:06,951: New best test PER 0.1809 --> 0.1808
2025-11-02 11:43:06,951: Checkpointing model
2025-11-02 11:43:08,500: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:43:33,786: Train batch 30200: loss: 4.61 grad norm: 43.74 time: 0.067
2025-11-02 11:43:59,234: Train batch 30400: loss: 3.04 grad norm: 36.56 time: 0.074
2025-11-02 11:44:24,278: Train batch 30600: loss: 3.76 grad norm: 31.40 time: 0.063
2025-11-02 11:44:48,619: Train batch 30800: loss: 6.18 grad norm: 48.25 time: 0.066
2025-11-02 11:45:13,251: Train batch 31000: loss: 6.06 grad norm: 50.24 time: 0.085
2025-11-02 11:45:13,252: Running test after training batch: 31000
2025-11-02 11:45:25,522: Val batch 31000: PER (avg): 0.1800 CTC Loss (avg): 23.3806 time: 12.270
2025-11-02 11:45:25,523: t15.2023.08.13 val PER: 0.1258
2025-11-02 11:45:25,523: t15.2023.08.18 val PER: 0.1291
2025-11-02 11:45:25,524: t15.2023.08.20 val PER: 0.1247
2025-11-02 11:45:25,524: t15.2023.08.25 val PER: 0.1310
2025-11-02 11:45:25,524: t15.2023.08.27 val PER: 0.2026
2025-11-02 11:45:25,525: t15.2023.09.01 val PER: 0.0925
2025-11-02 11:45:25,525: t15.2023.09.03 val PER: 0.1793
2025-11-02 11:45:25,526: t15.2023.09.24 val PER: 0.1286
2025-11-02 11:45:25,526: t15.2023.09.29 val PER: 0.1487
2025-11-02 11:45:25,526: t15.2023.10.01 val PER: 0.1988
2025-11-02 11:45:25,526: t15.2023.10.06 val PER: 0.1141
2025-11-02 11:45:25,527: t15.2023.10.08 val PER: 0.2395
2025-11-02 11:45:25,527: t15.2023.10.13 val PER: 0.2327
2025-11-02 11:45:25,527: t15.2023.10.15 val PER: 0.1721
2025-11-02 11:45:25,527: t15.2023.10.20 val PER: 0.1913
2025-11-02 11:45:25,528: t15.2023.10.22 val PER: 0.1392
2025-11-02 11:45:25,528: t15.2023.11.03 val PER: 0.1967
2025-11-02 11:45:25,528: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:45:25,528: t15.2023.11.17 val PER: 0.0529
2025-11-02 11:45:25,528: t15.2023.11.19 val PER: 0.0639
2025-11-02 11:45:25,529: t15.2023.11.26 val PER: 0.1652
2025-11-02 11:45:25,529: t15.2023.12.03 val PER: 0.1345
2025-11-02 11:45:25,529: t15.2023.12.08 val PER: 0.1538
2025-11-02 11:45:25,529: t15.2023.12.10 val PER: 0.1301
2025-11-02 11:45:25,530: t15.2023.12.17 val PER: 0.1819
2025-11-02 11:45:25,530: t15.2023.12.29 val PER: 0.1668
2025-11-02 11:45:25,530: t15.2024.02.25 val PER: 0.1362
2025-11-02 11:45:25,531: t15.2024.03.08 val PER: 0.2461
2025-11-02 11:45:25,531: t15.2024.03.15 val PER: 0.2470
2025-11-02 11:45:25,531: t15.2024.03.17 val PER: 0.1681
2025-11-02 11:45:25,531: t15.2024.05.10 val PER: 0.1753
2025-11-02 11:45:25,532: t15.2024.06.14 val PER: 0.2050
2025-11-02 11:45:25,532: t15.2024.07.19 val PER: 0.2597
2025-11-02 11:45:25,532: t15.2024.07.21 val PER: 0.1228
2025-11-02 11:45:25,532: t15.2024.07.28 val PER: 0.1735
2025-11-02 11:45:25,532: t15.2025.01.10 val PER: 0.3499
2025-11-02 11:45:25,533: t15.2025.01.12 val PER: 0.1955
2025-11-02 11:45:25,533: t15.2025.03.14 val PER: 0.4038
2025-11-02 11:45:25,533: t15.2025.03.16 val PER: 0.2421
2025-11-02 11:45:25,534: t15.2025.03.30 val PER: 0.3241
2025-11-02 11:45:25,534: t15.2025.04.13 val PER: 0.2753
2025-11-02 11:45:25,534: New best test PER 0.1808 --> 0.1800
2025-11-02 11:45:25,534: Checkpointing model
2025-11-02 11:45:27,118: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:45:52,459: Train batch 31200: loss: 4.83 grad norm: 42.27 time: 0.069
2025-11-02 11:46:17,218: Train batch 31400: loss: 3.49 grad norm: 34.37 time: 0.063
2025-11-02 11:46:41,737: Train batch 31600: loss: 2.36 grad norm: 34.75 time: 0.077
2025-11-02 11:47:07,189: Train batch 31800: loss: 3.71 grad norm: 33.46 time: 0.060
2025-11-02 11:47:32,178: Train batch 32000: loss: 1.49 grad norm: 18.28 time: 0.081
2025-11-02 11:47:32,178: Running test after training batch: 32000
2025-11-02 11:47:44,630: Val batch 32000: PER (avg): 0.1790 CTC Loss (avg): 23.4985 time: 12.451
2025-11-02 11:47:44,630: t15.2023.08.13 val PER: 0.1227
2025-11-02 11:47:44,631: t15.2023.08.18 val PER: 0.1299
2025-11-02 11:47:44,631: t15.2023.08.20 val PER: 0.1247
2025-11-02 11:47:44,631: t15.2023.08.25 val PER: 0.1310
2025-11-02 11:47:44,631: t15.2023.08.27 val PER: 0.2042
2025-11-02 11:47:44,632: t15.2023.09.01 val PER: 0.0860
2025-11-02 11:47:44,632: t15.2023.09.03 val PER: 0.1805
2025-11-02 11:47:44,632: t15.2023.09.24 val PER: 0.1262
2025-11-02 11:47:44,632: t15.2023.09.29 val PER: 0.1442
2025-11-02 11:47:44,633: t15.2023.10.01 val PER: 0.1909
2025-11-02 11:47:44,633: t15.2023.10.06 val PER: 0.1163
2025-11-02 11:47:44,633: t15.2023.10.08 val PER: 0.2368
2025-11-02 11:47:44,633: t15.2023.10.13 val PER: 0.2234
2025-11-02 11:47:44,634: t15.2023.10.15 val PER: 0.1701
2025-11-02 11:47:44,634: t15.2023.10.20 val PER: 0.1812
2025-11-02 11:47:44,634: t15.2023.10.22 val PER: 0.1403
2025-11-02 11:47:44,634: t15.2023.11.03 val PER: 0.1995
2025-11-02 11:47:44,635: t15.2023.11.04 val PER: 0.0239
2025-11-02 11:47:44,635: t15.2023.11.17 val PER: 0.0544
2025-11-02 11:47:44,636: t15.2023.11.19 val PER: 0.0639
2025-11-02 11:47:44,636: t15.2023.11.26 val PER: 0.1703
2025-11-02 11:47:44,636: t15.2023.12.03 val PER: 0.1334
2025-11-02 11:47:44,636: t15.2023.12.08 val PER: 0.1458
2025-11-02 11:47:44,637: t15.2023.12.10 val PER: 0.1275
2025-11-02 11:47:44,637: t15.2023.12.17 val PER: 0.1902
2025-11-02 11:47:44,637: t15.2023.12.29 val PER: 0.1675
2025-11-02 11:47:44,637: t15.2024.02.25 val PER: 0.1433
2025-11-02 11:47:44,637: t15.2024.03.08 val PER: 0.2504
2025-11-02 11:47:44,638: t15.2024.03.15 val PER: 0.2427
2025-11-02 11:47:44,638: t15.2024.03.17 val PER: 0.1646
2025-11-02 11:47:44,638: t15.2024.05.10 val PER: 0.1857
2025-11-02 11:47:44,638: t15.2024.06.14 val PER: 0.1987
2025-11-02 11:47:44,639: t15.2024.07.19 val PER: 0.2630
2025-11-02 11:47:44,639: t15.2024.07.21 val PER: 0.1207
2025-11-02 11:47:44,639: t15.2024.07.28 val PER: 0.1772
2025-11-02 11:47:44,639: t15.2025.01.10 val PER: 0.3444
2025-11-02 11:47:44,640: t15.2025.01.12 val PER: 0.1932
2025-11-02 11:47:44,640: t15.2025.03.14 val PER: 0.4009
2025-11-02 11:47:44,640: t15.2025.03.16 val PER: 0.2369
2025-11-02 11:47:44,641: t15.2025.03.30 val PER: 0.3299
2025-11-02 11:47:44,641: t15.2025.04.13 val PER: 0.2853
2025-11-02 11:47:44,641: New best test PER 0.1800 --> 0.1790
2025-11-02 11:47:44,641: Checkpointing model
2025-11-02 11:47:46,054: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:48:10,696: Train batch 32200: loss: 3.05 grad norm: 35.50 time: 0.071
2025-11-02 11:48:35,726: Train batch 32400: loss: 1.62 grad norm: 26.64 time: 0.065
2025-11-02 11:49:00,970: Train batch 32600: loss: 1.66 grad norm: 31.58 time: 0.075
2025-11-02 11:49:26,410: Train batch 32800: loss: 3.47 grad norm: 39.47 time: 0.081
2025-11-02 11:49:51,412: Train batch 33000: loss: 2.49 grad norm: 35.56 time: 0.085
2025-11-02 11:49:51,413: Running test after training batch: 33000
2025-11-02 11:50:04,209: Val batch 33000: PER (avg): 0.1787 CTC Loss (avg): 23.9854 time: 12.796
2025-11-02 11:50:04,209: t15.2023.08.13 val PER: 0.1268
2025-11-02 11:50:04,210: t15.2023.08.18 val PER: 0.1274
2025-11-02 11:50:04,210: t15.2023.08.20 val PER: 0.1215
2025-11-02 11:50:04,211: t15.2023.08.25 val PER: 0.1310
2025-11-02 11:50:04,211: t15.2023.08.27 val PER: 0.2010
2025-11-02 11:50:04,211: t15.2023.09.01 val PER: 0.0852
2025-11-02 11:50:04,211: t15.2023.09.03 val PER: 0.1853
2025-11-02 11:50:04,212: t15.2023.09.24 val PER: 0.1274
2025-11-02 11:50:04,212: t15.2023.09.29 val PER: 0.1455
2025-11-02 11:50:04,212: t15.2023.10.01 val PER: 0.1948
2025-11-02 11:50:04,212: t15.2023.10.06 val PER: 0.1130
2025-11-02 11:50:04,213: t15.2023.10.08 val PER: 0.2273
2025-11-02 11:50:04,213: t15.2023.10.13 val PER: 0.2258
2025-11-02 11:50:04,213: t15.2023.10.15 val PER: 0.1628
2025-11-02 11:50:04,214: t15.2023.10.20 val PER: 0.1846
2025-11-02 11:50:04,214: t15.2023.10.22 val PER: 0.1403
2025-11-02 11:50:04,214: t15.2023.11.03 val PER: 0.1961
2025-11-02 11:50:04,214: t15.2023.11.04 val PER: 0.0307
2025-11-02 11:50:04,214: t15.2023.11.17 val PER: 0.0529
2025-11-02 11:50:04,215: t15.2023.11.19 val PER: 0.0699
2025-11-02 11:50:04,216: t15.2023.11.26 val PER: 0.1681
2025-11-02 11:50:04,216: t15.2023.12.03 val PER: 0.1345
2025-11-02 11:50:04,216: t15.2023.12.08 val PER: 0.1538
2025-11-02 11:50:04,217: t15.2023.12.10 val PER: 0.1235
2025-11-02 11:50:04,217: t15.2023.12.17 val PER: 0.1923
2025-11-02 11:50:04,217: t15.2023.12.29 val PER: 0.1668
2025-11-02 11:50:04,217: t15.2024.02.25 val PER: 0.1334
2025-11-02 11:50:04,217: t15.2024.03.08 val PER: 0.2432
2025-11-02 11:50:04,218: t15.2024.03.15 val PER: 0.2395
2025-11-02 11:50:04,218: t15.2024.03.17 val PER: 0.1695
2025-11-02 11:50:04,219: t15.2024.05.10 val PER: 0.1917
2025-11-02 11:50:04,219: t15.2024.06.14 val PER: 0.2066
2025-11-02 11:50:04,219: t15.2024.07.19 val PER: 0.2604
2025-11-02 11:50:04,220: t15.2024.07.21 val PER: 0.1228
2025-11-02 11:50:04,220: t15.2024.07.28 val PER: 0.1728
2025-11-02 11:50:04,221: t15.2025.01.10 val PER: 0.3430
2025-11-02 11:50:04,221: t15.2025.01.12 val PER: 0.1909
2025-11-02 11:50:04,221: t15.2025.03.14 val PER: 0.4068
2025-11-02 11:50:04,221: t15.2025.03.16 val PER: 0.2317
2025-11-02 11:50:04,222: t15.2025.03.30 val PER: 0.3253
2025-11-02 11:50:04,222: t15.2025.04.13 val PER: 0.2910
2025-11-02 11:50:04,222: New best test PER 0.1790 --> 0.1787
2025-11-02 11:50:04,222: Checkpointing model
2025-11-02 11:50:05,822: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:50:31,227: Train batch 33200: loss: 2.72 grad norm: 29.75 time: 0.076
2025-11-02 11:50:56,045: Train batch 33400: loss: 2.30 grad norm: 37.21 time: 0.060
2025-11-02 11:51:20,930: Train batch 33600: loss: 3.24 grad norm: 34.62 time: 0.069
2025-11-02 11:51:45,771: Train batch 33800: loss: 4.10 grad norm: 46.03 time: 0.064
2025-11-02 11:52:11,782: Train batch 34000: loss: 2.21 grad norm: 27.75 time: 0.068
2025-11-02 11:52:11,783: Running test after training batch: 34000
2025-11-02 11:52:23,932: Val batch 34000: PER (avg): 0.1788 CTC Loss (avg): 24.2814 time: 12.149
2025-11-02 11:52:23,933: t15.2023.08.13 val PER: 0.1258
2025-11-02 11:52:23,933: t15.2023.08.18 val PER: 0.1291
2025-11-02 11:52:23,933: t15.2023.08.20 val PER: 0.1215
2025-11-02 11:52:23,934: t15.2023.08.25 val PER: 0.1280
2025-11-02 11:52:23,934: t15.2023.08.27 val PER: 0.1945
2025-11-02 11:52:23,934: t15.2023.09.01 val PER: 0.0877
2025-11-02 11:52:23,934: t15.2023.09.03 val PER: 0.1770
2025-11-02 11:52:23,935: t15.2023.09.24 val PER: 0.1420
2025-11-02 11:52:23,935: t15.2023.09.29 val PER: 0.1455
2025-11-02 11:52:23,936: t15.2023.10.01 val PER: 0.1889
2025-11-02 11:52:23,936: t15.2023.10.06 val PER: 0.1130
2025-11-02 11:52:23,936: t15.2023.10.08 val PER: 0.2165
2025-11-02 11:52:23,936: t15.2023.10.13 val PER: 0.2366
2025-11-02 11:52:23,936: t15.2023.10.15 val PER: 0.1661
2025-11-02 11:52:23,937: t15.2023.10.20 val PER: 0.1913
2025-11-02 11:52:23,937: t15.2023.10.22 val PER: 0.1381
2025-11-02 11:52:23,937: t15.2023.11.03 val PER: 0.2049
2025-11-02 11:52:23,937: t15.2023.11.04 val PER: 0.0444
2025-11-02 11:52:23,938: t15.2023.11.17 val PER: 0.0498
2025-11-02 11:52:23,938: t15.2023.11.19 val PER: 0.0679
2025-11-02 11:52:23,938: t15.2023.11.26 val PER: 0.1616
2025-11-02 11:52:23,939: t15.2023.12.03 val PER: 0.1334
2025-11-02 11:52:23,939: t15.2023.12.08 val PER: 0.1425
2025-11-02 11:52:23,939: t15.2023.12.10 val PER: 0.1340
2025-11-02 11:52:23,939: t15.2023.12.17 val PER: 0.1892
2025-11-02 11:52:23,940: t15.2023.12.29 val PER: 0.1661
2025-11-02 11:52:23,940: t15.2024.02.25 val PER: 0.1376
2025-11-02 11:52:23,940: t15.2024.03.08 val PER: 0.2390
2025-11-02 11:52:23,941: t15.2024.03.15 val PER: 0.2439
2025-11-02 11:52:23,941: t15.2024.03.17 val PER: 0.1604
2025-11-02 11:52:23,941: t15.2024.05.10 val PER: 0.1842
2025-11-02 11:52:23,941: t15.2024.06.14 val PER: 0.2019
2025-11-02 11:52:23,942: t15.2024.07.19 val PER: 0.2637
2025-11-02 11:52:23,942: t15.2024.07.21 val PER: 0.1221
2025-11-02 11:52:23,942: t15.2024.07.28 val PER: 0.1801
2025-11-02 11:52:23,942: t15.2025.01.10 val PER: 0.3402
2025-11-02 11:52:23,942: t15.2025.01.12 val PER: 0.1932
2025-11-02 11:52:23,943: t15.2025.03.14 val PER: 0.4098
2025-11-02 11:52:23,943: t15.2025.03.16 val PER: 0.2513
2025-11-02 11:52:23,943: t15.2025.03.30 val PER: 0.3241
2025-11-02 11:52:23,943: t15.2025.04.13 val PER: 0.2767
2025-11-02 11:52:48,907: Train batch 34200: loss: 2.59 grad norm: 40.37 time: 0.085
2025-11-02 11:53:13,465: Train batch 34400: loss: 2.35 grad norm: 31.41 time: 0.082
2025-11-02 11:53:37,891: Train batch 34600: loss: 2.12 grad norm: 32.64 time: 0.076
2025-11-02 11:54:03,007: Train batch 34800: loss: 3.22 grad norm: 40.41 time: 0.077
2025-11-02 11:54:28,645: Train batch 35000: loss: 3.41 grad norm: 42.76 time: 0.096
2025-11-02 11:54:28,646: Running test after training batch: 35000
2025-11-02 11:54:42,728: Val batch 35000: PER (avg): 0.1789 CTC Loss (avg): 24.6185 time: 14.082
2025-11-02 11:54:42,729: t15.2023.08.13 val PER: 0.1216
2025-11-02 11:54:42,729: t15.2023.08.18 val PER: 0.1350
2025-11-02 11:54:42,730: t15.2023.08.20 val PER: 0.1191
2025-11-02 11:54:42,730: t15.2023.08.25 val PER: 0.1280
2025-11-02 11:54:42,731: t15.2023.08.27 val PER: 0.1977
2025-11-02 11:54:42,731: t15.2023.09.01 val PER: 0.0828
2025-11-02 11:54:42,732: t15.2023.09.03 val PER: 0.1841
2025-11-02 11:54:42,732: t15.2023.09.24 val PER: 0.1274
2025-11-02 11:54:42,732: t15.2023.09.29 val PER: 0.1461
2025-11-02 11:54:42,733: t15.2023.10.01 val PER: 0.1876
2025-11-02 11:54:42,733: t15.2023.10.06 val PER: 0.1152
2025-11-02 11:54:42,733: t15.2023.10.08 val PER: 0.2287
2025-11-02 11:54:42,734: t15.2023.10.13 val PER: 0.2296
2025-11-02 11:54:42,734: t15.2023.10.15 val PER: 0.1688
2025-11-02 11:54:42,734: t15.2023.10.20 val PER: 0.2047
2025-11-02 11:54:42,734: t15.2023.10.22 val PER: 0.1459
2025-11-02 11:54:42,735: t15.2023.11.03 val PER: 0.1934
2025-11-02 11:54:42,735: t15.2023.11.04 val PER: 0.0341
2025-11-02 11:54:42,736: t15.2023.11.17 val PER: 0.0622
2025-11-02 11:54:42,784: t15.2023.11.19 val PER: 0.0699
2025-11-02 11:54:42,784: t15.2023.11.26 val PER: 0.1587
2025-11-02 11:54:42,784: t15.2023.12.03 val PER: 0.1345
2025-11-02 11:54:42,785: t15.2023.12.08 val PER: 0.1498
2025-11-02 11:54:42,786: t15.2023.12.10 val PER: 0.1275
2025-11-02 11:54:42,786: t15.2023.12.17 val PER: 0.1913
2025-11-02 11:54:42,786: t15.2023.12.29 val PER: 0.1633
2025-11-02 11:54:42,787: t15.2024.02.25 val PER: 0.1348
2025-11-02 11:54:42,787: t15.2024.03.08 val PER: 0.2532
2025-11-02 11:54:42,787: t15.2024.03.15 val PER: 0.2458
2025-11-02 11:54:42,788: t15.2024.03.17 val PER: 0.1618
2025-11-02 11:54:42,788: t15.2024.05.10 val PER: 0.1917
2025-11-02 11:54:42,788: t15.2024.06.14 val PER: 0.2145
2025-11-02 11:54:42,789: t15.2024.07.19 val PER: 0.2591
2025-11-02 11:54:42,789: t15.2024.07.21 val PER: 0.1186
2025-11-02 11:54:42,790: t15.2024.07.28 val PER: 0.1757
2025-11-02 11:54:42,790: t15.2025.01.10 val PER: 0.3375
2025-11-02 11:54:42,791: t15.2025.01.12 val PER: 0.1871
2025-11-02 11:54:42,791: t15.2025.03.14 val PER: 0.4068
2025-11-02 11:54:42,792: t15.2025.03.16 val PER: 0.2487
2025-11-02 11:54:42,792: t15.2025.03.30 val PER: 0.3333
2025-11-02 11:54:42,793: t15.2025.04.13 val PER: 0.2853
2025-11-02 11:55:07,276: Train batch 35200: loss: 1.89 grad norm: 27.67 time: 0.081
2025-11-02 11:55:32,032: Train batch 35400: loss: 1.66 grad norm: 22.02 time: 0.084
2025-11-02 11:55:57,043: Train batch 35600: loss: 2.27 grad norm: 30.50 time: 0.082
2025-11-02 11:56:20,750: Train batch 35800: loss: 4.65 grad norm: 51.48 time: 0.115
2025-11-02 11:56:44,699: Train batch 36000: loss: 2.94 grad norm: 39.74 time: 0.070
2025-11-02 11:56:44,704: Running test after training batch: 36000
2025-11-02 11:56:58,020: Val batch 36000: PER (avg): 0.1779 CTC Loss (avg): 24.7466 time: 13.315
2025-11-02 11:56:58,021: t15.2023.08.13 val PER: 0.1258
2025-11-02 11:56:58,021: t15.2023.08.18 val PER: 0.1148
2025-11-02 11:56:58,021: t15.2023.08.20 val PER: 0.1207
2025-11-02 11:56:58,022: t15.2023.08.25 val PER: 0.1295
2025-11-02 11:56:58,022: t15.2023.08.27 val PER: 0.2010
2025-11-02 11:56:58,022: t15.2023.09.01 val PER: 0.0917
2025-11-02 11:56:58,023: t15.2023.09.03 val PER: 0.1758
2025-11-02 11:56:58,023: t15.2023.09.24 val PER: 0.1335
2025-11-02 11:56:58,023: t15.2023.09.29 val PER: 0.1493
2025-11-02 11:56:58,024: t15.2023.10.01 val PER: 0.1968
2025-11-02 11:56:58,024: t15.2023.10.06 val PER: 0.1098
2025-11-02 11:56:58,024: t15.2023.10.08 val PER: 0.2260
2025-11-02 11:56:58,025: t15.2023.10.13 val PER: 0.2180
2025-11-02 11:56:58,026: t15.2023.10.15 val PER: 0.1707
2025-11-02 11:56:58,026: t15.2023.10.20 val PER: 0.1946
2025-11-02 11:56:58,026: t15.2023.10.22 val PER: 0.1425
2025-11-02 11:56:58,026: t15.2023.11.03 val PER: 0.1967
2025-11-02 11:56:58,027: t15.2023.11.04 val PER: 0.0307
2025-11-02 11:56:58,027: t15.2023.11.17 val PER: 0.0420
2025-11-02 11:56:58,027: t15.2023.11.19 val PER: 0.0758
2025-11-02 11:56:58,028: t15.2023.11.26 val PER: 0.1572
2025-11-02 11:56:58,028: t15.2023.12.03 val PER: 0.1408
2025-11-02 11:56:58,028: t15.2023.12.08 val PER: 0.1425
2025-11-02 11:56:58,028: t15.2023.12.10 val PER: 0.1261
2025-11-02 11:56:58,029: t15.2023.12.17 val PER: 0.1902
2025-11-02 11:56:58,029: t15.2023.12.29 val PER: 0.1558
2025-11-02 11:56:58,029: t15.2024.02.25 val PER: 0.1447
2025-11-02 11:56:58,029: t15.2024.03.08 val PER: 0.2390
2025-11-02 11:56:58,030: t15.2024.03.15 val PER: 0.2439
2025-11-02 11:56:58,030: t15.2024.03.17 val PER: 0.1618
2025-11-02 11:56:58,031: t15.2024.05.10 val PER: 0.1857
2025-11-02 11:56:58,031: t15.2024.06.14 val PER: 0.2114
2025-11-02 11:56:58,031: t15.2024.07.19 val PER: 0.2584
2025-11-02 11:56:58,031: t15.2024.07.21 val PER: 0.1241
2025-11-02 11:56:58,032: t15.2024.07.28 val PER: 0.1735
2025-11-02 11:56:58,032: t15.2025.01.10 val PER: 0.3485
2025-11-02 11:56:58,032: t15.2025.01.12 val PER: 0.1848
2025-11-02 11:56:58,032: t15.2025.03.14 val PER: 0.4068
2025-11-02 11:56:58,033: t15.2025.03.16 val PER: 0.2526
2025-11-02 11:56:58,033: t15.2025.03.30 val PER: 0.3333
2025-11-02 11:56:58,033: t15.2025.04.13 val PER: 0.2853
2025-11-02 11:56:58,034: New best test PER 0.1787 --> 0.1779
2025-11-02 11:56:58,034: Checkpointing model
2025-11-02 11:56:59,908: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:57:23,488: Train batch 36200: loss: 1.30 grad norm: 20.95 time: 0.095
2025-11-02 11:57:47,081: Train batch 36400: loss: 2.32 grad norm: 35.39 time: 0.102
2025-11-02 11:58:10,410: Train batch 36600: loss: 1.87 grad norm: 25.90 time: 0.071
2025-11-02 11:58:34,121: Train batch 36800: loss: 2.47 grad norm: 37.77 time: 0.088
2025-11-02 11:58:57,587: Train batch 37000: loss: 2.02 grad norm: 30.45 time: 0.079
2025-11-02 11:58:57,587: Running test after training batch: 37000
2025-11-02 11:59:11,620: Val batch 37000: PER (avg): 0.1772 CTC Loss (avg): 24.8759 time: 14.033
2025-11-02 11:59:11,621: t15.2023.08.13 val PER: 0.1216
2025-11-02 11:59:11,622: t15.2023.08.18 val PER: 0.1266
2025-11-02 11:59:11,622: t15.2023.08.20 val PER: 0.1215
2025-11-02 11:59:11,623: t15.2023.08.25 val PER: 0.1355
2025-11-02 11:59:11,623: t15.2023.08.27 val PER: 0.2010
2025-11-02 11:59:11,624: t15.2023.09.01 val PER: 0.0901
2025-11-02 11:59:11,624: t15.2023.09.03 val PER: 0.1770
2025-11-02 11:59:11,626: t15.2023.09.24 val PER: 0.1299
2025-11-02 11:59:11,626: t15.2023.09.29 val PER: 0.1474
2025-11-02 11:59:11,626: t15.2023.10.01 val PER: 0.1922
2025-11-02 11:59:11,627: t15.2023.10.06 val PER: 0.1119
2025-11-02 11:59:11,627: t15.2023.10.08 val PER: 0.2165
2025-11-02 11:59:11,627: t15.2023.10.13 val PER: 0.2258
2025-11-02 11:59:11,628: t15.2023.10.15 val PER: 0.1727
2025-11-02 11:59:11,628: t15.2023.10.20 val PER: 0.2013
2025-11-02 11:59:11,628: t15.2023.10.22 val PER: 0.1347
2025-11-02 11:59:11,629: t15.2023.11.03 val PER: 0.1954
2025-11-02 11:59:11,629: t15.2023.11.04 val PER: 0.0307
2025-11-02 11:59:11,629: t15.2023.11.17 val PER: 0.0560
2025-11-02 11:59:11,629: t15.2023.11.19 val PER: 0.0778
2025-11-02 11:59:11,630: t15.2023.11.26 val PER: 0.1580
2025-11-02 11:59:11,630: t15.2023.12.03 val PER: 0.1366
2025-11-02 11:59:11,631: t15.2023.12.08 val PER: 0.1498
2025-11-02 11:59:11,631: t15.2023.12.10 val PER: 0.1235
2025-11-02 11:59:11,631: t15.2023.12.17 val PER: 0.1840
2025-11-02 11:59:11,632: t15.2023.12.29 val PER: 0.1599
2025-11-02 11:59:11,632: t15.2024.02.25 val PER: 0.1348
2025-11-02 11:59:11,632: t15.2024.03.08 val PER: 0.2418
2025-11-02 11:59:11,633: t15.2024.03.15 val PER: 0.2339
2025-11-02 11:59:11,633: t15.2024.03.17 val PER: 0.1674
2025-11-02 11:59:11,633: t15.2024.05.10 val PER: 0.1724
2025-11-02 11:59:11,633: t15.2024.06.14 val PER: 0.2145
2025-11-02 11:59:11,684: t15.2024.07.19 val PER: 0.2624
2025-11-02 11:59:11,684: t15.2024.07.21 val PER: 0.1248
2025-11-02 11:59:11,685: t15.2024.07.28 val PER: 0.1757
2025-11-02 11:59:11,686: t15.2025.01.10 val PER: 0.3388
2025-11-02 11:59:11,686: t15.2025.01.12 val PER: 0.1909
2025-11-02 11:59:11,687: t15.2025.03.14 val PER: 0.4053
2025-11-02 11:59:11,687: t15.2025.03.16 val PER: 0.2251
2025-11-02 11:59:11,688: t15.2025.03.30 val PER: 0.3195
2025-11-02 11:59:11,688: t15.2025.04.13 val PER: 0.2767
2025-11-02 11:59:11,688: New best test PER 0.1779 --> 0.1772
2025-11-02 11:59:11,689: Checkpointing model
2025-11-02 11:59:13,637: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 11:59:37,011: Train batch 37200: loss: 1.98 grad norm: 30.03 time: 0.093
2025-11-02 11:59:59,870: Train batch 37400: loss: 1.74 grad norm: 30.07 time: 0.069
2025-11-02 12:00:23,366: Train batch 37600: loss: 3.34 grad norm: 38.75 time: 0.092
2025-11-02 12:00:46,888: Train batch 37800: loss: 2.37 grad norm: 33.35 time: 0.097
2025-11-02 12:01:10,086: Train batch 38000: loss: 2.83 grad norm: 34.16 time: 0.076
2025-11-02 12:01:10,087: Running test after training batch: 38000
2025-11-02 12:01:23,916: Val batch 38000: PER (avg): 0.1773 CTC Loss (avg): 25.1477 time: 13.829
2025-11-02 12:01:23,917: t15.2023.08.13 val PER: 0.1195
2025-11-02 12:01:23,917: t15.2023.08.18 val PER: 0.1174
2025-11-02 12:01:23,917: t15.2023.08.20 val PER: 0.1199
2025-11-02 12:01:23,918: t15.2023.08.25 val PER: 0.1370
2025-11-02 12:01:23,918: t15.2023.08.27 val PER: 0.1977
2025-11-02 12:01:23,918: t15.2023.09.01 val PER: 0.0860
2025-11-02 12:01:23,919: t15.2023.09.03 val PER: 0.1805
2025-11-02 12:01:23,919: t15.2023.09.24 val PER: 0.1262
2025-11-02 12:01:23,919: t15.2023.09.29 val PER: 0.1506
2025-11-02 12:01:23,919: t15.2023.10.01 val PER: 0.1876
2025-11-02 12:01:23,920: t15.2023.10.06 val PER: 0.1163
2025-11-02 12:01:23,921: t15.2023.10.08 val PER: 0.2152
2025-11-02 12:01:23,921: t15.2023.10.13 val PER: 0.2211
2025-11-02 12:01:23,921: t15.2023.10.15 val PER: 0.1714
2025-11-02 12:01:23,921: t15.2023.10.20 val PER: 0.1879
2025-11-02 12:01:23,922: t15.2023.10.22 val PER: 0.1448
2025-11-02 12:01:23,922: t15.2023.11.03 val PER: 0.1961
2025-11-02 12:01:23,922: t15.2023.11.04 val PER: 0.0410
2025-11-02 12:01:23,923: t15.2023.11.17 val PER: 0.0591
2025-11-02 12:01:23,923: t15.2023.11.19 val PER: 0.0739
2025-11-02 12:01:23,923: t15.2023.11.26 val PER: 0.1558
2025-11-02 12:01:23,924: t15.2023.12.03 val PER: 0.1313
2025-11-02 12:01:23,924: t15.2023.12.08 val PER: 0.1465
2025-11-02 12:01:23,924: t15.2023.12.10 val PER: 0.1235
2025-11-02 12:01:23,924: t15.2023.12.17 val PER: 0.1809
2025-11-02 12:01:23,925: t15.2023.12.29 val PER: 0.1613
2025-11-02 12:01:23,925: t15.2024.02.25 val PER: 0.1320
2025-11-02 12:01:23,926: t15.2024.03.08 val PER: 0.2475
2025-11-02 12:01:23,926: t15.2024.03.15 val PER: 0.2458
2025-11-02 12:01:23,927: t15.2024.03.17 val PER: 0.1632
2025-11-02 12:01:23,927: t15.2024.05.10 val PER: 0.1887
2025-11-02 12:01:23,927: t15.2024.06.14 val PER: 0.2129
2025-11-02 12:01:23,928: t15.2024.07.19 val PER: 0.2604
2025-11-02 12:01:23,928: t15.2024.07.21 val PER: 0.1248
2025-11-02 12:01:23,928: t15.2024.07.28 val PER: 0.1772
2025-11-02 12:01:23,929: t15.2025.01.10 val PER: 0.3471
2025-11-02 12:01:23,929: t15.2025.01.12 val PER: 0.1832
2025-11-02 12:01:23,929: t15.2025.03.14 val PER: 0.4112
2025-11-02 12:01:23,929: t15.2025.03.16 val PER: 0.2330
2025-11-02 12:01:23,930: t15.2025.03.30 val PER: 0.3207
2025-11-02 12:01:23,930: t15.2025.04.13 val PER: 0.2867
2025-11-02 12:01:47,704: Train batch 38200: loss: 3.46 grad norm: 45.36 time: 0.071
2025-11-02 12:02:11,413: Train batch 38400: loss: 1.00 grad norm: 21.33 time: 0.093
2025-11-02 12:02:36,061: Train batch 38600: loss: 2.07 grad norm: 29.44 time: 0.081
2025-11-02 12:03:00,058: Train batch 38800: loss: 2.30 grad norm: 36.98 time: 0.088
2025-11-02 12:03:25,133: Train batch 39000: loss: 1.56 grad norm: 33.55 time: 0.090
2025-11-02 12:03:25,135: Running test after training batch: 39000
2025-11-02 12:03:39,726: Val batch 39000: PER (avg): 0.1774 CTC Loss (avg): 25.5628 time: 14.590
2025-11-02 12:03:39,726: t15.2023.08.13 val PER: 0.1195
2025-11-02 12:03:39,727: t15.2023.08.18 val PER: 0.1190
2025-11-02 12:03:39,727: t15.2023.08.20 val PER: 0.1168
2025-11-02 12:03:39,728: t15.2023.08.25 val PER: 0.1370
2025-11-02 12:03:39,728: t15.2023.08.27 val PER: 0.2026
2025-11-02 12:03:39,729: t15.2023.09.01 val PER: 0.0860
2025-11-02 12:03:39,729: t15.2023.09.03 val PER: 0.1793
2025-11-02 12:03:39,729: t15.2023.09.24 val PER: 0.1250
2025-11-02 12:03:39,730: t15.2023.09.29 val PER: 0.1481
2025-11-02 12:03:39,731: t15.2023.10.01 val PER: 0.1955
2025-11-02 12:03:39,731: t15.2023.10.06 val PER: 0.1119
2025-11-02 12:03:39,731: t15.2023.10.08 val PER: 0.2206
2025-11-02 12:03:39,732: t15.2023.10.13 val PER: 0.2203
2025-11-02 12:03:39,732: t15.2023.10.15 val PER: 0.1694
2025-11-02 12:03:39,732: t15.2023.10.20 val PER: 0.2013
2025-11-02 12:03:39,733: t15.2023.10.22 val PER: 0.1425
2025-11-02 12:03:39,733: t15.2023.11.03 val PER: 0.1954
2025-11-02 12:03:39,783: t15.2023.11.04 val PER: 0.0239
2025-11-02 12:03:39,784: t15.2023.11.17 val PER: 0.0544
2025-11-02 12:03:39,784: t15.2023.11.19 val PER: 0.0699
2025-11-02 12:03:39,785: t15.2023.11.26 val PER: 0.1558
2025-11-02 12:03:39,786: t15.2023.12.03 val PER: 0.1355
2025-11-02 12:03:39,786: t15.2023.12.08 val PER: 0.1518
2025-11-02 12:03:39,786: t15.2023.12.10 val PER: 0.1209
2025-11-02 12:03:39,787: t15.2023.12.17 val PER: 0.1985
2025-11-02 12:03:39,787: t15.2023.12.29 val PER: 0.1585
2025-11-02 12:03:39,787: t15.2024.02.25 val PER: 0.1264
2025-11-02 12:03:39,788: t15.2024.03.08 val PER: 0.2404
2025-11-02 12:03:39,788: t15.2024.03.15 val PER: 0.2445
2025-11-02 12:03:39,788: t15.2024.03.17 val PER: 0.1604
2025-11-02 12:03:39,789: t15.2024.05.10 val PER: 0.2006
2025-11-02 12:03:39,789: t15.2024.06.14 val PER: 0.2098
2025-11-02 12:03:39,790: t15.2024.07.19 val PER: 0.2670
2025-11-02 12:03:39,791: t15.2024.07.21 val PER: 0.1214
2025-11-02 12:03:39,791: t15.2024.07.28 val PER: 0.1750
2025-11-02 12:03:39,791: t15.2025.01.10 val PER: 0.3347
2025-11-02 12:03:39,791: t15.2025.01.12 val PER: 0.1855
2025-11-02 12:03:39,792: t15.2025.03.14 val PER: 0.3994
2025-11-02 12:03:39,792: t15.2025.03.16 val PER: 0.2356
2025-11-02 12:03:39,792: t15.2025.03.30 val PER: 0.3241
2025-11-02 12:03:39,793: t15.2025.04.13 val PER: 0.2939
2025-11-02 12:04:03,202: Train batch 39200: loss: 2.10 grad norm: 29.53 time: 0.087
2025-11-02 12:04:26,892: Train batch 39400: loss: 1.03 grad norm: 20.21 time: 0.083
2025-11-02 12:04:50,969: Train batch 39600: loss: 3.21 grad norm: 40.40 time: 0.120
2025-11-02 12:05:14,807: Train batch 39800: loss: 1.88 grad norm: 25.68 time: 0.073
2025-11-02 12:05:38,772: Train batch 40000: loss: 2.28 grad norm: 38.27 time: 0.099
2025-11-02 12:05:38,773: Running test after training batch: 40000
2025-11-02 12:05:53,725: Val batch 40000: PER (avg): 0.1774 CTC Loss (avg): 25.8558 time: 14.951
2025-11-02 12:05:53,726: t15.2023.08.13 val PER: 0.1206
2025-11-02 12:05:53,726: t15.2023.08.18 val PER: 0.1224
2025-11-02 12:05:53,727: t15.2023.08.20 val PER: 0.1223
2025-11-02 12:05:53,727: t15.2023.08.25 val PER: 0.1295
2025-11-02 12:05:53,727: t15.2023.08.27 val PER: 0.1849
2025-11-02 12:05:53,728: t15.2023.09.01 val PER: 0.0852
2025-11-02 12:05:53,728: t15.2023.09.03 val PER: 0.1781
2025-11-02 12:05:53,729: t15.2023.09.24 val PER: 0.1165
2025-11-02 12:05:53,729: t15.2023.09.29 val PER: 0.1417
2025-11-02 12:05:53,729: t15.2023.10.01 val PER: 0.1942
2025-11-02 12:05:53,730: t15.2023.10.06 val PER: 0.1195
2025-11-02 12:05:53,730: t15.2023.10.08 val PER: 0.2111
2025-11-02 12:05:53,731: t15.2023.10.13 val PER: 0.2296
2025-11-02 12:05:53,731: t15.2023.10.15 val PER: 0.1655
2025-11-02 12:05:53,731: t15.2023.10.20 val PER: 0.1879
2025-11-02 12:05:53,732: t15.2023.10.22 val PER: 0.1459
2025-11-02 12:05:53,732: t15.2023.11.03 val PER: 0.2028
2025-11-02 12:05:53,733: t15.2023.11.04 val PER: 0.0307
2025-11-02 12:05:53,733: t15.2023.11.17 val PER: 0.0560
2025-11-02 12:05:53,784: t15.2023.11.19 val PER: 0.0778
2025-11-02 12:05:53,784: t15.2023.11.26 val PER: 0.1543
2025-11-02 12:05:53,785: t15.2023.12.03 val PER: 0.1271
2025-11-02 12:05:53,786: t15.2023.12.08 val PER: 0.1411
2025-11-02 12:05:53,786: t15.2023.12.10 val PER: 0.1235
2025-11-02 12:05:53,787: t15.2023.12.17 val PER: 0.1902
2025-11-02 12:05:53,787: t15.2023.12.29 val PER: 0.1599
2025-11-02 12:05:53,788: t15.2024.02.25 val PER: 0.1376
2025-11-02 12:05:53,788: t15.2024.03.08 val PER: 0.2560
2025-11-02 12:05:53,788: t15.2024.03.15 val PER: 0.2495
2025-11-02 12:05:53,789: t15.2024.03.17 val PER: 0.1534
2025-11-02 12:05:53,789: t15.2024.05.10 val PER: 0.1887
2025-11-02 12:05:53,789: t15.2024.06.14 val PER: 0.2224
2025-11-02 12:05:53,790: t15.2024.07.19 val PER: 0.2683
2025-11-02 12:05:53,791: t15.2024.07.21 val PER: 0.1179
2025-11-02 12:05:53,791: t15.2024.07.28 val PER: 0.1669
2025-11-02 12:05:53,791: t15.2025.01.10 val PER: 0.3457
2025-11-02 12:05:53,792: t15.2025.01.12 val PER: 0.1878
2025-11-02 12:05:53,792: t15.2025.03.14 val PER: 0.4260
2025-11-02 12:05:53,792: t15.2025.03.16 val PER: 0.2408
2025-11-02 12:05:53,793: t15.2025.03.30 val PER: 0.3207
2025-11-02 12:05:53,793: t15.2025.04.13 val PER: 0.2867
2025-11-02 12:06:17,916: Train batch 40200: loss: 0.83 grad norm: 18.25 time: 0.073
2025-11-02 12:06:42,835: Train batch 40400: loss: 1.47 grad norm: 23.14 time: 0.087
2025-11-02 12:07:07,091: Train batch 40600: loss: 1.07 grad norm: 19.94 time: 0.077
2025-11-02 12:07:31,089: Train batch 40800: loss: 1.73 grad norm: 26.84 time: 0.084
2025-11-02 12:07:55,041: Train batch 41000: loss: 2.13 grad norm: 37.75 time: 0.108
2025-11-02 12:07:55,042: Running test after training batch: 41000
2025-11-02 12:08:09,823: Val batch 41000: PER (avg): 0.1769 CTC Loss (avg): 25.9256 time: 14.781
2025-11-02 12:08:09,824: t15.2023.08.13 val PER: 0.1206
2025-11-02 12:08:09,825: t15.2023.08.18 val PER: 0.1215
2025-11-02 12:08:09,825: t15.2023.08.20 val PER: 0.1160
2025-11-02 12:08:09,826: t15.2023.08.25 val PER: 0.1295
2025-11-02 12:08:09,826: t15.2023.08.27 val PER: 0.2026
2025-11-02 12:08:09,827: t15.2023.09.01 val PER: 0.0852
2025-11-02 12:08:09,827: t15.2023.09.03 val PER: 0.1746
2025-11-02 12:08:09,827: t15.2023.09.24 val PER: 0.1238
2025-11-02 12:08:09,828: t15.2023.09.29 val PER: 0.1429
2025-11-02 12:08:09,828: t15.2023.10.01 val PER: 0.1929
2025-11-02 12:08:09,828: t15.2023.10.06 val PER: 0.1152
2025-11-02 12:08:09,829: t15.2023.10.08 val PER: 0.2165
2025-11-02 12:08:09,829: t15.2023.10.13 val PER: 0.2250
2025-11-02 12:08:09,829: t15.2023.10.15 val PER: 0.1655
2025-11-02 12:08:09,829: t15.2023.10.20 val PER: 0.1812
2025-11-02 12:08:09,830: t15.2023.10.22 val PER: 0.1448
2025-11-02 12:08:09,830: t15.2023.11.03 val PER: 0.1967
2025-11-02 12:08:09,831: t15.2023.11.04 val PER: 0.0307
2025-11-02 12:08:09,831: t15.2023.11.17 val PER: 0.0575
2025-11-02 12:08:09,831: t15.2023.11.19 val PER: 0.0758
2025-11-02 12:08:09,832: t15.2023.11.26 val PER: 0.1565
2025-11-02 12:08:09,832: t15.2023.12.03 val PER: 0.1282
2025-11-02 12:08:09,832: t15.2023.12.08 val PER: 0.1438
2025-11-02 12:08:09,833: t15.2023.12.10 val PER: 0.1209
2025-11-02 12:08:09,833: t15.2023.12.17 val PER: 0.1902
2025-11-02 12:08:09,833: t15.2023.12.29 val PER: 0.1572
2025-11-02 12:08:09,834: t15.2024.02.25 val PER: 0.1404
2025-11-02 12:08:09,834: t15.2024.03.08 val PER: 0.2546
2025-11-02 12:08:09,834: t15.2024.03.15 val PER: 0.2477
2025-11-02 12:08:09,835: t15.2024.03.17 val PER: 0.1520
2025-11-02 12:08:09,835: t15.2024.05.10 val PER: 0.1842
2025-11-02 12:08:09,835: t15.2024.06.14 val PER: 0.2145
2025-11-02 12:08:09,836: t15.2024.07.19 val PER: 0.2617
2025-11-02 12:08:09,836: t15.2024.07.21 val PER: 0.1221
2025-11-02 12:08:09,836: t15.2024.07.28 val PER: 0.1676
2025-11-02 12:08:09,837: t15.2025.01.10 val PER: 0.3512
2025-11-02 12:08:09,837: t15.2025.01.12 val PER: 0.1963
2025-11-02 12:08:09,837: t15.2025.03.14 val PER: 0.4142
2025-11-02 12:08:09,838: t15.2025.03.16 val PER: 0.2330
2025-11-02 12:08:09,838: t15.2025.03.30 val PER: 0.3287
2025-11-02 12:08:09,838: t15.2025.04.13 val PER: 0.2853
2025-11-02 12:08:09,838: New best test PER 0.1772 --> 0.1769
2025-11-02 12:08:09,839: Checkpointing model
2025-11-02 12:08:12,020: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 12:08:36,229: Train batch 41200: loss: 1.35 grad norm: 27.92 time: 0.070
2025-11-02 12:08:59,996: Train batch 41400: loss: 2.40 grad norm: 39.85 time: 0.082
2025-11-02 12:09:23,895: Train batch 41600: loss: 1.68 grad norm: 34.39 time: 0.084
2025-11-02 12:09:48,018: Train batch 41800: loss: 1.56 grad norm: 32.37 time: 0.097
2025-11-02 12:10:12,390: Train batch 42000: loss: 1.60 grad norm: 36.29 time: 0.137
2025-11-02 12:10:12,391: Running test after training batch: 42000
2025-11-02 12:10:26,229: Val batch 42000: PER (avg): 0.1761 CTC Loss (avg): 26.1734 time: 13.838
2025-11-02 12:10:26,229: t15.2023.08.13 val PER: 0.1154
2025-11-02 12:10:26,230: t15.2023.08.18 val PER: 0.1274
2025-11-02 12:10:26,231: t15.2023.08.20 val PER: 0.1176
2025-11-02 12:10:26,231: t15.2023.08.25 val PER: 0.1325
2025-11-02 12:10:26,231: t15.2023.08.27 val PER: 0.1977
2025-11-02 12:10:26,232: t15.2023.09.01 val PER: 0.0844
2025-11-02 12:10:26,232: t15.2023.09.03 val PER: 0.1770
2025-11-02 12:10:26,232: t15.2023.09.24 val PER: 0.1250
2025-11-02 12:10:26,232: t15.2023.09.29 val PER: 0.1468
2025-11-02 12:10:26,233: t15.2023.10.01 val PER: 0.1922
2025-11-02 12:10:26,233: t15.2023.10.06 val PER: 0.1098
2025-11-02 12:10:26,233: t15.2023.10.08 val PER: 0.2192
2025-11-02 12:10:26,234: t15.2023.10.13 val PER: 0.2227
2025-11-02 12:10:26,234: t15.2023.10.15 val PER: 0.1721
2025-11-02 12:10:26,234: t15.2023.10.20 val PER: 0.2013
2025-11-02 12:10:26,235: t15.2023.10.22 val PER: 0.1370
2025-11-02 12:10:26,235: t15.2023.11.03 val PER: 0.1940
2025-11-02 12:10:26,235: t15.2023.11.04 val PER: 0.0307
2025-11-02 12:10:26,236: t15.2023.11.17 val PER: 0.0622
2025-11-02 12:10:26,236: t15.2023.11.19 val PER: 0.0758
2025-11-02 12:10:26,236: t15.2023.11.26 val PER: 0.1478
2025-11-02 12:10:26,237: t15.2023.12.03 val PER: 0.1218
2025-11-02 12:10:26,237: t15.2023.12.08 val PER: 0.1411
2025-11-02 12:10:26,237: t15.2023.12.10 val PER: 0.1064
2025-11-02 12:10:26,237: t15.2023.12.17 val PER: 0.1871
2025-11-02 12:10:26,238: t15.2023.12.29 val PER: 0.1558
2025-11-02 12:10:26,238: t15.2024.02.25 val PER: 0.1390
2025-11-02 12:10:26,238: t15.2024.03.08 val PER: 0.2418
2025-11-02 12:10:26,238: t15.2024.03.15 val PER: 0.2445
2025-11-02 12:10:26,239: t15.2024.03.17 val PER: 0.1632
2025-11-02 12:10:26,239: t15.2024.05.10 val PER: 0.1902
2025-11-02 12:10:26,239: t15.2024.06.14 val PER: 0.2098
2025-11-02 12:10:26,239: t15.2024.07.19 val PER: 0.2657
2025-11-02 12:10:26,240: t15.2024.07.21 val PER: 0.1221
2025-11-02 12:10:26,240: t15.2024.07.28 val PER: 0.1750
2025-11-02 12:10:26,240: t15.2025.01.10 val PER: 0.3416
2025-11-02 12:10:26,241: t15.2025.01.12 val PER: 0.1848
2025-11-02 12:10:26,241: t15.2025.03.14 val PER: 0.3979
2025-11-02 12:10:26,241: t15.2025.03.16 val PER: 0.2461
2025-11-02 12:10:26,241: t15.2025.03.30 val PER: 0.3218
2025-11-02 12:10:26,242: t15.2025.04.13 val PER: 0.2939
2025-11-02 12:10:26,242: New best test PER 0.1769 --> 0.1761
2025-11-02 12:10:26,242: Checkpointing model
2025-11-02 12:10:28,864: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 12:10:53,050: Train batch 42200: loss: 1.47 grad norm: 24.96 time: 0.093
2025-11-02 12:11:17,077: Train batch 42400: loss: 2.18 grad norm: 35.14 time: 0.089
2025-11-02 12:11:41,124: Train batch 42600: loss: 1.02 grad norm: 19.90 time: 0.069
2025-11-02 12:12:04,978: Train batch 42800: loss: 1.41 grad norm: 26.18 time: 0.083
2025-11-02 12:12:29,113: Train batch 43000: loss: 0.90 grad norm: 25.58 time: 0.094
2025-11-02 12:12:29,114: Running test after training batch: 43000
2025-11-02 12:12:43,120: Val batch 43000: PER (avg): 0.1758 CTC Loss (avg): 26.2671 time: 14.006
2025-11-02 12:12:43,121: t15.2023.08.13 val PER: 0.1216
2025-11-02 12:12:43,121: t15.2023.08.18 val PER: 0.1257
2025-11-02 12:12:43,122: t15.2023.08.20 val PER: 0.1263
2025-11-02 12:12:43,122: t15.2023.08.25 val PER: 0.1250
2025-11-02 12:12:43,123: t15.2023.08.27 val PER: 0.2010
2025-11-02 12:12:43,123: t15.2023.09.01 val PER: 0.0860
2025-11-02 12:12:43,123: t15.2023.09.03 val PER: 0.1722
2025-11-02 12:12:43,124: t15.2023.09.24 val PER: 0.1201
2025-11-02 12:12:43,124: t15.2023.09.29 val PER: 0.1436
2025-11-02 12:12:43,124: t15.2023.10.01 val PER: 0.1902
2025-11-02 12:12:43,125: t15.2023.10.06 val PER: 0.1184
2025-11-02 12:12:43,126: t15.2023.10.08 val PER: 0.2179
2025-11-02 12:12:43,126: t15.2023.10.13 val PER: 0.2211
2025-11-02 12:12:43,127: t15.2023.10.15 val PER: 0.1674
2025-11-02 12:12:43,127: t15.2023.10.20 val PER: 0.1946
2025-11-02 12:12:43,128: t15.2023.10.22 val PER: 0.1325
2025-11-02 12:12:43,128: t15.2023.11.03 val PER: 0.1974
2025-11-02 12:12:43,128: t15.2023.11.04 val PER: 0.0375
2025-11-02 12:12:43,129: t15.2023.11.17 val PER: 0.0575
2025-11-02 12:12:43,129: t15.2023.11.19 val PER: 0.0679
2025-11-02 12:12:43,129: t15.2023.11.26 val PER: 0.1587
2025-11-02 12:12:43,130: t15.2023.12.03 val PER: 0.1229
2025-11-02 12:12:43,130: t15.2023.12.08 val PER: 0.1451
2025-11-02 12:12:43,131: t15.2023.12.10 val PER: 0.1130
2025-11-02 12:12:43,131: t15.2023.12.17 val PER: 0.1892
2025-11-02 12:12:43,131: t15.2023.12.29 val PER: 0.1620
2025-11-02 12:12:43,132: t15.2024.02.25 val PER: 0.1292
2025-11-02 12:12:43,132: t15.2024.03.08 val PER: 0.2390
2025-11-02 12:12:43,132: t15.2024.03.15 val PER: 0.2439
2025-11-02 12:12:43,133: t15.2024.03.17 val PER: 0.1576
2025-11-02 12:12:43,133: t15.2024.05.10 val PER: 0.1947
2025-11-02 12:12:43,133: t15.2024.06.14 val PER: 0.2208
2025-11-02 12:12:43,134: t15.2024.07.19 val PER: 0.2597
2025-11-02 12:12:43,134: t15.2024.07.21 val PER: 0.1214
2025-11-02 12:12:43,134: t15.2024.07.28 val PER: 0.1735
2025-11-02 12:12:43,134: t15.2025.01.10 val PER: 0.3430
2025-11-02 12:12:43,135: t15.2025.01.12 val PER: 0.1848
2025-11-02 12:12:43,136: t15.2025.03.14 val PER: 0.3891
2025-11-02 12:12:43,136: t15.2025.03.16 val PER: 0.2395
2025-11-02 12:12:43,136: t15.2025.03.30 val PER: 0.3184
2025-11-02 12:12:43,137: t15.2025.04.13 val PER: 0.2825
2025-11-02 12:12:43,137: New best test PER 0.1761 --> 0.1758
2025-11-02 12:12:43,137: Checkpointing model
2025-11-02 12:12:45,526: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 12:13:10,031: Train batch 43200: loss: 1.01 grad norm: 20.21 time: 0.074
2025-11-02 12:13:34,383: Train batch 43400: loss: 3.62 grad norm: 38.99 time: 0.079
2025-11-02 12:13:58,317: Train batch 43600: loss: 0.91 grad norm: 24.02 time: 0.074
2025-11-02 12:14:22,052: Train batch 43800: loss: 1.35 grad norm: 24.88 time: 0.072
2025-11-02 12:14:45,907: Train batch 44000: loss: 1.05 grad norm: 23.68 time: 0.089
2025-11-02 12:14:45,908: Running test after training batch: 44000
2025-11-02 12:15:00,420: Val batch 44000: PER (avg): 0.1746 CTC Loss (avg): 26.5901 time: 14.512
2025-11-02 12:15:00,421: t15.2023.08.13 val PER: 0.1164
2025-11-02 12:15:00,421: t15.2023.08.18 val PER: 0.1182
2025-11-02 12:15:00,422: t15.2023.08.20 val PER: 0.1215
2025-11-02 12:15:00,422: t15.2023.08.25 val PER: 0.1250
2025-11-02 12:15:00,422: t15.2023.08.27 val PER: 0.2042
2025-11-02 12:15:00,423: t15.2023.09.01 val PER: 0.0820
2025-11-02 12:15:00,423: t15.2023.09.03 val PER: 0.1734
2025-11-02 12:15:00,423: t15.2023.09.24 val PER: 0.1238
2025-11-02 12:15:00,424: t15.2023.09.29 val PER: 0.1378
2025-11-02 12:15:00,424: t15.2023.10.01 val PER: 0.1948
2025-11-02 12:15:00,425: t15.2023.10.06 val PER: 0.1163
2025-11-02 12:15:00,425: t15.2023.10.08 val PER: 0.2124
2025-11-02 12:15:00,426: t15.2023.10.13 val PER: 0.2234
2025-11-02 12:15:00,426: t15.2023.10.15 val PER: 0.1694
2025-11-02 12:15:00,426: t15.2023.10.20 val PER: 0.2013
2025-11-02 12:15:00,427: t15.2023.10.22 val PER: 0.1347
2025-11-02 12:15:00,427: t15.2023.11.03 val PER: 0.1893
2025-11-02 12:15:00,427: t15.2023.11.04 val PER: 0.0375
2025-11-02 12:15:00,428: t15.2023.11.17 val PER: 0.0529
2025-11-02 12:15:00,428: t15.2023.11.19 val PER: 0.0699
2025-11-02 12:15:00,428: t15.2023.11.26 val PER: 0.1558
2025-11-02 12:15:00,429: t15.2023.12.03 val PER: 0.1250
2025-11-02 12:15:00,429: t15.2023.12.08 val PER: 0.1471
2025-11-02 12:15:00,429: t15.2023.12.10 val PER: 0.1222
2025-11-02 12:15:00,430: t15.2023.12.17 val PER: 0.1861
2025-11-02 12:15:00,430: t15.2023.12.29 val PER: 0.1531
2025-11-02 12:15:00,430: t15.2024.02.25 val PER: 0.1320
2025-11-02 12:15:00,431: t15.2024.03.08 val PER: 0.2390
2025-11-02 12:15:00,431: t15.2024.03.15 val PER: 0.2427
2025-11-02 12:15:00,432: t15.2024.03.17 val PER: 0.1548
2025-11-02 12:15:00,432: t15.2024.05.10 val PER: 0.1947
2025-11-02 12:15:00,432: t15.2024.06.14 val PER: 0.2098
2025-11-02 12:15:00,433: t15.2024.07.19 val PER: 0.2624
2025-11-02 12:15:00,439: t15.2024.07.21 val PER: 0.1207
2025-11-02 12:15:00,439: t15.2024.07.28 val PER: 0.1713
2025-11-02 12:15:00,439: t15.2025.01.10 val PER: 0.3320
2025-11-02 12:15:00,440: t15.2025.01.12 val PER: 0.1871
2025-11-02 12:15:00,440: t15.2025.03.14 val PER: 0.3950
2025-11-02 12:15:00,440: t15.2025.03.16 val PER: 0.2435
2025-11-02 12:15:00,441: t15.2025.03.30 val PER: 0.3218
2025-11-02 12:15:00,441: t15.2025.04.13 val PER: 0.2753
2025-11-02 12:15:00,441: New best test PER 0.1758 --> 0.1746
2025-11-02 12:15:00,442: Checkpointing model
2025-11-02 12:15:02,809: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/best_checkpoint
2025-11-02 12:15:27,735: Train batch 44200: loss: 1.35 grad norm: 26.74 time: 0.058
2025-11-02 12:15:52,040: Train batch 44400: loss: 1.48 grad norm: 30.30 time: 0.076
2025-11-02 12:16:15,901: Train batch 44600: loss: 2.39 grad norm: 35.57 time: 0.084
2025-11-02 12:16:40,266: Train batch 44800: loss: 1.66 grad norm: 26.35 time: 0.092
2025-11-02 12:17:04,184: Train batch 45000: loss: 0.24 grad norm: 8.59 time: 0.069
2025-11-02 12:17:04,184: Running test after training batch: 45000
2025-11-02 12:17:18,221: Val batch 45000: PER (avg): 0.1763 CTC Loss (avg): 27.2008 time: 14.035
2025-11-02 12:17:18,221: t15.2023.08.13 val PER: 0.1185
2025-11-02 12:17:18,222: t15.2023.08.18 val PER: 0.1215
2025-11-02 12:17:18,222: t15.2023.08.20 val PER: 0.1199
2025-11-02 12:17:18,222: t15.2023.08.25 val PER: 0.1431
2025-11-02 12:17:18,222: t15.2023.08.27 val PER: 0.2010
2025-11-02 12:17:18,223: t15.2023.09.01 val PER: 0.0828
2025-11-02 12:17:18,223: t15.2023.09.03 val PER: 0.1781
2025-11-02 12:17:18,223: t15.2023.09.24 val PER: 0.1201
2025-11-02 12:17:18,224: t15.2023.09.29 val PER: 0.1378
2025-11-02 12:17:18,224: t15.2023.10.01 val PER: 0.1915
2025-11-02 12:17:18,224: t15.2023.10.06 val PER: 0.1141
2025-11-02 12:17:18,225: t15.2023.10.08 val PER: 0.2152
2025-11-02 12:17:18,226: t15.2023.10.13 val PER: 0.2242
2025-11-02 12:17:18,226: t15.2023.10.15 val PER: 0.1760
2025-11-02 12:17:18,226: t15.2023.10.20 val PER: 0.1980
2025-11-02 12:17:18,226: t15.2023.10.22 val PER: 0.1414
2025-11-02 12:17:18,227: t15.2023.11.03 val PER: 0.1913
2025-11-02 12:17:18,227: t15.2023.11.04 val PER: 0.0307
2025-11-02 12:17:18,227: t15.2023.11.17 val PER: 0.0607
2025-11-02 12:17:18,228: t15.2023.11.19 val PER: 0.0739
2025-11-02 12:17:18,228: t15.2023.11.26 val PER: 0.1558
2025-11-02 12:17:18,228: t15.2023.12.03 val PER: 0.1261
2025-11-02 12:17:18,228: t15.2023.12.08 val PER: 0.1332
2025-11-02 12:17:18,229: t15.2023.12.10 val PER: 0.1156
2025-11-02 12:17:18,229: t15.2023.12.17 val PER: 0.1840
2025-11-02 12:17:18,229: t15.2023.12.29 val PER: 0.1565
2025-11-02 12:17:18,230: t15.2024.02.25 val PER: 0.1362
2025-11-02 12:17:18,230: t15.2024.03.08 val PER: 0.2475
2025-11-02 12:17:18,231: t15.2024.03.15 val PER: 0.2489
2025-11-02 12:17:18,231: t15.2024.03.17 val PER: 0.1562
2025-11-02 12:17:18,231: t15.2024.05.10 val PER: 0.2006
2025-11-02 12:17:18,232: t15.2024.06.14 val PER: 0.2161
2025-11-02 12:17:18,232: t15.2024.07.19 val PER: 0.2584
2025-11-02 12:17:18,232: t15.2024.07.21 val PER: 0.1172
2025-11-02 12:17:18,232: t15.2024.07.28 val PER: 0.1699
2025-11-02 12:17:18,233: t15.2025.01.10 val PER: 0.3540
2025-11-02 12:17:18,233: t15.2025.01.12 val PER: 0.1917
2025-11-02 12:17:18,233: t15.2025.03.14 val PER: 0.3979
2025-11-02 12:17:18,234: t15.2025.03.16 val PER: 0.2448
2025-11-02 12:17:18,234: t15.2025.03.30 val PER: 0.3322
2025-11-02 12:17:18,234: t15.2025.04.13 val PER: 0.2839
2025-11-02 12:17:42,456: Train batch 45200: loss: 2.34 grad norm: 38.38 time: 0.060
2025-11-02 12:18:06,220: Train batch 45400: loss: 1.27 grad norm: 22.33 time: 0.071
2025-11-02 12:18:30,333: Train batch 45600: loss: 1.66 grad norm: 30.23 time: 0.091
2025-11-02 12:18:53,964: Train batch 45800: loss: 1.89 grad norm: 30.88 time: 0.060
2025-11-02 12:19:17,939: Train batch 46000: loss: 1.64 grad norm: 31.71 time: 0.089
2025-11-02 12:19:17,940: Running test after training batch: 46000
2025-11-02 12:19:32,423: Val batch 46000: PER (avg): 0.1771 CTC Loss (avg): 27.2211 time: 14.482
2025-11-02 12:19:32,424: t15.2023.08.13 val PER: 0.1268
2025-11-02 12:19:32,424: t15.2023.08.18 val PER: 0.1291
2025-11-02 12:19:32,424: t15.2023.08.20 val PER: 0.1183
2025-11-02 12:19:32,425: t15.2023.08.25 val PER: 0.1295
2025-11-02 12:19:32,425: t15.2023.08.27 val PER: 0.1994
2025-11-02 12:19:32,426: t15.2023.09.01 val PER: 0.0779
2025-11-02 12:19:32,426: t15.2023.09.03 val PER: 0.1865
2025-11-02 12:19:32,426: t15.2023.09.24 val PER: 0.1214
2025-11-02 12:19:32,427: t15.2023.09.29 val PER: 0.1461
2025-11-02 12:19:32,427: t15.2023.10.01 val PER: 0.1962
2025-11-02 12:19:32,430: t15.2023.10.06 val PER: 0.1130
2025-11-02 12:19:32,430: t15.2023.10.08 val PER: 0.2165
2025-11-02 12:19:32,431: t15.2023.10.13 val PER: 0.2219
2025-11-02 12:19:32,431: t15.2023.10.15 val PER: 0.1701
2025-11-02 12:19:32,431: t15.2023.10.20 val PER: 0.1980
2025-11-02 12:19:32,432: t15.2023.10.22 val PER: 0.1370
2025-11-02 12:19:32,432: t15.2023.11.03 val PER: 0.1900
2025-11-02 12:19:32,432: t15.2023.11.04 val PER: 0.0307
2025-11-02 12:19:32,433: t15.2023.11.17 val PER: 0.0544
2025-11-02 12:19:32,433: t15.2023.11.19 val PER: 0.0659
2025-11-02 12:19:32,433: t15.2023.11.26 val PER: 0.1522
2025-11-02 12:19:32,434: t15.2023.12.03 val PER: 0.1261
2025-11-02 12:19:32,434: t15.2023.12.08 val PER: 0.1385
2025-11-02 12:19:32,434: t15.2023.12.10 val PER: 0.1235
2025-11-02 12:19:32,434: t15.2023.12.17 val PER: 0.1913
2025-11-02 12:19:32,435: t15.2023.12.29 val PER: 0.1633
2025-11-02 12:19:32,435: t15.2024.02.25 val PER: 0.1320
2025-11-02 12:19:32,436: t15.2024.03.08 val PER: 0.2418
2025-11-02 12:19:32,436: t15.2024.03.15 val PER: 0.2502
2025-11-02 12:19:32,436: t15.2024.03.17 val PER: 0.1597
2025-11-02 12:19:32,436: t15.2024.05.10 val PER: 0.1902
2025-11-02 12:19:32,437: t15.2024.06.14 val PER: 0.2192
2025-11-02 12:19:32,437: t15.2024.07.19 val PER: 0.2657
2025-11-02 12:19:32,437: t15.2024.07.21 val PER: 0.1138
2025-11-02 12:19:32,438: t15.2024.07.28 val PER: 0.1676
2025-11-02 12:19:32,438: t15.2025.01.10 val PER: 0.3444
2025-11-02 12:19:32,438: t15.2025.01.12 val PER: 0.1824
2025-11-02 12:19:32,438: t15.2025.03.14 val PER: 0.3935
2025-11-02 12:19:32,439: t15.2025.03.16 val PER: 0.2565
2025-11-02 12:19:32,439: t15.2025.03.30 val PER: 0.3448
2025-11-02 12:19:32,439: t15.2025.04.13 val PER: 0.2967
2025-11-02 12:19:56,481: Train batch 46200: loss: 2.22 grad norm: 36.60 time: 0.104
2025-11-02 12:20:20,603: Train batch 46400: loss: 1.00 grad norm: 25.35 time: 0.110
2025-11-02 12:20:44,563: Train batch 46600: loss: 1.86 grad norm: 30.87 time: 0.071
2025-11-02 12:21:08,527: Train batch 46800: loss: 2.19 grad norm: 24.39 time: 0.069
2025-11-02 12:21:32,350: Train batch 47000: loss: 1.63 grad norm: 32.50 time: 0.063
2025-11-02 12:21:32,351: Running test after training batch: 47000
2025-11-02 12:21:47,631: Val batch 47000: PER (avg): 0.1775 CTC Loss (avg): 27.5207 time: 15.280
2025-11-02 12:21:47,632: t15.2023.08.13 val PER: 0.1247
2025-11-02 12:21:47,632: t15.2023.08.18 val PER: 0.1257
2025-11-02 12:21:47,633: t15.2023.08.20 val PER: 0.1183
2025-11-02 12:21:47,633: t15.2023.08.25 val PER: 0.1506
2025-11-02 12:21:47,634: t15.2023.08.27 val PER: 0.2042
2025-11-02 12:21:47,634: t15.2023.09.01 val PER: 0.0869
2025-11-02 12:21:47,635: t15.2023.09.03 val PER: 0.1805
2025-11-02 12:21:47,635: t15.2023.09.24 val PER: 0.1311
2025-11-02 12:21:47,636: t15.2023.09.29 val PER: 0.1449
2025-11-02 12:21:47,636: t15.2023.10.01 val PER: 0.1922
2025-11-02 12:21:47,637: t15.2023.10.06 val PER: 0.1098
2025-11-02 12:21:47,637: t15.2023.10.08 val PER: 0.2070
2025-11-02 12:21:47,684: t15.2023.10.13 val PER: 0.2258
2025-11-02 12:21:47,684: t15.2023.10.15 val PER: 0.1635
2025-11-02 12:21:47,685: t15.2023.10.20 val PER: 0.1913
2025-11-02 12:21:47,686: t15.2023.10.22 val PER: 0.1437
2025-11-02 12:21:47,686: t15.2023.11.03 val PER: 0.1927
2025-11-02 12:21:47,687: t15.2023.11.04 val PER: 0.0375
2025-11-02 12:21:47,688: t15.2023.11.17 val PER: 0.0638
2025-11-02 12:21:47,688: t15.2023.11.19 val PER: 0.0659
2025-11-02 12:21:47,688: t15.2023.11.26 val PER: 0.1551
2025-11-02 12:21:47,689: t15.2023.12.03 val PER: 0.1208
2025-11-02 12:21:47,689: t15.2023.12.08 val PER: 0.1451
2025-11-02 12:21:47,690: t15.2023.12.10 val PER: 0.1143
2025-11-02 12:21:47,690: t15.2023.12.17 val PER: 0.1913
2025-11-02 12:21:47,691: t15.2023.12.29 val PER: 0.1620
2025-11-02 12:21:47,691: t15.2024.02.25 val PER: 0.1362
2025-11-02 12:21:47,692: t15.2024.03.08 val PER: 0.2475
2025-11-02 12:21:47,692: t15.2024.03.15 val PER: 0.2477
2025-11-02 12:21:47,692: t15.2024.03.17 val PER: 0.1534
2025-11-02 12:21:47,693: t15.2024.05.10 val PER: 0.1947
2025-11-02 12:21:47,693: t15.2024.06.14 val PER: 0.2192
2025-11-02 12:21:47,694: t15.2024.07.19 val PER: 0.2676
2025-11-02 12:21:47,694: t15.2024.07.21 val PER: 0.1145
2025-11-02 12:21:47,694: t15.2024.07.28 val PER: 0.1706
2025-11-02 12:21:47,695: t15.2025.01.10 val PER: 0.3554
2025-11-02 12:21:47,695: t15.2025.01.12 val PER: 0.1925
2025-11-02 12:21:47,696: t15.2025.03.14 val PER: 0.3891
2025-11-02 12:21:47,696: t15.2025.03.16 val PER: 0.2369
2025-11-02 12:21:47,696: t15.2025.03.30 val PER: 0.3460
2025-11-02 12:21:47,696: t15.2025.04.13 val PER: 0.2853
2025-11-02 12:22:11,555: Train batch 47200: loss: 1.39 grad norm: 24.26 time: 0.089
2025-11-02 12:22:35,156: Train batch 47400: loss: 1.69 grad norm: 31.68 time: 0.061
2025-11-02 12:22:59,211: Train batch 47600: loss: 1.82 grad norm: 28.05 time: 0.069
2025-11-02 12:23:23,293: Train batch 47800: loss: 1.11 grad norm: 22.34 time: 0.072
2025-11-02 12:23:46,894: Train batch 48000: loss: 1.12 grad norm: 29.13 time: 0.103
2025-11-02 12:23:46,896: Running test after training batch: 48000
2025-11-02 12:24:01,439: Val batch 48000: PER (avg): 0.1756 CTC Loss (avg): 27.7681 time: 14.542
2025-11-02 12:24:01,439: t15.2023.08.13 val PER: 0.1216
2025-11-02 12:24:01,440: t15.2023.08.18 val PER: 0.1274
2025-11-02 12:24:01,441: t15.2023.08.20 val PER: 0.1255
2025-11-02 12:24:01,441: t15.2023.08.25 val PER: 0.1325
2025-11-02 12:24:01,441: t15.2023.08.27 val PER: 0.1994
2025-11-02 12:24:01,442: t15.2023.09.01 val PER: 0.0763
2025-11-02 12:24:01,442: t15.2023.09.03 val PER: 0.1829
2025-11-02 12:24:01,442: t15.2023.09.24 val PER: 0.1238
2025-11-02 12:24:01,443: t15.2023.09.29 val PER: 0.1442
2025-11-02 12:24:01,443: t15.2023.10.01 val PER: 0.1922
2025-11-02 12:24:01,484: t15.2023.10.06 val PER: 0.1087
2025-11-02 12:24:01,484: t15.2023.10.08 val PER: 0.2097
2025-11-02 12:24:01,485: t15.2023.10.13 val PER: 0.2211
2025-11-02 12:24:01,485: t15.2023.10.15 val PER: 0.1681
2025-11-02 12:24:01,485: t15.2023.10.20 val PER: 0.1980
2025-11-02 12:24:01,486: t15.2023.10.22 val PER: 0.1314
2025-11-02 12:24:01,486: t15.2023.11.03 val PER: 0.1906
2025-11-02 12:24:01,487: t15.2023.11.04 val PER: 0.0341
2025-11-02 12:24:01,487: t15.2023.11.17 val PER: 0.0544
2025-11-02 12:24:01,487: t15.2023.11.19 val PER: 0.0699
2025-11-02 12:24:01,487: t15.2023.11.26 val PER: 0.1558
2025-11-02 12:24:01,488: t15.2023.12.03 val PER: 0.1303
2025-11-02 12:24:01,488: t15.2023.12.08 val PER: 0.1391
2025-11-02 12:24:01,488: t15.2023.12.10 val PER: 0.1117
2025-11-02 12:24:01,489: t15.2023.12.17 val PER: 0.1840
2025-11-02 12:24:01,489: t15.2023.12.29 val PER: 0.1606
2025-11-02 12:24:01,489: t15.2024.02.25 val PER: 0.1348
2025-11-02 12:24:01,490: t15.2024.03.08 val PER: 0.2504
2025-11-02 12:24:01,490: t15.2024.03.15 val PER: 0.2433
2025-11-02 12:24:01,491: t15.2024.03.17 val PER: 0.1534
2025-11-02 12:24:01,491: t15.2024.05.10 val PER: 0.1961
2025-11-02 12:24:01,491: t15.2024.06.14 val PER: 0.2224
2025-11-02 12:24:01,492: t15.2024.07.19 val PER: 0.2637
2025-11-02 12:24:01,492: t15.2024.07.21 val PER: 0.1241
2025-11-02 12:24:01,492: t15.2024.07.28 val PER: 0.1691
2025-11-02 12:24:01,493: t15.2025.01.10 val PER: 0.3430
2025-11-02 12:24:01,493: t15.2025.01.12 val PER: 0.1863
2025-11-02 12:24:01,493: t15.2025.03.14 val PER: 0.3817
2025-11-02 12:24:01,493: t15.2025.03.16 val PER: 0.2448
2025-11-02 12:24:01,494: t15.2025.03.30 val PER: 0.3287
2025-11-02 12:24:01,494: t15.2025.04.13 val PER: 0.2839
2025-11-02 12:24:25,580: Train batch 48200: loss: 1.02 grad norm: 21.18 time: 0.114
2025-11-02 12:24:49,501: Train batch 48400: loss: 1.39 grad norm: 27.49 time: 0.100
2025-11-02 12:25:14,467: Train batch 48600: loss: 1.57 grad norm: 31.08 time: 0.074
2025-11-02 12:25:38,815: Train batch 48800: loss: 0.95 grad norm: 23.17 time: 0.075
2025-11-02 12:26:04,274: Train batch 49000: loss: 2.27 grad norm: 40.76 time: 0.095
2025-11-02 12:26:04,275: Running test after training batch: 49000
2025-11-02 12:26:19,022: Val batch 49000: PER (avg): 0.1785 CTC Loss (avg): 28.2367 time: 14.746
2025-11-02 12:26:19,023: t15.2023.08.13 val PER: 0.1227
2025-11-02 12:26:19,024: t15.2023.08.18 val PER: 0.1350
2025-11-02 12:26:19,024: t15.2023.08.20 val PER: 0.1263
2025-11-02 12:26:19,024: t15.2023.08.25 val PER: 0.1340
2025-11-02 12:26:19,025: t15.2023.08.27 val PER: 0.2058
2025-11-02 12:26:19,026: t15.2023.09.01 val PER: 0.0828
2025-11-02 12:26:19,026: t15.2023.09.03 val PER: 0.1841
2025-11-02 12:26:19,026: t15.2023.09.24 val PER: 0.1238
2025-11-02 12:26:19,027: t15.2023.09.29 val PER: 0.1481
2025-11-02 12:26:19,027: t15.2023.10.01 val PER: 0.1922
2025-11-02 12:26:19,027: t15.2023.10.06 val PER: 0.1152
2025-11-02 12:26:19,028: t15.2023.10.08 val PER: 0.2124
2025-11-02 12:26:19,028: t15.2023.10.13 val PER: 0.2273
2025-11-02 12:26:19,028: t15.2023.10.15 val PER: 0.1753
2025-11-02 12:26:19,028: t15.2023.10.20 val PER: 0.1812
2025-11-02 12:26:19,029: t15.2023.10.22 val PER: 0.1359
2025-11-02 12:26:19,029: t15.2023.11.03 val PER: 0.1967
2025-11-02 12:26:19,029: t15.2023.11.04 val PER: 0.0341
2025-11-02 12:26:19,030: t15.2023.11.17 val PER: 0.0575
2025-11-02 12:26:19,030: t15.2023.11.19 val PER: 0.0659
2025-11-02 12:26:19,031: t15.2023.11.26 val PER: 0.1638
2025-11-02 12:26:19,031: t15.2023.12.03 val PER: 0.1229
2025-11-02 12:26:19,031: t15.2023.12.08 val PER: 0.1418
2025-11-02 12:26:19,032: t15.2023.12.10 val PER: 0.1156
2025-11-02 12:26:19,032: t15.2023.12.17 val PER: 0.1892
2025-11-02 12:26:19,032: t15.2023.12.29 val PER: 0.1606
2025-11-02 12:26:19,032: t15.2024.02.25 val PER: 0.1419
2025-11-02 12:26:19,033: t15.2024.03.08 val PER: 0.2518
2025-11-02 12:26:19,033: t15.2024.03.15 val PER: 0.2545
2025-11-02 12:26:19,033: t15.2024.03.17 val PER: 0.1569
2025-11-02 12:26:19,034: t15.2024.05.10 val PER: 0.1976
2025-11-02 12:26:19,034: t15.2024.06.14 val PER: 0.2303
2025-11-02 12:26:19,034: t15.2024.07.19 val PER: 0.2597
2025-11-02 12:26:19,035: t15.2024.07.21 val PER: 0.1241
2025-11-02 12:26:19,035: t15.2024.07.28 val PER: 0.1691
2025-11-02 12:26:19,035: t15.2025.01.10 val PER: 0.3540
2025-11-02 12:26:19,036: t15.2025.01.12 val PER: 0.1855
2025-11-02 12:26:19,036: t15.2025.03.14 val PER: 0.3891
2025-11-02 12:26:19,036: t15.2025.03.16 val PER: 0.2421
2025-11-02 12:26:19,037: t15.2025.03.30 val PER: 0.3230
2025-11-02 12:26:19,037: t15.2025.04.13 val PER: 0.2882
2025-11-02 12:26:43,787: Train batch 49200: loss: 1.64 grad norm: 34.35 time: 0.118
2025-11-02 12:27:08,921: Train batch 49400: loss: 1.48 grad norm: 30.66 time: 0.076
2025-11-02 12:27:33,439: Train batch 49600: loss: 1.24 grad norm: 29.94 time: 0.122
2025-11-02 12:27:57,814: Train batch 49800: loss: 2.00 grad norm: 38.66 time: 0.099
2025-11-02 12:28:21,838: Train batch 50000: loss: 3.77 grad norm: 36.60 time: 0.088
2025-11-02 12:28:21,839: Running test after training batch: 50000
2025-11-02 12:28:35,917: Val batch 50000: PER (avg): 0.1772 CTC Loss (avg): 27.9785 time: 14.078
2025-11-02 12:28:35,917: t15.2023.08.13 val PER: 0.1247
2025-11-02 12:28:35,918: t15.2023.08.18 val PER: 0.1333
2025-11-02 12:28:35,918: t15.2023.08.20 val PER: 0.1207
2025-11-02 12:28:35,919: t15.2023.08.25 val PER: 0.1370
2025-11-02 12:28:35,919: t15.2023.08.27 val PER: 0.1977
2025-11-02 12:28:35,919: t15.2023.09.01 val PER: 0.0877
2025-11-02 12:28:35,920: t15.2023.09.03 val PER: 0.1758
2025-11-02 12:28:35,920: t15.2023.09.24 val PER: 0.1274
2025-11-02 12:28:35,921: t15.2023.09.29 val PER: 0.1449
2025-11-02 12:28:35,921: t15.2023.10.01 val PER: 0.1896
2025-11-02 12:28:35,922: t15.2023.10.06 val PER: 0.1195
2025-11-02 12:28:35,922: t15.2023.10.08 val PER: 0.2219
2025-11-02 12:28:35,922: t15.2023.10.13 val PER: 0.2219
2025-11-02 12:28:35,923: t15.2023.10.15 val PER: 0.1694
2025-11-02 12:28:35,923: t15.2023.10.20 val PER: 0.1879
2025-11-02 12:28:35,923: t15.2023.10.22 val PER: 0.1403
2025-11-02 12:28:35,924: t15.2023.11.03 val PER: 0.1940
2025-11-02 12:28:35,924: t15.2023.11.04 val PER: 0.0273
2025-11-02 12:28:35,924: t15.2023.11.17 val PER: 0.0607
2025-11-02 12:28:35,925: t15.2023.11.19 val PER: 0.0778
2025-11-02 12:28:35,925: t15.2023.11.26 val PER: 0.1594
2025-11-02 12:28:35,926: t15.2023.12.03 val PER: 0.1229
2025-11-02 12:28:35,926: t15.2023.12.08 val PER: 0.1385
2025-11-02 12:28:35,926: t15.2023.12.10 val PER: 0.1209
2025-11-02 12:28:35,927: t15.2023.12.17 val PER: 0.1944
2025-11-02 12:28:35,927: t15.2023.12.29 val PER: 0.1627
2025-11-02 12:28:35,927: t15.2024.02.25 val PER: 0.1334
2025-11-02 12:28:35,928: t15.2024.03.08 val PER: 0.2418
2025-11-02 12:28:35,928: t15.2024.03.15 val PER: 0.2395
2025-11-02 12:28:35,928: t15.2024.03.17 val PER: 0.1534
2025-11-02 12:28:35,928: t15.2024.05.10 val PER: 0.1902
2025-11-02 12:28:35,929: t15.2024.06.14 val PER: 0.2303
2025-11-02 12:28:35,929: t15.2024.07.19 val PER: 0.2558
2025-11-02 12:28:35,929: t15.2024.07.21 val PER: 0.1283
2025-11-02 12:28:35,930: t15.2024.07.28 val PER: 0.1721
2025-11-02 12:28:35,930: t15.2025.01.10 val PER: 0.3471
2025-11-02 12:28:35,931: t15.2025.01.12 val PER: 0.1886
2025-11-02 12:28:35,931: t15.2025.03.14 val PER: 0.3935
2025-11-02 12:28:35,931: t15.2025.03.16 val PER: 0.2448
2025-11-02 12:28:35,932: t15.2025.03.30 val PER: 0.3230
2025-11-02 12:28:35,932: t15.2025.04.13 val PER: 0.2867
2025-11-02 12:28:59,662: Train batch 50200: loss: 1.13 grad norm: 25.61 time: 0.079
2025-11-02 12:29:24,269: Train batch 50400: loss: 1.03 grad norm: 28.12 time: 0.073
2025-11-02 12:29:48,047: Train batch 50600: loss: 0.93 grad norm: 20.16 time: 0.106
2025-11-02 12:30:12,102: Train batch 50800: loss: 1.32 grad norm: 30.79 time: 0.073
2025-11-02 12:30:36,180: Train batch 51000: loss: 0.89 grad norm: 29.24 time: 0.065
2025-11-02 12:30:36,181: Running test after training batch: 51000
2025-11-02 12:30:50,827: Val batch 51000: PER (avg): 0.1755 CTC Loss (avg): 28.2180 time: 14.646
2025-11-02 12:30:50,828: t15.2023.08.13 val PER: 0.1268
2025-11-02 12:30:50,828: t15.2023.08.18 val PER: 0.1199
2025-11-02 12:30:50,828: t15.2023.08.20 val PER: 0.1199
2025-11-02 12:30:50,829: t15.2023.08.25 val PER: 0.1325
2025-11-02 12:30:50,829: t15.2023.08.27 val PER: 0.1945
2025-11-02 12:30:50,830: t15.2023.09.01 val PER: 0.0852
2025-11-02 12:30:50,830: t15.2023.09.03 val PER: 0.1746
2025-11-02 12:30:50,830: t15.2023.09.24 val PER: 0.1238
2025-11-02 12:30:50,831: t15.2023.09.29 val PER: 0.1455
2025-11-02 12:30:50,831: t15.2023.10.01 val PER: 0.1915
2025-11-02 12:30:50,831: t15.2023.10.06 val PER: 0.1119
2025-11-02 12:30:50,831: t15.2023.10.08 val PER: 0.2233
2025-11-02 12:30:50,832: t15.2023.10.13 val PER: 0.2180
2025-11-02 12:30:50,832: t15.2023.10.15 val PER: 0.1628
2025-11-02 12:30:50,832: t15.2023.10.20 val PER: 0.1846
2025-11-02 12:30:50,833: t15.2023.10.22 val PER: 0.1448
2025-11-02 12:30:50,833: t15.2023.11.03 val PER: 0.1879
2025-11-02 12:30:50,833: t15.2023.11.04 val PER: 0.0410
2025-11-02 12:30:50,834: t15.2023.11.17 val PER: 0.0498
2025-11-02 12:30:50,834: t15.2023.11.19 val PER: 0.0778
2025-11-02 12:30:50,834: t15.2023.11.26 val PER: 0.1565
2025-11-02 12:30:50,884: t15.2023.12.03 val PER: 0.1229
2025-11-02 12:30:50,884: t15.2023.12.08 val PER: 0.1478
2025-11-02 12:30:50,885: t15.2023.12.10 val PER: 0.1196
2025-11-02 12:30:50,885: t15.2023.12.17 val PER: 0.1871
2025-11-02 12:30:50,886: t15.2023.12.29 val PER: 0.1558
2025-11-02 12:30:50,886: t15.2024.02.25 val PER: 0.1320
2025-11-02 12:30:50,886: t15.2024.03.08 val PER: 0.2461
2025-11-02 12:30:50,887: t15.2024.03.15 val PER: 0.2452
2025-11-02 12:30:50,887: t15.2024.03.17 val PER: 0.1548
2025-11-02 12:30:50,887: t15.2024.05.10 val PER: 0.1857
2025-11-02 12:30:50,888: t15.2024.06.14 val PER: 0.2208
2025-11-02 12:30:50,888: t15.2024.07.19 val PER: 0.2650
2025-11-02 12:30:50,888: t15.2024.07.21 val PER: 0.1172
2025-11-02 12:30:50,889: t15.2024.07.28 val PER: 0.1640
2025-11-02 12:30:50,889: t15.2025.01.10 val PER: 0.3512
2025-11-02 12:30:50,890: t15.2025.01.12 val PER: 0.1840
2025-11-02 12:30:50,890: t15.2025.03.14 val PER: 0.3861
2025-11-02 12:30:50,891: t15.2025.03.16 val PER: 0.2500
2025-11-02 12:30:50,891: t15.2025.03.30 val PER: 0.3253
2025-11-02 12:30:50,891: t15.2025.04.13 val PER: 0.2867
2025-11-02 12:31:15,387: Train batch 51200: loss: 0.90 grad norm: 21.61 time: 0.087
2025-11-02 12:31:39,212: Train batch 51400: loss: 0.67 grad norm: 19.60 time: 0.064
2025-11-02 12:32:03,073: Train batch 51600: loss: 1.08 grad norm: 20.15 time: 0.091
2025-11-02 12:32:27,703: Train batch 51800: loss: 0.88 grad norm: 18.77 time: 0.067
2025-11-02 12:32:52,357: Train batch 52000: loss: 1.16 grad norm: 25.47 time: 0.065
2025-11-02 12:32:52,358: Running test after training batch: 52000
2025-11-02 12:33:07,121: Val batch 52000: PER (avg): 0.1774 CTC Loss (avg): 28.7645 time: 14.763
2025-11-02 12:33:07,121: t15.2023.08.13 val PER: 0.1206
2025-11-02 12:33:07,122: t15.2023.08.18 val PER: 0.1266
2025-11-02 12:33:07,122: t15.2023.08.20 val PER: 0.1152
2025-11-02 12:33:07,122: t15.2023.08.25 val PER: 0.1416
2025-11-02 12:33:07,123: t15.2023.08.27 val PER: 0.1994
2025-11-02 12:33:07,123: t15.2023.09.01 val PER: 0.0828
2025-11-02 12:33:07,123: t15.2023.09.03 val PER: 0.1841
2025-11-02 12:33:07,124: t15.2023.09.24 val PER: 0.1299
2025-11-02 12:33:07,124: t15.2023.09.29 val PER: 0.1455
2025-11-02 12:33:07,124: t15.2023.10.01 val PER: 0.1968
2025-11-02 12:33:07,125: t15.2023.10.06 val PER: 0.1119
2025-11-02 12:33:07,125: t15.2023.10.08 val PER: 0.2070
2025-11-02 12:33:07,126: t15.2023.10.13 val PER: 0.2258
2025-11-02 12:33:07,126: t15.2023.10.15 val PER: 0.1714
2025-11-02 12:33:07,126: t15.2023.10.20 val PER: 0.2047
2025-11-02 12:33:07,126: t15.2023.10.22 val PER: 0.1347
2025-11-02 12:33:07,127: t15.2023.11.03 val PER: 0.2008
2025-11-02 12:33:07,127: t15.2023.11.04 val PER: 0.0375
2025-11-02 12:33:07,127: t15.2023.11.17 val PER: 0.0513
2025-11-02 12:33:07,127: t15.2023.11.19 val PER: 0.0858
2025-11-02 12:33:07,128: t15.2023.11.26 val PER: 0.1500
2025-11-02 12:33:07,128: t15.2023.12.03 val PER: 0.1303
2025-11-02 12:33:07,128: t15.2023.12.08 val PER: 0.1418
2025-11-02 12:33:07,129: t15.2023.12.10 val PER: 0.1196
2025-11-02 12:33:07,129: t15.2023.12.17 val PER: 0.1975
2025-11-02 12:33:07,129: t15.2023.12.29 val PER: 0.1489
2025-11-02 12:33:07,129: t15.2024.02.25 val PER: 0.1503
2025-11-02 12:33:07,130: t15.2024.03.08 val PER: 0.2432
2025-11-02 12:33:07,130: t15.2024.03.15 val PER: 0.2427
2025-11-02 12:33:07,131: t15.2024.03.17 val PER: 0.1555
2025-11-02 12:33:07,131: t15.2024.05.10 val PER: 0.1902
2025-11-02 12:33:07,131: t15.2024.06.14 val PER: 0.2129
2025-11-02 12:33:07,131: t15.2024.07.19 val PER: 0.2637
2025-11-02 12:33:07,132: t15.2024.07.21 val PER: 0.1207
2025-11-02 12:33:07,132: t15.2024.07.28 val PER: 0.1699
2025-11-02 12:33:07,132: t15.2025.01.10 val PER: 0.3471
2025-11-02 12:33:07,133: t15.2025.01.12 val PER: 0.1878
2025-11-02 12:33:07,133: t15.2025.03.14 val PER: 0.4127
2025-11-02 12:33:07,133: t15.2025.03.16 val PER: 0.2356
2025-11-02 12:33:07,133: t15.2025.03.30 val PER: 0.3310
2025-11-02 12:33:07,134: t15.2025.04.13 val PER: 0.2981
2025-11-02 12:33:31,498: Train batch 52200: loss: 0.94 grad norm: 23.86 time: 0.097
2025-11-02 12:33:55,360: Train batch 52400: loss: 0.55 grad norm: 13.86 time: 0.110
2025-11-02 12:34:19,241: Train batch 52600: loss: 0.66 grad norm: 17.62 time: 0.095
2025-11-02 12:34:43,187: Train batch 52800: loss: 1.33 grad norm: 28.39 time: 0.091
2025-11-02 12:35:06,776: Train batch 53000: loss: 1.76 grad norm: 37.97 time: 0.099
2025-11-02 12:35:06,777: Running test after training batch: 53000
2025-11-02 12:35:21,120: Val batch 53000: PER (avg): 0.1765 CTC Loss (avg): 29.2457 time: 14.344
2025-11-02 12:35:21,121: t15.2023.08.13 val PER: 0.1237
2025-11-02 12:35:21,122: t15.2023.08.18 val PER: 0.1366
2025-11-02 12:35:21,122: t15.2023.08.20 val PER: 0.1136
2025-11-02 12:35:21,122: t15.2023.08.25 val PER: 0.1355
2025-11-02 12:35:21,123: t15.2023.08.27 val PER: 0.2026
2025-11-02 12:35:21,123: t15.2023.09.01 val PER: 0.0836
2025-11-02 12:35:21,123: t15.2023.09.03 val PER: 0.1829
2025-11-02 12:35:21,124: t15.2023.09.24 val PER: 0.1214
2025-11-02 12:35:21,124: t15.2023.09.29 val PER: 0.1436
2025-11-02 12:35:21,124: t15.2023.10.01 val PER: 0.2008
2025-11-02 12:35:21,125: t15.2023.10.06 val PER: 0.1098
2025-11-02 12:35:21,125: t15.2023.10.08 val PER: 0.2097
2025-11-02 12:35:21,126: t15.2023.10.13 val PER: 0.2211
2025-11-02 12:35:21,126: t15.2023.10.15 val PER: 0.1701
2025-11-02 12:35:21,126: t15.2023.10.20 val PER: 0.2047
2025-11-02 12:35:21,127: t15.2023.10.22 val PER: 0.1303
2025-11-02 12:35:21,127: t15.2023.11.03 val PER: 0.1913
2025-11-02 12:35:21,127: t15.2023.11.04 val PER: 0.0341
2025-11-02 12:35:21,127: t15.2023.11.17 val PER: 0.0591
2025-11-02 12:35:21,128: t15.2023.11.19 val PER: 0.0719
2025-11-02 12:35:21,128: t15.2023.11.26 val PER: 0.1507
2025-11-02 12:35:21,128: t15.2023.12.03 val PER: 0.1303
2025-11-02 12:35:21,129: t15.2023.12.08 val PER: 0.1278
2025-11-02 12:35:21,129: t15.2023.12.10 val PER: 0.1143
2025-11-02 12:35:21,129: t15.2023.12.17 val PER: 0.1975
2025-11-02 12:35:21,130: t15.2023.12.29 val PER: 0.1579
2025-11-02 12:35:21,130: t15.2024.02.25 val PER: 0.1362
2025-11-02 12:35:21,131: t15.2024.03.08 val PER: 0.2646
2025-11-02 12:35:21,131: t15.2024.03.15 val PER: 0.2458
2025-11-02 12:35:21,131: t15.2024.03.17 val PER: 0.1527
2025-11-02 12:35:21,132: t15.2024.05.10 val PER: 0.1857
2025-11-02 12:35:21,132: t15.2024.06.14 val PER: 0.2224
2025-11-02 12:35:21,132: t15.2024.07.19 val PER: 0.2584
2025-11-02 12:35:21,133: t15.2024.07.21 val PER: 0.1241
2025-11-02 12:35:21,133: t15.2024.07.28 val PER: 0.1691
2025-11-02 12:35:21,133: t15.2025.01.10 val PER: 0.3444
2025-11-02 12:35:21,133: t15.2025.01.12 val PER: 0.1878
2025-11-02 12:35:21,134: t15.2025.03.14 val PER: 0.4053
2025-11-02 12:35:21,134: t15.2025.03.16 val PER: 0.2448
2025-11-02 12:35:21,134: t15.2025.03.30 val PER: 0.3230
2025-11-02 12:35:21,135: t15.2025.04.13 val PER: 0.2924
2025-11-02 12:35:45,386: Train batch 53200: loss: 0.51 grad norm: 11.95 time: 0.071
2025-11-02 12:36:09,983: Train batch 53400: loss: 1.38 grad norm: 27.82 time: 0.073
2025-11-02 12:36:33,915: Train batch 53600: loss: 0.69 grad norm: 21.60 time: 0.061
2025-11-02 12:36:57,504: Train batch 53800: loss: 0.93 grad norm: 25.74 time: 0.071
2025-11-02 12:37:20,635: Train batch 54000: loss: 1.61 grad norm: 30.89 time: 0.088
2025-11-02 12:37:20,636: Running test after training batch: 54000
2025-11-02 12:37:34,919: Val batch 54000: PER (avg): 0.1783 CTC Loss (avg): 29.0400 time: 14.282
2025-11-02 12:37:34,919: t15.2023.08.13 val PER: 0.1268
2025-11-02 12:37:34,920: t15.2023.08.18 val PER: 0.1324
2025-11-02 12:37:34,921: t15.2023.08.20 val PER: 0.1215
2025-11-02 12:37:34,921: t15.2023.08.25 val PER: 0.1250
2025-11-02 12:37:34,922: t15.2023.08.27 val PER: 0.1929
2025-11-02 12:37:34,922: t15.2023.09.01 val PER: 0.0763
2025-11-02 12:37:34,922: t15.2023.09.03 val PER: 0.1805
2025-11-02 12:37:34,923: t15.2023.09.24 val PER: 0.1323
2025-11-02 12:37:34,923: t15.2023.09.29 val PER: 0.1461
2025-11-02 12:37:34,923: t15.2023.10.01 val PER: 0.1902
2025-11-02 12:37:34,924: t15.2023.10.06 val PER: 0.1163
2025-11-02 12:37:34,924: t15.2023.10.08 val PER: 0.2124
2025-11-02 12:37:34,924: t15.2023.10.13 val PER: 0.2203
2025-11-02 12:37:34,925: t15.2023.10.15 val PER: 0.1727
2025-11-02 12:37:34,925: t15.2023.10.20 val PER: 0.1913
2025-11-02 12:37:34,926: t15.2023.10.22 val PER: 0.1514
2025-11-02 12:37:34,926: t15.2023.11.03 val PER: 0.1954
2025-11-02 12:37:34,926: t15.2023.11.04 val PER: 0.0273
2025-11-02 12:37:34,927: t15.2023.11.17 val PER: 0.0622
2025-11-02 12:37:34,927: t15.2023.11.19 val PER: 0.0758
2025-11-02 12:37:34,928: t15.2023.11.26 val PER: 0.1601
2025-11-02 12:37:34,928: t15.2023.12.03 val PER: 0.1239
2025-11-02 12:37:34,928: t15.2023.12.08 val PER: 0.1445
2025-11-02 12:37:34,929: t15.2023.12.10 val PER: 0.1143
2025-11-02 12:37:34,929: t15.2023.12.17 val PER: 0.1933
2025-11-02 12:37:34,929: t15.2023.12.29 val PER: 0.1592
2025-11-02 12:37:34,930: t15.2024.02.25 val PER: 0.1404
2025-11-02 12:37:34,930: t15.2024.03.08 val PER: 0.2504
2025-11-02 12:37:34,931: t15.2024.03.15 val PER: 0.2458
2025-11-02 12:37:34,931: t15.2024.03.17 val PER: 0.1541
2025-11-02 12:37:34,931: t15.2024.05.10 val PER: 0.1902
2025-11-02 12:37:34,932: t15.2024.06.14 val PER: 0.2177
2025-11-02 12:37:34,932: t15.2024.07.19 val PER: 0.2703
2025-11-02 12:37:34,932: t15.2024.07.21 val PER: 0.1221
2025-11-02 12:37:34,933: t15.2024.07.28 val PER: 0.1699
2025-11-02 12:37:34,933: t15.2025.01.10 val PER: 0.3347
2025-11-02 12:37:34,933: t15.2025.01.12 val PER: 0.1871
2025-11-02 12:37:34,934: t15.2025.03.14 val PER: 0.4157
2025-11-02 12:37:34,934: t15.2025.03.16 val PER: 0.2579
2025-11-02 12:37:34,934: t15.2025.03.30 val PER: 0.3333
2025-11-02 12:37:34,935: t15.2025.04.13 val PER: 0.2910
2025-11-02 12:37:34,936: Overall validation PER has not improved in 10 validation steps. Stopping training early at batch: 54000
2025-11-02 12:37:35,023: Best avg val PER achieved: 0.17462
2025-11-02 12:37:35,023: Total training time: 127.12 minutes
2025-11-02 12:37:36,735: Saved model to checkpoint: trained_models/baseline_rnn/checkpoint/final_checkpoint_batch_54000
